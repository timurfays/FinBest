[2025-05-08T19:39:21.477+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-08T19:39:13.814354+00:00 [queued]>
[2025-05-08T19:39:21.482+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-08T19:39:13.814354+00:00 [queued]>
[2025-05-08T19:39:21.482+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2025-05-08T19:39:21.492+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-08 19:39:13.814354+00:00
[2025-05-08T19:39:21.496+0000] {standard_task_runner.py:57} INFO - Started process 13016 to run task
[2025-05-08T19:39:21.498+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-08T19:39:13.814354+00:00', '--job-id', '356', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmpsa3_1vlr']
[2025-05-08T19:39:21.498+0000] {standard_task_runner.py:85} INFO - Job 356: Subtask build_graph
[2025-05-08T19:39:21.510+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-08T19:39:21.536+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-08T19:39:13.814354+00:00 [running]> on host f2a432e4376a
[2025-05-08T19:39:21.603+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T19:39:13.814354+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-08T19:39:13.814354+00:00'
[2025-05-08T19:39:21.611+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-08T19:39:21.611+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-08T19:39:21.626+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-08T19:39:22.517+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-08T19:39:22.589+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-08T19:39:22.590+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-08T19:39:22.590+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-08T19:39:22.590+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-08T19:39:22.590+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-08T19:39:22.623+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-08T19:39:22.624+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - jars                    null
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-08T19:39:22.625+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-08T19:39:22.626+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:39:22.626+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:39:22.728+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-08T19:39:22.821+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-08T19:39:22.821+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-08T19:39:22.826+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-08T19:39:22.826+0000] {spark_submit.py:571} INFO - graphframes#graphframes added as a dependency
[2025-05-08T19:39:22.827+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-49037b0a-ecc2-42ec-b771-9ba9b9d1f5b8;1.0
[2025-05-08T19:39:22.827+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-08T19:39:22.931+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-08T19:39:22.955+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-08T19:39:22.975+0000] {spark_submit.py:571} INFO - found graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages
[2025-05-08T19:39:22.998+0000] {spark_submit.py:571} INFO - found org.slf4j#slf4j-api;1.7.16 in central
[2025-05-08T19:39:23.019+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 182ms :: artifacts dl 9ms
[2025-05-08T19:39:23.020+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-08T19:39:23.020+0000] {spark_submit.py:571} INFO - graphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]
[2025-05-08T19:39:23.020+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-08T19:39:23.020+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-08T19:39:23.020+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.16 from central in [default]
[2025-05-08T19:39:23.021+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-08T19:39:23.021+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-08T19:39:23.021+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-08T19:39:23.021+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-08T19:39:23.021+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-05-08T19:39:23.021+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-08T19:39:23.025+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-49037b0a-ecc2-42ec-b771-9ba9b9d1f5b8
[2025-05-08T19:39:23.025+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-08T19:39:23.031+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/6ms)
[2025-05-08T19:39:23.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-08T19:39:23.444+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - --user
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - finbest
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - --password
[2025-05-08T19:39:23.445+0000] {spark_submit.py:571} INFO - ***
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,/home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-08T19:39:23.447+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-08T19:39:23.448+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-08T19:39:23.448+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-08T19:39:23.448+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-08T19:39:23.448+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:39:23.448+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:39:24.616+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-08T19:39:24.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SparkContext: Running Spark version 3.2.4
[2025-05-08T19:39:24.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO ResourceUtils: ==============================================================
[2025-05-08T19:39:24.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-08T19:39:24.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO ResourceUtils: ==============================================================
[2025-05-08T19:39:24.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-08T19:39:24.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-08T19:39:24.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-08T19:39:24.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-08T19:39:24.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SecurityManager: Changing view acls to: airflow
[2025-05-08T19:39:24.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-08T19:39:24.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SecurityManager: Changing view acls groups to:
[2025-05-08T19:39:24.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SecurityManager: Changing modify acls groups to:
[2025-05-08T19:39:24.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-08T19:39:24.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO Utils: Successfully started service 'sparkDriver' on port 42351.
[2025-05-08T19:39:24.970+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SparkEnv: Registering MapOutputTracker
[2025-05-08T19:39:24.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:24 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-08T19:39:25.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-08T19:39:25.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-08T19:39:25.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-08T19:39:25.040+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3f978e3b-cc20-4e10-967d-0bfac62afc02
[2025-05-08T19:39:25.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-08T19:39:25.082+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-08T19:39:25.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-08T19:39:25.264+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://f2a432e4376a:4040
[2025-05-08T19:39:25.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://f2a432e4376a:42351/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746733164614
[2025-05-08T19:39:25.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://f2a432e4376a:42351/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746733164614
[2025-05-08T19:39:25.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://f2a432e4376a:42351/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746733164614
[2025-05-08T19:39:25.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://f2a432e4376a:42351/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746733164614
[2025-05-08T19:39:25.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://f2a432e4376a:42351/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746733164614
[2025-05-08T19:39:25.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-b365f90a-d489-4d1d-b661-04514a948913/userFiles-372e1289-15bc-4d28-bad7-c3e94a9fc4da/org.postgresql_postgresql-42.6.0.jar
[2025-05-08T19:39:25.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://f2a432e4376a:42351/files/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746733164614
[2025-05-08T19:39:25.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO Utils: Copying /home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar to /tmp/spark-b365f90a-d489-4d1d-b661-04514a948913/userFiles-372e1289-15bc-4d28-bad7-c3e94a9fc4da/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-08T19:39:25.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://f2a432e4376a:42351/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746733164614
[2025-05-08T19:39:25.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-b365f90a-d489-4d1d-b661-04514a948913/userFiles-372e1289-15bc-4d28-bad7-c3e94a9fc4da/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-08T19:39:25.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://f2a432e4376a:42351/files/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746733164614
[2025-05-08T19:39:25.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO Utils: Copying /home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-b365f90a-d489-4d1d-b661-04514a948913/userFiles-372e1289-15bc-4d28-bad7-c3e94a9fc4da/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-08T19:39:25.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-08T19:39:25.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.3:7077 after 21 ms (0 ms spent in bootstraps)
[2025-05-08T19:39:25.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250508193925-0005
[2025-05-08T19:39:25.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250508193925-0005/0 on worker-20250508061515-172.20.0.5-45383 (172.20.0.5:45383) with 1 core(s)
[2025-05-08T19:39:25.530+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20250508193925-0005/0 on hostPort 172.20.0.5:45383 with 1 core(s), 1024.0 MiB RAM
[2025-05-08T19:39:25.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35283.
[2025-05-08T19:39:25.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO NettyBlockTransferService: Server created on f2a432e4376a:35283
[2025-05-08T19:39:25.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-08T19:39:25.541+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f2a432e4376a, 35283, None)
[2025-05-08T19:39:25.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO BlockManagerMasterEndpoint: Registering block manager f2a432e4376a:35283 with 434.4 MiB RAM, BlockManagerId(driver, f2a432e4376a, 35283, None)
[2025-05-08T19:39:25.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f2a432e4376a, 35283, None)
[2025-05-08T19:39:25.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f2a432e4376a, 35283, None)
[2025-05-08T19:39:25.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/0 is now RUNNING
[2025-05-08T19:39:25.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-08T19:39:25.875+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-08T19:39:25.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:25 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-08T19:39:26.604+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:26,603 [INFO] SparkSession создана
[2025-05-08T19:39:26.605+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:26,604 [INFO] Загружаем клиентов и транзакции
[2025-05-08T19:39:27.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:59376) with ID 0,  ResourceProfileId 0
[2025-05-08T19:39:28.023+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:28 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:37427 with 434.4 MiB RAM, BlockManagerId(0, 172.20.0.5, 37427, None)
[2025-05-08T19:39:29.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO CodeGenerator: Code generated in 97.330332 ms
[2025-05-08T19:39:29.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-08T19:39:29.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T19:39:29.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T19:39:29.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:29.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:29.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T19:39:29.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-08T19:39:29.393+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-08T19:39:29.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on f2a432e4376a:35283 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:29.398+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:29.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:29.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-08T19:39:29.436+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:29.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.5:37427 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.477+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1048 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:30.478+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-08T19:39:30.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.192 s
[2025-05-08T19:39:30.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:30.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:30.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:30.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:30.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO CodeGenerator: Code generated in 12.908056 ms
[2025-05-08T19:39:30.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-08T19:39:30.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T19:39:30.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T19:39:30.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-08T19:39:30.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:30.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T19:39:30.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-08T19:39:30.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-08T19:39:30.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on f2a432e4376a:35283 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:30.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:30.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-08T19:39:30.583+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:30.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.5:37427 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.5:59376
[2025-05-08T19:39:30.737+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 156 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:30.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-08T19:39:30.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.171 s
[2025-05-08T19:39:30.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:30.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-08T19:39:30.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.185288 s
[2025-05-08T19:39:30.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-08T19:39:30.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T19:39:30.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T19:39:30.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:30.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:30.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T19:39:30.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-08T19:39:30.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.3 MiB)
[2025-05-08T19:39:30.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on f2a432e4376a:35283 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:30.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:30.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-08T19:39:30.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:30.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.5:37427 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 44 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:30.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-08T19:39:30.847+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.057 s
[2025-05-08T19:39:30.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:30.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:30.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:30.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:30.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-08T19:39:30.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-08T19:39:30.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-08T19:39:30.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-08T19:39:30.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:30.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-08T19:39:30.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-08T19:39:30.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.3 MiB)
[2025-05-08T19:39:30.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on f2a432e4376a:35283 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:30.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:30.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-08T19:39:30.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:30.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on f2a432e4376a:35283 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.5:37427 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.933+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.5:37427 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.939+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on f2a432e4376a:35283 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.941+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.5:37427 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.942+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.5:59376
[2025-05-08T19:39:30.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on f2a432e4376a:35283 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.951+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.0.5:37427 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:30.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 49 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:30.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.066 s
[2025-05-08T19:39:30.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-08T19:39:30.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:30.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-08T19:39:30.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:30 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.073598 s
[2025-05-08T19:39:30.958+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:30,958 [INFO] Загружено 4652 транзакций и 1200 клиентов
[2025-05-08T19:39:31.110+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:31,110 [INFO] Создаем P2P ребра
[2025-05-08T19:39:31.159+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:31,158 [INFO] Создаем ребра по общим атрибутам
[2025-05-08T19:39:31.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on f2a432e4376a:35283 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:31.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.5:37427 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:31.790+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:31,790 [INFO] Объединяем все ребра
[2025-05-08T19:39:31.905+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:31,904 [INFO] Создаем вершины графа
[2025-05-08T19:39:31.996+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:31,996 [INFO] Создаем финальный граф
[2025-05-08T19:39:32.022+0000] {spark_submit.py:571} INFO - 2025-05-08 19:39:32,022 [INFO] Вычисляем метрики графа
[2025-05-08T19:39:33.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO CodeGenerator: Code generated in 10.959613 ms
[2025-05-08T19:39:33.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Registering RDD 34 (rdd at GraphFrame.scala:187) as input to shuffle 2
[2025-05-08T19:39:33.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Got map stage job 4 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-08T19:39:33.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:33.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:33.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:33.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:33.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO CodeGenerator: Code generated in 11.729648 ms
[2025-05-08T19:39:33.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 23.9 KiB, free 434.4 MiB)
[2025-05-08T19:39:33.500+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 434.4 MiB)
[2025-05-08T19:39:33.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO CodeGenerator: Code generated in 11.811302 ms
[2025-05-08T19:39:33.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:33.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:33.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:33.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-05-08T19:39:33.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Registering RDD 37 (rdd at GraphFrame.scala:187) as input to shuffle 3
[2025-05-08T19:39:33.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:33.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Got map stage job 5 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-08T19:39:33.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:33.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:33.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:33.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[37] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:33.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 22.4 KiB, free 434.3 MiB)
[2025-05-08T19:39:33.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-08T19:39:33.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:33.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:33.522+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[37] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:33.522+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2025-05-08T19:39:33.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Registering RDD 40 (rdd at GraphFrame.scala:187) as input to shuffle 4
[2025-05-08T19:39:33.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Got map stage job 6 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-08T19:39:33.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:33.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:33.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:33.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[40] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:33.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:33.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 22.4 KiB, free 434.3 MiB)
[2025-05-08T19:39:33.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 434.3 MiB)
[2025-05-08T19:39:33.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:33.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:33.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[40] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:33.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-08T19:39:33.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO CodeGenerator: Code generated in 44.092478 ms
[2025-05-08T19:39:33.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Registering RDD 43 (rdd at GraphFrame.scala:187) as input to shuffle 5
[2025-05-08T19:39:33.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Got map stage job 7 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-08T19:39:33.656+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:33.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:33.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:33.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[43] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:33.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 28.8 KiB, free 434.3 MiB)
[2025-05-08T19:39:33.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 434.3 MiB)
[2025-05-08T19:39:33.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:33.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:33.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[43] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:33.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:33 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-05-08T19:39:34.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:34.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 512 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:34.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-08T19:39:34.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: ShuffleMapStage 6 (rdd at GraphFrame.scala:187) finished in 0.545 s
[2025-05-08T19:39:34.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:34.017+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: running: Set(ShuffleMapStage 9, ShuffleMapStage 7, ShuffleMapStage 8)
[2025-05-08T19:39:34.017+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:34.017+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:34.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:34.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:34.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 285 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:34.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-05-08T19:39:34.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: ShuffleMapStage 7 (rdd at GraphFrame.scala:187) finished in 0.794 s
[2025-05-08T19:39:34.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:34.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: running: Set(ShuffleMapStage 9, ShuffleMapStage 8)
[2025-05-08T19:39:34.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:34.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:34.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:34.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:34.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 106 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:34.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-08T19:39:34.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: ShuffleMapStage 8 (rdd at GraphFrame.scala:187) finished in 0.878 s
[2025-05-08T19:39:34.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:34.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: running: Set(ShuffleMapStage 9)
[2025-05-08T19:39:34.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:34.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:34.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.5:37427 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:34.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 498 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:34.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-08T19:39:34.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: ShuffleMapStage 9 (rdd at GraphFrame.scala:187) finished in 1.246 s
[2025-05-08T19:39:34.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:34.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:34.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:34.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:35.023+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 57.401772 ms
[2025-05-08T19:39:35.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 8.715775 ms
[2025-05-08T19:39:35.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 10.296908 ms
[2025-05-08T19:39:35.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 8.861038 ms
[2025-05-08T19:39:35.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 6.241686 ms
[2025-05-08T19:39:35.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 5.701882 ms
[2025-05-08T19:39:35.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 9.036224 ms
[2025-05-08T19:39:35.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 6.204328 ms
[2025-05-08T19:39:35.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 20.046966 ms
[2025-05-08T19:39:35.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.5:37427 in memory (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 9.009321 ms
[2025-05-08T19:39:35.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_5_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_6_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.195+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_4_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.5:37427 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Registering RDD 81 (rdd at GraphFrame.scala:187) as input to shuffle 6
[2025-05-08T19:39:35.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Got map stage job 8 (rdd at GraphFrame.scala:187) with 41 output partitions
[2025-05-08T19:39:35.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:35.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 11)
[2025-05-08T19:39:35.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:35.245+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[81] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:35.266+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 107.6 KiB, free 434.3 MiB)
[2025-05-08T19:39:35.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 39.4 KiB, free 434.3 MiB)
[2025-05-08T19:39:35.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on f2a432e4376a:35283 (size: 39.4 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:35.270+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[81] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:35.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO TaskSchedulerImpl: Adding task set 14.0 with 41 tasks resource profile 0
[2025-05-08T19:39:35.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 8) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:35.279+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 31.418902 ms
[2025-05-08T19:39:35.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 9.768844 ms
[2025-05-08T19:39:35.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.5:37427 (size: 39.4 KiB, free: 434.4 MiB)
[2025-05-08T19:39:35.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 9.631272 ms
[2025-05-08T19:39:35.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 7.451255 ms
[2025-05-08T19:39:35.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 8.567369 ms
[2025-05-08T19:39:35.352+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 7.51597 ms
[2025-05-08T19:39:35.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 10.12604 ms
[2025-05-08T19:39:35.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 7.500846 ms
[2025-05-08T19:39:35.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 9.982161 ms
[2025-05-08T19:39:35.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO CodeGenerator: Code generated in 8.576262 ms
[2025-05-08T19:39:35.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Registering RDD 101 (rdd at GraphFrame.scala:187) as input to shuffle 7
[2025-05-08T19:39:35.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Got map stage job 9 (rdd at GraphFrame.scala:187) with 41 output partitions
[2025-05-08T19:39:35.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:35.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 11)
[2025-05-08T19:39:35.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:35.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[101] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:35.485+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 109.6 KiB, free 434.1 MiB)
[2025-05-08T19:39:35.516+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 40.0 KiB, free 434.1 MiB)
[2025-05-08T19:39:35.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.5:59376
[2025-05-08T19:39:35.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on f2a432e4376a:35283 (size: 40.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:35.522+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:35.525+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[101] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:35.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:35 INFO TaskSchedulerImpl: Adding task set 15.0 with 41 tasks resource profile 0
[2025-05-08T19:39:36.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 9) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:36.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 8) in 1450 ms on 172.20.0.5 (executor 0) (1/41)
[2025-05-08T19:39:36.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 10) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:36.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 9) in 78 ms on 172.20.0.5 (executor 0) (2/41)
[2025-05-08T19:39:36.840+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Starting task 6.0 in stage 14.0 (TID 11) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:36.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 10) in 53 ms on 172.20.0.5 (executor 0) (3/41)
[2025-05-08T19:39:36.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Starting task 7.0 in stage 14.0 (TID 12) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:36.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Finished task 6.0 in stage 14.0 (TID 11) in 62 ms on 172.20.0.5 (executor 0) (4/41)
[2025-05-08T19:39:36.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Starting task 8.0 in stage 14.0 (TID 13) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:36.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:36 INFO TaskSetManager: Finished task 7.0 in stage 14.0 (TID 12) in 91 ms on 172.20.0.5 (executor 0) (5/41)
[2025-05-08T19:39:37.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 9.0 in stage 14.0 (TID 14) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.067+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 8.0 in stage 14.0 (TID 13) in 78 ms on 172.20.0.5 (executor 0) (6/41)
[2025-05-08T19:39:37.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 10.0 in stage 14.0 (TID 15) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 9.0 in stage 14.0 (TID 14) in 51 ms on 172.20.0.5 (executor 0) (7/41)
[2025-05-08T19:39:37.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 11.0 in stage 14.0 (TID 16) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 10.0 in stage 14.0 (TID 15) in 66 ms on 172.20.0.5 (executor 0) (8/41)
[2025-05-08T19:39:37.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:59376
[2025-05-08T19:39:37.364+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 12.0 in stage 14.0 (TID 17) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 11.0 in stage 14.0 (TID 16) in 196 ms on 172.20.0.5 (executor 0) (9/41)
[2025-05-08T19:39:37.436+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 13.0 in stage 14.0 (TID 18) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.441+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 12.0 in stage 14.0 (TID 17) in 78 ms on 172.20.0.5 (executor 0) (10/41)
[2025-05-08T19:39:37.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 14.0 in stage 14.0 (TID 19) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 13.0 in stage 14.0 (TID 18) in 86 ms on 172.20.0.5 (executor 0) (11/41)
[2025-05-08T19:39:37.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 15.0 in stage 14.0 (TID 20) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 14.0 in stage 14.0 (TID 19) in 76 ms on 172.20.0.5 (executor 0) (12/41)
[2025-05-08T19:39:37.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 16.0 in stage 14.0 (TID 21) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 15.0 in stage 14.0 (TID 20) in 88 ms on 172.20.0.5 (executor 0) (13/41)
[2025-05-08T19:39:37.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 17.0 in stage 14.0 (TID 22) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 16.0 in stage 14.0 (TID 21) in 80 ms on 172.20.0.5 (executor 0) (14/41)
[2025-05-08T19:39:37.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 18.0 in stage 14.0 (TID 23) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 17.0 in stage 14.0 (TID 22) in 108 ms on 172.20.0.5 (executor 0) (15/41)
[2025-05-08T19:39:37.951+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Starting task 19.0 in stage 14.0 (TID 24) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:37.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:37 INFO TaskSetManager: Finished task 18.0 in stage 14.0 (TID 23) in 92 ms on 172.20.0.5 (executor 0) (16/41)
[2025-05-08T19:39:38.011+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 20.0 in stage 14.0 (TID 25) (172.20.0.5, executor 0, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.011+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 19.0 in stage 14.0 (TID 24) in 60 ms on 172.20.0.5 (executor 0) (17/41)
[2025-05-08T19:39:38.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 21.0 in stage 14.0 (TID 26) (172.20.0.5, executor 0, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 20.0 in stage 14.0 (TID 25) in 54 ms on 172.20.0.5 (executor 0) (18/41)
[2025-05-08T19:39:38.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.20.0.5:59376
[2025-05-08T19:39:38.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 22.0 in stage 14.0 (TID 27) (172.20.0.5, executor 0, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.137+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 21.0 in stage 14.0 (TID 26) in 75 ms on 172.20.0.5 (executor 0) (19/41)
[2025-05-08T19:39:38.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 23.0 in stage 14.0 (TID 28) (172.20.0.5, executor 0, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 22.0 in stage 14.0 (TID 27) in 51 ms on 172.20.0.5 (executor 0) (20/41)
[2025-05-08T19:39:38.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 24.0 in stage 14.0 (TID 29) (172.20.0.5, executor 0, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 23.0 in stage 14.0 (TID 28) in 36 ms on 172.20.0.5 (executor 0) (21/41)
[2025-05-08T19:39:38.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 25.0 in stage 14.0 (TID 30) (172.20.0.5, executor 0, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 24.0 in stage 14.0 (TID 29) in 67 ms on 172.20.0.5 (executor 0) (22/41)
[2025-05-08T19:39:38.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 26.0 in stage 14.0 (TID 31) (172.20.0.5, executor 0, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 25.0 in stage 14.0 (TID 30) in 56 ms on 172.20.0.5 (executor 0) (23/41)
[2025-05-08T19:39:38.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 27.0 in stage 14.0 (TID 32) (172.20.0.5, executor 0, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.391+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 26.0 in stage 14.0 (TID 31) in 54 ms on 172.20.0.5 (executor 0) (24/41)
[2025-05-08T19:39:38.431+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 28.0 in stage 14.0 (TID 33) (172.20.0.5, executor 0, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 27.0 in stage 14.0 (TID 32) in 43 ms on 172.20.0.5 (executor 0) (25/41)
[2025-05-08T19:39:38.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 29.0 in stage 14.0 (TID 34) (172.20.0.5, executor 0, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 28.0 in stage 14.0 (TID 33) in 43 ms on 172.20.0.5 (executor 0) (26/41)
[2025-05-08T19:39:38.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 30.0 in stage 14.0 (TID 35) (172.20.0.5, executor 0, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 29.0 in stage 14.0 (TID 34) in 47 ms on 172.20.0.5 (executor 0) (27/41)
[2025-05-08T19:39:38.563+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 31.0 in stage 14.0 (TID 36) (172.20.0.5, executor 0, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 30.0 in stage 14.0 (TID 35) in 53 ms on 172.20.0.5 (executor 0) (28/41)
[2025-05-08T19:39:38.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:59376
[2025-05-08T19:39:38.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 32.0 in stage 14.0 (TID 37) (172.20.0.5, executor 0, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 31.0 in stage 14.0 (TID 36) in 94 ms on 172.20.0.5 (executor 0) (29/41)
[2025-05-08T19:39:38.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 33.0 in stage 14.0 (TID 38) (172.20.0.5, executor 0, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.696+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 32.0 in stage 14.0 (TID 37) in 41 ms on 172.20.0.5 (executor 0) (30/41)
[2025-05-08T19:39:38.775+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 34.0 in stage 14.0 (TID 39) (172.20.0.5, executor 0, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.781+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 33.0 in stage 14.0 (TID 38) in 82 ms on 172.20.0.5 (executor 0) (31/41)
[2025-05-08T19:39:38.841+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 35.0 in stage 14.0 (TID 40) (172.20.0.5, executor 0, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.842+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 34.0 in stage 14.0 (TID 39) in 66 ms on 172.20.0.5 (executor 0) (32/41)
[2025-05-08T19:39:38.958+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 36.0 in stage 14.0 (TID 41) (172.20.0.5, executor 0, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 35.0 in stage 14.0 (TID 40) in 123 ms on 172.20.0.5 (executor 0) (33/41)
[2025-05-08T19:39:38.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Starting task 37.0 in stage 14.0 (TID 42) (172.20.0.5, executor 0, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:38.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:38 INFO TaskSetManager: Finished task 36.0 in stage 14.0 (TID 41) in 37 ms on 172.20.0.5 (executor 0) (34/41)
[2025-05-08T19:39:39.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 37.0 in stage 14.0 (TID 42) in 41 ms on 172.20.0.5 (executor 0) (35/41)
[2025-05-08T19:39:39.033+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 38.0 in stage 14.0 (TID 43) (172.20.0.5, executor 0, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 39.0 in stage 14.0 (TID 44) (172.20.0.5, executor 0, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 38.0 in stage 14.0 (TID 43) in 35 ms on 172.20.0.5 (executor 0) (36/41)
[2025-05-08T19:39:39.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 40.0 in stage 14.0 (TID 45) (172.20.0.5, executor 0, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 39.0 in stage 14.0 (TID 44) in 33 ms on 172.20.0.5 (executor 0) (37/41)
[2025-05-08T19:39:39.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 46) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 40.0 in stage 14.0 (TID 45) in 25 ms on 172.20.0.5 (executor 0) (38/41)
[2025-05-08T19:39:39.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 47) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 46) in 67 ms on 172.20.0.5 (executor 0) (39/41)
[2025-05-08T19:39:39.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 48) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 47) in 24 ms on 172.20.0.5 (executor 0) (40/41)
[2025-05-08T19:39:39.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 49) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 48) in 24 ms on 172.20.0.5 (executor 0) (41/41)
[2025-05-08T19:39:39.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-08T19:39:39.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: ShuffleMapStage 14 (rdd at GraphFrame.scala:187) finished in 3.980 s
[2025-05-08T19:39:39.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:39.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: running: Set(ShuffleMapStage 15)
[2025-05-08T19:39:39.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:39.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:39.249+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.5:37427 (size: 40.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:39.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:39.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:39.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:39.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO CodeGenerator: Code generated in 35.604442 ms
[2025-05-08T19:39:39.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 50) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 49) in 154 ms on 172.20.0.5 (executor 0) (1/41)
[2025-05-08T19:39:39.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: Registering RDD 104 (rdd at GraphFrame.scala:187) as input to shuffle 8
[2025-05-08T19:39:39.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: Got map stage job 10 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-08T19:39:39.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:39.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2025-05-08T19:39:39.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:39.398+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[104] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:39.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 87.6 KiB, free 434.0 MiB)
[2025-05-08T19:39:39.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 434.0 MiB)
[2025-05-08T19:39:39.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on f2a432e4376a:35283 (size: 32.5 KiB, free: 434.3 MiB)
[2025-05-08T19:39:39.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:39.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[104] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:39.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-05-08T19:39:39.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on f2a432e4376a:35283 in memory (size: 39.4 KiB, free: 434.3 MiB)
[2025-05-08T19:39:39.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 51) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.5:37427 in memory (size: 39.4 KiB, free: 434.4 MiB)
[2025-05-08T19:39:39.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 50) in 61 ms on 172.20.0.5 (executor 0) (2/41)
[2025-05-08T19:39:39.496+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 52) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 51) in 54 ms on 172.20.0.5 (executor 0) (3/41)
[2025-05-08T19:39:39.531+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 53) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.531+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 52) in 48 ms on 172.20.0.5 (executor 0) (4/41)
[2025-05-08T19:39:39.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 54) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 53) in 42 ms on 172.20.0.5 (executor 0) (5/41)
[2025-05-08T19:39:39.619+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 55) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.619+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 54) in 48 ms on 172.20.0.5 (executor 0) (6/41)
[2025-05-08T19:39:39.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 56) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.647+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 55) in 29 ms on 172.20.0.5 (executor 0) (7/41)
[2025-05-08T19:39:39.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 57) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 56) in 31 ms on 172.20.0.5 (executor 0) (8/41)
[2025-05-08T19:39:39.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 12.0 in stage 15.0 (TID 58) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 57) in 69 ms on 172.20.0.5 (executor 0) (9/41)
[2025-05-08T19:39:39.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 13.0 in stage 15.0 (TID 59) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.781+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 12.0 in stage 15.0 (TID 58) in 37 ms on 172.20.0.5 (executor 0) (10/41)
[2025-05-08T19:39:39.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 14.0 in stage 15.0 (TID 60) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 13.0 in stage 15.0 (TID 59) in 36 ms on 172.20.0.5 (executor 0) (11/41)
[2025-05-08T19:39:39.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 15.0 in stage 15.0 (TID 61) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 14.0 in stage 15.0 (TID 60) in 36 ms on 172.20.0.5 (executor 0) (12/41)
[2025-05-08T19:39:39.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 16.0 in stage 15.0 (TID 62) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 15.0 in stage 15.0 (TID 61) in 33 ms on 172.20.0.5 (executor 0) (13/41)
[2025-05-08T19:39:39.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 17.0 in stage 15.0 (TID 63) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 16.0 in stage 15.0 (TID 62) in 33 ms on 172.20.0.5 (executor 0) (14/41)
[2025-05-08T19:39:39.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 18.0 in stage 15.0 (TID 64) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 17.0 in stage 15.0 (TID 63) in 32 ms on 172.20.0.5 (executor 0) (15/41)
[2025-05-08T19:39:39.976+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 19.0 in stage 15.0 (TID 65) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.976+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 18.0 in stage 15.0 (TID 64) in 31 ms on 172.20.0.5 (executor 0) (16/41)
[2025-05-08T19:39:39.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Starting task 20.0 in stage 15.0 (TID 66) (172.20.0.5, executor 0, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:39.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:39 INFO TaskSetManager: Finished task 19.0 in stage 15.0 (TID 65) in 19 ms on 172.20.0.5 (executor 0) (17/41)
[2025-05-08T19:39:40.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 21.0 in stage 15.0 (TID 67) (172.20.0.5, executor 0, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 20.0 in stage 15.0 (TID 66) in 20 ms on 172.20.0.5 (executor 0) (18/41)
[2025-05-08T19:39:40.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 22.0 in stage 15.0 (TID 68) (172.20.0.5, executor 0, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 21.0 in stage 15.0 (TID 67) in 41 ms on 172.20.0.5 (executor 0) (19/41)
[2025-05-08T19:39:40.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 23.0 in stage 15.0 (TID 69) (172.20.0.5, executor 0, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 22.0 in stage 15.0 (TID 68) in 18 ms on 172.20.0.5 (executor 0) (20/41)
[2025-05-08T19:39:40.089+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 24.0 in stage 15.0 (TID 70) (172.20.0.5, executor 0, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 23.0 in stage 15.0 (TID 69) in 18 ms on 172.20.0.5 (executor 0) (21/41)
[2025-05-08T19:39:40.107+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 25.0 in stage 15.0 (TID 71) (172.20.0.5, executor 0, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.108+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 24.0 in stage 15.0 (TID 70) in 18 ms on 172.20.0.5 (executor 0) (22/41)
[2025-05-08T19:39:40.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 26.0 in stage 15.0 (TID 72) (172.20.0.5, executor 0, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 25.0 in stage 15.0 (TID 71) in 15 ms on 172.20.0.5 (executor 0) (23/41)
[2025-05-08T19:39:40.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 27.0 in stage 15.0 (TID 73) (172.20.0.5, executor 0, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 26.0 in stage 15.0 (TID 72) in 14 ms on 172.20.0.5 (executor 0) (24/41)
[2025-05-08T19:39:40.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 28.0 in stage 15.0 (TID 74) (172.20.0.5, executor 0, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 27.0 in stage 15.0 (TID 73) in 15 ms on 172.20.0.5 (executor 0) (25/41)
[2025-05-08T19:39:40.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 29.0 in stage 15.0 (TID 75) (172.20.0.5, executor 0, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 28.0 in stage 15.0 (TID 74) in 16 ms on 172.20.0.5 (executor 0) (26/41)
[2025-05-08T19:39:40.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 30.0 in stage 15.0 (TID 76) (172.20.0.5, executor 0, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 29.0 in stage 15.0 (TID 75) in 15 ms on 172.20.0.5 (executor 0) (27/41)
[2025-05-08T19:39:40.198+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 31.0 in stage 15.0 (TID 77) (172.20.0.5, executor 0, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 30.0 in stage 15.0 (TID 76) in 18 ms on 172.20.0.5 (executor 0) (28/41)
[2025-05-08T19:39:40.234+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 32.0 in stage 15.0 (TID 78) (172.20.0.5, executor 0, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 31.0 in stage 15.0 (TID 77) in 36 ms on 172.20.0.5 (executor 0) (29/41)
[2025-05-08T19:39:40.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 33.0 in stage 15.0 (TID 79) (172.20.0.5, executor 0, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 32.0 in stage 15.0 (TID 78) in 18 ms on 172.20.0.5 (executor 0) (30/41)
[2025-05-08T19:39:40.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 34.0 in stage 15.0 (TID 80) (172.20.0.5, executor 0, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 33.0 in stage 15.0 (TID 79) in 21 ms on 172.20.0.5 (executor 0) (31/41)
[2025-05-08T19:39:40.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 35.0 in stage 15.0 (TID 81) (172.20.0.5, executor 0, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 34.0 in stage 15.0 (TID 80) in 24 ms on 172.20.0.5 (executor 0) (32/41)
[2025-05-08T19:39:40.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 36.0 in stage 15.0 (TID 82) (172.20.0.5, executor 0, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 35.0 in stage 15.0 (TID 81) in 18 ms on 172.20.0.5 (executor 0) (33/41)
[2025-05-08T19:39:40.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 37.0 in stage 15.0 (TID 83) (172.20.0.5, executor 0, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 36.0 in stage 15.0 (TID 82) in 22 ms on 172.20.0.5 (executor 0) (34/41)
[2025-05-08T19:39:40.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 38.0 in stage 15.0 (TID 84) (172.20.0.5, executor 0, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 37.0 in stage 15.0 (TID 83) in 38 ms on 172.20.0.5 (executor 0) (35/41)
[2025-05-08T19:39:40.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 39.0 in stage 15.0 (TID 85) (172.20.0.5, executor 0, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 38.0 in stage 15.0 (TID 84) in 38 ms on 172.20.0.5 (executor 0) (36/41)
[2025-05-08T19:39:40.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 40.0 in stage 15.0 (TID 86) (172.20.0.5, executor 0, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 39.0 in stage 15.0 (TID 85) in 29 ms on 172.20.0.5 (executor 0) (37/41)
[2025-05-08T19:39:40.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 87) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 40.0 in stage 15.0 (TID 86) in 23 ms on 172.20.0.5 (executor 0) (38/41)
[2025-05-08T19:39:40.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 88) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 87) in 44 ms on 172.20.0.5 (executor 0) (39/41)
[2025-05-08T19:39:40.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 89) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 88) in 12 ms on 172.20.0.5 (executor 0) (40/41)
[2025-05-08T19:39:40.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 90) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 89) in 10 ms on 172.20.0.5 (executor 0) (41/41)
[2025-05-08T19:39:40.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-08T19:39:40.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: ShuffleMapStage 15 (rdd at GraphFrame.scala:187) finished in 5.044 s
[2025-05-08T19:39:40.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:40.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: running: Set(ShuffleMapStage 17)
[2025-05-08T19:39:40.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:40.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:40.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:40.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.5:37427 (size: 32.5 KiB, free: 434.3 MiB)
[2025-05-08T19:39:40.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:40.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:40.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.20.0.5:59376
[2025-05-08T19:39:40.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO BlockManagerInfo: Removed broadcast_9_piece0 on f2a432e4376a:35283 in memory (size: 40.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:40.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.5:37427 in memory (size: 40.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:40.563+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO CodeGenerator: Code generated in 29.154731 ms
[2025-05-08T19:39:40.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Registering RDD 107 (rdd at GraphFrame.scala:187) as input to shuffle 9
[2025-05-08T19:39:40.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Got map stage job 11 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-08T19:39:40.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:40.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
[2025-05-08T19:39:40.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:40.596+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[107] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:40.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 89.5 KiB, free 434.2 MiB)
[2025-05-08T19:39:40.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 33.2 KiB, free 434.2 MiB)
[2025-05-08T19:39:40.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on f2a432e4376a:35283 (size: 33.2 KiB, free: 434.3 MiB)
[2025-05-08T19:39:40.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:40.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[107] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:40.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2025-05-08T19:39:40.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 91) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:40.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 90) in 155 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:40.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-05-08T19:39:40.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: ShuffleMapStage 17 (rdd at GraphFrame.scala:187) finished in 1.277 s
[2025-05-08T19:39:40.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:40.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: running: Set(ShuffleMapStage 19)
[2025-05-08T19:39:40.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:40.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:40.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:37427 (size: 33.2 KiB, free: 434.3 MiB)
[2025-05-08T19:39:40.697+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.20.0.5:59376
[2025-05-08T19:39:40.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO BlockManagerInfo: Removed broadcast_10_piece0 on f2a432e4376a:35283 in memory (size: 32.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:40.737+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.0.5:37427 in memory (size: 32.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:40.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 91) in 183 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:40.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-05-08T19:39:40.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: ShuffleMapStage 19 (rdd at GraphFrame.scala:187) finished in 0.259 s
[2025-05-08T19:39:40.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:40.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:40.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:40.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:40.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO ShufflePartitionsUtil: For shuffle(8, 9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:40.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:40.919+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO CodeGenerator: Code generated in 13.832617 ms
[2025-05-08T19:39:40.919+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:40.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO CodeGenerator: Code generated in 17.301006 ms
[2025-05-08T19:39:40.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:40.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO CodeGenerator: Code generated in 11.976 ms
[2025-05-08T19:39:40.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Registering RDD 114 (rdd at GraphFrame.scala:187) as input to shuffle 10
[2025-05-08T19:39:40.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Got map stage job 12 (rdd at GraphFrame.scala:187) with 2 output partitions
[2025-05-08T19:39:40.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Final stage: ShuffleMapStage 28 (rdd at GraphFrame.scala:187)
[2025-05-08T19:39:40.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27, ShuffleMapStage 26)
[2025-05-08T19:39:40.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:40.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:40 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[114] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:41.004+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 128.6 KiB, free 434.2 MiB)
[2025-05-08T19:39:41.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 47.8 KiB, free 434.1 MiB)
[2025-05-08T19:39:41.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on f2a432e4376a:35283 (size: 47.8 KiB, free: 434.3 MiB)
[2025-05-08T19:39:41.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:41.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[114] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-08T19:39:41.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks resource profile 0
[2025-05-08T19:39:41.022+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 92) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:41.022+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on f2a432e4376a:35283 in memory (size: 33.2 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.20.0.5:37427 in memory (size: 33.2 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.5:37427 (size: 47.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.20.0.5:59376
[2025-05-08T19:39:41.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 93) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:41.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 92) in 103 ms on 172.20.0.5 (executor 0) (1/2)
[2025-05-08T19:39:41.137+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.20.0.5:59376
[2025-05-08T19:39:41.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 93) in 86 ms on 172.20.0.5 (executor 0) (2/2)
[2025-05-08T19:39:41.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-05-08T19:39:41.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: ShuffleMapStage 28 (rdd at GraphFrame.scala:187) finished in 0.212 s
[2025-05-08T19:39:41.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:41.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:41.219+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:41.219+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:41.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:41.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 18.097511 ms
[2025-05-08T19:39:41.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:41.297+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Got job 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T19:39:41.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Final stage: ResultStage 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T19:39:41.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
[2025-05-08T19:39:41.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:41.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[117] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T19:39:41.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 123.7 KiB, free 434.1 MiB)
[2025-05-08T19:39:41.317+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 42.5 KiB, free 434.1 MiB)
[2025-05-08T19:39:41.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on f2a432e4376a:35283 (size: 42.5 KiB, free: 434.3 MiB)
[2025-05-08T19:39:41.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:41.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on f2a432e4376a:35283 in memory (size: 47.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[117] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:41.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-05-08T19:39:41.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 94) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:41.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.20.0.5:37427 in memory (size: 47.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.5:37427 (size: 42.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.20.0.5:59376
[2025-05-08T19:39:41.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 94) in 103 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:41.431+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-05-08T19:39:41.431+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: ResultStage 38 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.125 s
[2025-05-08T19:39:41.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:41.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
[2025-05-08T19:39:41.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO DAGScheduler: Job 13 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.132840 s
[2025-05-08T19:39:41.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 7.990847 ms
[2025-05-08T19:39:41.510+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Removed broadcast_13_piece0 on f2a432e4376a:35283 in memory (size: 42.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.20.0.5:37427 in memory (size: 42.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:41.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-08T19:39:41.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 94.3 KiB, free 432.2 MiB)
[2025-05-08T19:39:41.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on f2a432e4376a:35283 (size: 94.3 KiB, free: 434.3 MiB)
[2025-05-08T19:39:41.547+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:41.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 8.831256 ms
[2025-05-08T19:39:41.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 24.051393 ms
[2025-05-08T19:39:41.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.642+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.656+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 11.65668 ms
[2025-05-08T19:39:41.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 21.776897 ms
[2025-05-08T19:39:41.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 27.377206 ms
[2025-05-08T19:39:41.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 9.048286 ms
[2025-05-08T19:39:41.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 7.707336 ms
[2025-05-08T19:39:41.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 7.117894 ms
[2025-05-08T19:39:41.766+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 8.24419 ms
[2025-05-08T19:39:41.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 20.043824 ms
[2025-05-08T19:39:41.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 6.107505 ms
[2025-05-08T19:39:41.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 7.283984 ms
[2025-05-08T19:39:41.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 7.115009 ms
[2025-05-08T19:39:41.839+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 6.566692 ms
[2025-05-08T19:39:41.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 7.515487 ms
[2025-05-08T19:39:41.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 6.245258 ms
[2025-05-08T19:39:41.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 6.916765 ms
[2025-05-08T19:39:41.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 12.923941 ms
[2025-05-08T19:39:41.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:41.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:41 INFO CodeGenerator: Code generated in 17.622219 ms
[2025-05-08T19:39:42.040+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#1729) generates partition filter: ((id.count#1854 - id.nullCount#1853) > 0)
[2025-05-08T19:39:42.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Registering RDD 185 (collect at GraphFrame.scala:574) as input to shuffle 19
[2025-05-08T19:39:42.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Got map stage job 14 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T19:39:42.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (collect at GraphFrame.scala:574)
[2025-05-08T19:39:42.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:42.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:42.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[185] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T19:39:42.263+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 23.9 KiB, free 432.2 MiB)
[2025-05-08T19:39:42.270+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 432.2 MiB)
[2025-05-08T19:39:42.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T19:39:42.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:42.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[185] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:42.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-05-08T19:39:42.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Registering RDD 188 (collect at GraphFrame.scala:574) as input to shuffle 20
[2025-05-08T19:39:42.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Got map stage job 15 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T19:39:42.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (collect at GraphFrame.scala:574)
[2025-05-08T19:39:42.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:42.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:42.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 95) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.280+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[188] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T19:39:42.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 22.4 KiB, free 432.2 MiB)
[2025-05-08T19:39:42.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 432.2 MiB)
[2025-05-08T19:39:42.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:42.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:42.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[188] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:42.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-05-08T19:39:42.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Registering RDD 191 (collect at GraphFrame.scala:574) as input to shuffle 21
[2025-05-08T19:39:42.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Got map stage job 16 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T19:39:42.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (collect at GraphFrame.scala:574)
[2025-05-08T19:39:42.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:42.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:42.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[191] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T19:39:42.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 22.4 KiB, free 432.2 MiB)
[2025-05-08T19:39:42.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 432.1 MiB)
[2025-05-08T19:39:42.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:42.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:42.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[191] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:42.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-05-08T19:39:42.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Registering RDD 194 (collect at GraphFrame.scala:574) as input to shuffle 22
[2025-05-08T19:39:42.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Got map stage job 17 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T19:39:42.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (collect at GraphFrame.scala:574)
[2025-05-08T19:39:42.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:42.313+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:42.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[194] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T19:39:42.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.319+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 28.8 KiB, free 432.1 MiB)
[2025-05-08T19:39:42.319+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 432.1 MiB)
[2025-05-08T19:39:42.319+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T19:39:42.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:42.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[194] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:42.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-05-08T19:39:42.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 95) in 96 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:42.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-08T19:39:42.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 96) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: ShuffleMapStage 39 (collect at GraphFrame.scala:574) finished in 0.114 s
[2025-05-08T19:39:42.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:42.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ShuffleMapStage 40, ShuffleMapStage 41)
[2025-05-08T19:39:42.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:42.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:42.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.444+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 97) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 96) in 77 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:42.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-05-08T19:39:42.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: ShuffleMapStage 40 (collect at GraphFrame.scala:574) finished in 0.164 s
[2025-05-08T19:39:42.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:42.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ShuffleMapStage 41)
[2025-05-08T19:39:42.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:42.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:42.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.497+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 98) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 97) in 54 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:42.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-05-08T19:39:42.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: ShuffleMapStage 41 (collect at GraphFrame.scala:574) finished in 0.200 s
[2025-05-08T19:39:42.499+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:42.499+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: running: Set(ShuffleMapStage 42)
[2025-05-08T19:39:42.499+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:42.499+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:42.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.20.0.5:37427 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 98) in 45 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:42.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-05-08T19:39:42.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: ShuffleMapStage 42 (collect at GraphFrame.scala:574) finished in 0.234 s
[2025-05-08T19:39:42.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:42.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:42.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:42.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:42.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO CodeGenerator: Code generated in 5.101799 ms
[2025-05-08T19:39:42.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO CodeGenerator: Code generated in 4.111346 ms
[2025-05-08T19:39:42.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO CodeGenerator: Code generated in 5.709825 ms
[2025-05-08T19:39:42.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO CodeGenerator: Code generated in 4.381063 ms
[2025-05-08T19:39:42.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO CodeGenerator: Code generated in 5.910523 ms
[2025-05-08T19:39:42.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO CodeGenerator: Code generated in 3.578212 ms
[2025-05-08T19:39:42.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO CodeGenerator: Code generated in 4.278384 ms
[2025-05-08T19:39:42.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Registering RDD 222 (collect at GraphFrame.scala:574) as input to shuffle 23
[2025-05-08T19:39:42.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Got map stage job 18 (collect at GraphFrame.scala:574) with 41 output partitions
[2025-05-08T19:39:42.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Final stage: ShuffleMapStage 47 (collect at GraphFrame.scala:574)
[2025-05-08T19:39:42.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45, ShuffleMapStage 46, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-08T19:39:42.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:42.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[222] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T19:39:42.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 102.1 KiB, free 432.0 MiB)
[2025-05-08T19:39:42.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 432.0 MiB)
[2025-05-08T19:39:42.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on f2a432e4376a:35283 (size: 38.7 KiB, free: 434.2 MiB)
[2025-05-08T19:39:42.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:42.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[222] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:42.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSchedulerImpl: Adding task set 47.0 with 41 tasks resource profile 0
[2025-05-08T19:39:42.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 99) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_15_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 434.2 MiB)
[2025-05-08T19:39:42.696+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.20.0.5:37427 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_18_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 434.2 MiB)
[2025-05-08T19:39:42.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.20.0.5:37427 in memory (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.20.0.5:37427 (size: 38.7 KiB, free: 434.3 MiB)
[2025-05-08T19:39:42.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_17_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:42.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.20.0.5:59376
[2025-05-08T19:39:42.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_16_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:42.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:42.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 99) in 109 ms on 172.20.0.5 (executor 0) (1/41)
[2025-05-08T19:39:42.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 100) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.822+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 101) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.827+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 100) in 27 ms on 172.20.0.5 (executor 0) (2/41)
[2025-05-08T19:39:42.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 6.0 in stage 47.0 (TID 102) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 101) in 23 ms on 172.20.0.5 (executor 0) (3/41)
[2025-05-08T19:39:42.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 7.0 in stage 47.0 (TID 103) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 6.0 in stage 47.0 (TID 102) in 29 ms on 172.20.0.5 (executor 0) (4/41)
[2025-05-08T19:39:42.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 8.0 in stage 47.0 (TID 104) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.918+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 7.0 in stage 47.0 (TID 103) in 47 ms on 172.20.0.5 (executor 0) (5/41)
[2025-05-08T19:39:42.970+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 9.0 in stage 47.0 (TID 105) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.971+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 8.0 in stage 47.0 (TID 104) in 56 ms on 172.20.0.5 (executor 0) (6/41)
[2025-05-08T19:39:42.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Starting task 10.0 in stage 47.0 (TID 106) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:42.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:42 INFO TaskSetManager: Finished task 9.0 in stage 47.0 (TID 105) in 22 ms on 172.20.0.5 (executor 0) (7/41)
[2025-05-08T19:39:43.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 11.0 in stage 47.0 (TID 107) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 10.0 in stage 47.0 (TID 106) in 24 ms on 172.20.0.5 (executor 0) (8/41)
[2025-05-08T19:39:43.022+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.20.0.5:59376
[2025-05-08T19:39:43.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 12.0 in stage 47.0 (TID 108) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 11.0 in stage 47.0 (TID 107) in 60 ms on 172.20.0.5 (executor 0) (9/41)
[2025-05-08T19:39:43.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 13.0 in stage 47.0 (TID 109) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 12.0 in stage 47.0 (TID 108) in 31 ms on 172.20.0.5 (executor 0) (10/41)
[2025-05-08T19:39:43.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 14.0 in stage 47.0 (TID 110) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 13.0 in stage 47.0 (TID 109) in 28 ms on 172.20.0.5 (executor 0) (11/41)
[2025-05-08T19:39:43.149+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 15.0 in stage 47.0 (TID 111) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 14.0 in stage 47.0 (TID 110) in 20 ms on 172.20.0.5 (executor 0) (12/41)
[2025-05-08T19:39:43.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 16.0 in stage 47.0 (TID 112) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 15.0 in stage 47.0 (TID 111) in 19 ms on 172.20.0.5 (executor 0) (13/41)
[2025-05-08T19:39:43.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 17.0 in stage 47.0 (TID 113) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 16.0 in stage 47.0 (TID 112) in 18 ms on 172.20.0.5 (executor 0) (14/41)
[2025-05-08T19:39:43.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 18.0 in stage 47.0 (TID 114) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.203+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 17.0 in stage 47.0 (TID 113) in 16 ms on 172.20.0.5 (executor 0) (15/41)
[2025-05-08T19:39:43.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 19.0 in stage 47.0 (TID 115) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 18.0 in stage 47.0 (TID 114) in 18 ms on 172.20.0.5 (executor 0) (16/41)
[2025-05-08T19:39:43.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 20.0 in stage 47.0 (TID 116) (172.20.0.5, executor 0, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 19.0 in stage 47.0 (TID 115) in 16 ms on 172.20.0.5 (executor 0) (17/41)
[2025-05-08T19:39:43.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 21.0 in stage 47.0 (TID 117) (172.20.0.5, executor 0, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.266+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 20.0 in stage 47.0 (TID 116) in 28 ms on 172.20.0.5 (executor 0) (18/41)
[2025-05-08T19:39:43.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.20.0.5:59376
[2025-05-08T19:39:43.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 22.0 in stage 47.0 (TID 118) (172.20.0.5, executor 0, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 21.0 in stage 47.0 (TID 117) in 60 ms on 172.20.0.5 (executor 0) (19/41)
[2025-05-08T19:39:43.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 23.0 in stage 47.0 (TID 119) (172.20.0.5, executor 0, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 22.0 in stage 47.0 (TID 118) in 25 ms on 172.20.0.5 (executor 0) (20/41)
[2025-05-08T19:39:43.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 24.0 in stage 47.0 (TID 120) (172.20.0.5, executor 0, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 23.0 in stage 47.0 (TID 119) in 20 ms on 172.20.0.5 (executor 0) (21/41)
[2025-05-08T19:39:43.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 25.0 in stage 47.0 (TID 121) (172.20.0.5, executor 0, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 24.0 in stage 47.0 (TID 120) in 19 ms on 172.20.0.5 (executor 0) (22/41)
[2025-05-08T19:39:43.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 26.0 in stage 47.0 (TID 122) (172.20.0.5, executor 0, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 25.0 in stage 47.0 (TID 121) in 19 ms on 172.20.0.5 (executor 0) (23/41)
[2025-05-08T19:39:43.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 27.0 in stage 47.0 (TID 123) (172.20.0.5, executor 0, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 26.0 in stage 47.0 (TID 122) in 16 ms on 172.20.0.5 (executor 0) (24/41)
[2025-05-08T19:39:43.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 28.0 in stage 47.0 (TID 124) (172.20.0.5, executor 0, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 27.0 in stage 47.0 (TID 123) in 15 ms on 172.20.0.5 (executor 0) (25/41)
[2025-05-08T19:39:43.452+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 29.0 in stage 47.0 (TID 125) (172.20.0.5, executor 0, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.452+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 28.0 in stage 47.0 (TID 124) in 18 ms on 172.20.0.5 (executor 0) (26/41)
[2025-05-08T19:39:43.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 30.0 in stage 47.0 (TID 126) (172.20.0.5, executor 0, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 29.0 in stage 47.0 (TID 125) in 21 ms on 172.20.0.5 (executor 0) (27/41)
[2025-05-08T19:39:43.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 31.0 in stage 47.0 (TID 127) (172.20.0.5, executor 0, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 30.0 in stage 47.0 (TID 126) in 17 ms on 172.20.0.5 (executor 0) (28/41)
[2025-05-08T19:39:43.496+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.20.0.5:59376
[2025-05-08T19:39:43.525+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 32.0 in stage 47.0 (TID 128) (172.20.0.5, executor 0, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 31.0 in stage 47.0 (TID 127) in 36 ms on 172.20.0.5 (executor 0) (29/41)
[2025-05-08T19:39:43.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 33.0 in stage 47.0 (TID 129) (172.20.0.5, executor 0, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 32.0 in stage 47.0 (TID 128) in 27 ms on 172.20.0.5 (executor 0) (30/41)
[2025-05-08T19:39:43.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 34.0 in stage 47.0 (TID 130) (172.20.0.5, executor 0, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 33.0 in stage 47.0 (TID 129) in 20 ms on 172.20.0.5 (executor 0) (31/41)
[2025-05-08T19:39:43.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 35.0 in stage 47.0 (TID 131) (172.20.0.5, executor 0, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 34.0 in stage 47.0 (TID 130) in 20 ms on 172.20.0.5 (executor 0) (32/41)
[2025-05-08T19:39:43.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 36.0 in stage 47.0 (TID 132) (172.20.0.5, executor 0, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 35.0 in stage 47.0 (TID 131) in 18 ms on 172.20.0.5 (executor 0) (33/41)
[2025-05-08T19:39:43.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 37.0 in stage 47.0 (TID 133) (172.20.0.5, executor 0, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 36.0 in stage 47.0 (TID 132) in 19 ms on 172.20.0.5 (executor 0) (34/41)
[2025-05-08T19:39:43.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 38.0 in stage 47.0 (TID 134) (172.20.0.5, executor 0, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 37.0 in stage 47.0 (TID 133) in 15 ms on 172.20.0.5 (executor 0) (35/41)
[2025-05-08T19:39:43.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 39.0 in stage 47.0 (TID 135) (172.20.0.5, executor 0, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 38.0 in stage 47.0 (TID 134) in 14 ms on 172.20.0.5 (executor 0) (36/41)
[2025-05-08T19:39:43.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 40.0 in stage 47.0 (TID 136) (172.20.0.5, executor 0, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 39.0 in stage 47.0 (TID 135) in 18 ms on 172.20.0.5 (executor 0) (37/41)
[2025-05-08T19:39:43.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 137) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 40.0 in stage 47.0 (TID 136) in 16 ms on 172.20.0.5 (executor 0) (38/41)
[2025-05-08T19:39:43.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 4.0 in stage 47.0 (TID 138) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 137) in 28 ms on 172.20.0.5 (executor 0) (39/41)
[2025-05-08T19:39:43.724+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 5.0 in stage 47.0 (TID 139) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.724+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 4.0 in stage 47.0 (TID 138) in 10 ms on 172.20.0.5 (executor 0) (40/41)
[2025-05-08T19:39:43.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Finished task 5.0 in stage 47.0 (TID 139) in 12 ms on 172.20.0.5 (executor 0) (41/41)
[2025-05-08T19:39:43.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool
[2025-05-08T19:39:43.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: ShuffleMapStage 47 (collect at GraphFrame.scala:574) finished in 1.066 s
[2025-05-08T19:39:43.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:43.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:43.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:43.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:43.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:43.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:43.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO CodeGenerator: Code generated in 15.997201 ms
[2025-05-08T19:39:43.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: Registering RDD 225 (collect at GraphFrame.scala:574) as input to shuffle 24
[2025-05-08T19:39:43.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: Got map stage job 19 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T19:39:43.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: Final stage: ShuffleMapStage 53 (collect at GraphFrame.scala:574)
[2025-05-08T19:39:43.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2025-05-08T19:39:43.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:43.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[225] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T19:39:43.805+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 94.2 KiB, free 432.0 MiB)
[2025-05-08T19:39:43.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 432.0 MiB)
[2025-05-08T19:39:43.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on f2a432e4376a:35283 (size: 34.6 KiB, free: 434.2 MiB)
[2025-05-08T19:39:43.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:43.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[225] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:43.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-05-08T19:39:43.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.0.5:37427 in memory (size: 38.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:43.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 140) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:43.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO BlockManagerInfo: Removed broadcast_19_piece0 on f2a432e4376a:35283 in memory (size: 38.7 KiB, free: 434.3 MiB)
[2025-05-08T19:39:43.838+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.20.0.5:37427 (size: 34.6 KiB, free: 434.4 MiB)
[2025-05-08T19:39:43.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.20.0.5:59376
[2025-05-08T19:39:44.010+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 140) in 187 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:44.011+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-05-08T19:39:44.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: ShuffleMapStage 53 (collect at GraphFrame.scala:574) finished in 0.210 s
[2025-05-08T19:39:44.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:44.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:44.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:44.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:44.017+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:44.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:44.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO CodeGenerator: Code generated in 14.960955 ms
[2025-05-08T19:39:44.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-08T19:39:44.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Got job 20 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-08T19:39:44.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Final stage: ResultStage 60 (collect at GraphFrame.scala:574)
[2025-05-08T19:39:44.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-05-08T19:39:44.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:44.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[228] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-08T19:39:44.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 87.3 KiB, free 432.0 MiB)
[2025-05-08T19:39:44.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 432.0 MiB)
[2025-05-08T19:39:44.154+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on f2a432e4376a:35283 (size: 33.5 KiB, free: 434.2 MiB)
[2025-05-08T19:39:44.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:44.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[228] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:44.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-05-08T19:39:44.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO BlockManagerInfo: Removed broadcast_20_piece0 on f2a432e4376a:35283 in memory (size: 34.6 KiB, free: 434.3 MiB)
[2025-05-08T19:39:44.184+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 141) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:44.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.20.0.5:37427 in memory (size: 34.6 KiB, free: 434.4 MiB)
[2025-05-08T19:39:44.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.20.0.5:37427 (size: 33.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:44.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.20.0.5:59376
[2025-05-08T19:39:44.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 141) in 160 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:44.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-08T19:39:44.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: ResultStage 60 (collect at GraphFrame.scala:574) finished in 0.232 s
[2025-05-08T19:39:44.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:44.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
[2025-05-08T19:39:44.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO DAGScheduler: Job 20 finished: collect at GraphFrame.scala:574, took 0.239207 s
[2025-05-08T19:39:44.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO BlockManagerInfo: Removed broadcast_21_piece0 on f2a432e4376a:35283 in memory (size: 33.5 KiB, free: 434.3 MiB)
[2025-05-08T19:39:44.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:44 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.0.5:37427 in memory (size: 33.5 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Registering RDD 256 (rdd at GraphFrame.scala:188) as input to shuffle 25
[2025-05-08T19:39:45.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Got map stage job 21 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T19:39:45.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Final stage: ShuffleMapStage 61 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:45.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:45.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:45.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[256] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:45.245+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 23.9 KiB, free 432.2 MiB)
[2025-05-08T19:39:45.248+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 432.2 MiB)
[2025-05-08T19:39:45.249+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:45.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[256] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:45.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
[2025-05-08T19:39:45.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Registering RDD 259 (rdd at GraphFrame.scala:188) as input to shuffle 26
[2025-05-08T19:39:45.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Got map stage job 22 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T19:39:45.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:45.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:45.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 142) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:45.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:45.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[259] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:45.263+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 22.4 KiB, free 432.2 MiB)
[2025-05-08T19:39:45.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 432.2 MiB)
[2025-05-08T19:39:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[259] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
[2025-05-08T19:39:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Registering RDD 262 (rdd at GraphFrame.scala:188) as input to shuffle 27
[2025-05-08T19:39:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Got map stage job 23 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T19:39:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Final stage: ShuffleMapStage 63 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[262] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:45.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 22.4 KiB, free 432.2 MiB)
[2025-05-08T19:39:45.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 432.1 MiB)
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[262] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Registering RDD 265 (rdd at GraphFrame.scala:188) as input to shuffle 28
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:45.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[265] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:45.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 28.8 KiB, free 432.1 MiB)
[2025-05-08T19:39:45.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 432.1 MiB)
[2025-05-08T19:39:45.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:45.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[265] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:45.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
[2025-05-08T19:39:45.337+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 143) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:45.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 142) in 87 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:45.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-05-08T19:39:45.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: ShuffleMapStage 61 (rdd at GraphFrame.scala:188) finished in 0.109 s
[2025-05-08T19:39:45.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:45.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: running: Set(ShuffleMapStage 63, ShuffleMapStage 64, ShuffleMapStage 62)
[2025-05-08T19:39:45.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:45.372+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:45.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.452+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 144) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:45.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 143) in 116 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:45.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-05-08T19:39:45.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: ShuffleMapStage 62 (rdd at GraphFrame.scala:188) finished in 0.200 s
[2025-05-08T19:39:45.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:45.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: running: Set(ShuffleMapStage 63, ShuffleMapStage 64)
[2025-05-08T19:39:45.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:45.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:45.480+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 145) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:45.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 144) in 98 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:45.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool
[2025-05-08T19:39:45.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: ShuffleMapStage 63 (rdd at GraphFrame.scala:188) finished in 0.276 s
[2025-05-08T19:39:45.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:45.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: running: Set(ShuffleMapStage 64)
[2025-05-08T19:39:45.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:45.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:45.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.20.0.5:37427 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 145) in 94 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:45.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-05-08T19:39:45.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: ShuffleMapStage 64 (rdd at GraphFrame.scala:188) finished in 0.354 s
[2025-05-08T19:39:45.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:45.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:45.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:45.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:45.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 9.461688 ms
[2025-05-08T19:39:45.723+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 4.269735 ms
[2025-05-08T19:39:45.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 4.785977 ms
[2025-05-08T19:39:45.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_22_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.20.0.5:37427 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 7.238268 ms
[2025-05-08T19:39:45.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_24_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_23_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.766+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 7.134639 ms
[2025-05-08T19:39:45.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_25_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.778+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.20.0.5:37427 in memory (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.778+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 7.831717 ms
[2025-05-08T19:39:45.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 5.505044 ms
[2025-05-08T19:39:45.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 4.405697 ms
[2025-05-08T19:39:45.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Registering RDD 309 (rdd at GraphFrame.scala:188) as input to shuffle 29
[2025-05-08T19:39:45.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Got map stage job 25 (rdd at GraphFrame.scala:188) with 41 output partitions
[2025-05-08T19:39:45.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Final stage: ShuffleMapStage 69 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:45.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66, ShuffleMapStage 67, ShuffleMapStage 68, ShuffleMapStage 65)
[2025-05-08T19:39:45.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:45.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting ShuffleMapStage 69 (MapPartitionsRDD[309] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:45.847+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 89.2 KiB, free 432.2 MiB)
[2025-05-08T19:39:45.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 432.1 MiB)
[2025-05-08T19:39:45.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on f2a432e4376a:35283 (size: 33.1 KiB, free: 434.3 MiB)
[2025-05-08T19:39:45.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:45.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[309] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:45.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSchedulerImpl: Adding task set 69.0 with 41 tasks resource profile 0
[2025-05-08T19:39:45.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 146) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:45.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 46.323604 ms
[2025-05-08T19:39:45.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.20.0.5:37427 (size: 33.1 KiB, free: 434.4 MiB)
[2025-05-08T19:39:45.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 6.503809 ms
[2025-05-08T19:39:45.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:59376
[2025-05-08T19:39:45.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 26.206673 ms
[2025-05-08T19:39:45.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 18.576419 ms
[2025-05-08T19:39:45.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 30.665893 ms
[2025-05-08T19:39:45.980+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 8.662043 ms
[2025-05-08T19:39:46.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:45 INFO CodeGenerator: Code generated in 11.121631 ms
[2025-05-08T19:39:46.010+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 8.775411 ms
[2025-05-08T19:39:46.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 14.961442 ms
[2025-05-08T19:39:46.068+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 147) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 146) in 220 ms on 172.20.0.5 (executor 0) (1/41)
[2025-05-08T19:39:46.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 13.024166 ms
[2025-05-08T19:39:46.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Registering RDD 329 (rdd at GraphFrame.scala:188) as input to shuffle 30
[2025-05-08T19:39:46.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Got map stage job 26 (rdd at GraphFrame.scala:188) with 41 output partitions
[2025-05-08T19:39:46.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:46.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66, ShuffleMapStage 67, ShuffleMapStage 68, ShuffleMapStage 65)
[2025-05-08T19:39:46.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:46.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[329] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:46.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 109.8 KiB, free 432.0 MiB)
[2025-05-08T19:39:46.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 40.1 KiB, free 432.0 MiB)
[2025-05-08T19:39:46.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 148) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 147) in 100 ms on 172.20.0.5 (executor 0) (2/41)
[2025-05-08T19:39:46.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on f2a432e4376a:35283 (size: 40.1 KiB, free: 434.2 MiB)
[2025-05-08T19:39:46.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:46.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[329] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:46.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSchedulerImpl: Adding task set 70.0 with 41 tasks resource profile 0
[2025-05-08T19:39:46.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 84.816686 ms
[2025-05-08T19:39:46.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 9.883115 ms
[2025-05-08T19:39:46.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 19.080322 ms
[2025-05-08T19:39:46.246+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 149) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 148) in 84 ms on 172.20.0.5 (executor 0) (3/41)
[2025-05-08T19:39:46.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 16.687534 ms
[2025-05-08T19:39:46.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 150) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 149) in 83 ms on 172.20.0.5 (executor 0) (4/41)
[2025-05-08T19:39:46.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 15.696668 ms
[2025-05-08T19:39:46.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 16.880896 ms
[2025-05-08T19:39:46.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 10.437133 ms
[2025-05-08T19:39:46.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 151) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.424+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 150) in 95 ms on 172.20.0.5 (executor 0) (5/41)
[2025-05-08T19:39:46.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 12.87372 ms
[2025-05-08T19:39:46.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 8.888837 ms
[2025-05-08T19:39:46.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO CodeGenerator: Code generated in 8.628229 ms
[2025-05-08T19:39:46.492+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 152) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 151) in 73 ms on 172.20.0.5 (executor 0) (6/41)
[2025-05-08T19:39:46.497+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Registering RDD 349 (rdd at GraphFrame.scala:188) as input to shuffle 31
[2025-05-08T19:39:46.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Got map stage job 27 (rdd at GraphFrame.scala:188) with 41 output partitions
[2025-05-08T19:39:46.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Final stage: ShuffleMapStage 71 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:46.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66, ShuffleMapStage 67, ShuffleMapStage 68, ShuffleMapStage 65)
[2025-05-08T19:39:46.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:46.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[349] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:46.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 10.0 in stage 69.0 (TID 153) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.522+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 152) in 31 ms on 172.20.0.5 (executor 0) (7/41)
[2025-05-08T19:39:46.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 109.7 KiB, free 431.9 MiB)
[2025-05-08T19:39:46.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 40.0 KiB, free 431.8 MiB)
[2025-05-08T19:39:46.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on f2a432e4376a:35283 (size: 40.0 KiB, free: 434.2 MiB)
[2025-05-08T19:39:46.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:46.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[349] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:46.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSchedulerImpl: Adding task set 71.0 with 41 tasks resource profile 0
[2025-05-08T19:39:46.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 11.0 in stage 69.0 (TID 154) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 10.0 in stage 69.0 (TID 153) in 33 ms on 172.20.0.5 (executor 0) (8/41)
[2025-05-08T19:39:46.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.20.0.5:59376
[2025-05-08T19:39:46.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 12.0 in stage 69.0 (TID 155) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 11.0 in stage 69.0 (TID 154) in 53 ms on 172.20.0.5 (executor 0) (9/41)
[2025-05-08T19:39:46.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 13.0 in stage 69.0 (TID 156) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 12.0 in stage 69.0 (TID 155) in 36 ms on 172.20.0.5 (executor 0) (10/41)
[2025-05-08T19:39:46.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 14.0 in stage 69.0 (TID 157) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 13.0 in stage 69.0 (TID 156) in 43 ms on 172.20.0.5 (executor 0) (11/41)
[2025-05-08T19:39:46.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 15.0 in stage 69.0 (TID 158) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.730+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 14.0 in stage 69.0 (TID 157) in 48 ms on 172.20.0.5 (executor 0) (12/41)
[2025-05-08T19:39:46.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 16.0 in stage 69.0 (TID 159) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 15.0 in stage 69.0 (TID 158) in 43 ms on 172.20.0.5 (executor 0) (13/41)
[2025-05-08T19:39:46.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 17.0 in stage 69.0 (TID 160) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 16.0 in stage 69.0 (TID 159) in 47 ms on 172.20.0.5 (executor 0) (14/41)
[2025-05-08T19:39:46.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 18.0 in stage 69.0 (TID 161) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 17.0 in stage 69.0 (TID 160) in 38 ms on 172.20.0.5 (executor 0) (15/41)
[2025-05-08T19:39:46.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 19.0 in stage 69.0 (TID 162) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 18.0 in stage 69.0 (TID 161) in 38 ms on 172.20.0.5 (executor 0) (16/41)
[2025-05-08T19:39:46.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 20.0 in stage 69.0 (TID 163) (172.20.0.5, executor 0, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 19.0 in stage 69.0 (TID 162) in 28 ms on 172.20.0.5 (executor 0) (17/41)
[2025-05-08T19:39:46.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 21.0 in stage 69.0 (TID 164) (172.20.0.5, executor 0, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 20.0 in stage 69.0 (TID 163) in 33 ms on 172.20.0.5 (executor 0) (18/41)
[2025-05-08T19:39:46.959+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.20.0.5:59376
[2025-05-08T19:39:46.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Starting task 22.0 in stage 69.0 (TID 165) (172.20.0.5, executor 0, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:46.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:46 INFO TaskSetManager: Finished task 21.0 in stage 69.0 (TID 164) in 41 ms on 172.20.0.5 (executor 0) (19/41)
[2025-05-08T19:39:47.012+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 23.0 in stage 69.0 (TID 166) (172.20.0.5, executor 0, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 22.0 in stage 69.0 (TID 165) in 22 ms on 172.20.0.5 (executor 0) (20/41)
[2025-05-08T19:39:47.035+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 24.0 in stage 69.0 (TID 167) (172.20.0.5, executor 0, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.036+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 23.0 in stage 69.0 (TID 166) in 23 ms on 172.20.0.5 (executor 0) (21/41)
[2025-05-08T19:39:47.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 25.0 in stage 69.0 (TID 168) (172.20.0.5, executor 0, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 24.0 in stage 69.0 (TID 167) in 17 ms on 172.20.0.5 (executor 0) (22/41)
[2025-05-08T19:39:47.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 26.0 in stage 69.0 (TID 169) (172.20.0.5, executor 0, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 25.0 in stage 69.0 (TID 168) in 25 ms on 172.20.0.5 (executor 0) (23/41)
[2025-05-08T19:39:47.101+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 27.0 in stage 69.0 (TID 170) (172.20.0.5, executor 0, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 26.0 in stage 69.0 (TID 169) in 26 ms on 172.20.0.5 (executor 0) (24/41)
[2025-05-08T19:39:47.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 28.0 in stage 69.0 (TID 171) (172.20.0.5, executor 0, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 27.0 in stage 69.0 (TID 170) in 33 ms on 172.20.0.5 (executor 0) (25/41)
[2025-05-08T19:39:47.165+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 29.0 in stage 69.0 (TID 172) (172.20.0.5, executor 0, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.165+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 28.0 in stage 69.0 (TID 171) in 33 ms on 172.20.0.5 (executor 0) (26/41)
[2025-05-08T19:39:47.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 30.0 in stage 69.0 (TID 173) (172.20.0.5, executor 0, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 29.0 in stage 69.0 (TID 172) in 28 ms on 172.20.0.5 (executor 0) (27/41)
[2025-05-08T19:39:47.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 31.0 in stage 69.0 (TID 174) (172.20.0.5, executor 0, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 30.0 in stage 69.0 (TID 173) in 20 ms on 172.20.0.5 (executor 0) (28/41)
[2025-05-08T19:39:47.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:59376
[2025-05-08T19:39:47.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 32.0 in stage 69.0 (TID 175) (172.20.0.5, executor 0, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 31.0 in stage 69.0 (TID 174) in 29 ms on 172.20.0.5 (executor 0) (29/41)
[2025-05-08T19:39:47.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 33.0 in stage 69.0 (TID 176) (172.20.0.5, executor 0, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 32.0 in stage 69.0 (TID 175) in 16 ms on 172.20.0.5 (executor 0) (30/41)
[2025-05-08T19:39:47.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 34.0 in stage 69.0 (TID 177) (172.20.0.5, executor 0, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 33.0 in stage 69.0 (TID 176) in 16 ms on 172.20.0.5 (executor 0) (31/41)
[2025-05-08T19:39:47.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 35.0 in stage 69.0 (TID 178) (172.20.0.5, executor 0, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 34.0 in stage 69.0 (TID 177) in 17 ms on 172.20.0.5 (executor 0) (32/41)
[2025-05-08T19:39:47.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 36.0 in stage 69.0 (TID 179) (172.20.0.5, executor 0, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 35.0 in stage 69.0 (TID 178) in 18 ms on 172.20.0.5 (executor 0) (33/41)
[2025-05-08T19:39:47.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 37.0 in stage 69.0 (TID 180) (172.20.0.5, executor 0, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 36.0 in stage 69.0 (TID 179) in 16 ms on 172.20.0.5 (executor 0) (34/41)
[2025-05-08T19:39:47.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 38.0 in stage 69.0 (TID 181) (172.20.0.5, executor 0, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 37.0 in stage 69.0 (TID 180) in 17 ms on 172.20.0.5 (executor 0) (35/41)
[2025-05-08T19:39:47.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 39.0 in stage 69.0 (TID 182) (172.20.0.5, executor 0, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 38.0 in stage 69.0 (TID 181) in 16 ms on 172.20.0.5 (executor 0) (36/41)
[2025-05-08T19:39:47.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 40.0 in stage 69.0 (TID 183) (172.20.0.5, executor 0, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 39.0 in stage 69.0 (TID 182) in 15 ms on 172.20.0.5 (executor 0) (37/41)
[2025-05-08T19:39:47.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 184) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 40.0 in stage 69.0 (TID 183) in 15 ms on 172.20.0.5 (executor 0) (38/41)
[2025-05-08T19:39:47.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 185) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 184) in 38 ms on 172.20.0.5 (executor 0) (39/41)
[2025-05-08T19:39:47.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 186) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 185) in 13 ms on 172.20.0.5 (executor 0) (40/41)
[2025-05-08T19:39:47.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 187) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 186) in 13 ms on 172.20.0.5 (executor 0) (41/41)
[2025-05-08T19:39:47.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-08T19:39:47.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: ShuffleMapStage 69 (rdd at GraphFrame.scala:188) finished in 1.631 s
[2025-05-08T19:39:47.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:47.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: running: Set(ShuffleMapStage 70, ShuffleMapStage 71)
[2025-05-08T19:39:47.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:47.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:47.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.20.0.5:37427 (size: 40.1 KiB, free: 434.3 MiB)
[2025-05-08T19:39:47.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO ShufflePartitionsUtil: For shuffle(29), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:47.496+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO CodeGenerator: Code generated in 15.493663 ms
[2025-05-08T19:39:47.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 188) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.536+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 187) in 90 ms on 172.20.0.5 (executor 0) (1/41)
[2025-05-08T19:39:47.563+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:47.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T19:39:47.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: Final stage: ResultStage 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T19:39:47.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
[2025-05-08T19:39:47.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:47.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[353] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T19:39:47.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 189) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 188) in 43 ms on 172.20.0.5 (executor 0) (2/41)
[2025-05-08T19:39:47.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 80.4 KiB, free 431.8 MiB)
[2025-05-08T19:39:47.581+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 431.7 MiB)
[2025-05-08T19:39:47.583+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on f2a432e4376a:35283 (size: 31.0 KiB, free: 434.2 MiB)
[2025-05-08T19:39:47.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:47.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[353] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:47.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
[2025-05-08T19:39:47.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 190) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 189) in 22 ms on 172.20.0.5 (executor 0) (3/41)
[2025-05-08T19:39:47.618+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 191) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.618+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 190) in 26 ms on 172.20.0.5 (executor 0) (4/41)
[2025-05-08T19:39:47.656+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 192) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 191) in 40 ms on 172.20.0.5 (executor 0) (5/41)
[2025-05-08T19:39:47.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 193) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 192) in 34 ms on 172.20.0.5 (executor 0) (6/41)
[2025-05-08T19:39:47.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 10.0 in stage 70.0 (TID 194) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 193) in 17 ms on 172.20.0.5 (executor 0) (7/41)
[2025-05-08T19:39:47.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 11.0 in stage 70.0 (TID 195) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 10.0 in stage 70.0 (TID 194) in 15 ms on 172.20.0.5 (executor 0) (8/41)
[2025-05-08T19:39:47.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 12.0 in stage 70.0 (TID 196) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 11.0 in stage 70.0 (TID 195) in 41 ms on 172.20.0.5 (executor 0) (9/41)
[2025-05-08T19:39:47.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 13.0 in stage 70.0 (TID 197) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 12.0 in stage 70.0 (TID 196) in 20 ms on 172.20.0.5 (executor 0) (10/41)
[2025-05-08T19:39:47.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 14.0 in stage 70.0 (TID 198) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 13.0 in stage 70.0 (TID 197) in 23 ms on 172.20.0.5 (executor 0) (11/41)
[2025-05-08T19:39:47.829+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 15.0 in stage 70.0 (TID 199) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.829+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 14.0 in stage 70.0 (TID 198) in 27 ms on 172.20.0.5 (executor 0) (12/41)
[2025-05-08T19:39:47.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 16.0 in stage 70.0 (TID 200) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 15.0 in stage 70.0 (TID 199) in 22 ms on 172.20.0.5 (executor 0) (13/41)
[2025-05-08T19:39:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 17.0 in stage 70.0 (TID 201) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 16.0 in stage 70.0 (TID 200) in 18 ms on 172.20.0.5 (executor 0) (14/41)
[2025-05-08T19:39:47.886+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 18.0 in stage 70.0 (TID 202) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.886+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 17.0 in stage 70.0 (TID 201) in 18 ms on 172.20.0.5 (executor 0) (15/41)
[2025-05-08T19:39:47.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 19.0 in stage 70.0 (TID 203) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 18.0 in stage 70.0 (TID 202) in 21 ms on 172.20.0.5 (executor 0) (16/41)
[2025-05-08T19:39:47.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 20.0 in stage 70.0 (TID 204) (172.20.0.5, executor 0, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 19.0 in stage 70.0 (TID 203) in 29 ms on 172.20.0.5 (executor 0) (17/41)
[2025-05-08T19:39:47.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 21.0 in stage 70.0 (TID 205) (172.20.0.5, executor 0, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.958+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 20.0 in stage 70.0 (TID 204) in 21 ms on 172.20.0.5 (executor 0) (18/41)
[2025-05-08T19:39:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Starting task 22.0 in stage 70.0 (TID 206) (172.20.0.5, executor 0, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:47.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:47 INFO TaskSetManager: Finished task 21.0 in stage 70.0 (TID 205) in 29 ms on 172.20.0.5 (executor 0) (19/41)
[2025-05-08T19:39:48.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 23.0 in stage 70.0 (TID 207) (172.20.0.5, executor 0, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 22.0 in stage 70.0 (TID 206) in 16 ms on 172.20.0.5 (executor 0) (20/41)
[2025-05-08T19:39:48.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 24.0 in stage 70.0 (TID 208) (172.20.0.5, executor 0, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 23.0 in stage 70.0 (TID 207) in 15 ms on 172.20.0.5 (executor 0) (21/41)
[2025-05-08T19:39:48.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 25.0 in stage 70.0 (TID 209) (172.20.0.5, executor 0, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 24.0 in stage 70.0 (TID 208) in 13 ms on 172.20.0.5 (executor 0) (22/41)
[2025-05-08T19:39:48.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 26.0 in stage 70.0 (TID 210) (172.20.0.5, executor 0, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 25.0 in stage 70.0 (TID 209) in 15 ms on 172.20.0.5 (executor 0) (23/41)
[2025-05-08T19:39:48.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 27.0 in stage 70.0 (TID 211) (172.20.0.5, executor 0, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 26.0 in stage 70.0 (TID 210) in 15 ms on 172.20.0.5 (executor 0) (24/41)
[2025-05-08T19:39:48.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 28.0 in stage 70.0 (TID 212) (172.20.0.5, executor 0, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 27.0 in stage 70.0 (TID 211) in 14 ms on 172.20.0.5 (executor 0) (25/41)
[2025-05-08T19:39:48.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 29.0 in stage 70.0 (TID 213) (172.20.0.5, executor 0, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 28.0 in stage 70.0 (TID 212) in 15 ms on 172.20.0.5 (executor 0) (26/41)
[2025-05-08T19:39:48.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 30.0 in stage 70.0 (TID 214) (172.20.0.5, executor 0, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 29.0 in stage 70.0 (TID 213) in 14 ms on 172.20.0.5 (executor 0) (27/41)
[2025-05-08T19:39:48.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 31.0 in stage 70.0 (TID 215) (172.20.0.5, executor 0, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 30.0 in stage 70.0 (TID 214) in 14 ms on 172.20.0.5 (executor 0) (28/41)
[2025-05-08T19:39:48.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 32.0 in stage 70.0 (TID 216) (172.20.0.5, executor 0, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 31.0 in stage 70.0 (TID 215) in 28 ms on 172.20.0.5 (executor 0) (29/41)
[2025-05-08T19:39:48.154+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 33.0 in stage 70.0 (TID 217) (172.20.0.5, executor 0, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.154+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 32.0 in stage 70.0 (TID 216) in 16 ms on 172.20.0.5 (executor 0) (30/41)
[2025-05-08T19:39:48.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 34.0 in stage 70.0 (TID 218) (172.20.0.5, executor 0, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 33.0 in stage 70.0 (TID 217) in 13 ms on 172.20.0.5 (executor 0) (31/41)
[2025-05-08T19:39:48.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 35.0 in stage 70.0 (TID 219) (172.20.0.5, executor 0, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 34.0 in stage 70.0 (TID 218) in 13 ms on 172.20.0.5 (executor 0) (32/41)
[2025-05-08T19:39:48.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 36.0 in stage 70.0 (TID 220) (172.20.0.5, executor 0, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 35.0 in stage 70.0 (TID 219) in 11 ms on 172.20.0.5 (executor 0) (33/41)
[2025-05-08T19:39:48.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 37.0 in stage 70.0 (TID 221) (172.20.0.5, executor 0, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 36.0 in stage 70.0 (TID 220) in 17 ms on 172.20.0.5 (executor 0) (34/41)
[2025-05-08T19:39:48.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 38.0 in stage 70.0 (TID 222) (172.20.0.5, executor 0, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 37.0 in stage 70.0 (TID 221) in 19 ms on 172.20.0.5 (executor 0) (35/41)
[2025-05-08T19:39:48.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 39.0 in stage 70.0 (TID 223) (172.20.0.5, executor 0, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 38.0 in stage 70.0 (TID 222) in 18 ms on 172.20.0.5 (executor 0) (36/41)
[2025-05-08T19:39:48.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 40.0 in stage 70.0 (TID 224) (172.20.0.5, executor 0, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 39.0 in stage 70.0 (TID 223) in 23 ms on 172.20.0.5 (executor 0) (37/41)
[2025-05-08T19:39:48.287+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 225) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 40.0 in stage 70.0 (TID 224) in 24 ms on 172.20.0.5 (executor 0) (38/41)
[2025-05-08T19:39:48.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 226) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.349+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 225) in 61 ms on 172.20.0.5 (executor 0) (39/41)
[2025-05-08T19:39:48.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 227) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.358+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 226) in 9 ms on 172.20.0.5 (executor 0) (40/41)
[2025-05-08T19:39:48.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 228) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 227) in 11 ms on 172.20.0.5 (executor 0) (41/41)
[2025-05-08T19:39:48.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-08T19:39:48.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: ShuffleMapStage 70 (rdd at GraphFrame.scala:188) finished in 2.245 s
[2025-05-08T19:39:48.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:48.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: running: Set(ShuffleMapStage 71, ResultStage 73)
[2025-05-08T19:39:48.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:48.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:48.375+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.20.0.5:37427 (size: 40.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:48.381+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:48.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:48.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:48.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:48.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO CodeGenerator: Code generated in 18.572698 ms
[2025-05-08T19:39:48.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: Registering RDD 356 (rdd at GraphFrame.scala:188) as input to shuffle 32
[2025-05-08T19:39:48.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: Got map stage job 29 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T19:39:48.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: Final stage: ShuffleMapStage 75 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:48.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
[2025-05-08T19:39:48.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:48.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[356] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:48.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 89.7 KiB, free 431.6 MiB)
[2025-05-08T19:39:48.440+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 431.6 MiB)
[2025-05-08T19:39:48.441+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on f2a432e4376a:35283 (size: 33.1 KiB, free: 434.1 MiB)
[2025-05-08T19:39:48.441+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:48.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[356] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:48.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
[2025-05-08T19:39:48.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 229) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 228) in 84 ms on 172.20.0.5 (executor 0) (1/41)
[2025-05-08T19:39:48.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 230) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 229) in 28 ms on 172.20.0.5 (executor 0) (2/41)
[2025-05-08T19:39:48.492+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 231) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 230) in 17 ms on 172.20.0.5 (executor 0) (3/41)
[2025-05-08T19:39:48.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 232) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 231) in 22 ms on 172.20.0.5 (executor 0) (4/41)
[2025-05-08T19:39:48.550+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 8.0 in stage 71.0 (TID 233) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.550+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 232) in 37 ms on 172.20.0.5 (executor 0) (5/41)
[2025-05-08T19:39:48.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 9.0 in stage 71.0 (TID 234) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 8.0 in stage 71.0 (TID 233) in 36 ms on 172.20.0.5 (executor 0) (6/41)
[2025-05-08T19:39:48.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 10.0 in stage 71.0 (TID 235) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 9.0 in stage 71.0 (TID 234) in 20 ms on 172.20.0.5 (executor 0) (7/41)
[2025-05-08T19:39:48.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 11.0 in stage 71.0 (TID 236) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.624+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 10.0 in stage 71.0 (TID 235) in 18 ms on 172.20.0.5 (executor 0) (8/41)
[2025-05-08T19:39:48.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 12.0 in stage 71.0 (TID 237) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 11.0 in stage 71.0 (TID 236) in 40 ms on 172.20.0.5 (executor 0) (9/41)
[2025-05-08T19:39:48.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 13.0 in stage 71.0 (TID 238) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 12.0 in stage 71.0 (TID 237) in 19 ms on 172.20.0.5 (executor 0) (10/41)
[2025-05-08T19:39:48.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 14.0 in stage 71.0 (TID 239) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 13.0 in stage 71.0 (TID 238) in 21 ms on 172.20.0.5 (executor 0) (11/41)
[2025-05-08T19:39:48.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 15.0 in stage 71.0 (TID 240) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 14.0 in stage 71.0 (TID 239) in 20 ms on 172.20.0.5 (executor 0) (12/41)
[2025-05-08T19:39:48.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 16.0 in stage 71.0 (TID 241) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 15.0 in stage 71.0 (TID 240) in 20 ms on 172.20.0.5 (executor 0) (13/41)
[2025-05-08T19:39:48.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 17.0 in stage 71.0 (TID 242) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 16.0 in stage 71.0 (TID 241) in 19 ms on 172.20.0.5 (executor 0) (14/41)
[2025-05-08T19:39:48.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 18.0 in stage 71.0 (TID 243) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 17.0 in stage 71.0 (TID 242) in 17 ms on 172.20.0.5 (executor 0) (15/41)
[2025-05-08T19:39:48.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 19.0 in stage 71.0 (TID 244) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 18.0 in stage 71.0 (TID 243) in 20 ms on 172.20.0.5 (executor 0) (16/41)
[2025-05-08T19:39:48.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 20.0 in stage 71.0 (TID 245) (172.20.0.5, executor 0, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.822+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 19.0 in stage 71.0 (TID 244) in 29 ms on 172.20.0.5 (executor 0) (17/41)
[2025-05-08T19:39:48.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 21.0 in stage 71.0 (TID 246) (172.20.0.5, executor 0, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 20.0 in stage 71.0 (TID 245) in 48 ms on 172.20.0.5 (executor 0) (18/41)
[2025-05-08T19:39:48.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 22.0 in stage 71.0 (TID 247) (172.20.0.5, executor 0, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 21.0 in stage 71.0 (TID 246) in 30 ms on 172.20.0.5 (executor 0) (19/41)
[2025-05-08T19:39:48.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 23.0 in stage 71.0 (TID 248) (172.20.0.5, executor 0, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 22.0 in stage 71.0 (TID 247) in 15 ms on 172.20.0.5 (executor 0) (20/41)
[2025-05-08T19:39:48.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 24.0 in stage 71.0 (TID 249) (172.20.0.5, executor 0, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 23.0 in stage 71.0 (TID 248) in 14 ms on 172.20.0.5 (executor 0) (21/41)
[2025-05-08T19:39:48.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 25.0 in stage 71.0 (TID 250) (172.20.0.5, executor 0, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 24.0 in stage 71.0 (TID 249) in 13 ms on 172.20.0.5 (executor 0) (22/41)
[2025-05-08T19:39:48.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 26.0 in stage 71.0 (TID 251) (172.20.0.5, executor 0, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 25.0 in stage 71.0 (TID 250) in 15 ms on 172.20.0.5 (executor 0) (23/41)
[2025-05-08T19:39:48.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 27.0 in stage 71.0 (TID 252) (172.20.0.5, executor 0, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 26.0 in stage 71.0 (TID 251) in 14 ms on 172.20.0.5 (executor 0) (24/41)
[2025-05-08T19:39:48.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 28.0 in stage 71.0 (TID 253) (172.20.0.5, executor 0, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 27.0 in stage 71.0 (TID 252) in 17 ms on 172.20.0.5 (executor 0) (25/41)
[2025-05-08T19:39:48.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Starting task 29.0 in stage 71.0 (TID 254) (172.20.0.5, executor 0, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:48.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:48 INFO TaskSetManager: Finished task 28.0 in stage 71.0 (TID 253) in 12 ms on 172.20.0.5 (executor 0) (26/41)
[2025-05-08T19:39:49.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 30.0 in stage 71.0 (TID 255) (172.20.0.5, executor 0, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 29.0 in stage 71.0 (TID 254) in 14 ms on 172.20.0.5 (executor 0) (27/41)
[2025-05-08T19:39:49.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 31.0 in stage 71.0 (TID 256) (172.20.0.5, executor 0, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.026+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 30.0 in stage 71.0 (TID 255) in 17 ms on 172.20.0.5 (executor 0) (28/41)
[2025-05-08T19:39:49.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 32.0 in stage 71.0 (TID 257) (172.20.0.5, executor 0, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.049+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 31.0 in stage 71.0 (TID 256) in 24 ms on 172.20.0.5 (executor 0) (29/41)
[2025-05-08T19:39:49.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 33.0 in stage 71.0 (TID 258) (172.20.0.5, executor 0, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 32.0 in stage 71.0 (TID 257) in 12 ms on 172.20.0.5 (executor 0) (30/41)
[2025-05-08T19:39:49.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 34.0 in stage 71.0 (TID 259) (172.20.0.5, executor 0, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 33.0 in stage 71.0 (TID 258) in 14 ms on 172.20.0.5 (executor 0) (31/41)
[2025-05-08T19:39:49.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 35.0 in stage 71.0 (TID 260) (172.20.0.5, executor 0, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 34.0 in stage 71.0 (TID 259) in 14 ms on 172.20.0.5 (executor 0) (32/41)
[2025-05-08T19:39:49.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 36.0 in stage 71.0 (TID 261) (172.20.0.5, executor 0, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 35.0 in stage 71.0 (TID 260) in 15 ms on 172.20.0.5 (executor 0) (33/41)
[2025-05-08T19:39:49.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 37.0 in stage 71.0 (TID 262) (172.20.0.5, executor 0, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 36.0 in stage 71.0 (TID 261) in 15 ms on 172.20.0.5 (executor 0) (34/41)
[2025-05-08T19:39:49.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 38.0 in stage 71.0 (TID 263) (172.20.0.5, executor 0, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 37.0 in stage 71.0 (TID 262) in 13 ms on 172.20.0.5 (executor 0) (35/41)
[2025-05-08T19:39:49.141+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 39.0 in stage 71.0 (TID 264) (172.20.0.5, executor 0, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 38.0 in stage 71.0 (TID 263) in 14 ms on 172.20.0.5 (executor 0) (36/41)
[2025-05-08T19:39:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 40.0 in stage 71.0 (TID 265) (172.20.0.5, executor 0, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 39.0 in stage 71.0 (TID 264) in 21 ms on 172.20.0.5 (executor 0) (37/41)
[2025-05-08T19:39:49.195+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 266) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.196+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 40.0 in stage 71.0 (TID 265) in 33 ms on 172.20.0.5 (executor 0) (38/41)
[2025-05-08T19:39:49.246+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 267) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.246+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 266) in 51 ms on 172.20.0.5 (executor 0) (39/41)
[2025-05-08T19:39:49.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 268) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 267) in 27 ms on 172.20.0.5 (executor 0) (40/41)
[2025-05-08T19:39:49.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.20.0.5:37427 in memory (size: 40.1 KiB, free: 434.3 MiB)
[2025-05-08T19:39:49.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_27_piece0 on f2a432e4376a:35283 in memory (size: 40.1 KiB, free: 434.2 MiB)
[2025-05-08T19:39:49.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_26_piece0 on f2a432e4376a:35283 in memory (size: 33.1 KiB, free: 434.2 MiB)
[2025-05-08T19:39:49.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.20.0.5:37427 in memory (size: 33.1 KiB, free: 434.4 MiB)
[2025-05-08T19:39:49.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 269) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 268) in 14 ms on 172.20.0.5 (executor 0) (41/41)
[2025-05-08T19:39:49.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-08T19:39:49.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: ShuffleMapStage 71 (rdd at GraphFrame.scala:188) finished in 2.764 s
[2025-05-08T19:39:49.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:49.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: running: Set(ShuffleMapStage 75, ResultStage 73)
[2025-05-08T19:39:49.287+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:49.287+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:49.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.20.0.5:37427 (size: 31.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:49.297+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:49.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:49.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:59376
[2025-05-08T19:39:49.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:49.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:49.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO CodeGenerator: Code generated in 12.438733 ms
[2025-05-08T19:39:49.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Registering RDD 359 (rdd at GraphFrame.scala:188) as input to shuffle 33
[2025-05-08T19:39:49.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Got map stage job 30 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-08T19:39:49.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Final stage: ShuffleMapStage 77 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:49.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
[2025-05-08T19:39:49.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:49.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[359] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:49.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 89.5 KiB, free 431.8 MiB)
[2025-05-08T19:39:49.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 33.1 KiB, free 431.8 MiB)
[2025-05-08T19:39:49.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on f2a432e4376a:35283 (size: 33.1 KiB, free: 434.2 MiB)
[2025-05-08T19:39:49.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:49.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[359] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:49.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0
[2025-05-08T19:39:49.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 270) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 269) in 162 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:49.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool
[2025-05-08T19:39:49.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: ResultStage 73 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.879 s
[2025-05-08T19:39:49.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:49.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
[2025-05-08T19:39:49.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.886191 s
[2025-05-08T19:39:49.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.20.0.5:37427 (size: 33.1 KiB, free: 434.3 MiB)
[2025-05-08T19:39:49.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:59376
[2025-05-08T19:39:49.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 4.5 MiB, free 427.3 MiB)
[2025-05-08T19:39:49.550+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 586.3 KiB, free 426.7 MiB)
[2025-05-08T19:39:49.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on f2a432e4376a:35283 (size: 586.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:49.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO SparkContext: Created broadcast 32 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:49.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 271) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 270) in 119 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:49.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-05-08T19:39:49.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: ShuffleMapStage 75 (rdd at GraphFrame.scala:188) finished in 1.132 s
[2025-05-08T19:39:49.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:49.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: running: Set(ShuffleMapStage 77)
[2025-05-08T19:39:49.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:49.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:49.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.20.0.5:37427 (size: 33.1 KiB, free: 434.3 MiB)
[2025-05-08T19:39:49.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:59376
[2025-05-08T19:39:49.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 271) in 107 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:49.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-05-08T19:39:49.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: ShuffleMapStage 77 (rdd at GraphFrame.scala:188) finished in 0.344 s
[2025-05-08T19:39:49.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:49.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:49.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:49.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:49.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO ShufflePartitionsUtil: For shuffle(32, 33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:49.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO ShufflePartitionsUtil: For shuffle(32, 33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:49.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:49.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO CodeGenerator: Code generated in 5.953046 ms
[2025-05-08T19:39:49.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:49.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO CodeGenerator: Code generated in 5.633962 ms
[2025-05-08T19:39:49.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:49.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO CodeGenerator: Code generated in 6.760593 ms
[2025-05-08T19:39:49.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Registering RDD 366 (rdd at GraphFrame.scala:188) as input to shuffle 34
[2025-05-08T19:39:49.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Got map stage job 31 (rdd at GraphFrame.scala:188) with 2 output partitions
[2025-05-08T19:39:49.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Final stage: ShuffleMapStage 86 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:49.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84, ShuffleMapStage 85)
[2025-05-08T19:39:49.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:49.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[366] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:49.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 130.1 KiB, free 426.6 MiB)
[2025-05-08T19:39:49.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 48.3 KiB, free 426.5 MiB)
[2025-05-08T19:39:49.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on f2a432e4376a:35283 (size: 48.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:49.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:49.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[366] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1))
[2025-05-08T19:39:49.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks resource profile 0
[2025-05-08T19:39:49.741+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 272) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.20.0.5:37427 (size: 48.3 KiB, free: 434.2 MiB)
[2025-05-08T19:39:49.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:59376
[2025-05-08T19:39:49.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_29_piece0 on f2a432e4376a:35283 in memory (size: 31.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:49.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.20.0.5:37427 in memory (size: 31.0 KiB, free: 434.2 MiB)
[2025-05-08T19:39:49.775+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_30_piece0 on f2a432e4376a:35283 in memory (size: 33.1 KiB, free: 433.6 MiB)
[2025-05-08T19:39:49.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.20.0.5:37427 in memory (size: 33.1 KiB, free: 434.3 MiB)
[2025-05-08T19:39:49.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_28_piece0 on f2a432e4376a:35283 in memory (size: 40.0 KiB, free: 433.7 MiB)
[2025-05-08T19:39:49.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.20.0.5:37427 in memory (size: 40.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:49.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_31_piece0 on f2a432e4376a:35283 in memory (size: 33.1 KiB, free: 433.7 MiB)
[2025-05-08T19:39:49.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.20.0.5:37427 in memory (size: 33.1 KiB, free: 434.4 MiB)
[2025-05-08T19:39:49.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 273) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 272) in 74 ms on 172.20.0.5 (executor 0) (1/2)
[2025-05-08T19:39:49.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:59376
[2025-05-08T19:39:49.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 273) in 54 ms on 172.20.0.5 (executor 0) (2/2)
[2025-05-08T19:39:49.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool
[2025-05-08T19:39:49.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: ShuffleMapStage 86 (rdd at GraphFrame.scala:188) finished in 0.140 s
[2025-05-08T19:39:49.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:49.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:49.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:49.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:49.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:49.884+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:49.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T19:39:49.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO CodeGenerator: Code generated in 13.355503 ms
[2025-05-08T19:39:49.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:49.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Got job 32 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T19:39:49.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Final stage: ResultStage 96 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T19:39:49.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
[2025-05-08T19:39:49.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:49.937+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[369] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T19:39:49.941+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 123.6 KiB, free 426.9 MiB)
[2025-05-08T19:39:49.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 42.2 KiB, free 426.8 MiB)
[2025-05-08T19:39:49.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on f2a432e4376a:35283 (size: 42.2 KiB, free: 433.6 MiB)
[2025-05-08T19:39:49.947+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:49.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[369] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:49.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
[2025-05-08T19:39:49.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 274) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:49.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.20.0.5:37427 (size: 42.2 KiB, free: 434.3 MiB)
[2025-05-08T19:39:49.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:59376
[2025-05-08T19:39:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 274) in 41 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:49.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-05-08T19:39:49.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: ResultStage 96 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.056 s
[2025-05-08T19:39:49.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:49.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished
[2025-05-08T19:39:49.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO DAGScheduler: Job 32 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.063070 s
[2025-05-08T19:39:49.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:49 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.1 MiB, free 424.8 MiB)
[2025-05-08T19:39:50.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 80.3 KiB, free 424.7 MiB)
[2025-05-08T19:39:50.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on f2a432e4376a:35283 (size: 80.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:50.033+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO CodeGenerator: Code generated in 13.224462 ms
[2025-05-08T19:39:50.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#1729) generates partition filter: ((id.count#2603 - id.nullCount#2602) > 0)
[2025-05-08T19:39:50.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 121 (rdd at GraphFrame.scala:187) as input to shuffle 11
[2025-05-08T19:39:50.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 129 (rdd at GraphFrame.scala:187) as input to shuffle 12
[2025-05-08T19:39:50.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 137 (rdd at GraphFrame.scala:187) as input to shuffle 13
[2025-05-08T19:39:50.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 145 (rdd at GraphFrame.scala:187) as input to shuffle 14
[2025-05-08T19:39:50.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 153 (rdd at GraphFrame.scala:187) as input to shuffle 15
[2025-05-08T19:39:50.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 156 (rdd at GraphFrame.scala:187) as input to shuffle 16
[2025-05-08T19:39:50.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 160 (rdd at GraphFrame.scala:187) as input to shuffle 17
[2025-05-08T19:39:50.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 165 (rdd at GraphFrame.scala:187) as input to shuffle 18
[2025-05-08T19:39:50.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Registering RDD 374 (rdd at GraphFrame.scala:188) as input to shuffle 35
[2025-05-08T19:39:50.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-08T19:39:50.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Final stage: ShuffleMapStage 105 (rdd at GraphFrame.scala:188)
[2025-05-08T19:39:50.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
[2025-05-08T19:39:50.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
[2025-05-08T19:39:50.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:50.046+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 23.9 KiB, free 424.7 MiB)
[2025-05-08T19:39:50.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 424.7 MiB)
[2025-05-08T19:39:50.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:50.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:50.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0
[2025-05-08T19:39:50.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_34_piece0 on f2a432e4376a:35283 in memory (size: 42.2 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:50.067+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 275) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.068+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 22.4 KiB, free 424.8 MiB)
[2025-05-08T19:39:50.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 424.8 MiB)
[2025-05-08T19:39:50.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:50.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:50.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
[2025-05-08T19:39:50.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.20.0.5:37427 in memory (size: 42.2 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting ShuffleMapStage 99 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:50.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 22.4 KiB, free 424.8 MiB)
[2025-05-08T19:39:50.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 424.8 MiB)
[2025-05-08T19:39:50.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:50.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 99 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:50.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
[2025-05-08T19:39:50.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:50.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T19:39:50.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 28.8 KiB, free 424.8 MiB)
[2025-05-08T19:39:50.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_33_piece0 on f2a432e4376a:35283 in memory (size: 48.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 424.9 MiB)
[2025-05-08T19:39:50.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.20.0.5:37427 in memory (size: 48.3 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:50.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:50.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
[2025-05-08T19:39:50.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 276) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 275) in 71 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:50.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool
[2025-05-08T19:39:50.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: ShuffleMapStage 97 (rdd at GraphFrame.scala:187) finished in 0.093 s
[2025-05-08T19:39:50.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:50.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: running: Set(ShuffleMapStage 99, ShuffleMapStage 100, ShuffleMapStage 98)
[2025-05-08T19:39:50.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ShuffleMapStage 103, ShuffleMapStage 104, ShuffleMapStage 101, ShuffleMapStage 105)
[2025-05-08T19:39:50.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:50.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 277) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 276) in 53 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:50.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool
[2025-05-08T19:39:50.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: ShuffleMapStage 98 (rdd at GraphFrame.scala:187) finished in 0.124 s
[2025-05-08T19:39:50.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:50.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: running: Set(ShuffleMapStage 99, ShuffleMapStage 100)
[2025-05-08T19:39:50.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ShuffleMapStage 103, ShuffleMapStage 104, ShuffleMapStage 101, ShuffleMapStage 105)
[2025-05-08T19:39:50.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:50.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 278) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 277) in 45 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:50.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-05-08T19:39:50.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: ShuffleMapStage 99 (rdd at GraphFrame.scala:187) finished in 0.164 s
[2025-05-08T19:39:50.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:50.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: running: Set(ShuffleMapStage 100)
[2025-05-08T19:39:50.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ShuffleMapStage 103, ShuffleMapStage 104, ShuffleMapStage 101, ShuffleMapStage 105)
[2025-05-08T19:39:50.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:50.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.20.0.5:37427 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.287+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 278) in 52 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:50.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-05-08T19:39:50.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: ShuffleMapStage 100 (rdd at GraphFrame.scala:187) finished in 0.205 s
[2025-05-08T19:39:50.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:50.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:50.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ShuffleMapStage 103, ShuffleMapStage 104, ShuffleMapStage 101, ShuffleMapStage 105)
[2025-05-08T19:39:50.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:50.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:50.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 96.7 KiB, free 424.8 MiB)
[2025-05-08T19:39:50.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 424.8 MiB)
[2025-05-08T19:39:50.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_37_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on f2a432e4376a:35283 (size: 36.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:50.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:50.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSchedulerImpl: Adding task set 101.0 with 41 tasks resource profile 0
[2025-05-08T19:39:50.328+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 279) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_36_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.20.0.5:37427 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_38_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:50.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.20.0.5:37427 (size: 36.3 KiB, free: 434.4 MiB)
[2025-05-08T19:39:50.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:59376
[2025-05-08T19:39:50.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 280) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 279) in 84 ms on 172.20.0.5 (executor 0) (1/41)
[2025-05-08T19:39:50.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 281) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 280) in 29 ms on 172.20.0.5 (executor 0) (2/41)
[2025-05-08T19:39:50.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 6.0 in stage 101.0 (TID 282) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 281) in 14 ms on 172.20.0.5 (executor 0) (3/41)
[2025-05-08T19:39:50.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 7.0 in stage 101.0 (TID 283) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 6.0 in stage 101.0 (TID 282) in 18 ms on 172.20.0.5 (executor 0) (4/41)
[2025-05-08T19:39:50.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 8.0 in stage 101.0 (TID 284) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 7.0 in stage 101.0 (TID 283) in 47 ms on 172.20.0.5 (executor 0) (5/41)
[2025-05-08T19:39:50.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 9.0 in stage 101.0 (TID 285) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 8.0 in stage 101.0 (TID 284) in 23 ms on 172.20.0.5 (executor 0) (6/41)
[2025-05-08T19:39:50.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 10.0 in stage 101.0 (TID 286) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 9.0 in stage 101.0 (TID 285) in 12 ms on 172.20.0.5 (executor 0) (7/41)
[2025-05-08T19:39:50.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 11.0 in stage 101.0 (TID 287) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 10.0 in stage 101.0 (TID 286) in 11 ms on 172.20.0.5 (executor 0) (8/41)
[2025-05-08T19:39:50.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:59376
[2025-05-08T19:39:50.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 12.0 in stage 101.0 (TID 288) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 11.0 in stage 101.0 (TID 287) in 29 ms on 172.20.0.5 (executor 0) (9/41)
[2025-05-08T19:39:50.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 13.0 in stage 101.0 (TID 289) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.603+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 12.0 in stage 101.0 (TID 288) in 15 ms on 172.20.0.5 (executor 0) (10/41)
[2025-05-08T19:39:50.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 14.0 in stage 101.0 (TID 290) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 13.0 in stage 101.0 (TID 289) in 15 ms on 172.20.0.5 (executor 0) (11/41)
[2025-05-08T19:39:50.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 15.0 in stage 101.0 (TID 291) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 14.0 in stage 101.0 (TID 290) in 17 ms on 172.20.0.5 (executor 0) (12/41)
[2025-05-08T19:39:50.648+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 16.0 in stage 101.0 (TID 292) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 15.0 in stage 101.0 (TID 291) in 15 ms on 172.20.0.5 (executor 0) (13/41)
[2025-05-08T19:39:50.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 17.0 in stage 101.0 (TID 293) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 16.0 in stage 101.0 (TID 292) in 17 ms on 172.20.0.5 (executor 0) (14/41)
[2025-05-08T19:39:50.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 18.0 in stage 101.0 (TID 294) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 17.0 in stage 101.0 (TID 293) in 19 ms on 172.20.0.5 (executor 0) (15/41)
[2025-05-08T19:39:50.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 19.0 in stage 101.0 (TID 295) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 18.0 in stage 101.0 (TID 294) in 16 ms on 172.20.0.5 (executor 0) (16/41)
[2025-05-08T19:39:50.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 20.0 in stage 101.0 (TID 296) (172.20.0.5, executor 0, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 19.0 in stage 101.0 (TID 295) in 15 ms on 172.20.0.5 (executor 0) (17/41)
[2025-05-08T19:39:50.737+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 21.0 in stage 101.0 (TID 297) (172.20.0.5, executor 0, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 20.0 in stage 101.0 (TID 296) in 22 ms on 172.20.0.5 (executor 0) (18/41)
[2025-05-08T19:39:50.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:59376
[2025-05-08T19:39:50.769+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 22.0 in stage 101.0 (TID 298) (172.20.0.5, executor 0, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.769+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 21.0 in stage 101.0 (TID 297) in 32 ms on 172.20.0.5 (executor 0) (19/41)
[2025-05-08T19:39:50.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 23.0 in stage 101.0 (TID 299) (172.20.0.5, executor 0, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 22.0 in stage 101.0 (TID 298) in 19 ms on 172.20.0.5 (executor 0) (20/41)
[2025-05-08T19:39:50.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 24.0 in stage 101.0 (TID 300) (172.20.0.5, executor 0, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 23.0 in stage 101.0 (TID 299) in 17 ms on 172.20.0.5 (executor 0) (21/41)
[2025-05-08T19:39:50.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 25.0 in stage 101.0 (TID 301) (172.20.0.5, executor 0, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 24.0 in stage 101.0 (TID 300) in 15 ms on 172.20.0.5 (executor 0) (22/41)
[2025-05-08T19:39:50.832+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 26.0 in stage 101.0 (TID 302) (172.20.0.5, executor 0, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 25.0 in stage 101.0 (TID 301) in 15 ms on 172.20.0.5 (executor 0) (23/41)
[2025-05-08T19:39:50.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 27.0 in stage 101.0 (TID 303) (172.20.0.5, executor 0, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 26.0 in stage 101.0 (TID 302) in 19 ms on 172.20.0.5 (executor 0) (24/41)
[2025-05-08T19:39:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 28.0 in stage 101.0 (TID 304) (172.20.0.5, executor 0, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 27.0 in stage 101.0 (TID 303) in 18 ms on 172.20.0.5 (executor 0) (25/41)
[2025-05-08T19:39:50.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 29.0 in stage 101.0 (TID 305) (172.20.0.5, executor 0, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 28.0 in stage 101.0 (TID 304) in 30 ms on 172.20.0.5 (executor 0) (26/41)
[2025-05-08T19:39:50.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 30.0 in stage 101.0 (TID 306) (172.20.0.5, executor 0, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 29.0 in stage 101.0 (TID 305) in 14 ms on 172.20.0.5 (executor 0) (27/41)
[2025-05-08T19:39:50.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 31.0 in stage 101.0 (TID 307) (172.20.0.5, executor 0, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 30.0 in stage 101.0 (TID 306) in 15 ms on 172.20.0.5 (executor 0) (28/41)
[2025-05-08T19:39:50.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:59376
[2025-05-08T19:39:50.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 32.0 in stage 101.0 (TID 308) (172.20.0.5, executor 0, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 31.0 in stage 101.0 (TID 307) in 16 ms on 172.20.0.5 (executor 0) (29/41)
[2025-05-08T19:39:50.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 33.0 in stage 101.0 (TID 309) (172.20.0.5, executor 0, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 32.0 in stage 101.0 (TID 308) in 13 ms on 172.20.0.5 (executor 0) (30/41)
[2025-05-08T19:39:50.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 34.0 in stage 101.0 (TID 310) (172.20.0.5, executor 0, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 33.0 in stage 101.0 (TID 309) in 11 ms on 172.20.0.5 (executor 0) (31/41)
[2025-05-08T19:39:50.974+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 35.0 in stage 101.0 (TID 311) (172.20.0.5, executor 0, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 34.0 in stage 101.0 (TID 310) in 12 ms on 172.20.0.5 (executor 0) (32/41)
[2025-05-08T19:39:50.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 36.0 in stage 101.0 (TID 312) (172.20.0.5, executor 0, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 35.0 in stage 101.0 (TID 311) in 12 ms on 172.20.0.5 (executor 0) (33/41)
[2025-05-08T19:39:50.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Starting task 37.0 in stage 101.0 (TID 313) (172.20.0.5, executor 0, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:50.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:50 INFO TaskSetManager: Finished task 36.0 in stage 101.0 (TID 312) in 10 ms on 172.20.0.5 (executor 0) (34/41)
[2025-05-08T19:39:51.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 38.0 in stage 101.0 (TID 314) (172.20.0.5, executor 0, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 37.0 in stage 101.0 (TID 313) in 12 ms on 172.20.0.5 (executor 0) (35/41)
[2025-05-08T19:39:51.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 39.0 in stage 101.0 (TID 315) (172.20.0.5, executor 0, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 38.0 in stage 101.0 (TID 314) in 12 ms on 172.20.0.5 (executor 0) (36/41)
[2025-05-08T19:39:51.032+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 40.0 in stage 101.0 (TID 316) (172.20.0.5, executor 0, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.032+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 39.0 in stage 101.0 (TID 315) in 12 ms on 172.20.0.5 (executor 0) (37/41)
[2025-05-08T19:39:51.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 317) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 40.0 in stage 101.0 (TID 316) in 10 ms on 172.20.0.5 (executor 0) (38/41)
[2025-05-08T19:39:51.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 4.0 in stage 101.0 (TID 318) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 317) in 29 ms on 172.20.0.5 (executor 0) (39/41)
[2025-05-08T19:39:51.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 5.0 in stage 101.0 (TID 319) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 4.0 in stage 101.0 (TID 318) in 8 ms on 172.20.0.5 (executor 0) (40/41)
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 5.0 in stage 101.0 (TID 319) in 9 ms on 172.20.0.5 (executor 0) (41/41)
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: ShuffleMapStage 101 (rdd at GraphFrame.scala:187) finished in 0.797 s
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 102, ShuffleMapStage 103, ShuffleMapStage 104, ShuffleMapStage 105)
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:51.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting ShuffleMapStage 102 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:51.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 70.3 KiB, free 424.8 MiB)
[2025-05-08T19:39:51.092+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 424.8 MiB)
[2025-05-08T19:39:51.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on f2a432e4376a:35283 (size: 28.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:51.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:51.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 102 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:51.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Adding task set 102.0 with 10 tasks resource profile 0
[2025-05-08T19:39:51.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:51.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 320) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.096+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 70.6 KiB, free 424.7 MiB)
[2025-05-08T19:39:51.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 28.4 KiB, free 424.7 MiB)
[2025-05-08T19:39:51.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on f2a432e4376a:35283 (size: 28.4 KiB, free: 433.6 MiB)
[2025-05-08T19:39:51.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_39_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 433.6 MiB)
[2025-05-08T19:39:51.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:51.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:51.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.20.0.5:37427 in memory (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T19:39:51.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-08T19:39:51.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.20.0.5:37427 (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T19:39:51.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:59376
[2025-05-08T19:39:51.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 321) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 320) in 58 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:51.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 322) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 321) in 20 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:51.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 323) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 322) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:51.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 4.0 in stage 102.0 (TID 324) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 323) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:51.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 5.0 in stage 102.0 (TID 325) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 4.0 in stage 102.0 (TID 324) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:51.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 6.0 in stage 102.0 (TID 326) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 5.0 in stage 102.0 (TID 325) in 20 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:51.260+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 7.0 in stage 102.0 (TID 327) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.261+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 6.0 in stage 102.0 (TID 326) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:51.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 8.0 in stage 102.0 (TID 328) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 7.0 in stage 102.0 (TID 327) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:51.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 9.0 in stage 102.0 (TID 329) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 8.0 in stage 102.0 (TID 328) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:51.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 330) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 9.0 in stage 102.0 (TID 329) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:51.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool
[2025-05-08T19:39:51.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: ShuffleMapStage 102 (rdd at GraphFrame.scala:187) finished in 0.214 s
[2025-05-08T19:39:51.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:51.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: running: Set(ShuffleMapStage 103)
[2025-05-08T19:39:51.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ShuffleMapStage 105)
[2025-05-08T19:39:51.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:51.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.20.0.5:37427 (size: 28.4 KiB, free: 434.3 MiB)
[2025-05-08T19:39:51.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 331) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 330) in 32 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:51.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 332) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 331) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:51.364+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 333) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 332) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:51.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 334) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 333) in 20 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:51.402+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 335) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 334) in 21 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:51.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 336) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 335) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:51.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 337) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 336) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:51.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 338) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 337) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:51.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 339) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 338) in 21 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:51.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 339) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:51.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-08T19:39:51.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: ShuffleMapStage 103 (rdd at GraphFrame.scala:187) finished in 0.394 s
[2025-05-08T19:39:51.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:51.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:51.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ShuffleMapStage 105)
[2025-05-08T19:39:51.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:51.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:51.524+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 83.7 KiB, free 424.6 MiB)
[2025-05-08T19:39:51.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 32.0 KiB, free 424.6 MiB)
[2025-05-08T19:39:51.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on f2a432e4376a:35283 (size: 32.0 KiB, free: 433.5 MiB)
[2025-05-08T19:39:51.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:51.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting 20 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:39:51.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Adding task set 104.0 with 20 tasks resource profile 0
[2025-05-08T19:39:51.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 340) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.20.0.5:37427 (size: 32.0 KiB, free: 434.3 MiB)
[2025-05-08T19:39:51.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:59376
[2025-05-08T19:39:51.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 341) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 340) in 69 ms on 172.20.0.5 (executor 0) (1/20)
[2025-05-08T19:39:51.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 342) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 341) in 10 ms on 172.20.0.5 (executor 0) (2/20)
[2025-05-08T19:39:51.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 343) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 342) in 12 ms on 172.20.0.5 (executor 0) (3/20)
[2025-05-08T19:39:51.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 344) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 343) in 15 ms on 172.20.0.5 (executor 0) (4/20)
[2025-05-08T19:39:51.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 345) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 344) in 12 ms on 172.20.0.5 (executor 0) (5/20)
[2025-05-08T19:39:51.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 346) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 345) in 10 ms on 172.20.0.5 (executor 0) (6/20)
[2025-05-08T19:39:51.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 347) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 346) in 9 ms on 172.20.0.5 (executor 0) (7/20)
[2025-05-08T19:39:51.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 8.0 in stage 104.0 (TID 348) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 347) in 8 ms on 172.20.0.5 (executor 0) (8/20)
[2025-05-08T19:39:51.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 9.0 in stage 104.0 (TID 349) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.718+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 8.0 in stage 104.0 (TID 348) in 10 ms on 172.20.0.5 (executor 0) (9/20)
[2025-05-08T19:39:51.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 10.0 in stage 104.0 (TID 350) (172.20.0.5, executor 0, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 9.0 in stage 104.0 (TID 349) in 8 ms on 172.20.0.5 (executor 0) (10/20)
[2025-05-08T19:39:51.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:59376
[2025-05-08T19:39:51.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 11.0 in stage 104.0 (TID 351) (172.20.0.5, executor 0, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 10.0 in stage 104.0 (TID 350) in 17 ms on 172.20.0.5 (executor 0) (11/20)
[2025-05-08T19:39:51.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 12.0 in stage 104.0 (TID 352) (172.20.0.5, executor 0, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 11.0 in stage 104.0 (TID 351) in 11 ms on 172.20.0.5 (executor 0) (12/20)
[2025-05-08T19:39:51.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 13.0 in stage 104.0 (TID 353) (172.20.0.5, executor 0, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 12.0 in stage 104.0 (TID 352) in 8 ms on 172.20.0.5 (executor 0) (13/20)
[2025-05-08T19:39:51.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 14.0 in stage 104.0 (TID 354) (172.20.0.5, executor 0, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 13.0 in stage 104.0 (TID 353) in 9 ms on 172.20.0.5 (executor 0) (14/20)
[2025-05-08T19:39:51.778+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 15.0 in stage 104.0 (TID 355) (172.20.0.5, executor 0, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 14.0 in stage 104.0 (TID 354) in 9 ms on 172.20.0.5 (executor 0) (15/20)
[2025-05-08T19:39:51.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 16.0 in stage 104.0 (TID 356) (172.20.0.5, executor 0, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 15.0 in stage 104.0 (TID 355) in 9 ms on 172.20.0.5 (executor 0) (16/20)
[2025-05-08T19:39:51.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 17.0 in stage 104.0 (TID 357) (172.20.0.5, executor 0, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 16.0 in stage 104.0 (TID 356) in 10 ms on 172.20.0.5 (executor 0) (17/20)
[2025-05-08T19:39:51.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 18.0 in stage 104.0 (TID 358) (172.20.0.5, executor 0, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 17.0 in stage 104.0 (TID 357) in 11 ms on 172.20.0.5 (executor 0) (18/20)
[2025-05-08T19:39:51.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 19.0 in stage 104.0 (TID 359) (172.20.0.5, executor 0, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 18.0 in stage 104.0 (TID 358) in 11 ms on 172.20.0.5 (executor 0) (19/20)
[2025-05-08T19:39:51.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Finished task 19.0 in stage 104.0 (TID 359) in 11 ms on 172.20.0.5 (executor 0) (20/20)
[2025-05-08T19:39:51.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-05-08T19:39:51.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: ShuffleMapStage 104 (rdd at GraphFrame.scala:187) finished in 0.322 s
[2025-05-08T19:39:51.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:51.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:51.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 105)
[2025-05-08T19:39:51.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:51.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting ShuffleMapStage 105 (MapPartitionsRDD[374] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-08T19:39:51.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 104.2 KiB, free 424.5 MiB)
[2025-05-08T19:39:51.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 39.5 KiB, free 424.5 MiB)
[2025-05-08T19:39:51.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on f2a432e4376a:35283 (size: 39.5 KiB, free: 433.5 MiB)
[2025-05-08T19:39:51.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:51.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_41_piece0 on f2a432e4376a:35283 in memory (size: 28.3 KiB, free: 433.5 MiB)
[2025-05-08T19:39:51.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 105 (MapPartitionsRDD[374] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:51.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSchedulerImpl: Adding task set 105.0 with 10 tasks resource profile 0
[2025-05-08T19:39:51.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 360) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:51.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.20.0.5:37427 in memory (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T19:39:51.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:37427 (size: 39.5 KiB, free: 434.3 MiB)
[2025-05-08T19:39:51.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_42_piece0 on f2a432e4376a:35283 in memory (size: 28.4 KiB, free: 433.6 MiB)
[2025-05-08T19:39:51.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.20.0.5:37427 in memory (size: 28.4 KiB, free: 434.3 MiB)
[2025-05-08T19:39:51.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_40_piece0 on f2a432e4376a:35283 in memory (size: 36.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:51.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.20.0.5:37427 in memory (size: 36.3 KiB, free: 434.3 MiB)
[2025-05-08T19:39:51.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:59376
[2025-05-08T19:39:52.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_0 in memory on 172.20.0.5:37427 (size: 8.5 KiB, free: 434.3 MiB)
[2025-05-08T19:39:52.119+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:37427 (size: 80.3 KiB, free: 434.2 MiB)
[2025-05-08T19:39:52.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.20.0.5:37427 (size: 586.3 KiB, free: 433.7 MiB)
[2025-05-08T19:39:52.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 361) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 360) in 282 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:52.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_1 in memory on 172.20.0.5:37427 (size: 8.0 KiB, free: 433.7 MiB)
[2025-05-08T19:39:52.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 362) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 361) in 26 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:52.198+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_2 in memory on 172.20.0.5:37427 (size: 7.5 KiB, free: 433.7 MiB)
[2025-05-08T19:39:52.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 363) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.208+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 362) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:52.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_3 in memory on 172.20.0.5:37427 (size: 8.1 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 4.0 in stage 105.0 (TID 364) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.234+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 363) in 26 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:52.246+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_4 in memory on 172.20.0.5:37427 (size: 7.7 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 5.0 in stage 105.0 (TID 365) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 4.0 in stage 105.0 (TID 364) in 22 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:52.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_5 in memory on 172.20.0.5:37427 (size: 7.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 6.0 in stage 105.0 (TID 366) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 5.0 in stage 105.0 (TID 365) in 23 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:52.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_6 in memory on 172.20.0.5:37427 (size: 7.3 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 7.0 in stage 105.0 (TID 367) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 6.0 in stage 105.0 (TID 366) in 27 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:52.315+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_7 in memory on 172.20.0.5:37427 (size: 8.1 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 8.0 in stage 105.0 (TID 368) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 7.0 in stage 105.0 (TID 367) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:52.344+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_8 in memory on 172.20.0.5:37427 (size: 7.6 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 9.0 in stage 105.0 (TID 369) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 8.0 in stage 105.0 (TID 368) in 28 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:52.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added rdd_169_9 in memory on 172.20.0.5:37427 (size: 8.2 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.378+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 9.0 in stage 105.0 (TID 369) in 25 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:52.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-05-08T19:39:52.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: ShuffleMapStage 105 (rdd at GraphFrame.scala:188) finished in 0.546 s
[2025-05-08T19:39:52.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:52.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:52.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:39:52.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:52.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:39:52.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:52.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Got job 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-08T19:39:52.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Final stage: ResultStage 115 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-08T19:39:52.402+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 114)
[2025-05-08T19:39:52.402+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:39:52.402+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[376] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-08T19:39:52.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.2 KiB, free 424.8 MiB)
[2025-05-08T19:39:52.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 424.8 MiB)
[2025-05-08T19:39:52.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on f2a432e4376a:35283 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:52.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[376] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:39:52.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0
[2025-05-08T19:39:52.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 370) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.20.0.5:37427 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:59376
[2025-05-08T19:39:52.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 370) in 40 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:39:52.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-05-08T19:39:52.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: ResultStage 115 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.046 s
[2025-05-08T19:39:52.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:52.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished
[2025-05-08T19:39:52.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Removed broadcast_43_piece0 on f2a432e4376a:35283 in memory (size: 32.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Job 34 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.054622 s
[2025-05-08T19:39:52.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.20.0.5:37427 in memory (size: 32.0 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Removed broadcast_44_piece0 on f2a432e4376a:35283 in memory (size: 39.5 KiB, free: 433.7 MiB)
[2025-05-08T19:39:52.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.20.0.5:37427 in memory (size: 39.5 KiB, free: 433.7 MiB)
[2025-05-08T19:39:52.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 4.5 MiB, free 420.5 MiB)
[2025-05-08T19:39:52.487+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 764.6 KiB, free 419.8 MiB)
[2025-05-08T19:39:52.487+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on f2a432e4376a:35283 (size: 764.6 KiB, free: 432.9 MiB)
[2025-05-08T19:39:52.487+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-08T19:39:52.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO CodeGenerator: Code generated in 21.733634 ms
[2025-05-08T19:39:52.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#1729) generates partition filter: ((id.count#2613 - id.nullCount#2612) > 0)
[2025-05-08T19:39:52.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:39:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Registering RDD 389 (mapPartitions at VertexRDD.scala:356) as input to shuffle 40
[2025-05-08T19:39:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Registering RDD 177 (map at GraphFrame.scala:187) as input to shuffle 37
[2025-05-08T19:39:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Registering RDD 415 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 38
[2025-05-08T19:39:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Registering RDD 411 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-08T19:39:52.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Registering RDD 419 (mapPartitions at GraphImpl.scala:208) as input to shuffle 39
[2025-05-08T19:39:52.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Got job 35 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:39:52.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Final stage: ResultStage 129 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:39:52.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125, ShuffleMapStage 124, ShuffleMapStage 128)
[2025-05-08T19:39:52.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 125, ShuffleMapStage 124, ShuffleMapStage 128)
[2025-05-08T19:39:52.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Submitting ShuffleMapStage 124 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-08T19:39:52.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 232.9 KiB, free 419.5 MiB)
[2025-05-08T19:39:52.675+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Removed broadcast_45_piece0 on f2a432e4376a:35283 in memory (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-08T19:39:52.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 419.5 MiB)
[2025-05-08T19:39:52.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on f2a432e4376a:35283 (size: 77.4 KiB, free: 432.8 MiB)
[2025-05-08T19:39:52.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:52.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 124 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:52.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSchedulerImpl: Adding task set 124.0 with 10 tasks resource profile 0
[2025-05-08T19:39:52.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.20.0.5:37427 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-08T19:39:52.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Submitting ShuffleMapStage 125 (MapPartitionsRDD[177] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:39:52.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 371) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:52.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.20.0.5:37427 (size: 77.4 KiB, free: 433.6 MiB)
[2025-05-08T19:39:52.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 189.5 KiB, free 419.3 MiB)
[2025-05-08T19:39:52.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 64.9 KiB, free 419.2 MiB)
[2025-05-08T19:39:52.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on f2a432e4376a:35283 (size: 64.9 KiB, free: 432.8 MiB)
[2025-05-08T19:39:52.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:52.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 125 (MapPartitionsRDD[177] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:52.696+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO TaskSchedulerImpl: Adding task set 125.0 with 10 tasks resource profile 0
[2025-05-08T19:39:52.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:52 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:37427 (size: 764.6 KiB, free: 432.9 MiB)
[2025-05-08T19:39:53.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:53 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 372) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:53.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:53 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 371) in 1109 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:53.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:53 INFO TaskSetManager: Starting task 2.0 in stage 124.0 (TID 373) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:53.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:53 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 372) in 133 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:53.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:53 INFO TaskSetManager: Starting task 3.0 in stage 124.0 (TID 374) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:53.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:53 INFO TaskSetManager: Finished task 2.0 in stage 124.0 (TID 373) in 60 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:54.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 4.0 in stage 124.0 (TID 375) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.017+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 3.0 in stage 124.0 (TID 374) in 65 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:54.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 5.0 in stage 124.0 (TID 376) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.082+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 4.0 in stage 124.0 (TID 375) in 65 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:54.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 6.0 in stage 124.0 (TID 377) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 5.0 in stage 124.0 (TID 376) in 76 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:54.198+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 7.0 in stage 124.0 (TID 378) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 6.0 in stage 124.0 (TID 377) in 43 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:54.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 8.0 in stage 124.0 (TID 379) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 7.0 in stage 124.0 (TID 378) in 46 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:54.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 9.0 in stage 124.0 (TID 380) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 8.0 in stage 124.0 (TID 379) in 49 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:54.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 381) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.349+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 9.0 in stage 124.0 (TID 380) in 57 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:54.350+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool
[2025-05-08T19:39:54.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: ShuffleMapStage 124 (mapPartitions at VertexRDD.scala:356) finished in 1.719 s
[2025-05-08T19:39:54.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:54.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: running: Set(ShuffleMapStage 125)
[2025-05-08T19:39:54.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: waiting: Set(ResultStage 129, ShuffleMapStage 126, ShuffleMapStage 127, ShuffleMapStage 128)
[2025-05-08T19:39:54.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:54.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 432.8 MiB)
[2025-05-08T19:39:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:37427 (size: 94.3 KiB, free: 432.7 MiB)
[2025-05-08T19:39:54.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 382) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 381) in 74 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:54.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 2.0 in stage 125.0 (TID 383) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 382) in 39 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:54.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 3.0 in stage 125.0 (TID 384) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 2.0 in stage 125.0 (TID 383) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:54.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 4.0 in stage 125.0 (TID 385) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.508+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 3.0 in stage 125.0 (TID 384) in 25 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:54.530+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 5.0 in stage 125.0 (TID 386) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.531+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 4.0 in stage 125.0 (TID 385) in 24 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:54.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 6.0 in stage 125.0 (TID 387) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 5.0 in stage 125.0 (TID 386) in 22 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:54.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 7.0 in stage 125.0 (TID 388) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 6.0 in stage 125.0 (TID 387) in 26 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:54.596+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 8.0 in stage 125.0 (TID 389) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 7.0 in stage 125.0 (TID 388) in 20 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:54.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 9.0 in stage 125.0 (TID 390) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.613+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 8.0 in stage 125.0 (TID 389) in 17 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:54.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Finished task 9.0 in stage 125.0 (TID 390) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:54.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool
[2025-05-08T19:39:54.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: ShuffleMapStage 125 (map at GraphFrame.scala:187) finished in 1.949 s
[2025-05-08T19:39:54.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:54.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:54.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: waiting: Set(ResultStage 129, ShuffleMapStage 126, ShuffleMapStage 127, ShuffleMapStage 128)
[2025-05-08T19:39:54.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:54.632+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: Submitting ShuffleMapStage 126 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[415] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:39:54.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 9.9 KiB, free 419.2 MiB)
[2025-05-08T19:39:54.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 419.2 MiB)
[2025-05-08T19:39:54.723+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on f2a432e4376a:35283 (size: 4.9 KiB, free: 432.8 MiB)
[2025-05-08T19:39:54.723+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Removed broadcast_47_piece0 on f2a432e4376a:35283 in memory (size: 77.4 KiB, free: 432.8 MiB)
[2025-05-08T19:39:54.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:54.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.20.0.5:37427 in memory (size: 77.4 KiB, free: 432.8 MiB)
[2025-05-08T19:39:54.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 126 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[415] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:54.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSchedulerImpl: Adding task set 126.0 with 10 tasks resource profile 0
[2025-05-08T19:39:54.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: Submitting ShuffleMapStage 127 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[411] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:39:54.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 10.3 KiB, free 419.5 MiB)
[2025-05-08T19:39:54.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 391) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:54.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 419.5 MiB)
[2025-05-08T19:39:54.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on f2a432e4376a:35283 (size: 5.0 KiB, free: 432.8 MiB)
[2025-05-08T19:39:54.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:54.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 127 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[411] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:54.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO TaskSchedulerImpl: Adding task set 127.0 with 10 tasks resource profile 0
[2025-05-08T19:39:54.775+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.20.0.5:37427 (size: 4.9 KiB, free: 432.8 MiB)
[2025-05-08T19:39:54.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:59376
[2025-05-08T19:39:54.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Removed broadcast_48_piece0 on f2a432e4376a:35283 in memory (size: 64.9 KiB, free: 432.9 MiB)
[2025-05-08T19:39:54.903+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.20.0.5:37427 in memory (size: 64.9 KiB, free: 432.8 MiB)
[2025-05-08T19:39:54.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:59376
[2025-05-08T19:39:55.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_0 in memory on 172.20.0.5:37427 (size: 36.3 KiB, free: 432.8 MiB)
[2025-05-08T19:39:55.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_0 in memory on 172.20.0.5:37427 (size: 11.2 KiB, free: 432.8 MiB)
[2025-05-08T19:39:55.152+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 432.8 MiB)
[2025-05-08T19:39:55.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 432.8 MiB)
[2025-05-08T19:39:55.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 392) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 391) in 456 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:55.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_1 in memory on 172.20.0.5:37427 (size: 36.7 KiB, free: 432.7 MiB)
[2025-05-08T19:39:55.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_1 in memory on 172.20.0.5:37427 (size: 12.1 KiB, free: 432.7 MiB)
[2025-05-08T19:39:55.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 432.7 MiB)
[2025-05-08T19:39:55.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 432.7 MiB)
[2025-05-08T19:39:55.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 393) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 392) in 65 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:55.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_2 in memory on 172.20.0.5:37427 (size: 34.2 KiB, free: 432.6 MiB)
[2025-05-08T19:39:55.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_2 in memory on 172.20.0.5:37427 (size: 10.9 KiB, free: 432.6 MiB)
[2025-05-08T19:39:55.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 432.6 MiB)
[2025-05-08T19:39:55.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 432.6 MiB)
[2025-05-08T19:39:55.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 3.0 in stage 126.0 (TID 394) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 393) in 47 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:55.313+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_3 in memory on 172.20.0.5:37427 (size: 34.5 KiB, free: 432.6 MiB)
[2025-05-08T19:39:55.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_3 in memory on 172.20.0.5:37427 (size: 10.9 KiB, free: 432.6 MiB)
[2025-05-08T19:39:55.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 432.6 MiB)
[2025-05-08T19:39:55.331+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 432.5 MiB)
[2025-05-08T19:39:55.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 4.0 in stage 126.0 (TID 395) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 3.0 in stage 126.0 (TID 394) in 52 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:55.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_4 in memory on 172.20.0.5:37427 (size: 33.4 KiB, free: 432.5 MiB)
[2025-05-08T19:39:55.362+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_4 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 432.5 MiB)
[2025-05-08T19:39:55.364+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 432.5 MiB)
[2025-05-08T19:39:55.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 432.5 MiB)
[2025-05-08T19:39:55.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 5.0 in stage 126.0 (TID 396) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 4.0 in stage 126.0 (TID 395) in 33 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:55.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_5 in memory on 172.20.0.5:37427 (size: 34.7 KiB, free: 432.4 MiB)
[2025-05-08T19:39:55.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_5 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 432.4 MiB)
[2025-05-08T19:39:55.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 432.4 MiB)
[2025-05-08T19:39:55.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 432.4 MiB)
[2025-05-08T19:39:55.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 6.0 in stage 126.0 (TID 397) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 5.0 in stage 126.0 (TID 396) in 40 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:55.426+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_6 in memory on 172.20.0.5:37427 (size: 34.8 KiB, free: 432.4 MiB)
[2025-05-08T19:39:55.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_6 in memory on 172.20.0.5:37427 (size: 11.4 KiB, free: 432.4 MiB)
[2025-05-08T19:39:55.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 432.3 MiB)
[2025-05-08T19:39:55.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 432.3 MiB)
[2025-05-08T19:39:55.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 7.0 in stage 126.0 (TID 398) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 6.0 in stage 126.0 (TID 397) in 34 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:55.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_7 in memory on 172.20.0.5:37427 (size: 35.5 KiB, free: 432.3 MiB)
[2025-05-08T19:39:55.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_7 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 432.3 MiB)
[2025-05-08T19:39:55.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 432.3 MiB)
[2025-05-08T19:39:55.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 432.3 MiB)
[2025-05-08T19:39:55.477+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 8.0 in stage 126.0 (TID 399) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.478+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 7.0 in stage 126.0 (TID 398) in 36 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:55.496+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_8 in memory on 172.20.0.5:37427 (size: 36.5 KiB, free: 432.2 MiB)
[2025-05-08T19:39:55.499+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_8 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 432.2 MiB)
[2025-05-08T19:39:55.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 432.2 MiB)
[2025-05-08T19:39:55.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 432.2 MiB)
[2025-05-08T19:39:55.517+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 9.0 in stage 126.0 (TID 400) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.517+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 8.0 in stage 126.0 (TID 399) in 41 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:55.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_392_9 in memory on 172.20.0.5:37427 (size: 35.4 KiB, free: 432.1 MiB)
[2025-05-08T19:39:55.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_397_9 in memory on 172.20.0.5:37427 (size: 11.3 KiB, free: 432.1 MiB)
[2025-05-08T19:39:55.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_403_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 432.1 MiB)
[2025-05-08T19:39:55.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_407_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 432.1 MiB)
[2025-05-08T19:39:55.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 401) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 9.0 in stage 126.0 (TID 400) in 54 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:55.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool
[2025-05-08T19:39:55.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: ShuffleMapStage 126 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.935 s
[2025-05-08T19:39:55.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:55.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: running: Set(ShuffleMapStage 127)
[2025-05-08T19:39:55.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: waiting: Set(ResultStage 129, ShuffleMapStage 128)
[2025-05-08T19:39:55.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:55.583+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.20.0.5:37427 (size: 5.0 KiB, free: 432.1 MiB)
[2025-05-08T19:39:55.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 402) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 401) in 63 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:55.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 2.0 in stage 127.0 (TID 403) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 402) in 44 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:55.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 3.0 in stage 127.0 (TID 404) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 2.0 in stage 127.0 (TID 403) in 40 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:55.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 4.0 in stage 127.0 (TID 405) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 3.0 in stage 127.0 (TID 404) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:55.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 5.0 in stage 127.0 (TID 406) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.702+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 4.0 in stage 127.0 (TID 405) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:55.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 6.0 in stage 127.0 (TID 407) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 5.0 in stage 127.0 (TID 406) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:55.723+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 7.0 in stage 127.0 (TID 408) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.723+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 6.0 in stage 127.0 (TID 407) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:55.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 8.0 in stage 127.0 (TID 409) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 7.0 in stage 127.0 (TID 408) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:55.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 9.0 in stage 127.0 (TID 410) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 8.0 in stage 127.0 (TID 409) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:55.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Finished task 9.0 in stage 127.0 (TID 410) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:55.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool
[2025-05-08T19:39:55.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: ShuffleMapStage 127 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.018 s
[2025-05-08T19:39:55.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:55.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:55.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: waiting: Set(ResultStage 129, ShuffleMapStage 128)
[2025-05-08T19:39:55.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:55.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: Submitting ShuffleMapStage 128 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[419] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:39:55.777+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 237.5 KiB, free 419.5 MiB)
[2025-05-08T19:39:55.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 419.4 MiB)
[2025-05-08T19:39:55.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.8 MiB)
[2025-05-08T19:39:55.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:55.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 128 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[419] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:55.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSchedulerImpl: Adding task set 128.0 with 10 tasks resource profile 0
[2025-05-08T19:39:55.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 411) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:55.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.20.0.5:37427 (size: 79.0 KiB, free: 432.0 MiB)
[2025-05-08T19:39:55.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_395_0 in memory on 172.20.0.5:37427 (size: 560.1 KiB, free: 431.5 MiB)
[2025-05-08T19:39:55.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.20.0.5:37427 (size: 560.1 KiB, free: 430.9 MiB)
[2025-05-08T19:39:55.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_405_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 430.9 MiB)
[2025-05-08T19:39:55.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:59376
[2025-05-08T19:39:55.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.20.0.5:37427 in memory (size: 5.0 KiB, free: 430.9 MiB)
[2025-05-08T19:39:55.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Removed broadcast_50_piece0 on f2a432e4376a:35283 in memory (size: 5.0 KiB, free: 432.8 MiB)
[2025-05-08T19:39:55.971+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Removed broadcast_49_piece0 on f2a432e4376a:35283 in memory (size: 4.9 KiB, free: 432.8 MiB)
[2025-05-08T19:39:55.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.20.0.5:37427 in memory (size: 4.9 KiB, free: 430.9 MiB)
[2025-05-08T19:39:55.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO BlockManagerInfo: Added rdd_413_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 430.8 MiB)
[2025-05-08T19:39:55.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:59376
[2025-05-08T19:39:56.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 412) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 411) in 363 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:56.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_1 in memory on 172.20.0.5:37427 (size: 558.2 KiB, free: 430.3 MiB)
[2025-05-08T19:39:56.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.20.0.5:37427 (size: 558.2 KiB, free: 429.8 MiB)
[2025-05-08T19:39:56.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 429.7 MiB)
[2025-05-08T19:39:56.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 429.6 MiB)
[2025-05-08T19:39:56.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 413) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 412) in 149 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_2 in memory on 172.20.0.5:37427 (size: 663.8 KiB, free: 429.0 MiB)
[2025-05-08T19:39:56.343+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.20.0.5:37427 (size: 663.8 KiB, free: 428.4 MiB)
[2025-05-08T19:39:56.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 428.3 MiB)
[2025-05-08T19:39:56.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 428.2 MiB)
[2025-05-08T19:39:56.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 414) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 413) in 141 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:56.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_3 in memory on 172.20.0.5:37427 (size: 695.0 KiB, free: 427.6 MiB)
[2025-05-08T19:39:56.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.20.0.5:37427 (size: 695.0 KiB, free: 426.9 MiB)
[2025-05-08T19:39:56.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 426.8 MiB)
[2025-05-08T19:39:56.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 426.8 MiB)
[2025-05-08T19:39:56.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 4.0 in stage 128.0 (TID 415) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 414) in 124 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:56.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_4 in memory on 172.20.0.5:37427 (size: 451.0 KiB, free: 426.3 MiB)
[2025-05-08T19:39:56.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.20.0.5:37427 (size: 451.0 KiB, free: 425.9 MiB)
[2025-05-08T19:39:56.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 425.8 MiB)
[2025-05-08T19:39:56.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 425.8 MiB)
[2025-05-08T19:39:56.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 5.0 in stage 128.0 (TID 416) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 4.0 in stage 128.0 (TID 415) in 92 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:56.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_5 in memory on 172.20.0.5:37427 (size: 654.0 KiB, free: 425.2 MiB)
[2025-05-08T19:39:56.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.20.0.5:37427 (size: 654.0 KiB, free: 424.5 MiB)
[2025-05-08T19:39:56.675+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 424.5 MiB)
[2025-05-08T19:39:56.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 424.4 MiB)
[2025-05-08T19:39:56.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 6.0 in stage 128.0 (TID 417) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 5.0 in stage 128.0 (TID 416) in 75 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:56.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_6 in memory on 172.20.0.5:37427 (size: 548.2 KiB, free: 423.9 MiB)
[2025-05-08T19:39:56.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.20.0.5:37427 (size: 548.2 KiB, free: 423.3 MiB)
[2025-05-08T19:39:56.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 423.3 MiB)
[2025-05-08T19:39:56.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 423.2 MiB)
[2025-05-08T19:39:56.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 7.0 in stage 128.0 (TID 418) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 6.0 in stage 128.0 (TID 417) in 74 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:56.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_7 in memory on 172.20.0.5:37427 (size: 557.0 KiB, free: 422.7 MiB)
[2025-05-08T19:39:56.829+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.20.0.5:37427 (size: 557.0 KiB, free: 422.2 MiB)
[2025-05-08T19:39:56.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 422.1 MiB)
[2025-05-08T19:39:56.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 422.0 MiB)
[2025-05-08T19:39:56.891+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 8.0 in stage 128.0 (TID 419) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 7.0 in stage 128.0 (TID 418) in 91 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:56.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_8 in memory on 172.20.0.5:37427 (size: 485.3 KiB, free: 421.6 MiB)
[2025-05-08T19:39:56.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.20.0.5:37427 (size: 485.3 KiB, free: 421.1 MiB)
[2025-05-08T19:39:56.919+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 421.1 MiB)
[2025-05-08T19:39:56.922+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 421.0 MiB)
[2025-05-08T19:39:56.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Starting task 9.0 in stage 128.0 (TID 420) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:56.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO TaskSetManager: Finished task 8.0 in stage 128.0 (TID 419) in 72 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:56.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_395_9 in memory on 172.20.0.5:37427 (size: 694.0 KiB, free: 420.3 MiB)
[2025-05-08T19:39:56.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.20.0.5:37427 (size: 694.0 KiB, free: 419.6 MiB)
[2025-05-08T19:39:56.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_405_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 419.6 MiB)
[2025-05-08T19:39:56.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:56 INFO BlockManagerInfo: Added rdd_413_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 419.5 MiB)
[2025-05-08T19:39:57.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 9.0 in stage 128.0 (TID 420) in 115 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:57.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool
[2025-05-08T19:39:57.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: ShuffleMapStage 128 (mapPartitions at GraphImpl.scala:208) finished in 1.327 s
[2025-05-08T19:39:57.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:57.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:57.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: waiting: Set(ResultStage 129)
[2025-05-08T19:39:57.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:57.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[423] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:39:57.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 11.2 KiB, free 419.5 MiB)
[2025-05-08T19:39:57.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 419.5 MiB)
[2025-05-08T19:39:57.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on f2a432e4376a:35283 (size: 5.3 KiB, free: 432.8 MiB)
[2025-05-08T19:39:57.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:57.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 129 (MapPartitionsRDD[423] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:57.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Adding task set 129.0 with 10 tasks resource profile 0
[2025-05-08T19:39:57.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 421) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.20.0.5:37427 (size: 5.3 KiB, free: 419.5 MiB)
[2025-05-08T19:39:57.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:59376
[2025-05-08T19:39:57.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.20.0.5:37427 in memory (size: 79.0 KiB, free: 419.6 MiB)
[2025-05-08T19:39:57.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Removed broadcast_51_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.9 MiB)
[2025-05-08T19:39:57.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_0 in memory on 172.20.0.5:37427 (size: 213.1 KiB, free: 419.4 MiB)
[2025-05-08T19:39:57.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 422) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 421) in 109 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:57.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_1 in memory on 172.20.0.5:37427 (size: 148.0 KiB, free: 419.3 MiB)
[2025-05-08T19:39:57.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 2.0 in stage 129.0 (TID 423) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 422) in 43 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:57.279+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_2 in memory on 172.20.0.5:37427 (size: 110.8 KiB, free: 419.1 MiB)
[2025-05-08T19:39:57.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 3.0 in stage 129.0 (TID 424) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 2.0 in stage 129.0 (TID 423) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:57.297+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_3 in memory on 172.20.0.5:37427 (size: 110.9 KiB, free: 419.0 MiB)
[2025-05-08T19:39:57.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 4.0 in stage 129.0 (TID 425) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 3.0 in stage 129.0 (TID 424) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:57.353+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_4 in memory on 172.20.0.5:37427 (size: 129.6 KiB, free: 418.9 MiB)
[2025-05-08T19:39:57.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 5.0 in stage 129.0 (TID 426) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 4.0 in stage 129.0 (TID 425) in 58 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_5 in memory on 172.20.0.5:37427 (size: 179.0 KiB, free: 418.7 MiB)
[2025-05-08T19:39:57.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 6.0 in stage 129.0 (TID 427) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 5.0 in stage 129.0 (TID 426) in 44 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:57.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_6 in memory on 172.20.0.5:37427 (size: 137.0 KiB, free: 418.6 MiB)
[2025-05-08T19:39:57.424+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 7.0 in stage 129.0 (TID 428) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 6.0 in stage 129.0 (TID 427) in 25 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:57.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_7 in memory on 172.20.0.5:37427 (size: 159.8 KiB, free: 418.4 MiB)
[2025-05-08T19:39:57.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 8.0 in stage 129.0 (TID 429) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 7.0 in stage 129.0 (TID 428) in 43 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:57.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_8 in memory on 172.20.0.5:37427 (size: 123.8 KiB, free: 418.3 MiB)
[2025-05-08T19:39:57.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 9.0 in stage 129.0 (TID 430) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 8.0 in stage 129.0 (TID 429) in 38 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:57.524+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_421_9 in memory on 172.20.0.5:37427 (size: 207.8 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 9.0 in stage 129.0 (TID 430) in 22 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:57.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool
[2025-05-08T19:39:57.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: ResultStage 129 (fold at VertexRDDImpl.scala:90) finished in 0.441 s
[2025-05-08T19:39:57.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:57.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
[2025-05-08T19:39:57.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Job 35 finished: fold at VertexRDDImpl.scala:90, took 4.903690 s
[2025-05-08T19:39:57.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:39:57.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Registering RDD 428 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 41
[2025-05-08T19:39:57.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Registering RDD 432 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 42
[2025-05-08T19:39:57.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Registering RDD 436 (mapPartitions at GraphImpl.scala:208) as input to shuffle 43
[2025-05-08T19:39:57.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Got job 36 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:39:57.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Final stage: ResultStage 146 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:39:57.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 139, ShuffleMapStage 138, ShuffleMapStage 145, ShuffleMapStage 142)
[2025-05-08T19:39:57.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 145)
[2025-05-08T19:39:57.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting ShuffleMapStage 143 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[428] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:39:57.563+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 11.7 KiB, free 419.8 MiB)
[2025-05-08T19:39:57.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 419.8 MiB)
[2025-05-08T19:39:57.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on f2a432e4376a:35283 (size: 5.4 KiB, free: 432.9 MiB)
[2025-05-08T19:39:57.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:57.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 143 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[428] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:57.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Adding task set 143.0 with 10 tasks resource profile 0
[2025-05-08T19:39:57.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting ShuffleMapStage 144 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[432] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:39:57.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 431) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 10.5 KiB, free 419.7 MiB)
[2025-05-08T19:39:57.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 419.7 MiB)
[2025-05-08T19:39:57.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on f2a432e4376a:35283 (size: 5.1 KiB, free: 432.9 MiB)
[2025-05-08T19:39:57.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Removed broadcast_52_piece0 on f2a432e4376a:35283 in memory (size: 5.3 KiB, free: 432.9 MiB)
[2025-05-08T19:39:57.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:57.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 144 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[432] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:57.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Adding task set 144.0 with 10 tasks resource profile 0
[2025-05-08T19:39:57.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.20.0.5:37427 in memory (size: 5.3 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.581+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.20.0.5:37427 (size: 5.4 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 432) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 431) in 46 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:57.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 2.0 in stage 143.0 (TID 433) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 432) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:57.642+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 3.0 in stage 143.0 (TID 434) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 2.0 in stage 143.0 (TID 433) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:57.650+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 4.0 in stage 143.0 (TID 435) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 3.0 in stage 143.0 (TID 434) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:57.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.1 MiB)
[2025-05-08T19:39:57.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 5.0 in stage 143.0 (TID 436) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 4.0 in stage 143.0 (TID 435) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:57.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.0 MiB)
[2025-05-08T19:39:57.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 6.0 in stage 143.0 (TID 437) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 5.0 in stage 143.0 (TID 436) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:57.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.0 MiB)
[2025-05-08T19:39:57.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 7.0 in stage 143.0 (TID 438) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 6.0 in stage 143.0 (TID 437) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:57.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.0 MiB)
[2025-05-08T19:39:57.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 8.0 in stage 143.0 (TID 439) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 7.0 in stage 143.0 (TID 438) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:57.702+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.0 MiB)
[2025-05-08T19:39:57.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 9.0 in stage 143.0 (TID 440) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 8.0 in stage 143.0 (TID 439) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:57.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_424_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.0 MiB)
[2025-05-08T19:39:57.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 441) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 9.0 in stage 143.0 (TID 440) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:57.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool
[2025-05-08T19:39:57.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: ShuffleMapStage 143 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.152 s
[2025-05-08T19:39:57.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:57.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: running: Set(ShuffleMapStage 144)
[2025-05-08T19:39:57.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 145, ResultStage 146)
[2025-05-08T19:39:57.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:57.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.20.0.5:37427 (size: 5.1 KiB, free: 418.0 MiB)
[2025-05-08T19:39:57.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 1.0 in stage 144.0 (TID 442) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 441) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:57.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 2.0 in stage 144.0 (TID 443) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 1.0 in stage 144.0 (TID 442) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:57.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 3.0 in stage 144.0 (TID 444) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 2.0 in stage 144.0 (TID 443) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:57.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 4.0 in stage 144.0 (TID 445) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 3.0 in stage 144.0 (TID 444) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:57.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 5.0 in stage 144.0 (TID 446) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 4.0 in stage 144.0 (TID 445) in 20 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:57.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 6.0 in stage 144.0 (TID 447) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.837+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 5.0 in stage 144.0 (TID 446) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:57.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 7.0 in stage 144.0 (TID 448) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 6.0 in stage 144.0 (TID 447) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:57.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 8.0 in stage 144.0 (TID 449) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 7.0 in stage 144.0 (TID 448) in 18 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:57.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 9.0 in stage 144.0 (TID 450) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.888+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 8.0 in stage 144.0 (TID 449) in 18 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:57.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 9.0 in stage 144.0 (TID 450) in 19 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:57.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool
[2025-05-08T19:39:57.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: ShuffleMapStage 144 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.340 s
[2025-05-08T19:39:57.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:57.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:57.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 145, ResultStage 146)
[2025-05-08T19:39:57.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:57.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting ShuffleMapStage 145 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[436] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:39:57.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 238.6 KiB, free 419.5 MiB)
[2025-05-08T19:39:57.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Removed broadcast_53_piece0 on f2a432e4376a:35283 in memory (size: 5.4 KiB, free: 432.9 MiB)
[2025-05-08T19:39:57.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 419.5 MiB)
[2025-05-08T19:39:57.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.8 MiB)
[2025-05-08T19:39:57.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:57.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 145 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[436] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:57.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSchedulerImpl: Adding task set 145.0 with 10 tasks resource profile 0
[2025-05-08T19:39:57.928+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 451) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.928+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.20.0.5:37427 in memory (size: 5.4 KiB, free: 418.0 MiB)
[2025-05-08T19:39:57.935+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.20.0.5:37427 (size: 79.0 KiB, free: 417.9 MiB)
[2025-05-08T19:39:57.951+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:59376
[2025-05-08T19:39:57.954+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:59376
[2025-05-08T19:39:57.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO BlockManagerInfo: Added rdd_430_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 417.9 MiB)
[2025-05-08T19:39:57.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:59376
[2025-05-08T19:39:57.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Starting task 1.0 in stage 145.0 (TID 452) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:57.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:57 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 451) in 67 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:58.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 417.8 MiB)
[2025-05-08T19:39:58.032+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 2.0 in stage 145.0 (TID 453) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.033+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 1.0 in stage 145.0 (TID 452) in 39 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:58.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 417.8 MiB)
[2025-05-08T19:39:58.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 3.0 in stage 145.0 (TID 454) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 2.0 in stage 145.0 (TID 453) in 63 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:58.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 417.7 MiB)
[2025-05-08T19:39:58.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 4.0 in stage 145.0 (TID 455) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 3.0 in stage 145.0 (TID 454) in 82 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:58.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 417.7 MiB)
[2025-05-08T19:39:58.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 5.0 in stage 145.0 (TID 456) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 4.0 in stage 145.0 (TID 455) in 36 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:58.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 417.6 MiB)
[2025-05-08T19:39:58.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 6.0 in stage 145.0 (TID 457) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 5.0 in stage 145.0 (TID 456) in 76 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:58.311+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 417.5 MiB)
[2025-05-08T19:39:58.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 7.0 in stage 145.0 (TID 458) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 6.0 in stage 145.0 (TID 457) in 51 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:58.351+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 417.5 MiB)
[2025-05-08T19:39:58.378+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 8.0 in stage 145.0 (TID 459) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.378+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 7.0 in stage 145.0 (TID 458) in 44 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:58.391+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 417.4 MiB)
[2025-05-08T19:39:58.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 9.0 in stage 145.0 (TID 460) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.412+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 8.0 in stage 145.0 (TID 459) in 35 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:58.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_430_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 417.4 MiB)
[2025-05-08T19:39:58.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 9.0 in stage 145.0 (TID 460) in 53 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:58.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool
[2025-05-08T19:39:58.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: ShuffleMapStage 145 (mapPartitions at GraphImpl.scala:208) finished in 0.556 s
[2025-05-08T19:39:58.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:58.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:58.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: waiting: Set(ResultStage 146)
[2025-05-08T19:39:58.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:58.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[440] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:39:58.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 12.3 KiB, free 419.4 MiB)
[2025-05-08T19:39:58.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 419.4 MiB)
[2025-05-08T19:39:58.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Removed broadcast_54_piece0 on f2a432e4376a:35283 in memory (size: 5.1 KiB, free: 432.8 MiB)
[2025-05-08T19:39:58.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on f2a432e4376a:35283 (size: 5.6 KiB, free: 432.8 MiB)
[2025-05-08T19:39:58.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:58.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.20.0.5:37427 in memory (size: 5.1 KiB, free: 417.4 MiB)
[2025-05-08T19:39:58.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 146 (MapPartitionsRDD[440] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:58.491+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSchedulerImpl: Adding task set 146.0 with 10 tasks resource profile 0
[2025-05-08T19:39:58.491+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 461) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.497+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.20.0.5:37427 (size: 5.6 KiB, free: 417.4 MiB)
[2025-05-08T19:39:58.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:59376
[2025-05-08T19:39:58.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_0 in memory on 172.20.0.5:37427 (size: 55.5 KiB, free: 417.3 MiB)
[2025-05-08T19:39:58.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 462) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 461) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:58.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_1 in memory on 172.20.0.5:37427 (size: 51.1 KiB, free: 417.3 MiB)
[2025-05-08T19:39:58.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 2.0 in stage 146.0 (TID 463) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 462) in 50 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:58.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_2 in memory on 172.20.0.5:37427 (size: 45.5 KiB, free: 417.2 MiB)
[2025-05-08T19:39:58.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 3.0 in stage 146.0 (TID 464) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 2.0 in stage 146.0 (TID 463) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:58.596+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_3 in memory on 172.20.0.5:37427 (size: 45.1 KiB, free: 417.2 MiB)
[2025-05-08T19:39:58.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 4.0 in stage 146.0 (TID 465) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.599+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 3.0 in stage 146.0 (TID 464) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:58.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_4 in memory on 172.20.0.5:37427 (size: 51.2 KiB, free: 417.1 MiB)
[2025-05-08T19:39:58.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 5.0 in stage 146.0 (TID 466) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 4.0 in stage 146.0 (TID 465) in 41 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:58.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_5 in memory on 172.20.0.5:37427 (size: 59.2 KiB, free: 417.1 MiB)
[2025-05-08T19:39:58.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 6.0 in stage 146.0 (TID 467) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 5.0 in stage 146.0 (TID 466) in 44 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:58.697+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_6 in memory on 172.20.0.5:37427 (size: 53.5 KiB, free: 417.0 MiB)
[2025-05-08T19:39:58.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 7.0 in stage 146.0 (TID 468) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 6.0 in stage 146.0 (TID 467) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:58.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_7 in memory on 172.20.0.5:37427 (size: 54.5 KiB, free: 417.0 MiB)
[2025-05-08T19:39:58.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 8.0 in stage 146.0 (TID 469) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 7.0 in stage 146.0 (TID 468) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:58.723+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_8 in memory on 172.20.0.5:37427 (size: 52.9 KiB, free: 416.9 MiB)
[2025-05-08T19:39:58.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 9.0 in stage 146.0 (TID 470) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 8.0 in stage 146.0 (TID 469) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:58.734+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added rdd_438_9 in memory on 172.20.0.5:37427 (size: 62.6 KiB, free: 416.9 MiB)
[2025-05-08T19:39:58.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 9.0 in stage 146.0 (TID 470) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:58.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool
[2025-05-08T19:39:58.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: ResultStage 146 (fold at VertexRDDImpl.scala:90) finished in 0.272 s
[2025-05-08T19:39:58.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:58.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 146: Stage finished
[2025-05-08T19:39:58.741+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Job 36 finished: fold at VertexRDDImpl.scala:90, took 1.181752 s
[2025-05-08T19:39:58.752+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO Pregel: Pregel finished iteration 0
[2025-05-08T19:39:58.752+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO ZippedPartitionsRDD2: Removing RDD 421 from persistence list
[2025-05-08T19:39:58.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManager: Removing RDD 421
[2025-05-08T19:39:58.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MapPartitionsRDD: Removing RDD 407 from persistence list
[2025-05-08T19:39:58.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManager: Removing RDD 407
[2025-05-08T19:39:58.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO ZippedPartitionsRDD2: Removing RDD 413 from persistence list
[2025-05-08T19:39:58.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManager: Removing RDD 413
[2025-05-08T19:39:58.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:39:58.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Registering RDD 449 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 45
[2025-05-08T19:39:58.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Registering RDD 445 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 44
[2025-05-08T19:39:58.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Registering RDD 453 (mapPartitions at GraphImpl.scala:208) as input to shuffle 46
[2025-05-08T19:39:58.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Got job 37 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:39:58.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Final stage: ResultStage 166 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:39:58.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 165, ShuffleMapStage 155, ShuffleMapStage 162, ShuffleMapStage 159, ShuffleMapStage 156)
[2025-05-08T19:39:58.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 165)
[2025-05-08T19:39:58.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Submitting ShuffleMapStage 163 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[449] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:39:58.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 11.6 KiB, free 419.4 MiB)
[2025-05-08T19:39:58.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 419.4 MiB)
[2025-05-08T19:39:58.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on f2a432e4376a:35283 (size: 5.4 KiB, free: 432.8 MiB)
[2025-05-08T19:39:58.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Removed broadcast_56_piece0 on f2a432e4376a:35283 in memory (size: 5.6 KiB, free: 432.8 MiB)
[2025-05-08T19:39:58.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:58.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 163 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[449] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:58.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSchedulerImpl: Adding task set 163.0 with 10 tasks resource profile 0
[2025-05-08T19:39:58.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Submitting ShuffleMapStage 164 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[445] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:39:58.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 471) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.20.0.5:37427 in memory (size: 5.6 KiB, free: 419.0 MiB)
[2025-05-08T19:39:58.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 12.3 KiB, free 419.4 MiB)
[2025-05-08T19:39:58.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 419.4 MiB)
[2025-05-08T19:39:58.822+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on f2a432e4376a:35283 (size: 5.6 KiB, free: 432.8 MiB)
[2025-05-08T19:39:58.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:58.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 164 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[445] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:58.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSchedulerImpl: Adding task set 164.0 with 10 tasks resource profile 0
[2025-05-08T19:39:58.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.20.0.5:37427 in memory (size: 79.0 KiB, free: 419.1 MiB)
[2025-05-08T19:39:58.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Removed broadcast_55_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.9 MiB)
[2025-05-08T19:39:58.832+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.20.0.5:37427 (size: 5.4 KiB, free: 419.1 MiB)
[2025-05-08T19:39:58.858+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 1.0 in stage 163.0 (TID 472) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 471) in 41 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:58.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 2.0 in stage 163.0 (TID 473) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.888+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 1.0 in stage 163.0 (TID 472) in 31 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:58.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 3.0 in stage 163.0 (TID 474) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 2.0 in stage 163.0 (TID 473) in 23 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:58.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 4.0 in stage 163.0 (TID 475) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 3.0 in stage 163.0 (TID 474) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:58.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 5.0 in stage 163.0 (TID 476) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 4.0 in stage 163.0 (TID 475) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:58.970+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 6.0 in stage 163.0 (TID 477) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.970+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 5.0 in stage 163.0 (TID 476) in 21 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:58.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Starting task 7.0 in stage 163.0 (TID 478) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:58.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:58 INFO TaskSetManager: Finished task 6.0 in stage 163.0 (TID 477) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:59.012+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 8.0 in stage 163.0 (TID 479) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 7.0 in stage 163.0 (TID 478) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:59.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 9.0 in stage 163.0 (TID 480) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 8.0 in stage 163.0 (TID 479) in 17 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:59.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 481) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 9.0 in stage 163.0 (TID 480) in 41 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:59.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool
[2025-05-08T19:39:59.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: ShuffleMapStage 163 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.274 s
[2025-05-08T19:39:59.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:59.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: running: Set(ShuffleMapStage 164)
[2025-05-08T19:39:59.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 165, ResultStage 166)
[2025-05-08T19:39:59.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:59.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.20.0.5:37427 (size: 5.6 KiB, free: 419.1 MiB)
[2025-05-08T19:39:59.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.1 MiB)
[2025-05-08T19:39:59.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 1.0 in stage 164.0 (TID 482) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 481) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:59.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.1 MiB)
[2025-05-08T19:39:59.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 2.0 in stage 164.0 (TID 483) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 1.0 in stage 164.0 (TID 482) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:59.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 3.0 in stage 164.0 (TID 484) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 2.0 in stage 164.0 (TID 483) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:59.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 4.0 in stage 164.0 (TID 485) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 3.0 in stage 164.0 (TID 484) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:59.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 5.0 in stage 164.0 (TID 486) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.125+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 4.0 in stage 164.0 (TID 485) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:59.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 6.0 in stage 164.0 (TID 487) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 5.0 in stage 164.0 (TID 486) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:59.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 7.0 in stage 164.0 (TID 488) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 6.0 in stage 164.0 (TID 487) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:59.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 8.0 in stage 164.0 (TID 489) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 7.0 in stage 164.0 (TID 488) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:59.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 9.0 in stage 164.0 (TID 490) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 8.0 in stage 164.0 (TID 489) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:59.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_441_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 9.0 in stage 164.0 (TID 490) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:59.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool
[2025-05-08T19:39:59.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: ShuffleMapStage 164 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.352 s
[2025-05-08T19:39:59.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:59.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:59.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 165, ResultStage 166)
[2025-05-08T19:39:59.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:59.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting ShuffleMapStage 165 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[453] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:39:59.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 238.9 KiB, free 419.5 MiB)
[2025-05-08T19:39:59.204+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_57_piece0 on f2a432e4376a:35283 in memory (size: 5.4 KiB, free: 432.9 MiB)
[2025-05-08T19:39:59.204+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.20.0.5:37427 in memory (size: 5.4 KiB, free: 419.0 MiB)
[2025-05-08T19:39:59.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 419.5 MiB)
[2025-05-08T19:39:59.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.8 MiB)
[2025-05-08T19:39:59.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:59.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 165 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[453] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:59.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Adding task set 165.0 with 10 tasks resource profile 0
[2025-05-08T19:39:59.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 491) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.20.0.5:37427 (size: 78.8 KiB, free: 418.9 MiB)
[2025-05-08T19:39:59.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:59376
[2025-05-08T19:39:59.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.8 MiB)
[2025-05-08T19:39:59.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:59376
[2025-05-08T19:39:59.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 1.0 in stage 165.0 (TID 492) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 491) in 46 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:59.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 418.8 MiB)
[2025-05-08T19:39:59.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 2.0 in stage 165.0 (TID 493) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 1.0 in stage 165.0 (TID 492) in 40 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:59.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.7 MiB)
[2025-05-08T19:39:59.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 3.0 in stage 165.0 (TID 494) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 2.0 in stage 165.0 (TID 493) in 29 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:59.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.7 MiB)
[2025-05-08T19:39:59.344+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 4.0 in stage 165.0 (TID 495) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 3.0 in stage 165.0 (TID 494) in 25 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:59.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.6 MiB)
[2025-05-08T19:39:59.372+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 5.0 in stage 165.0 (TID 496) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 4.0 in stage 165.0 (TID 495) in 29 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:59.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.6 MiB)
[2025-05-08T19:39:59.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 6.0 in stage 165.0 (TID 497) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.398+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 5.0 in stage 165.0 (TID 496) in 25 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:59.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.5 MiB)
[2025-05-08T19:39:59.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 7.0 in stage 165.0 (TID 498) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 6.0 in stage 165.0 (TID 497) in 24 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:59.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.5 MiB)
[2025-05-08T19:39:59.452+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 8.0 in stage 165.0 (TID 499) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 7.0 in stage 165.0 (TID 498) in 33 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:59.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.4 MiB)
[2025-05-08T19:39:59.486+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 9.0 in stage 165.0 (TID 500) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.487+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 8.0 in stage 165.0 (TID 499) in 34 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:59.500+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_447_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.4 MiB)
[2025-05-08T19:39:59.517+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 9.0 in stage 165.0 (TID 500) in 32 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:59.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool
[2025-05-08T19:39:59.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: ShuffleMapStage 165 (mapPartitions at GraphImpl.scala:208) finished in 0.344 s
[2025-05-08T19:39:59.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:59.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: running: Set()
[2025-05-08T19:39:59.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: waiting: Set(ResultStage 166)
[2025-05-08T19:39:59.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:59.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[457] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:39:59.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 12.9 KiB, free 419.4 MiB)
[2025-05-08T19:39:59.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 419.4 MiB)
[2025-05-08T19:39:59.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.20.0.5:37427 in memory (size: 5.6 KiB, free: 418.4 MiB)
[2025-05-08T19:39:59.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_58_piece0 on f2a432e4376a:35283 in memory (size: 5.6 KiB, free: 432.8 MiB)
[2025-05-08T19:39:59.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on f2a432e4376a:35283 (size: 5.8 KiB, free: 432.8 MiB)
[2025-05-08T19:39:59.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:59.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 166 (MapPartitionsRDD[457] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:59.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Adding task set 166.0 with 10 tasks resource profile 0
[2025-05-08T19:39:59.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 501) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.20.0.5:37427 (size: 5.8 KiB, free: 418.4 MiB)
[2025-05-08T19:39:59.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:59376
[2025-05-08T19:39:59.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_0 in memory on 172.20.0.5:37427 (size: 29.3 KiB, free: 418.3 MiB)
[2025-05-08T19:39:59.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 1.0 in stage 166.0 (TID 502) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 501) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:59.600+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_1 in memory on 172.20.0.5:37427 (size: 33.7 KiB, free: 418.3 MiB)
[2025-05-08T19:39:59.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 2.0 in stage 166.0 (TID 503) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 1.0 in stage 166.0 (TID 502) in 27 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:59.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_2 in memory on 172.20.0.5:37427 (size: 28.6 KiB, free: 418.3 MiB)
[2025-05-08T19:39:59.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 3.0 in stage 166.0 (TID 504) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.632+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 2.0 in stage 166.0 (TID 503) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:59.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_3 in memory on 172.20.0.5:37427 (size: 30.1 KiB, free: 418.2 MiB)
[2025-05-08T19:39:59.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 4.0 in stage 166.0 (TID 505) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 3.0 in stage 166.0 (TID 504) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:59.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_4 in memory on 172.20.0.5:37427 (size: 32.5 KiB, free: 418.2 MiB)
[2025-05-08T19:39:59.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 5.0 in stage 166.0 (TID 506) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 4.0 in stage 166.0 (TID 505) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:59.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_5 in memory on 172.20.0.5:37427 (size: 34.3 KiB, free: 418.2 MiB)
[2025-05-08T19:39:59.666+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 6.0 in stage 166.0 (TID 507) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 5.0 in stage 166.0 (TID 506) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:59.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_6 in memory on 172.20.0.5:37427 (size: 34.9 KiB, free: 418.1 MiB)
[2025-05-08T19:39:59.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 7.0 in stage 166.0 (TID 508) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 6.0 in stage 166.0 (TID 507) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:59.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_7 in memory on 172.20.0.5:37427 (size: 36.3 KiB, free: 418.1 MiB)
[2025-05-08T19:39:59.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 8.0 in stage 166.0 (TID 509) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 7.0 in stage 166.0 (TID 508) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:59.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_8 in memory on 172.20.0.5:37427 (size: 35.0 KiB, free: 418.1 MiB)
[2025-05-08T19:39:59.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 9.0 in stage 166.0 (TID 510) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4734 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 8.0 in stage 166.0 (TID 509) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:59.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_455_9 in memory on 172.20.0.5:37427 (size: 34.5 KiB, free: 418.0 MiB)
[2025-05-08T19:39:59.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 9.0 in stage 166.0 (TID 510) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:59.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool
[2025-05-08T19:39:59.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: ResultStage 166 (fold at VertexRDDImpl.scala:90) finished in 0.188 s
[2025-05-08T19:39:59.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:39:59.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 166: Stage finished
[2025-05-08T19:39:59.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Job 37 finished: fold at VertexRDDImpl.scala:90, took 0.919791 s
[2025-05-08T19:39:59.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO Pregel: Pregel finished iteration 1
[2025-05-08T19:39:59.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO ZippedPartitionsRDD2: Removing RDD 438 from persistence list
[2025-05-08T19:39:59.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManager: Removing RDD 438
[2025-05-08T19:39:59.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO ZippedPartitionsRDD2: Removing RDD 424 from persistence list
[2025-05-08T19:39:59.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManager: Removing RDD 424
[2025-05-08T19:39:59.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO ZippedPartitionsRDD2: Removing RDD 430 from persistence list
[2025-05-08T19:39:59.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManager: Removing RDD 430
[2025-05-08T19:39:59.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MapPartitionsRDD: Removing RDD 407 from persistence list
[2025-05-08T19:39:59.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManager: Removing RDD 407
[2025-05-08T19:39:59.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO ZippedPartitionsRDD2: Removing RDD 417 from persistence list
[2025-05-08T19:39:59.730+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManager: Removing RDD 417
[2025-05-08T19:39:59.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO ZippedPartitionsRDD2: Removing RDD 421 from persistence list
[2025-05-08T19:39:59.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManager: Removing RDD 421
[2025-05-08T19:39:59.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:39:59.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Registering RDD 462 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 47
[2025-05-08T19:39:59.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Registering RDD 466 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 48
[2025-05-08T19:39:59.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Registering RDD 470 (mapPartitions at GraphImpl.scala:208) as input to shuffle 49
[2025-05-08T19:39:59.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Got job 38 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:39:59.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Final stage: ResultStage 189 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:39:59.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 179, ShuffleMapStage 176, ShuffleMapStage 188, ShuffleMapStage 175, ShuffleMapStage 185, ShuffleMapStage 182)
[2025-05-08T19:39:59.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 188)
[2025-05-08T19:39:59.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting ShuffleMapStage 186 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[462] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:39:59.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 12.9 KiB, free 419.4 MiB)
[2025-05-08T19:39:59.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 419.4 MiB)
[2025-05-08T19:39:59.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.8 MiB)
[2025-05-08T19:39:59.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_60_piece0 on f2a432e4376a:35283 in memory (size: 5.8 KiB, free: 432.8 MiB)
[2025-05-08T19:39:59.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:59.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 186 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[462] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:59.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Adding task set 186.0 with 10 tasks resource profile 0
[2025-05-08T19:39:59.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 511) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.20.0.5:37427 in memory (size: 5.8 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting ShuffleMapStage 187 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[466] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:39:59.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 12.2 KiB, free 419.4 MiB)
[2025-05-08T19:39:59.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.20.0.5:37427 in memory (size: 78.8 KiB, free: 419.3 MiB)
[2025-05-08T19:39:59.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 419.4 MiB)
[2025-05-08T19:39:59.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on f2a432e4376a:35283 (size: 5.6 KiB, free: 432.8 MiB)
[2025-05-08T19:39:59.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:39:59.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 187 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[466] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:39:59.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Adding task set 187.0 with 10 tasks resource profile 0
[2025-05-08T19:39:59.777+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Removed broadcast_59_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.9 MiB)
[2025-05-08T19:39:59.778+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.20.0.5:37427 (size: 5.7 KiB, free: 419.3 MiB)
[2025-05-08T19:39:59.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:39:59.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 1.0 in stage 186.0 (TID 512) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 511) in 28 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:59.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:39:59.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 2.0 in stage 186.0 (TID 513) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 1.0 in stage 186.0 (TID 512) in 23 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:59.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 3.0 in stage 186.0 (TID 514) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 2.0 in stage 186.0 (TID 513) in 23 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:59.839+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 4.0 in stage 186.0 (TID 515) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 3.0 in stage 186.0 (TID 514) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:59.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 5.0 in stage 186.0 (TID 516) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 4.0 in stage 186.0 (TID 515) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:59.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 6.0 in stage 186.0 (TID 517) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 5.0 in stage 186.0 (TID 516) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:39:59.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 7.0 in stage 186.0 (TID 518) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 6.0 in stage 186.0 (TID 517) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:39:59.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 8.0 in stage 186.0 (TID 519) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 7.0 in stage 186.0 (TID 518) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:39:59.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 9.0 in stage 186.0 (TID 520) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 8.0 in stage 186.0 (TID 519) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:39:59.891+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added rdd_458_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:39:59.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 521) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 9.0 in stage 186.0 (TID 520) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:39:59.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool
[2025-05-08T19:39:59.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: ShuffleMapStage 186 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.150 s
[2025-05-08T19:39:59.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:39:59.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: running: Set(ShuffleMapStage 187)
[2025-05-08T19:39:59.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 188, ResultStage 189)
[2025-05-08T19:39:59.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO DAGScheduler: failed: Set()
[2025-05-08T19:39:59.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.20.0.5:37427 (size: 5.6 KiB, free: 419.1 MiB)
[2025-05-08T19:39:59.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 1.0 in stage 187.0 (TID 522) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 0.0 in stage 187.0 (TID 521) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:39:59.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 2.0 in stage 187.0 (TID 523) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 1.0 in stage 187.0 (TID 522) in 23 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:39:59.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 3.0 in stage 187.0 (TID 524) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 2.0 in stage 187.0 (TID 523) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:39:59.964+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 4.0 in stage 187.0 (TID 525) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.964+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 3.0 in stage 187.0 (TID 524) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:39:59.978+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 5.0 in stage 187.0 (TID 526) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.978+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 4.0 in stage 187.0 (TID 525) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:39:59.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Starting task 6.0 in stage 187.0 (TID 527) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:39:59.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:39:59 INFO TaskSetManager: Finished task 5.0 in stage 187.0 (TID 526) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:00.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 7.0 in stage 187.0 (TID 528) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.010+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 6.0 in stage 187.0 (TID 527) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:00.023+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 8.0 in stage 187.0 (TID 529) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.023+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 7.0 in stage 187.0 (TID 528) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:00.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 9.0 in stage 187.0 (TID 530) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 8.0 in stage 187.0 (TID 529) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:00.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 9.0 in stage 187.0 (TID 530) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:00.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool
[2025-05-08T19:40:00.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: ShuffleMapStage 187 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.290 s
[2025-05-08T19:40:00.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:00.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:00.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: waiting: Set(ShuffleMapStage 188, ResultStage 189)
[2025-05-08T19:40:00.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:00.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting ShuffleMapStage 188 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[470] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:00.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 239.2 KiB, free 419.5 MiB)
[2025-05-08T19:40:00.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 419.5 MiB)
[2025-05-08T19:40:00.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_61_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.9 MiB)
[2025-05-08T19:40:00.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:00.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:00.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 188 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[470] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:00.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Adding task set 188.0 with 10 tasks resource profile 0
[2025-05-08T19:40:00.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.20.0.5:37427 in memory (size: 5.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 531) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.20.0.5:37427 (size: 79.1 KiB, free: 419.1 MiB)
[2025-05-08T19:40:00.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:59376
[2025-05-08T19:40:00.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.0 MiB)
[2025-05-08T19:40:00.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:59376
[2025-05-08T19:40:00.137+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 1.0 in stage 188.0 (TID 532) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 531) in 59 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:00.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:00.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 2.0 in stage 188.0 (TID 533) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 1.0 in stage 188.0 (TID 532) in 37 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:00.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:00.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 3.0 in stage 188.0 (TID 534) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 2.0 in stage 188.0 (TID 533) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:00.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:00.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 4.0 in stage 188.0 (TID 535) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 3.0 in stage 188.0 (TID 534) in 31 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:00.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:00.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 5.0 in stage 188.0 (TID 536) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 4.0 in stage 188.0 (TID 535) in 29 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:00.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:00.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 6.0 in stage 188.0 (TID 537) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.282+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 5.0 in stage 188.0 (TID 536) in 26 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:00.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:00.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 7.0 in stage 188.0 (TID 538) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 6.0 in stage 188.0 (TID 537) in 26 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:00.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:00.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 8.0 in stage 188.0 (TID 539) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.349+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 7.0 in stage 188.0 (TID 538) in 42 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:00.362+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:00.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 9.0 in stage 188.0 (TID 540) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 8.0 in stage 188.0 (TID 539) in 29 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:00.393+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_464_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:00.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 9.0 in stage 188.0 (TID 540) in 37 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:00.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool
[2025-05-08T19:40:00.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: ShuffleMapStage 188 (mapPartitions at GraphImpl.scala:208) finished in 0.353 s
[2025-05-08T19:40:00.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:00.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:00.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: waiting: Set(ResultStage 189)
[2025-05-08T19:40:00.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:00.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[474] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:00.424+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 13.5 KiB, free 419.4 MiB)
[2025-05-08T19:40:00.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_62_piece0 on f2a432e4376a:35283 in memory (size: 5.6 KiB, free: 432.8 MiB)
[2025-05-08T19:40:00.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 419.4 MiB)
[2025-05-08T19:40:00.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.20.0.5:37427 in memory (size: 5.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:00.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:00.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:00.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 189 (MapPartitionsRDD[474] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:00.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Adding task set 189.0 with 10 tasks resource profile 0
[2025-05-08T19:40:00.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 541) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.20.0.5:37427 (size: 5.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:00.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:59376
[2025-05-08T19:40:00.480+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_0 in memory on 172.20.0.5:37427 (size: 27.8 KiB, free: 418.5 MiB)
[2025-05-08T19:40:00.482+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 1.0 in stage 189.0 (TID 542) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.482+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 541) in 27 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:00.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_1 in memory on 172.20.0.5:37427 (size: 31.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:00.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 2.0 in stage 189.0 (TID 543) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 1.0 in stage 189.0 (TID 542) in 23 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:00.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_2 in memory on 172.20.0.5:37427 (size: 27.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:00.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 3.0 in stage 189.0 (TID 544) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 2.0 in stage 189.0 (TID 543) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:00.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_3 in memory on 172.20.0.5:37427 (size: 28.5 KiB, free: 418.4 MiB)
[2025-05-08T19:40:00.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 4.0 in stage 189.0 (TID 545) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 3.0 in stage 189.0 (TID 544) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:00.530+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_4 in memory on 172.20.0.5:37427 (size: 31.6 KiB, free: 418.4 MiB)
[2025-05-08T19:40:00.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 5.0 in stage 189.0 (TID 546) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 4.0 in stage 189.0 (TID 545) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:00.539+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_5 in memory on 172.20.0.5:37427 (size: 32.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:00.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 6.0 in stage 189.0 (TID 547) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 5.0 in stage 189.0 (TID 546) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:00.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_6 in memory on 172.20.0.5:37427 (size: 33.1 KiB, free: 418.3 MiB)
[2025-05-08T19:40:00.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 7.0 in stage 189.0 (TID 548) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 6.0 in stage 189.0 (TID 547) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:00.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_7 in memory on 172.20.0.5:37427 (size: 34.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:00.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 8.0 in stage 189.0 (TID 549) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 7.0 in stage 189.0 (TID 548) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:00.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_8 in memory on 172.20.0.5:37427 (size: 32.6 KiB, free: 418.3 MiB)
[2025-05-08T19:40:00.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 9.0 in stage 189.0 (TID 550) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4807 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 8.0 in stage 189.0 (TID 549) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:00.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_472_9 in memory on 172.20.0.5:37427 (size: 32.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:00.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 9.0 in stage 189.0 (TID 550) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:00.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool
[2025-05-08T19:40:00.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: ResultStage 189 (fold at VertexRDDImpl.scala:90) finished in 0.160 s
[2025-05-08T19:40:00.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:00.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished
[2025-05-08T19:40:00.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Job 38 finished: fold at VertexRDDImpl.scala:90, took 0.836178 s
[2025-05-08T19:40:00.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO Pregel: Pregel finished iteration 2
[2025-05-08T19:40:00.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO ZippedPartitionsRDD2: Removing RDD 455 from persistence list
[2025-05-08T19:40:00.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManager: Removing RDD 455
[2025-05-08T19:40:00.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO ZippedPartitionsRDD2: Removing RDD 441 from persistence list
[2025-05-08T19:40:00.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManager: Removing RDD 441
[2025-05-08T19:40:00.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO ZippedPartitionsRDD2: Removing RDD 447 from persistence list
[2025-05-08T19:40:00.581+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManager: Removing RDD 447
[2025-05-08T19:40:00.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO ZippedPartitionsRDD2: Removing RDD 424 from persistence list
[2025-05-08T19:40:00.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManager: Removing RDD 424
[2025-05-08T19:40:00.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO ZippedPartitionsRDD2: Removing RDD 430 from persistence list
[2025-05-08T19:40:00.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManager: Removing RDD 430
[2025-05-08T19:40:00.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO ZippedPartitionsRDD2: Removing RDD 438 from persistence list
[2025-05-08T19:40:00.596+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManager: Removing RDD 438
[2025-05-08T19:40:00.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:00.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Registering RDD 479 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 50
[2025-05-08T19:40:00.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Registering RDD 483 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 51
[2025-05-08T19:40:00.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Registering RDD 487 (mapPartitions at GraphImpl.scala:208) as input to shuffle 52
[2025-05-08T19:40:00.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Got job 39 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:00.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Final stage: ResultStage 215 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:00.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 198, ShuffleMapStage 208, ShuffleMapStage 205, ShuffleMapStage 202, ShuffleMapStage 199, ShuffleMapStage 214, ShuffleMapStage 211)
[2025-05-08T19:40:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 214)
[2025-05-08T19:40:00.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting ShuffleMapStage 212 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[479] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:00.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 13.6 KiB, free 419.4 MiB)
[2025-05-08T19:40:00.619+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 419.4 MiB)
[2025-05-08T19:40:00.620+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on f2a432e4376a:35283 (size: 5.8 KiB, free: 432.8 MiB)
[2025-05-08T19:40:00.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:00.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 212 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[479] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:00.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Adding task set 212.0 with 10 tasks resource profile 0
[2025-05-08T19:40:00.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_63_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.9 MiB)
[2025-05-08T19:40:00.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting ShuffleMapStage 213 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[483] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:40:00.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 551) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.20.0.5:37427 in memory (size: 79.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:00.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 12.9 KiB, free 419.7 MiB)
[2025-05-08T19:40:00.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 419.7 MiB)
[2025-05-08T19:40:00.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.9 MiB)
[2025-05-08T19:40:00.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:00.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 213 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[483] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:00.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Adding task set 213.0 with 10 tasks resource profile 0
[2025-05-08T19:40:00.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_64_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-08T19:40:00.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.20.0.5:37427 in memory (size: 5.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:00.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.20.0.5:37427 (size: 5.8 KiB, free: 419.3 MiB)
[2025-05-08T19:40:00.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:00.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 1.0 in stage 212.0 (TID 552) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 551) in 33 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:00.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:00.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 2.0 in stage 212.0 (TID 553) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 1.0 in stage 212.0 (TID 552) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:00.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:00.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 3.0 in stage 212.0 (TID 554) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 2.0 in stage 212.0 (TID 553) in 23 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:00.696+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 4.0 in stage 212.0 (TID 555) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 3.0 in stage 212.0 (TID 554) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:00.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 5.0 in stage 212.0 (TID 556) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 4.0 in stage 212.0 (TID 555) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:00.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 6.0 in stage 212.0 (TID 557) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 5.0 in stage 212.0 (TID 556) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:00.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 7.0 in stage 212.0 (TID 558) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 6.0 in stage 212.0 (TID 557) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:00.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 8.0 in stage 212.0 (TID 559) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 7.0 in stage 212.0 (TID 558) in 38 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:00.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 9.0 in stage 212.0 (TID 560) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 8.0 in stage 212.0 (TID 559) in 30 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:00.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added rdd_475_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 561) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 9.0 in stage 212.0 (TID 560) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:00.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool
[2025-05-08T19:40:00.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: ShuffleMapStage 212 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.200 s
[2025-05-08T19:40:00.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:00.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: running: Set(ShuffleMapStage 213)
[2025-05-08T19:40:00.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: waiting: Set(ResultStage 215, ShuffleMapStage 214)
[2025-05-08T19:40:00.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:00.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.20.0.5:37427 (size: 5.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:00.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 1.0 in stage 213.0 (TID 562) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 561) in 27 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:00.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 2.0 in stage 213.0 (TID 563) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.845+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 1.0 in stage 213.0 (TID 562) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:00.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 3.0 in stage 213.0 (TID 564) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 2.0 in stage 213.0 (TID 563) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:00.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 4.0 in stage 213.0 (TID 565) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 3.0 in stage 213.0 (TID 564) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:00.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 5.0 in stage 213.0 (TID 566) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 4.0 in stage 213.0 (TID 565) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:00.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 6.0 in stage 213.0 (TID 567) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 5.0 in stage 213.0 (TID 566) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:00.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 7.0 in stage 213.0 (TID 568) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 6.0 in stage 213.0 (TID 567) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:00.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 8.0 in stage 213.0 (TID 569) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 7.0 in stage 213.0 (TID 568) in 20 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:00.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Starting task 9.0 in stage 213.0 (TID 570) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:00.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 8.0 in stage 213.0 (TID 569) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:00.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSetManager: Finished task 9.0 in stage 213.0 (TID 570) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:00.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool
[2025-05-08T19:40:00.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: ShuffleMapStage 213 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.340 s
[2025-05-08T19:40:00.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:00.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:00.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: waiting: Set(ResultStage 215, ShuffleMapStage 214)
[2025-05-08T19:40:00.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:00.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO DAGScheduler: Submitting ShuffleMapStage 214 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[487] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:00.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:00 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 239.5 KiB, free 419.5 MiB)
[2025-05-08T19:40:01.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 419.5 MiB)
[2025-05-08T19:40:01.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_65_piece0 on f2a432e4376a:35283 in memory (size: 5.8 KiB, free: 432.9 MiB)
[2025-05-08T19:40:01.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:01.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:01.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 214 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[487] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:01.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSchedulerImpl: Adding task set 214.0 with 10 tasks resource profile 0
[2025-05-08T19:40:01.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 571) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.20.0.5:37427 in memory (size: 5.8 KiB, free: 419.2 MiB)
[2025-05-08T19:40:01.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.20.0.5:37427 (size: 79.2 KiB, free: 419.1 MiB)
[2025-05-08T19:40:01.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:59376
[2025-05-08T19:40:01.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.0 MiB)
[2025-05-08T19:40:01.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:59376
[2025-05-08T19:40:01.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_66_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:01.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.20.0.5:37427 in memory (size: 5.7 KiB, free: 419.0 MiB)
[2025-05-08T19:40:01.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 1.0 in stage 214.0 (TID 572) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 571) in 101 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:01.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:01.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 2.0 in stage 214.0 (TID 573) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 1.0 in stage 214.0 (TID 572) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:01.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:01.208+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 3.0 in stage 214.0 (TID 574) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 2.0 in stage 214.0 (TID 573) in 39 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:01.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:01.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 4.0 in stage 214.0 (TID 575) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 3.0 in stage 214.0 (TID 574) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:01.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:01.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 5.0 in stage 214.0 (TID 576) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 4.0 in stage 214.0 (TID 575) in 23 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:01.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:01.280+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 6.0 in stage 214.0 (TID 577) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.280+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 5.0 in stage 214.0 (TID 576) in 27 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:01.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:01.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 7.0 in stage 214.0 (TID 578) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 6.0 in stage 214.0 (TID 577) in 27 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:01.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:01.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 8.0 in stage 214.0 (TID 579) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 7.0 in stage 214.0 (TID 578) in 27 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:01.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:01.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 9.0 in stage 214.0 (TID 580) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 8.0 in stage 214.0 (TID 579) in 26 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:01.378+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_481_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:01.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 9.0 in stage 214.0 (TID 580) in 36 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:01.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool
[2025-05-08T19:40:01.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: ShuffleMapStage 214 (mapPartitions at GraphImpl.scala:208) finished in 0.428 s
[2025-05-08T19:40:01.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:01.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:01.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: waiting: Set(ResultStage 215)
[2025-05-08T19:40:01.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:01.402+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Submitting ResultStage 215 (MapPartitionsRDD[491] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:01.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 14.2 KiB, free 419.5 MiB)
[2025-05-08T19:40:01.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 419.5 MiB)
[2025-05-08T19:40:01.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on f2a432e4376a:35283 (size: 6.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:01.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:01.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 215 (MapPartitionsRDD[491] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:01.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSchedulerImpl: Adding task set 215.0 with 10 tasks resource profile 0
[2025-05-08T19:40:01.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 581) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.20.0.5:37427 (size: 6.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:01.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.20.0.5:59376
[2025-05-08T19:40:01.480+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_0 in memory on 172.20.0.5:37427 (size: 28.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:01.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 1.0 in stage 215.0 (TID 582) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.487+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 581) in 20 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:01.495+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_1 in memory on 172.20.0.5:37427 (size: 30.5 KiB, free: 418.5 MiB)
[2025-05-08T19:40:01.499+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 2.0 in stage 215.0 (TID 583) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 1.0 in stage 215.0 (TID 582) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:01.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_2 in memory on 172.20.0.5:37427 (size: 27.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:01.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 3.0 in stage 215.0 (TID 584) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 2.0 in stage 215.0 (TID 583) in 31 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:01.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_3 in memory on 172.20.0.5:37427 (size: 28.5 KiB, free: 418.5 MiB)
[2025-05-08T19:40:01.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 4.0 in stage 215.0 (TID 585) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 3.0 in stage 215.0 (TID 584) in 23 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:01.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_4 in memory on 172.20.0.5:37427 (size: 30.9 KiB, free: 418.4 MiB)
[2025-05-08T19:40:01.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 5.0 in stage 215.0 (TID 586) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 4.0 in stage 215.0 (TID 585) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:01.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_5 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:01.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 6.0 in stage 215.0 (TID 587) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 5.0 in stage 215.0 (TID 586) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:01.581+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_6 in memory on 172.20.0.5:37427 (size: 32.5 KiB, free: 418.4 MiB)
[2025-05-08T19:40:01.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 7.0 in stage 215.0 (TID 588) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 6.0 in stage 215.0 (TID 587) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:01.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_7 in memory on 172.20.0.5:37427 (size: 33.5 KiB, free: 418.3 MiB)
[2025-05-08T19:40:01.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 8.0 in stage 215.0 (TID 589) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.656+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 7.0 in stage 215.0 (TID 588) in 73 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:01.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_8 in memory on 172.20.0.5:37427 (size: 32.1 KiB, free: 418.3 MiB)
[2025-05-08T19:40:01.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 9.0 in stage 215.0 (TID 590) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4880 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 8.0 in stage 215.0 (TID 589) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:01.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_489_9 in memory on 172.20.0.5:37427 (size: 32.6 KiB, free: 418.3 MiB)
[2025-05-08T19:40:01.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 9.0 in stage 215.0 (TID 590) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:01.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool
[2025-05-08T19:40:01.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: ResultStage 215 (fold at VertexRDDImpl.scala:90) finished in 0.270 s
[2025-05-08T19:40:01.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:01.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 215: Stage finished
[2025-05-08T19:40:01.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Job 39 finished: fold at VertexRDDImpl.scala:90, took 1.084451 s
[2025-05-08T19:40:01.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO Pregel: Pregel finished iteration 3
[2025-05-08T19:40:01.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO ZippedPartitionsRDD2: Removing RDD 472 from persistence list
[2025-05-08T19:40:01.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManager: Removing RDD 472
[2025-05-08T19:40:01.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO ZippedPartitionsRDD2: Removing RDD 458 from persistence list
[2025-05-08T19:40:01.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManager: Removing RDD 458
[2025-05-08T19:40:01.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO ZippedPartitionsRDD2: Removing RDD 464 from persistence list
[2025-05-08T19:40:01.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManager: Removing RDD 464
[2025-05-08T19:40:01.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO ZippedPartitionsRDD2: Removing RDD 441 from persistence list
[2025-05-08T19:40:01.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManager: Removing RDD 441
[2025-05-08T19:40:01.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO ZippedPartitionsRDD2: Removing RDD 447 from persistence list
[2025-05-08T19:40:01.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManager: Removing RDD 447
[2025-05-08T19:40:01.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO ZippedPartitionsRDD2: Removing RDD 455 from persistence list
[2025-05-08T19:40:01.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManager: Removing RDD 455
[2025-05-08T19:40:01.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:01.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Registering RDD 496 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 53
[2025-05-08T19:40:01.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Registering RDD 500 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 54
[2025-05-08T19:40:01.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Registering RDD 504 (mapPartitions at GraphImpl.scala:208) as input to shuffle 55
[2025-05-08T19:40:01.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Got job 40 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:01.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Final stage: ResultStage 244 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:01.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 237, ShuffleMapStage 234, ShuffleMapStage 224, ShuffleMapStage 231, ShuffleMapStage 228, ShuffleMapStage 225, ShuffleMapStage 240, ShuffleMapStage 243)
[2025-05-08T19:40:01.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 243)
[2025-05-08T19:40:01.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Submitting ShuffleMapStage 241 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[496] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:01.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 14.2 KiB, free 419.4 MiB)
[2025-05-08T19:40:01.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 419.4 MiB)
[2025-05-08T19:40:01.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:01.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.20.0.5:37427 in memory (size: 79.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:01.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:01.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 241 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[496] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:01.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSchedulerImpl: Adding task set 241.0 with 10 tasks resource profile 0
[2025-05-08T19:40:01.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Submitting ShuffleMapStage 242 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[500] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:40:01.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 0.0 in stage 241.0 (TID 591) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_67_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.9 MiB)
[2025-05-08T19:40:01.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 13.5 KiB, free 419.7 MiB)
[2025-05-08T19:40:01.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 419.7 MiB)
[2025-05-08T19:40:01.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on f2a432e4376a:35283 (size: 5.8 KiB, free: 432.9 MiB)
[2025-05-08T19:40:01.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:01.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_68_piece0 on f2a432e4376a:35283 in memory (size: 6.0 KiB, free: 432.9 MiB)
[2025-05-08T19:40:01.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 242 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[500] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:01.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSchedulerImpl: Adding task set 242.0 with 10 tasks resource profile 0
[2025-05-08T19:40:01.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.20.0.5:37427 in memory (size: 6.0 KiB, free: 419.3 MiB)
[2025-05-08T19:40:01.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.20.0.5:37427 (size: 5.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:01.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_492_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:01.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 1.0 in stage 241.0 (TID 592) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 0.0 in stage 241.0 (TID 591) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:01.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_492_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:01.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 2.0 in stage 241.0 (TID 593) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 1.0 in stage 241.0 (TID 592) in 39 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:01.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_492_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:01.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 3.0 in stage 241.0 (TID 594) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 2.0 in stage 241.0 (TID 593) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:01.903+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_492_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:01.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Starting task 4.0 in stage 241.0 (TID 595) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:01.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO TaskSetManager: Finished task 3.0 in stage 241.0 (TID 594) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:01.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:01 INFO BlockManagerInfo: Added rdd_492_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:02.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 5.0 in stage 241.0 (TID 596) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 4.0 in stage 241.0 (TID 595) in 123 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:02.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Added rdd_492_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 6.0 in stage 241.0 (TID 597) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 5.0 in stage 241.0 (TID 596) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:02.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Added rdd_492_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:02.051+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 7.0 in stage 241.0 (TID 598) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.051+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 6.0 in stage 241.0 (TID 597) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:02.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Added rdd_492_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:40:02.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 8.0 in stage 241.0 (TID 599) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 7.0 in stage 241.0 (TID 598) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:02.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Added rdd_492_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:02.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 9.0 in stage 241.0 (TID 600) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 8.0 in stage 241.0 (TID 599) in 6 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:02.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Added rdd_492_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:02.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 601) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 9.0 in stage 241.0 (TID 600) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:02.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSchedulerImpl: Removed TaskSet 241.0, whose tasks have all completed, from pool
[2025-05-08T19:40:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: ShuffleMapStage 241 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.316 s
[2025-05-08T19:40:02.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:02.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: running: Set(ShuffleMapStage 242)
[2025-05-08T19:40:02.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 243, ResultStage 244)
[2025-05-08T19:40:02.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:02.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.20.0.5:37427 (size: 5.8 KiB, free: 419.2 MiB)
[2025-05-08T19:40:02.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 1.0 in stage 242.0 (TID 602) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.119+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 601) in 49 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:02.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 2.0 in stage 242.0 (TID 603) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 1.0 in stage 242.0 (TID 602) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:02.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 3.0 in stage 242.0 (TID 604) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 2.0 in stage 242.0 (TID 603) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:02.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 4.0 in stage 242.0 (TID 605) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 3.0 in stage 242.0 (TID 604) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:02.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 5.0 in stage 242.0 (TID 606) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 4.0 in stage 242.0 (TID 605) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:02.178+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 6.0 in stage 242.0 (TID 607) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.178+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 5.0 in stage 242.0 (TID 606) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:02.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 7.0 in stage 242.0 (TID 608) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 6.0 in stage 242.0 (TID 607) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:02.219+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 8.0 in stage 242.0 (TID 609) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 7.0 in stage 242.0 (TID 608) in 29 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:02.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 9.0 in stage 242.0 (TID 610) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:02.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 8.0 in stage 242.0 (TID 609) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:02.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Finished task 9.0 in stage 242.0 (TID 610) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:02.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool
[2025-05-08T19:40:02.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: ShuffleMapStage 242 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.429 s
[2025-05-08T19:40:02.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:02.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:02.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 243, ResultStage 244)
[2025-05-08T19:40:02.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:02.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: Submitting ShuffleMapStage 243 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[504] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:02.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 239.8 KiB, free 419.5 MiB)
[2025-05-08T19:40:02.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 419.4 MiB)
[2025-05-08T19:40:02.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.8 MiB)
[2025-05-08T19:40:02.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO BlockManagerInfo: Removed broadcast_69_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:02.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:02.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 243 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[504] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:02.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSchedulerImpl: Adding task set 243.0 with 10 tasks resource profile 0
[2025-05-08T19:40:02.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:02 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 611) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:03.027+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:03 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.20.0.5:37427 in memory (size: 5.9 KiB, free: 419.2 MiB)
[2025-05-08T19:40:03.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:03 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.20.0.5:37427 (size: 79.4 KiB, free: 419.1 MiB)
[2025-05-08T19:40:05.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:59376
[2025-05-08T19:40:07.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:07 INFO BlockManagerInfo: Removed broadcast_70_piece0 on f2a432e4376a:35283 in memory (size: 5.8 KiB, free: 432.8 MiB)
[2025-05-08T19:40:07.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:07 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.20.0.5:37427 in memory (size: 5.8 KiB, free: 419.1 MiB)
[2025-05-08T19:40:08.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:08 INFO BlockManagerInfo: Added rdd_498_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.1 MiB)
[2025-05-08T19:40:08.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:59376
[2025-05-08T19:40:09.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 1.0 in stage 243.0 (TID 612) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 611) in 6363 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:09.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:09.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 2.0 in stage 243.0 (TID 613) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 1.0 in stage 243.0 (TID 612) in 207 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:09.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:09.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 3.0 in stage 243.0 (TID 614) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 2.0 in stage 243.0 (TID 613) in 196 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:09.506+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:09.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 4.0 in stage 243.0 (TID 615) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 3.0 in stage 243.0 (TID 614) in 157 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:09.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:09.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 5.0 in stage 243.0 (TID 616) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 4.0 in stage 243.0 (TID 615) in 87 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:09.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:09.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 6.0 in stage 243.0 (TID 617) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 5.0 in stage 243.0 (TID 616) in 40 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:09.724+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:09.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 7.0 in stage 243.0 (TID 618) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 6.0 in stage 243.0 (TID 617) in 24 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:09.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:09.759+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 8.0 in stage 243.0 (TID 619) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 7.0 in stage 243.0 (TID 618) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:09.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:09.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Starting task 9.0 in stage 243.0 (TID 620) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:09.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO TaskSetManager: Finished task 8.0 in stage 243.0 (TID 619) in 59 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:09.893+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:09 INFO BlockManagerInfo: Added rdd_498_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:10.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 9.0 in stage 243.0 (TID 620) in 474 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:10.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool
[2025-05-08T19:40:10.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: ShuffleMapStage 243 (mapPartitions at GraphImpl.scala:208) finished in 8.010 s
[2025-05-08T19:40:10.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:10.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:10.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: waiting: Set(ResultStage 244)
[2025-05-08T19:40:10.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:10.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: Submitting ResultStage 244 (MapPartitionsRDD[508] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:10.337+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 14.8 KiB, free 419.5 MiB)
[2025-05-08T19:40:10.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 419.5 MiB)
[2025-05-08T19:40:10.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:10.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:10.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 244 (MapPartitionsRDD[508] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:10.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSchedulerImpl: Adding task set 244.0 with 10 tasks resource profile 0
[2025-05-08T19:40:10.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 0.0 in stage 244.0 (TID 621) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.20.0.5:37427 (size: 6.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:10.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:59376
[2025-05-08T19:40:10.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_0 in memory on 172.20.0.5:37427 (size: 28.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:10.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 1.0 in stage 244.0 (TID 622) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 0.0 in stage 244.0 (TID 621) in 296 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:10.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_1 in memory on 172.20.0.5:37427 (size: 30.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:10.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 2.0 in stage 244.0 (TID 623) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 1.0 in stage 244.0 (TID 622) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:10.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_2 in memory on 172.20.0.5:37427 (size: 27.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:10.697+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 3.0 in stage 244.0 (TID 624) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 2.0 in stage 244.0 (TID 623) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:10.703+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_3 in memory on 172.20.0.5:37427 (size: 28.5 KiB, free: 418.5 MiB)
[2025-05-08T19:40:10.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 4.0 in stage 244.0 (TID 625) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 3.0 in stage 244.0 (TID 624) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:10.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_4 in memory on 172.20.0.5:37427 (size: 31.0 KiB, free: 418.4 MiB)
[2025-05-08T19:40:10.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 5.0 in stage 244.0 (TID 626) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 4.0 in stage 244.0 (TID 625) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:10.718+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_5 in memory on 172.20.0.5:37427 (size: 32.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:10.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 6.0 in stage 244.0 (TID 627) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 5.0 in stage 244.0 (TID 626) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:10.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_6 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:10.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 7.0 in stage 244.0 (TID 628) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 6.0 in stage 244.0 (TID 627) in 7 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:10.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_7 in memory on 172.20.0.5:37427 (size: 33.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:10.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 8.0 in stage 244.0 (TID 629) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.734+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 7.0 in stage 244.0 (TID 628) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:10.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_8 in memory on 172.20.0.5:37427 (size: 32.0 KiB, free: 418.3 MiB)
[2025-05-08T19:40:10.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Starting task 9.0 in stage 244.0 (TID 630) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4953 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:10.741+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 8.0 in stage 244.0 (TID 629) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:10.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManagerInfo: Added rdd_506_9 in memory on 172.20.0.5:37427 (size: 32.5 KiB, free: 418.3 MiB)
[2025-05-08T19:40:10.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSetManager: Finished task 9.0 in stage 244.0 (TID 630) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:10.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool
[2025-05-08T19:40:10.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: ResultStage 244 (fold at VertexRDDImpl.scala:90) finished in 0.432 s
[2025-05-08T19:40:10.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:10.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 244: Stage finished
[2025-05-08T19:40:10.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO DAGScheduler: Job 40 finished: fold at VertexRDDImpl.scala:90, took 9.048666 s
[2025-05-08T19:40:10.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO Pregel: Pregel finished iteration 4
[2025-05-08T19:40:10.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO ZippedPartitionsRDD2: Removing RDD 489 from persistence list
[2025-05-08T19:40:10.827+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManager: Removing RDD 489
[2025-05-08T19:40:10.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO ZippedPartitionsRDD2: Removing RDD 475 from persistence list
[2025-05-08T19:40:10.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManager: Removing RDD 475
[2025-05-08T19:40:10.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO ZippedPartitionsRDD2: Removing RDD 481 from persistence list
[2025-05-08T19:40:10.832+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:10 INFO BlockManager: Removing RDD 481
[2025-05-08T19:40:11.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO ZippedPartitionsRDD2: Removing RDD 458 from persistence list
[2025-05-08T19:40:11.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManager: Removing RDD 458
[2025-05-08T19:40:11.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO ZippedPartitionsRDD2: Removing RDD 464 from persistence list
[2025-05-08T19:40:11.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManager: Removing RDD 464
[2025-05-08T19:40:11.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO ZippedPartitionsRDD2: Removing RDD 472 from persistence list
[2025-05-08T19:40:11.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManager: Removing RDD 472
[2025-05-08T19:40:11.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Removed broadcast_71_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.9 MiB)
[2025-05-08T19:40:11.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:11.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Registering RDD 517 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 57
[2025-05-08T19:40:11.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Registering RDD 513 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 56
[2025-05-08T19:40:11.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Registering RDD 521 (mapPartitions at GraphImpl.scala:208) as input to shuffle 58
[2025-05-08T19:40:11.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Got job 41 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:11.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Final stage: ResultStage 276 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:11.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 266, ShuffleMapStage 263, ShuffleMapStage 253, ShuffleMapStage 260, ShuffleMapStage 275, ShuffleMapStage 272, ShuffleMapStage 257, ShuffleMapStage 254)
[2025-05-08T19:40:11.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 275)
[2025-05-08T19:40:11.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Submitting ShuffleMapStage 273 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[517] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:40:11.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 14.1 KiB, free 419.8 MiB)
[2025-05-08T19:40:11.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.20.0.5:37427 in memory (size: 79.4 KiB, free: 419.3 MiB)
[2025-05-08T19:40:11.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Removed broadcast_72_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-08T19:40:11.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.20.0.5:37427 in memory (size: 6.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:11.154+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 419.8 MiB)
[2025-05-08T19:40:11.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-08T19:40:11.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:11.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 273 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[517] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:11.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSchedulerImpl: Adding task set 273.0 with 10 tasks resource profile 0
[2025-05-08T19:40:11.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Submitting ShuffleMapStage 274 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[513] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:11.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 0.0 in stage 273.0 (TID 631) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 14.8 KiB, free 419.8 MiB)
[2025-05-08T19:40:11.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 419.7 MiB)
[2025-05-08T19:40:11.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on f2a432e4376a:35283 (size: 6.0 KiB, free: 432.9 MiB)
[2025-05-08T19:40:11.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:11.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 274 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[513] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:11.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSchedulerImpl: Adding task set 274.0 with 10 tasks resource profile 0
[2025-05-08T19:40:11.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.20.0.5:37427 (size: 5.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:11.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 1.0 in stage 273.0 (TID 632) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 0.0 in stage 273.0 (TID 631) in 159 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:11.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 2.0 in stage 273.0 (TID 633) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 1.0 in stage 273.0 (TID 632) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:11.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 3.0 in stage 273.0 (TID 634) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 2.0 in stage 273.0 (TID 633) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:11.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 4.0 in stage 273.0 (TID 635) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 3.0 in stage 273.0 (TID 634) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:11.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 5.0 in stage 273.0 (TID 636) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 4.0 in stage 273.0 (TID 635) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:11.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 6.0 in stage 273.0 (TID 637) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 5.0 in stage 273.0 (TID 636) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:11.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 7.0 in stage 273.0 (TID 638) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 6.0 in stage 273.0 (TID 637) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:11.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 8.0 in stage 273.0 (TID 639) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 7.0 in stage 273.0 (TID 638) in 20 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:11.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 9.0 in stage 273.0 (TID 640) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 8.0 in stage 273.0 (TID 639) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:11.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 0.0 in stage 274.0 (TID 641) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 9.0 in stage 273.0 (TID 640) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:11.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool
[2025-05-08T19:40:11.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: ShuffleMapStage 273 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.337 s
[2025-05-08T19:40:11.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:11.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: running: Set(ShuffleMapStage 274)
[2025-05-08T19:40:11.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 275, ResultStage 276)
[2025-05-08T19:40:11.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:11.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.20.0.5:37427 (size: 6.0 KiB, free: 419.3 MiB)
[2025-05-08T19:40:11.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:11.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 1.0 in stage 274.0 (TID 642) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 0.0 in stage 274.0 (TID 641) in 88 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:11.563+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:11.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 2.0 in stage 274.0 (TID 643) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 1.0 in stage 274.0 (TID 642) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:11.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:11.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 3.0 in stage 274.0 (TID 644) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 2.0 in stage 274.0 (TID 643) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:11.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 4.0 in stage 274.0 (TID 645) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 3.0 in stage 274.0 (TID 644) in 6 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:11.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.599+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 5.0 in stage 274.0 (TID 646) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.599+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 4.0 in stage 274.0 (TID 645) in 20 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:11.603+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 6.0 in stage 274.0 (TID 647) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 5.0 in stage 274.0 (TID 646) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:11.614+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 7.0 in stage 274.0 (TID 648) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 6.0 in stage 274.0 (TID 647) in 24 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:11.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 8.0 in stage 274.0 (TID 649) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 7.0 in stage 274.0 (TID 648) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:11.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.20.0.5:37427 in memory (size: 5.9 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Starting task 9.0 in stage 274.0 (TID 650) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:11.847+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 8.0 in stage 274.0 (TID 649) in 206 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:11.847+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Added rdd_509_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:11.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSetManager: Finished task 9.0 in stage 274.0 (TID 650) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:11.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO TaskSchedulerImpl: Removed TaskSet 274.0, whose tasks have all completed, from pool
[2025-05-08T19:40:11.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO BlockManagerInfo: Removed broadcast_73_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.9 MiB)
[2025-05-08T19:40:11.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: ShuffleMapStage 274 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.650 s
[2025-05-08T19:40:11.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:11.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:11.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 275, ResultStage 276)
[2025-05-08T19:40:11.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:11.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:11 INFO DAGScheduler: Submitting ShuffleMapStage 275 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[521] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:12.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 240.1 KiB, free 419.5 MiB)
[2025-05-08T19:40:12.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 419.5 MiB)
[2025-05-08T19:40:12.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:12.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:12.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 275 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[521] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:12.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO TaskSchedulerImpl: Adding task set 275.0 with 10 tasks resource profile 0
[2025-05-08T19:40:12.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO TaskSetManager: Starting task 0.0 in stage 275.0 (TID 651) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:12.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:12 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.20.0.5:37427 (size: 79.2 KiB, free: 419.1 MiB)
[2025-05-08T19:40:14.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:59376
[2025-05-08T19:40:16.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:16 INFO BlockManagerInfo: Added rdd_515_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.0 MiB)
[2025-05-08T19:40:17.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.20.0.5:59376
[2025-05-08T19:40:24.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:24 INFO TaskSetManager: Starting task 1.0 in stage 275.0 (TID 652) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:24.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:24 INFO TaskSetManager: Finished task 0.0 in stage 275.0 (TID 651) in 12575 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:24.943+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:24 INFO BlockManagerInfo: Added rdd_515_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:25.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 2.0 in stage 275.0 (TID 653) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 1.0 in stage 275.0 (TID 652) in 391 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:25.067+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:25.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 3.0 in stage 275.0 (TID 654) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 2.0 in stage 275.0 (TID 653) in 68 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:25.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:25.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 4.0 in stage 275.0 (TID 655) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 3.0 in stage 275.0 (TID 654) in 59 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:25.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:25.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 5.0 in stage 275.0 (TID 656) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 4.0 in stage 275.0 (TID 655) in 28 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:25.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:25.247+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 6.0 in stage 275.0 (TID 657) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 5.0 in stage 275.0 (TID 656) in 41 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:25.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:25.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 7.0 in stage 275.0 (TID 658) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.378+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 6.0 in stage 275.0 (TID 657) in 132 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:25.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:25.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 8.0 in stage 275.0 (TID 659) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 7.0 in stage 275.0 (TID 658) in 40 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:25.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:25.444+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 9.0 in stage 275.0 (TID 660) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 8.0 in stage 275.0 (TID 659) in 30 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:25.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_515_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:25.479+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 9.0 in stage 275.0 (TID 660) in 36 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:25.480+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool
[2025-05-08T19:40:25.485+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: ShuffleMapStage 275 (mapPartitions at GraphImpl.scala:208) finished in 13.599 s
[2025-05-08T19:40:25.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: waiting: Set(ResultStage 276)
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Submitting ResultStage 276 (MapPartitionsRDD[525] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 15.4 KiB, free 419.4 MiB)
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 419.4 MiB)
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on f2a432e4376a:35283 (size: 6.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:25.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:25.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 276 (MapPartitionsRDD[525] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:25.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSchedulerImpl: Adding task set 276.0 with 10 tasks resource profile 0
[2025-05-08T19:40:25.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 0.0 in stage 276.0 (TID 661) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.539+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.20.0.5:37427 (size: 6.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:25.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:59376
[2025-05-08T19:40:25.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_0 in memory on 172.20.0.5:37427 (size: 28.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:25.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 1.0 in stage 276.0 (TID 662) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.583+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 0.0 in stage 276.0 (TID 661) in 50 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:25.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_1 in memory on 172.20.0.5:37427 (size: 30.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:25.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 2.0 in stage 276.0 (TID 663) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 1.0 in stage 276.0 (TID 662) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:25.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_2 in memory on 172.20.0.5:37427 (size: 26.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:25.603+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 3.0 in stage 276.0 (TID 664) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 2.0 in stage 276.0 (TID 663) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:25.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_3 in memory on 172.20.0.5:37427 (size: 28.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:25.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 4.0 in stage 276.0 (TID 665) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.620+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 3.0 in stage 276.0 (TID 664) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:25.632+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_4 in memory on 172.20.0.5:37427 (size: 30.7 KiB, free: 418.4 MiB)
[2025-05-08T19:40:25.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 5.0 in stage 276.0 (TID 666) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 4.0 in stage 276.0 (TID 665) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:25.647+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_5 in memory on 172.20.0.5:37427 (size: 32.0 KiB, free: 418.4 MiB)
[2025-05-08T19:40:25.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 6.0 in stage 276.0 (TID 667) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 5.0 in stage 276.0 (TID 666) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:25.656+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_6 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:25.660+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 7.0 in stage 276.0 (TID 668) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 6.0 in stage 276.0 (TID 667) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:25.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_7 in memory on 172.20.0.5:37427 (size: 33.1 KiB, free: 418.3 MiB)
[2025-05-08T19:40:25.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 8.0 in stage 276.0 (TID 669) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 7.0 in stage 276.0 (TID 668) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:25.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Removed broadcast_75_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.9 MiB)
[2025-05-08T19:40:25.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.20.0.5:37427 in memory (size: 79.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:25.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.20.0.5:37427 in memory (size: 6.0 KiB, free: 418.4 MiB)
[2025-05-08T19:40:25.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Removed broadcast_74_piece0 on f2a432e4376a:35283 in memory (size: 6.0 KiB, free: 432.9 MiB)
[2025-05-08T19:40:25.697+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_8 in memory on 172.20.0.5:37427 (size: 31.8 KiB, free: 418.4 MiB)
[2025-05-08T19:40:25.702+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 9.0 in stage 276.0 (TID 670) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 8.0 in stage 276.0 (TID 669) in 32 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:25.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_523_9 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:25.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 9.0 in stage 276.0 (TID 670) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:25.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSchedulerImpl: Removed TaskSet 276.0, whose tasks have all completed, from pool
[2025-05-08T19:40:25.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: ResultStage 276 (fold at VertexRDDImpl.scala:90) finished in 0.230 s
[2025-05-08T19:40:25.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:25.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 276: Stage finished
[2025-05-08T19:40:25.718+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Job 41 finished: fold at VertexRDDImpl.scala:90, took 14.589395 s
[2025-05-08T19:40:25.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO Pregel: Pregel finished iteration 5
[2025-05-08T19:40:25.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO ZippedPartitionsRDD2: Removing RDD 506 from persistence list
[2025-05-08T19:40:25.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO ZippedPartitionsRDD2: Removing RDD 492 from persistence list
[2025-05-08T19:40:25.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO ZippedPartitionsRDD2: Removing RDD 498 from persistence list
[2025-05-08T19:40:25.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManager: Removing RDD 506
[2025-05-08T19:40:25.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManager: Removing RDD 492
[2025-05-08T19:40:25.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManager: Removing RDD 498
[2025-05-08T19:40:25.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO ZippedPartitionsRDD2: Removing RDD 475 from persistence list
[2025-05-08T19:40:25.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO ZippedPartitionsRDD2: Removing RDD 481 from persistence list
[2025-05-08T19:40:25.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManager: Removing RDD 475
[2025-05-08T19:40:25.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManager: Removing RDD 481
[2025-05-08T19:40:25.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO ZippedPartitionsRDD2: Removing RDD 489 from persistence list
[2025-05-08T19:40:25.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManager: Removing RDD 489
[2025-05-08T19:40:25.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:25.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Registering RDD 530 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 59
[2025-05-08T19:40:25.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Registering RDD 534 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 60
[2025-05-08T19:40:25.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Registering RDD 538 (mapPartitions at GraphImpl.scala:208) as input to shuffle 61
[2025-05-08T19:40:25.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Got job 42 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:25.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Final stage: ResultStage 311 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:25.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 285, ShuffleMapStage 310, ShuffleMapStage 307, ShuffleMapStage 286, ShuffleMapStage 304, ShuffleMapStage 292, ShuffleMapStage 289, ShuffleMapStage 301, ShuffleMapStage 298, ShuffleMapStage 295)
[2025-05-08T19:40:25.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 310)
[2025-05-08T19:40:25.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Submitting ShuffleMapStage 308 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:25.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 15.5 KiB, free 419.7 MiB)
[2025-05-08T19:40:25.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 419.7 MiB)
[2025-05-08T19:40:25.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-08T19:40:25.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:25.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 308 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:25.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSchedulerImpl: Adding task set 308.0 with 10 tasks resource profile 0
[2025-05-08T19:40:25.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Submitting ShuffleMapStage 309 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[534] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:40:25.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 0.0 in stage 308.0 (TID 671) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 14.8 KiB, free 419.7 MiB)
[2025-05-08T19:40:25.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 419.7 MiB)
[2025-05-08T19:40:25.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on f2a432e4376a:35283 (size: 6.0 KiB, free: 432.9 MiB)
[2025-05-08T19:40:25.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:25.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 309 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[534] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:25.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSchedulerImpl: Adding task set 309.0 with 10 tasks resource profile 0
[2025-05-08T19:40:25.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.20.0.5:37427 (size: 6.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:25.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:25.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 1.0 in stage 308.0 (TID 672) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 0.0 in stage 308.0 (TID 671) in 34 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:25.837+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:25.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 2.0 in stage 308.0 (TID 673) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 1.0 in stage 308.0 (TID 672) in 25 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:25.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Removed broadcast_76_piece0 on f2a432e4376a:35283 in memory (size: 6.2 KiB, free: 432.9 MiB)
[2025-05-08T19:40:25.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.20.0.5:37427 in memory (size: 6.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:25.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:25.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 3.0 in stage 308.0 (TID 674) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.881+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 2.0 in stage 308.0 (TID 673) in 37 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:25.888+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:25.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 4.0 in stage 308.0 (TID 675) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 3.0 in stage 308.0 (TID 674) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:25.900+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:25.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 5.0 in stage 308.0 (TID 676) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 4.0 in stage 308.0 (TID 675) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:25.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:25.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 6.0 in stage 308.0 (TID 677) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 5.0 in stage 308.0 (TID 676) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:25.933+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:25.941+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 7.0 in stage 308.0 (TID 678) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.941+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 6.0 in stage 308.0 (TID 677) in 18 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:25.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:40:25.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 8.0 in stage 308.0 (TID 679) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 7.0 in stage 308.0 (TID 678) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:25.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:25.958+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 9.0 in stage 308.0 (TID 680) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.958+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 8.0 in stage 308.0 (TID 679) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:25.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added rdd_526_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:25.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 681) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 9.0 in stage 308.0 (TID 680) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:25.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: ShuffleMapStage 308 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.175 s
[2025-05-08T19:40:25.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:25.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: running: Set(ShuffleMapStage 309)
[2025-05-08T19:40:25.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 310, ResultStage 311)
[2025-05-08T19:40:25.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:25.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSchedulerImpl: Removed TaskSet 308.0, whose tasks have all completed, from pool
[2025-05-08T19:40:25.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.20.0.5:37427 (size: 6.0 KiB, free: 419.2 MiB)
[2025-05-08T19:40:25.987+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 682) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:25.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:25 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 681) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:26.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 2.0 in stage 309.0 (TID 683) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 682) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:26.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 3.0 in stage 309.0 (TID 684) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 2.0 in stage 309.0 (TID 683) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:26.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 4.0 in stage 309.0 (TID 685) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 3.0 in stage 309.0 (TID 684) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:26.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 5.0 in stage 309.0 (TID 686) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 4.0 in stage 309.0 (TID 685) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:26.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 6.0 in stage 309.0 (TID 687) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 5.0 in stage 309.0 (TID 686) in 29 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:26.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 7.0 in stage 309.0 (TID 688) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 6.0 in stage 309.0 (TID 687) in 23 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:26.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 8.0 in stage 309.0 (TID 689) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 7.0 in stage 309.0 (TID 688) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:26.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 9.0 in stage 309.0 (TID 690) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 8.0 in stage 309.0 (TID 689) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:26.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 9.0 in stage 309.0 (TID 690) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:26.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool
[2025-05-08T19:40:26.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: ShuffleMapStage 309 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.333 s
[2025-05-08T19:40:26.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:26.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:26.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 310, ResultStage 311)
[2025-05-08T19:40:26.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:26.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: Submitting ShuffleMapStage 310 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[538] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:26.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 240.4 KiB, free 419.5 MiB)
[2025-05-08T19:40:26.178+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 419.4 MiB)
[2025-05-08T19:40:26.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:26.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:26.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 310 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[538] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:26.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSchedulerImpl: Adding task set 310.0 with 10 tasks resource profile 0
[2025-05-08T19:40:26.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 0.0 in stage 310.0 (TID 691) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.20.0.5:37427 (size: 79.3 KiB, free: 419.1 MiB)
[2025-05-08T19:40:26.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:59376
[2025-05-08T19:40:26.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.0 MiB)
[2025-05-08T19:40:26.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.20.0.5:59376
[2025-05-08T19:40:26.227+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 1.0 in stage 310.0 (TID 692) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 0.0 in stage 310.0 (TID 691) in 42 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:26.234+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:26.242+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 2.0 in stage 310.0 (TID 693) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.242+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 1.0 in stage 310.0 (TID 692) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:26.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:26.262+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 3.0 in stage 310.0 (TID 694) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.262+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 2.0 in stage 310.0 (TID 693) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:26.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:26.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 4.0 in stage 310.0 (TID 695) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 3.0 in stage 310.0 (TID 694) in 26 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:26.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:26.311+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 5.0 in stage 310.0 (TID 696) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 4.0 in stage 310.0 (TID 695) in 23 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:26.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:26.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 6.0 in stage 310.0 (TID 697) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.337+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 5.0 in stage 310.0 (TID 696) in 26 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:26.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:26.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 7.0 in stage 310.0 (TID 698) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 6.0 in stage 310.0 (TID 697) in 24 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:26.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:26.394+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 8.0 in stage 310.0 (TID 699) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.394+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 7.0 in stage 310.0 (TID 698) in 35 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:26.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:26.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Starting task 9.0 in stage 310.0 (TID 700) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:26.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 8.0 in stage 310.0 (TID 699) in 24 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:26.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO BlockManagerInfo: Added rdd_532_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:26.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSetManager: Finished task 9.0 in stage 310.0 (TID 700) in 104 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:26.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO TaskSchedulerImpl: Removed TaskSet 310.0, whose tasks have all completed, from pool
[2025-05-08T19:40:26.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: ShuffleMapStage 310 (mapPartitions at GraphImpl.scala:208) finished in 0.389 s
[2025-05-08T19:40:26.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:26.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:26.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: waiting: Set(ResultStage 311)
[2025-05-08T19:40:26.541+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:26.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO DAGScheduler: Submitting ResultStage 311 (MapPartitionsRDD[542] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:26.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:26 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 16.1 KiB, free 419.4 MiB)
[2025-05-08T19:40:27.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:27 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 419.4 MiB)
[2025-05-08T19:40:27.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:27 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:27.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:27 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:27.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:27 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 311 (MapPartitionsRDD[542] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:27.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:27 INFO TaskSchedulerImpl: Adding task set 311.0 with 10 tasks resource profile 0
[2025-05-08T19:40:27.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:27 INFO TaskSetManager: Starting task 0.0 in stage 311.0 (TID 701) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.20.0.5:37427 (size: 6.3 KiB, free: 418.6 MiB)
[2025-05-08T19:40:29.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:59376
[2025-05-08T19:40:29.782+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_0 in memory on 172.20.0.5:37427 (size: 28.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:29.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 1.0 in stage 311.0 (TID 702) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 0.0 in stage 311.0 (TID 701) in 2621 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:29.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_1 in memory on 172.20.0.5:37427 (size: 29.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:29.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 2.0 in stage 311.0 (TID 703) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 1.0 in stage 311.0 (TID 702) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:29.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_2 in memory on 172.20.0.5:37427 (size: 27.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:29.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 3.0 in stage 311.0 (TID 704) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 2.0 in stage 311.0 (TID 703) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:29.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_3 in memory on 172.20.0.5:37427 (size: 28.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:29.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 4.0 in stage 311.0 (TID 705) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 3.0 in stage 311.0 (TID 704) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:29.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_4 in memory on 172.20.0.5:37427 (size: 30.7 KiB, free: 418.4 MiB)
[2025-05-08T19:40:29.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 5.0 in stage 311.0 (TID 706) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 4.0 in stage 311.0 (TID 705) in 6 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:29.832+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_5 in memory on 172.20.0.5:37427 (size: 32.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:29.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 6.0 in stage 311.0 (TID 707) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 5.0 in stage 311.0 (TID 706) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:29.841+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_6 in memory on 172.20.0.5:37427 (size: 32.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:29.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 7.0 in stage 311.0 (TID 708) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 6.0 in stage 311.0 (TID 707) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:29.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_7 in memory on 172.20.0.5:37427 (size: 33.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:29.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 8.0 in stage 311.0 (TID 709) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 7.0 in stage 311.0 (TID 708) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:29.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_8 in memory on 172.20.0.5:37427 (size: 31.8 KiB, free: 418.3 MiB)
[2025-05-08T19:40:29.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 9.0 in stage 311.0 (TID 710) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5099 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 8.0 in stage 311.0 (TID 709) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:29.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added rdd_540_9 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:29.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Finished task 9.0 in stage 311.0 (TID 710) in 50 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:29.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSchedulerImpl: Removed TaskSet 311.0, whose tasks have all completed, from pool
[2025-05-08T19:40:29.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: ResultStage 311 (fold at VertexRDDImpl.scala:90) finished in 3.354 s
[2025-05-08T19:40:29.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:29.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 311: Stage finished
[2025-05-08T19:40:29.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Job 42 finished: fold at VertexRDDImpl.scala:90, took 4.144842 s
[2025-05-08T19:40:29.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO Pregel: Pregel finished iteration 6
[2025-05-08T19:40:29.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO ZippedPartitionsRDD2: Removing RDD 523 from persistence list
[2025-05-08T19:40:29.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManager: Removing RDD 523
[2025-05-08T19:40:29.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO ZippedPartitionsRDD2: Removing RDD 509 from persistence list
[2025-05-08T19:40:29.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManager: Removing RDD 509
[2025-05-08T19:40:29.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO ZippedPartitionsRDD2: Removing RDD 515 from persistence list
[2025-05-08T19:40:29.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManager: Removing RDD 515
[2025-05-08T19:40:29.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO ZippedPartitionsRDD2: Removing RDD 492 from persistence list
[2025-05-08T19:40:29.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManager: Removing RDD 492
[2025-05-08T19:40:29.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO ZippedPartitionsRDD2: Removing RDD 498 from persistence list
[2025-05-08T19:40:29.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManager: Removing RDD 498
[2025-05-08T19:40:29.958+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO ZippedPartitionsRDD2: Removing RDD 506 from persistence list
[2025-05-08T19:40:29.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManager: Removing RDD 506
[2025-05-08T19:40:29.971+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.20.0.5:37427 in memory (size: 79.3 KiB, free: 419.3 MiB)
[2025-05-08T19:40:29.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_79_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.9 MiB)
[2025-05-08T19:40:29.973+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_80_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-08T19:40:29.974+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.20.0.5:37427 in memory (size: 6.3 KiB, free: 419.3 MiB)
[2025-05-08T19:40:29.974+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:29.976+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.20.0.5:37427 in memory (size: 6.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:29.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_77_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Registering RDD 551 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 63
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.20.0.5:37427 in memory (size: 6.0 KiB, free: 419.3 MiB)
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Registering RDD 547 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 62
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Removed broadcast_78_piece0 on f2a432e4376a:35283 in memory (size: 6.0 KiB, free: 432.9 MiB)
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Registering RDD 555 (mapPartitions at GraphImpl.scala:208) as input to shuffle 64
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Got job 43 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Final stage: ResultStage 349 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:29.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 320, ShuffleMapStage 342, ShuffleMapStage 321, ShuffleMapStage 336, ShuffleMapStage 339, ShuffleMapStage 324, ShuffleMapStage 333, ShuffleMapStage 348, ShuffleMapStage 345, ShuffleMapStage 327, ShuffleMapStage 330)
[2025-05-08T19:40:29.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 348)
[2025-05-08T19:40:29.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Submitting ShuffleMapStage 346 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[551] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:40:29.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 15.4 KiB, free 419.8 MiB)
[2025-05-08T19:40:29.987+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 419.8 MiB)
[2025-05-08T19:40:29.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.9 MiB)
[2025-05-08T19:40:29.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:29.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 346 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[551] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:29.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSchedulerImpl: Adding task set 346.0 with 10 tasks resource profile 0
[2025-05-08T19:40:29.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Submitting ShuffleMapStage 347 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[547] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:29.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSetManager: Starting task 0.0 in stage 346.0 (TID 711) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:29.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 16.1 KiB, free 419.7 MiB)
[2025-05-08T19:40:29.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 419.7 MiB)
[2025-05-08T19:40:29.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-08T19:40:29.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:29.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 347 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[547] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:29.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO TaskSchedulerImpl: Adding task set 347.0 with 10 tasks resource profile 0
[2025-05-08T19:40:29.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:29 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.20.0.5:37427 (size: 6.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 1.0 in stage 346.0 (TID 712) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 0.0 in stage 346.0 (TID 711) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:30.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 2.0 in stage 346.0 (TID 713) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 1.0 in stage 346.0 (TID 712) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:30.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 3.0 in stage 346.0 (TID 714) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 2.0 in stage 346.0 (TID 713) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:30.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 4.0 in stage 346.0 (TID 715) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 3.0 in stage 346.0 (TID 714) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:30.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 5.0 in stage 346.0 (TID 716) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 4.0 in stage 346.0 (TID 715) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:30.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 6.0 in stage 346.0 (TID 717) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 5.0 in stage 346.0 (TID 716) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:30.075+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 7.0 in stage 346.0 (TID 718) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 6.0 in stage 346.0 (TID 717) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:30.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 8.0 in stage 346.0 (TID 719) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.089+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 7.0 in stage 346.0 (TID 718) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:30.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 9.0 in stage 346.0 (TID 720) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 8.0 in stage 346.0 (TID 719) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:30.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 0.0 in stage 347.0 (TID 721) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 9.0 in stage 346.0 (TID 720) in 20 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:30.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Removed TaskSet 346.0, whose tasks have all completed, from pool
[2025-05-08T19:40:30.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: ShuffleMapStage 346 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.139 s
[2025-05-08T19:40:30.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:30.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: running: Set(ShuffleMapStage 347)
[2025-05-08T19:40:30.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 348, ResultStage 349)
[2025-05-08T19:40:30.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:30.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.20.0.5:37427 (size: 6.3 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 1.0 in stage 347.0 (TID 722) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 0.0 in stage 347.0 (TID 721) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:30.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 2.0 in stage 347.0 (TID 723) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 1.0 in stage 347.0 (TID 722) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:30.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 3.0 in stage 347.0 (TID 724) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 2.0 in stage 347.0 (TID 723) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:30.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 4.0 in stage 347.0 (TID 725) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.165+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 3.0 in stage 347.0 (TID 724) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:30.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 5.0 in stage 347.0 (TID 726) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 4.0 in stage 347.0 (TID 725) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:30.178+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 6.0 in stage 347.0 (TID 727) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 5.0 in stage 347.0 (TID 726) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:30.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 7.0 in stage 347.0 (TID 728) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 6.0 in stage 347.0 (TID 727) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:30.198+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 8.0 in stage 347.0 (TID 729) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 7.0 in stage 347.0 (TID 728) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:30.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 9.0 in stage 347.0 (TID 730) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 8.0 in stage 347.0 (TID 729) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:30.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_543_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 9.0 in stage 347.0 (TID 730) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:30.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Removed TaskSet 347.0, whose tasks have all completed, from pool
[2025-05-08T19:40:30.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: ShuffleMapStage 347 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.240 s
[2025-05-08T19:40:30.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:30.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:30.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 348, ResultStage 349)
[2025-05-08T19:40:30.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:30.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting ShuffleMapStage 348 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[555] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:30.238+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 240.7 KiB, free 419.5 MiB)
[2025-05-08T19:40:30.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:30.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:30.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 348 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[555] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:30.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Adding task set 348.0 with 10 tasks resource profile 0
[2025-05-08T19:40:30.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 0.0 in stage 348.0 (TID 731) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.246+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.20.0.5:37427 (size: 79.3 KiB, free: 419.1 MiB)
[2025-05-08T19:40:30.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.20.0.5:59376
[2025-05-08T19:40:30.261+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.0 MiB)
[2025-05-08T19:40:30.262+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.20.0.5:59376
[2025-05-08T19:40:30.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 1.0 in stage 348.0 (TID 732) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 0.0 in stage 348.0 (TID 731) in 31 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:30.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:30.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 2.0 in stage 348.0 (TID 733) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 1.0 in stage 348.0 (TID 732) in 28 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:30.313+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:30.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 3.0 in stage 348.0 (TID 734) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 2.0 in stage 348.0 (TID 733) in 25 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:30.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:30.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 4.0 in stage 348.0 (TID 735) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 3.0 in stage 348.0 (TID 734) in 21 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:30.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:30.364+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 5.0 in stage 348.0 (TID 736) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 4.0 in stage 348.0 (TID 735) in 19 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:30.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:30.388+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 6.0 in stage 348.0 (TID 737) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.388+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 5.0 in stage 348.0 (TID 736) in 24 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:30.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:30.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 7.0 in stage 348.0 (TID 738) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 6.0 in stage 348.0 (TID 737) in 24 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:30.419+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:30.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 8.0 in stage 348.0 (TID 739) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 7.0 in stage 348.0 (TID 738) in 18 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:30.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:30.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 9.0 in stage 348.0 (TID 740) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 8.0 in stage 348.0 (TID 739) in 20 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:30.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_549_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:30.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 9.0 in stage 348.0 (TID 740) in 18 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:30.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Removed TaskSet 348.0, whose tasks have all completed, from pool
[2025-05-08T19:40:30.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: ShuffleMapStage 348 (mapPartitions at GraphImpl.scala:208) finished in 0.235 s
[2025-05-08T19:40:30.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:30.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:30.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: waiting: Set(ResultStage 349)
[2025-05-08T19:40:30.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:30.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting ResultStage 349 (MapPartitionsRDD[559] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:30.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 16.7 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.8 MiB)
[2025-05-08T19:40:30.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:30.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 349 (MapPartitionsRDD[559] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:30.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Adding task set 349.0 with 10 tasks resource profile 0
[2025-05-08T19:40:30.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 0.0 in stage 349.0 (TID 741) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.20.0.5:37427 (size: 6.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:30.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.20.0.5:59376
[2025-05-08T19:40:30.477+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_0 in memory on 172.20.0.5:37427 (size: 28.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:30.478+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 1.0 in stage 349.0 (TID 742) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.478+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 0.0 in stage 349.0 (TID 741) in 9 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:30.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_1 in memory on 172.20.0.5:37427 (size: 30.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:30.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 2.0 in stage 349.0 (TID 743) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 1.0 in stage 349.0 (TID 742) in 6 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:30.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_2 in memory on 172.20.0.5:37427 (size: 26.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:30.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 3.0 in stage 349.0 (TID 744) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 2.0 in stage 349.0 (TID 743) in 6 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:30.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_3 in memory on 172.20.0.5:37427 (size: 28.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:30.497+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 4.0 in stage 349.0 (TID 745) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 3.0 in stage 349.0 (TID 744) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:30.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_4 in memory on 172.20.0.5:37427 (size: 30.5 KiB, free: 418.4 MiB)
[2025-05-08T19:40:30.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 5.0 in stage 349.0 (TID 746) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 4.0 in stage 349.0 (TID 745) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:30.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_5 in memory on 172.20.0.5:37427 (size: 32.0 KiB, free: 418.4 MiB)
[2025-05-08T19:40:30.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 6.0 in stage 349.0 (TID 747) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 5.0 in stage 349.0 (TID 746) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:30.522+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_6 in memory on 172.20.0.5:37427 (size: 32.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:30.524+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 7.0 in stage 349.0 (TID 748) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.524+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 6.0 in stage 349.0 (TID 747) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:30.536+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_7 in memory on 172.20.0.5:37427 (size: 33.1 KiB, free: 418.3 MiB)
[2025-05-08T19:40:30.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 8.0 in stage 349.0 (TID 749) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 7.0 in stage 349.0 (TID 748) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:30.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_8 in memory on 172.20.0.5:37427 (size: 31.8 KiB, free: 418.3 MiB)
[2025-05-08T19:40:30.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 9.0 in stage 349.0 (TID 750) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5172 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 8.0 in stage 349.0 (TID 749) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:30.556+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_557_9 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:30.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 9.0 in stage 349.0 (TID 750) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:30.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Removed TaskSet 349.0, whose tasks have all completed, from pool
[2025-05-08T19:40:30.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: ResultStage 349 (fold at VertexRDDImpl.scala:90) finished in 0.091 s
[2025-05-08T19:40:30.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:30.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 349: Stage finished
[2025-05-08T19:40:30.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Job 43 finished: fold at VertexRDDImpl.scala:90, took 0.583286 s
[2025-05-08T19:40:30.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO Pregel: Pregel finished iteration 7
[2025-05-08T19:40:30.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO ZippedPartitionsRDD2: Removing RDD 540 from persistence list
[2025-05-08T19:40:30.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManager: Removing RDD 540
[2025-05-08T19:40:30.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO ZippedPartitionsRDD2: Removing RDD 526 from persistence list
[2025-05-08T19:40:30.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManager: Removing RDD 526
[2025-05-08T19:40:30.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO ZippedPartitionsRDD2: Removing RDD 532 from persistence list
[2025-05-08T19:40:30.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManager: Removing RDD 532
[2025-05-08T19:40:30.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO ZippedPartitionsRDD2: Removing RDD 509 from persistence list
[2025-05-08T19:40:30.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManager: Removing RDD 509
[2025-05-08T19:40:30.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO ZippedPartitionsRDD2: Removing RDD 515 from persistence list
[2025-05-08T19:40:30.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManager: Removing RDD 515
[2025-05-08T19:40:30.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO ZippedPartitionsRDD2: Removing RDD 523 from persistence list
[2025-05-08T19:40:30.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManager: Removing RDD 523
[2025-05-08T19:40:30.581+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:30.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Registering RDD 564 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 65
[2025-05-08T19:40:30.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Registering RDD 568 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 66
[2025-05-08T19:40:30.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Registering RDD 572 (mapPartitions at GraphImpl.scala:208) as input to shuffle 67
[2025-05-08T19:40:30.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Got job 44 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:30.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Final stage: ResultStage 390 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:30.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 389, ShuffleMapStage 386, ShuffleMapStage 383, ShuffleMapStage 371, ShuffleMapStage 368, ShuffleMapStage 358, ShuffleMapStage 365, ShuffleMapStage 380, ShuffleMapStage 359, ShuffleMapStage 377, ShuffleMapStage 362)
[2025-05-08T19:40:30.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 389)
[2025-05-08T19:40:30.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting ShuffleMapStage 387 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[564] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:30.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_82_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:30.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 16.7 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.20.0.5:37427 in memory (size: 6.3 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.8 MiB)
[2025-05-08T19:40:30.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:30.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 387 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[564] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:30.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Adding task set 387.0 with 10 tasks resource profile 0
[2025-05-08T19:40:30.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_81_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:30.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting ShuffleMapStage 388 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[568] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:40:30.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 0.0 in stage 387.0 (TID 751) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.20.0.5:37427 in memory (size: 6.1 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 16.0 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on f2a432e4376a:35283 (size: 6.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:30.599+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:30.600+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_83_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.9 MiB)
[2025-05-08T19:40:30.600+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 388 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[568] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:30.600+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Adding task set 388.0 with 10 tasks resource profile 0
[2025-05-08T19:40:30.600+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.20.0.5:37427 in memory (size: 79.3 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.20.0.5:37427 (size: 6.4 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_84_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.9 MiB)
[2025-05-08T19:40:30.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.20.0.5:37427 in memory (size: 6.4 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 1.0 in stage 387.0 (TID 752) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 0.0 in stage 387.0 (TID 751) in 14 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:30.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.614+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 2.0 in stage 387.0 (TID 753) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.614+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 1.0 in stage 387.0 (TID 752) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:30.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.624+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 3.0 in stage 387.0 (TID 754) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 2.0 in stage 387.0 (TID 753) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:30.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:30.632+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 4.0 in stage 387.0 (TID 755) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 3.0 in stage 387.0 (TID 754) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:30.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 5.0 in stage 387.0 (TID 756) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 4.0 in stage 387.0 (TID 755) in 6 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:30.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 6.0 in stage 387.0 (TID 757) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 5.0 in stage 387.0 (TID 756) in 6 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:30.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 7.0 in stage 387.0 (TID 758) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.652+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 6.0 in stage 387.0 (TID 757) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:30.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 8.0 in stage 387.0 (TID 759) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 7.0 in stage 387.0 (TID 758) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:30.660+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 9.0 in stage 387.0 (TID 760) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 8.0 in stage 387.0 (TID 759) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:30.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_560_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 0.0 in stage 388.0 (TID 761) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 9.0 in stage 387.0 (TID 760) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:30.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Removed TaskSet 387.0, whose tasks have all completed, from pool
[2025-05-08T19:40:30.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: ShuffleMapStage 387 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.083 s
[2025-05-08T19:40:30.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:30.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: running: Set(ShuffleMapStage 388)
[2025-05-08T19:40:30.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 389, ResultStage 390)
[2025-05-08T19:40:30.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:30.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.20.0.5:37427 (size: 6.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:30.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 1.0 in stage 388.0 (TID 762) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 0.0 in stage 388.0 (TID 761) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:30.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 2.0 in stage 388.0 (TID 763) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 1.0 in stage 388.0 (TID 762) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:30.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 3.0 in stage 388.0 (TID 764) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 2.0 in stage 388.0 (TID 763) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:30.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 4.0 in stage 388.0 (TID 765) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 3.0 in stage 388.0 (TID 764) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:30.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 5.0 in stage 388.0 (TID 766) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 4.0 in stage 388.0 (TID 765) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:30.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 6.0 in stage 388.0 (TID 767) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 5.0 in stage 388.0 (TID 766) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:30.758+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 7.0 in stage 388.0 (TID 768) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.758+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 6.0 in stage 388.0 (TID 767) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:30.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 8.0 in stage 388.0 (TID 769) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 7.0 in stage 388.0 (TID 768) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:30.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 9.0 in stage 388.0 (TID 770) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.784+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 8.0 in stage 388.0 (TID 769) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:30.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 9.0 in stage 388.0 (TID 770) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:30.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Removed TaskSet 388.0, whose tasks have all completed, from pool
[2025-05-08T19:40:30.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: ShuffleMapStage 388 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.199 s
[2025-05-08T19:40:30.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:30.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:30.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 389, ResultStage 390)
[2025-05-08T19:40:30.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:30.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting ShuffleMapStage 389 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[572] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:30.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 240.9 KiB, free 419.5 MiB)
[2025-05-08T19:40:30.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 419.4 MiB)
[2025-05-08T19:40:30.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.8 MiB)
[2025-05-08T19:40:30.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:30.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 389 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[572] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:30.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSchedulerImpl: Adding task set 389.0 with 10 tasks resource profile 0
[2025-05-08T19:40:30.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 0.0 in stage 389.0 (TID 771) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.20.0.5:37427 (size: 79.4 KiB, free: 419.1 MiB)
[2025-05-08T19:40:30.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.20.0.5:59376
[2025-05-08T19:40:30.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.0 MiB)
[2025-05-08T19:40:30.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.20.0.5:59376
[2025-05-08T19:40:30.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 1.0 in stage 389.0 (TID 772) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 0.0 in stage 389.0 (TID 771) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:30.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:30.841+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 2.0 in stage 389.0 (TID 773) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.842+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 1.0 in stage 389.0 (TID 772) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:30.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:30.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 3.0 in stage 389.0 (TID 774) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 2.0 in stage 389.0 (TID 773) in 20 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:30.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:30.884+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 4.0 in stage 389.0 (TID 775) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.884+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 3.0 in stage 389.0 (TID 774) in 24 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:30.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:30.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 5.0 in stage 389.0 (TID 776) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 4.0 in stage 389.0 (TID 775) in 25 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:30.920+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:30.933+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 6.0 in stage 389.0 (TID 777) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 5.0 in stage 389.0 (TID 776) in 26 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:30.941+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:30.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 7.0 in stage 389.0 (TID 778) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.954+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 6.0 in stage 389.0 (TID 777) in 21 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:30.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:30.974+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 8.0 in stage 389.0 (TID 779) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 7.0 in stage 389.0 (TID 778) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:30.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO BlockManagerInfo: Added rdd_566_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:30.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Starting task 9.0 in stage 389.0 (TID 780) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:30.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:30 INFO TaskSetManager: Finished task 8.0 in stage 389.0 (TID 779) in 20 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:31.003+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_566_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:31.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 9.0 in stage 389.0 (TID 780) in 20 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:31.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Removed TaskSet 389.0, whose tasks have all completed, from pool
[2025-05-08T19:40:31.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: ShuffleMapStage 389 (mapPartitions at GraphImpl.scala:208) finished in 0.222 s
[2025-05-08T19:40:31.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:31.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:31.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: waiting: Set(ResultStage 390)
[2025-05-08T19:40:31.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:31.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting ResultStage 390 (MapPartitionsRDD[576] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:31.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 17.3 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on f2a432e4376a:35283 (size: 6.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:31.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 390 (MapPartitionsRDD[576] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:31.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Adding task set 390.0 with 10 tasks resource profile 0
[2025-05-08T19:40:31.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 0.0 in stage 390.0 (TID 781) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.022+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.20.0.5:37427 (size: 6.5 KiB, free: 418.6 MiB)
[2025-05-08T19:40:31.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.20.0.5:59376
[2025-05-08T19:40:31.027+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_0 in memory on 172.20.0.5:37427 (size: 28.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 1.0 in stage 390.0 (TID 782) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 0.0 in stage 390.0 (TID 781) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:31.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_1 in memory on 172.20.0.5:37427 (size: 29.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 2.0 in stage 390.0 (TID 783) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 1.0 in stage 390.0 (TID 782) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:31.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_2 in memory on 172.20.0.5:37427 (size: 27.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.047+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 3.0 in stage 390.0 (TID 784) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 2.0 in stage 390.0 (TID 783) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:31.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_3 in memory on 172.20.0.5:37427 (size: 28.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 4.0 in stage 390.0 (TID 785) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 3.0 in stage 390.0 (TID 784) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:31.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_4 in memory on 172.20.0.5:37427 (size: 30.7 KiB, free: 418.4 MiB)
[2025-05-08T19:40:31.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 5.0 in stage 390.0 (TID 786) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 4.0 in stage 390.0 (TID 785) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:31.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_5 in memory on 172.20.0.5:37427 (size: 32.1 KiB, free: 418.4 MiB)
[2025-05-08T19:40:31.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 6.0 in stage 390.0 (TID 787) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 5.0 in stage 390.0 (TID 786) in 23 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:31.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_6 in memory on 172.20.0.5:37427 (size: 32.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:31.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 7.0 in stage 390.0 (TID 788) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 6.0 in stage 390.0 (TID 787) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:31.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_7 in memory on 172.20.0.5:37427 (size: 33.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:31.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 8.0 in stage 390.0 (TID 789) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 7.0 in stage 390.0 (TID 788) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:31.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_8 in memory on 172.20.0.5:37427 (size: 31.8 KiB, free: 418.3 MiB)
[2025-05-08T19:40:31.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 9.0 in stage 390.0 (TID 790) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5245 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 8.0 in stage 390.0 (TID 789) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:31.119+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_574_9 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:31.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 9.0 in stage 390.0 (TID 790) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:31.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Removed TaskSet 390.0, whose tasks have all completed, from pool
[2025-05-08T19:40:31.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: ResultStage 390 (fold at VertexRDDImpl.scala:90) finished in 0.105 s
[2025-05-08T19:40:31.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:31.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 390: Stage finished
[2025-05-08T19:40:31.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Job 44 finished: fold at VertexRDDImpl.scala:90, took 0.540382 s
[2025-05-08T19:40:31.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO Pregel: Pregel finished iteration 8
[2025-05-08T19:40:31.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 557 from persistence list
[2025-05-08T19:40:31.125+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 543 from persistence list
[2025-05-08T19:40:31.126+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 549 from persistence list
[2025-05-08T19:40:31.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 557
[2025-05-08T19:40:31.132+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 543
[2025-05-08T19:40:31.132+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 549
[2025-05-08T19:40:31.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 526 from persistence list
[2025-05-08T19:40:31.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 526
[2025-05-08T19:40:31.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 532 from persistence list
[2025-05-08T19:40:31.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 532
[2025-05-08T19:40:31.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 540 from persistence list
[2025-05-08T19:40:31.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 540
[2025-05-08T19:40:31.152+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:31.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Registering RDD 585 (mapPartitions at VertexRDDImpl.scala:251) as input to shuffle 69
[2025-05-08T19:40:31.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Registering RDD 581 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 68
[2025-05-08T19:40:31.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Registering RDD 589 (mapPartitions at GraphImpl.scala:208) as input to shuffle 70
[2025-05-08T19:40:31.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Got job 45 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:31.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Final stage: ResultStage 434 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:31.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 418, ShuffleMapStage 403, ShuffleMapStage 433, ShuffleMapStage 430, ShuffleMapStage 409, ShuffleMapStage 427, ShuffleMapStage 424, ShuffleMapStage 406, ShuffleMapStage 412, ShuffleMapStage 399, ShuffleMapStage 421, ShuffleMapStage 400, ShuffleMapStage 415)
[2025-05-08T19:40:31.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 433)
[2025-05-08T19:40:31.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting ShuffleMapStage 431 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[585] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:40:31.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 16.7 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:31.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 431 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[585] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:31.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Adding task set 431.0 with 10 tasks resource profile 0
[2025-05-08T19:40:31.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting ShuffleMapStage 432 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[581] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:31.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 0.0 in stage 431.0 (TID 791) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 17.4 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.20.0.5:37427 in memory (size: 6.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on f2a432e4376a:35283 (size: 6.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_85_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:31.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 432 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[581] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:31.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Adding task set 432.0 with 10 tasks resource profile 0
[2025-05-08T19:40:31.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.20.0.5:37427 (size: 6.3 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.204+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_88_piece0 on f2a432e4376a:35283 in memory (size: 6.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.20.0.5:37427 in memory (size: 6.5 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_87_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.9 MiB)
[2025-05-08T19:40:31.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.20.0.5:37427 in memory (size: 79.4 KiB, free: 419.3 MiB)
[2025-05-08T19:40:31.219+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_86_piece0 on f2a432e4376a:35283 in memory (size: 6.2 KiB, free: 432.9 MiB)
[2025-05-08T19:40:31.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 1.0 in stage 431.0 (TID 792) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 0.0 in stage 431.0 (TID 791) in 61 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:31.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.20.0.5:37427 in memory (size: 6.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:31.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 2.0 in stage 431.0 (TID 793) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 1.0 in stage 431.0 (TID 792) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:31.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 3.0 in stage 431.0 (TID 794) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 2.0 in stage 431.0 (TID 793) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:31.287+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 4.0 in stage 431.0 (TID 795) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.287+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 3.0 in stage 431.0 (TID 794) in 34 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:31.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 5.0 in stage 431.0 (TID 796) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 4.0 in stage 431.0 (TID 795) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:31.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 6.0 in stage 431.0 (TID 797) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 5.0 in stage 431.0 (TID 796) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:31.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 7.0 in stage 431.0 (TID 798) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 6.0 in stage 431.0 (TID 797) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:31.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 8.0 in stage 431.0 (TID 799) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 7.0 in stage 431.0 (TID 798) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:31.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 9.0 in stage 431.0 (TID 800) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5234 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 8.0 in stage 431.0 (TID 799) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:31.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 0.0 in stage 432.0 (TID 801) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 9.0 in stage 431.0 (TID 800) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Removed TaskSet 431.0, whose tasks have all completed, from pool
[2025-05-08T19:40:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: ShuffleMapStage 431 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.199 s
[2025-05-08T19:40:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: running: Set(ShuffleMapStage 432)
[2025-05-08T19:40:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: waiting: Set(ResultStage 434, ShuffleMapStage 433)
[2025-05-08T19:40:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:31.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.20.0.5:37427 (size: 6.5 KiB, free: 419.3 MiB)
[2025-05-08T19:40:31.363+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:31.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 1.0 in stage 432.0 (TID 802) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 0.0 in stage 432.0 (TID 801) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:31.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.3 MiB)
[2025-05-08T19:40:31.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 2.0 in stage 432.0 (TID 803) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 1.0 in stage 432.0 (TID 802) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:31.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.3 MiB)
[2025-05-08T19:40:31.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 3.0 in stage 432.0 (TID 804) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 2.0 in stage 432.0 (TID 803) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:31.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 4.0 in stage 432.0 (TID 805) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 3.0 in stage 432.0 (TID 804) in 6 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:31.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 5.0 in stage 432.0 (TID 806) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 4.0 in stage 432.0 (TID 805) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:31.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 6.0 in stage 432.0 (TID 807) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 5.0 in stage 432.0 (TID 806) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:31.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 7.0 in stage 432.0 (TID 808) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 6.0 in stage 432.0 (TID 807) in 6 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:31.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 8.0 in stage 432.0 (TID 809) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 7.0 in stage 432.0 (TID 808) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:31.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 9.0 in stage 432.0 (TID 810) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 8.0 in stage 432.0 (TID 809) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:31.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_577_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.2 MiB)
[2025-05-08T19:40:31.426+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 9.0 in stage 432.0 (TID 810) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:31.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Removed TaskSet 432.0, whose tasks have all completed, from pool
[2025-05-08T19:40:31.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: ShuffleMapStage 432 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.265 s
[2025-05-08T19:40:31.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:31.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:31.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: waiting: Set(ResultStage 434, ShuffleMapStage 433)
[2025-05-08T19:40:31.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:31.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting ShuffleMapStage 433 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[589] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:31.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 241.2 KiB, free 419.5 MiB)
[2025-05-08T19:40:31.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 79.7 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on f2a432e4376a:35283 (size: 79.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:31.440+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 433 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[589] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:31.440+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Adding task set 433.0 with 10 tasks resource profile 0
[2025-05-08T19:40:31.441+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 0.0 in stage 433.0 (TID 811) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.20.0.5:37427 (size: 79.7 KiB, free: 419.1 MiB)
[2025-05-08T19:40:31.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 68 to 172.20.0.5:59376
[2025-05-08T19:40:31.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_0 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 419.0 MiB)
[2025-05-08T19:40:31.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 69 to 172.20.0.5:59376
[2025-05-08T19:40:31.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 1.0 in stage 433.0 (TID 812) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 0.0 in stage 433.0 (TID 811) in 26 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:31.475+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_1 in memory on 172.20.0.5:37427 (size: 53.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:31.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 2.0 in stage 433.0 (TID 813) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.485+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 1.0 in stage 433.0 (TID 812) in 19 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:31.492+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_2 in memory on 172.20.0.5:37427 (size: 56.0 KiB, free: 418.9 MiB)
[2025-05-08T19:40:31.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 3.0 in stage 433.0 (TID 814) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 2.0 in stage 433.0 (TID 813) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:31.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_3 in memory on 172.20.0.5:37427 (size: 57.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:31.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 4.0 in stage 433.0 (TID 815) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 3.0 in stage 433.0 (TID 814) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:31.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_4 in memory on 172.20.0.5:37427 (size: 48.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:31.535+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 5.0 in stage 433.0 (TID 816) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.535+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 4.0 in stage 433.0 (TID 815) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:31.542+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_5 in memory on 172.20.0.5:37427 (size: 55.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:31.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 6.0 in stage 433.0 (TID 817) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 5.0 in stage 433.0 (TID 816) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:31.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_6 in memory on 172.20.0.5:37427 (size: 52.5 KiB, free: 418.7 MiB)
[2025-05-08T19:40:31.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 7.0 in stage 433.0 (TID 818) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 6.0 in stage 433.0 (TID 817) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:31.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_7 in memory on 172.20.0.5:37427 (size: 52.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:31.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 8.0 in stage 433.0 (TID 819) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 7.0 in stage 433.0 (TID 818) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:31.600+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_8 in memory on 172.20.0.5:37427 (size: 50.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:31.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 9.0 in stage 433.0 (TID 820) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 8.0 in stage 433.0 (TID 819) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:31.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_583_9 in memory on 172.20.0.5:37427 (size: 57.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:31.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 9.0 in stage 433.0 (TID 820) in 18 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:31.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Removed TaskSet 433.0, whose tasks have all completed, from pool
[2025-05-08T19:40:31.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: ShuffleMapStage 433 (mapPartitions at GraphImpl.scala:208) finished in 0.196 s
[2025-05-08T19:40:31.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:31.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:31.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: waiting: Set(ResultStage 434)
[2025-05-08T19:40:31.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:31.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting ResultStage 434 (MapPartitionsRDD[593] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:31.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 18.0 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 419.4 MiB)
[2025-05-08T19:40:31.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:31.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 434 (MapPartitionsRDD[593] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:31.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Adding task set 434.0 with 10 tasks resource profile 0
[2025-05-08T19:40:31.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 0.0 in stage 434.0 (TID 821) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.20.0.5:37427 (size: 6.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:31.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 70 to 172.20.0.5:59376
[2025-05-08T19:40:31.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_0 in memory on 172.20.0.5:37427 (size: 28.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 1.0 in stage 434.0 (TID 822) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 0.0 in stage 434.0 (TID 821) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:31.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_1 in memory on 172.20.0.5:37427 (size: 30.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.647+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 2.0 in stage 434.0 (TID 823) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.647+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 1.0 in stage 434.0 (TID 822) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:31.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_2 in memory on 172.20.0.5:37427 (size: 26.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 3.0 in stage 434.0 (TID 824) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 2.0 in stage 434.0 (TID 823) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:31.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_3 in memory on 172.20.0.5:37427 (size: 28.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:31.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 4.0 in stage 434.0 (TID 825) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 3.0 in stage 434.0 (TID 824) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:31.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_4 in memory on 172.20.0.5:37427 (size: 30.5 KiB, free: 418.4 MiB)
[2025-05-08T19:40:31.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 5.0 in stage 434.0 (TID 826) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 4.0 in stage 434.0 (TID 825) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:31.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_5 in memory on 172.20.0.5:37427 (size: 32.0 KiB, free: 418.4 MiB)
[2025-05-08T19:40:31.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 6.0 in stage 434.0 (TID 827) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 5.0 in stage 434.0 (TID 826) in 6 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:31.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_6 in memory on 172.20.0.5:37427 (size: 32.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:31.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 7.0 in stage 434.0 (TID 828) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 6.0 in stage 434.0 (TID 827) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:31.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_7 in memory on 172.20.0.5:37427 (size: 33.1 KiB, free: 418.3 MiB)
[2025-05-08T19:40:31.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 8.0 in stage 434.0 (TID 829) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 7.0 in stage 434.0 (TID 828) in 6 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:31.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_8 in memory on 172.20.0.5:37427 (size: 31.8 KiB, free: 418.3 MiB)
[2025-05-08T19:40:31.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Starting task 9.0 in stage 434.0 (TID 830) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5318 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:31.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 8.0 in stage 434.0 (TID 829) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:31.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Added rdd_591_9 in memory on 172.20.0.5:37427 (size: 32.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:31.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSetManager: Finished task 9.0 in stage 434.0 (TID 830) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:31.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Removed TaskSet 434.0, whose tasks have all completed, from pool
[2025-05-08T19:40:31.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: ResultStage 434 (fold at VertexRDDImpl.scala:90) finished in 0.079 s
[2025-05-08T19:40:31.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:31.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 434: Stage finished
[2025-05-08T19:40:31.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO DAGScheduler: Job 45 finished: fold at VertexRDDImpl.scala:90, took 0.553770 s
[2025-05-08T19:40:31.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO Pregel: Pregel finished iteration 9
[2025-05-08T19:40:31.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 574 from persistence list
[2025-05-08T19:40:31.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 574
[2025-05-08T19:40:31.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 560 from persistence list
[2025-05-08T19:40:31.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 560
[2025-05-08T19:40:31.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 566 from persistence list
[2025-05-08T19:40:31.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 566
[2025-05-08T19:40:31.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 557 from persistence list
[2025-05-08T19:40:31.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 557
[2025-05-08T19:40:31.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 574 from persistence list
[2025-05-08T19:40:31.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 574
[2025-05-08T19:40:31.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO ZippedPartitionsRDD2: Removing RDD 591 from persistence list
[2025-05-08T19:40:31.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 591
[2025-05-08T19:40:31.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManager: Removing RDD 591
[2025-05-08T19:40:31.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_90_piece0 on f2a432e4376a:35283 in memory (size: 6.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:31.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.20.0.5:37427 in memory (size: 6.5 KiB, free: 419.5 MiB)
[2025-05-08T19:40:31.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_91_piece0 on f2a432e4376a:35283 in memory (size: 79.7 KiB, free: 432.9 MiB)
[2025-05-08T19:40:31.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.20.0.5:37427 in memory (size: 79.7 KiB, free: 419.6 MiB)
[2025-05-08T19:40:31.937+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_92_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.9 MiB)
[2025-05-08T19:40:31.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.20.0.5:37427 in memory (size: 6.6 KiB, free: 419.6 MiB)
[2025-05-08T19:40:31.939+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_89_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.9 MiB)
[2025-05-08T19:40:31.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:31 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.20.0.5:37427 in memory (size: 6.3 KiB, free: 419.6 MiB)
[2025-05-08T19:40:32.051+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:32.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Registering RDD 596 (mapPartitions at GraphImpl.scala:208) as input to shuffle 72
[2025-05-08T19:40:32.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Registering RDD 614 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 73
[2025-05-08T19:40:32.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Registering RDD 604 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 71
[2025-05-08T19:40:32.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Registering RDD 618 (mapPartitions at GraphImpl.scala:208) as input to shuffle 75
[2025-05-08T19:40:32.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Registering RDD 626 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 74
[2025-05-08T19:40:32.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Got job 46 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:32.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Final stage: ResultStage 450 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:32.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 442, ShuffleMapStage 449, ShuffleMapStage 446, ShuffleMapStage 447)
[2025-05-08T19:40:32.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 449, ShuffleMapStage 446, ShuffleMapStage 447)
[2025-05-08T19:40:32.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting ShuffleMapStage 445 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:32.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 235.8 KiB, free 419.6 MiB)
[2025-05-08T19:40:32.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 419.5 MiB)
[2025-05-08T19:40:32.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on f2a432e4376a:35283 (size: 77.8 KiB, free: 432.8 MiB)
[2025-05-08T19:40:32.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:32.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 445 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:32.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Adding task set 445.0 with 10 tasks resource profile 0
[2025-05-08T19:40:32.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 0.0 in stage 445.0 (TID 831) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.20.0.5:37427 (size: 77.8 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 1.0 in stage 445.0 (TID 832) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 0.0 in stage 445.0 (TID 831) in 23 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:32.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 2.0 in stage 445.0 (TID 833) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.096+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 1.0 in stage 445.0 (TID 832) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:32.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 3.0 in stage 445.0 (TID 834) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 2.0 in stage 445.0 (TID 833) in 21 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:32.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 4.0 in stage 445.0 (TID 835) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 3.0 in stage 445.0 (TID 834) in 19 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:32.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 5.0 in stage 445.0 (TID 836) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 4.0 in stage 445.0 (TID 835) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:32.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 6.0 in stage 445.0 (TID 837) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 5.0 in stage 445.0 (TID 836) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:32.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 7.0 in stage 445.0 (TID 838) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 6.0 in stage 445.0 (TID 837) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:32.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 8.0 in stage 445.0 (TID 839) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 7.0 in stage 445.0 (TID 838) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:32.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 9.0 in stage 445.0 (TID 840) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 8.0 in stage 445.0 (TID 839) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:32.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 9.0 in stage 445.0 (TID 840) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:32.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Removed TaskSet 445.0, whose tasks have all completed, from pool
[2025-05-08T19:40:32.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: ShuffleMapStage 445 (mapPartitions at GraphImpl.scala:208) finished in 0.158 s
[2025-05-08T19:40:32.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:32.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:32.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ShuffleMapStage 446, ResultStage 450, ShuffleMapStage 447)
[2025-05-08T19:40:32.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:32.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting ShuffleMapStage 446 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:32.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 10.7 KiB, free 419.5 MiB)
[2025-05-08T19:40:32.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 419.5 MiB)
[2025-05-08T19:40:32.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on f2a432e4376a:35283 (size: 5.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:32.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:32.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 446 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:32.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Adding task set 446.0 with 10 tasks resource profile 0
[2025-05-08T19:40:32.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting ShuffleMapStage 447 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:32.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 0.0 in stage 446.0 (TID 841) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 10.1 KiB, free 419.5 MiB)
[2025-05-08T19:40:32.219+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 419.4 MiB)
[2025-05-08T19:40:32.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on f2a432e4376a:35283 (size: 5.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:32.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:32.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 447 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:32.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Adding task set 447.0 with 10 tasks resource profile 0
[2025-05-08T19:40:32.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.20.0.5:37427 (size: 5.3 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:59376
[2025-05-08T19:40:32.242+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_0 in memory on 172.20.0.5:37427 (size: 11.2 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 1.0 in stage 446.0 (TID 842) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 0.0 in stage 446.0 (TID 841) in 38 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:32.262+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_1 in memory on 172.20.0.5:37427 (size: 12.1 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.270+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 2.0 in stage 446.0 (TID 843) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 1.0 in stage 446.0 (TID 842) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:32.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_2 in memory on 172.20.0.5:37427 (size: 10.9 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.5 MiB)
[2025-05-08T19:40:32.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 3.0 in stage 446.0 (TID 844) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 2.0 in stage 446.0 (TID 843) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:32.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_3 in memory on 172.20.0.5:37427 (size: 10.9 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 4.0 in stage 446.0 (TID 845) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 3.0 in stage 446.0 (TID 844) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:32.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_4 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 5.0 in stage 446.0 (TID 846) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 4.0 in stage 446.0 (TID 845) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:32.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_5 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 6.0 in stage 446.0 (TID 847) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 5.0 in stage 446.0 (TID 846) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:32.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_6 in memory on 172.20.0.5:37427 (size: 11.4 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 419.4 MiB)
[2025-05-08T19:40:32.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 7.0 in stage 446.0 (TID 848) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 6.0 in stage 446.0 (TID 847) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:32.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_7 in memory on 172.20.0.5:37427 (size: 11.6 KiB, free: 419.3 MiB)
[2025-05-08T19:40:32.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 419.3 MiB)
[2025-05-08T19:40:32.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 8.0 in stage 446.0 (TID 849) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.349+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 7.0 in stage 446.0 (TID 848) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:32.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_8 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 419.3 MiB)
[2025-05-08T19:40:32.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 419.3 MiB)
[2025-05-08T19:40:32.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 9.0 in stage 446.0 (TID 850) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 8.0 in stage 446.0 (TID 849) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:32.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_600_9 in memory on 172.20.0.5:37427 (size: 11.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:32.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_610_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 419.3 MiB)
[2025-05-08T19:40:32.374+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 0.0 in stage 447.0 (TID 851) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.374+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 9.0 in stage 446.0 (TID 850) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:32.374+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Removed TaskSet 446.0, whose tasks have all completed, from pool
[2025-05-08T19:40:32.375+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: ShuffleMapStage 446 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.161 s
[2025-05-08T19:40:32.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:32.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: running: Set(ShuffleMapStage 447)
[2025-05-08T19:40:32.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ResultStage 450)
[2025-05-08T19:40:32.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:32.378+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.20.0.5:37427 (size: 5.0 KiB, free: 419.3 MiB)
[2025-05-08T19:40:32.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 1.0 in stage 447.0 (TID 852) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 0.0 in stage 447.0 (TID 851) in 11 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:32.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 2.0 in stage 447.0 (TID 853) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 1.0 in stage 447.0 (TID 852) in 5 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:32.393+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 3.0 in stage 447.0 (TID 854) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.394+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 2.0 in stage 447.0 (TID 853) in 4 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:32.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 4.0 in stage 447.0 (TID 855) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 3.0 in stage 447.0 (TID 854) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:32.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 5.0 in stage 447.0 (TID 856) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 4.0 in stage 447.0 (TID 855) in 5 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:32.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 6.0 in stage 447.0 (TID 857) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 5.0 in stage 447.0 (TID 856) in 5 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:32.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 7.0 in stage 447.0 (TID 858) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 6.0 in stage 447.0 (TID 857) in 5 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:32.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 8.0 in stage 447.0 (TID 859) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 7.0 in stage 447.0 (TID 858) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:32.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 9.0 in stage 447.0 (TID 860) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 8.0 in stage 447.0 (TID 859) in 4 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:32.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 9.0 in stage 447.0 (TID 860) in 3 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:32.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Removed TaskSet 447.0, whose tasks have all completed, from pool
[2025-05-08T19:40:32.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: ShuffleMapStage 447 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.212 s
[2025-05-08T19:40:32.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:32.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:32.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 448, ShuffleMapStage 449, ResultStage 450)
[2025-05-08T19:40:32.430+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:32.430+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting ShuffleMapStage 448 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:32.436+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 238.4 KiB, free 419.2 MiB)
[2025-05-08T19:40:32.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 419.1 MiB)
[2025-05-08T19:40:32.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.7 MiB)
[2025-05-08T19:40:32.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:32.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 448 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:32.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Adding task set 448.0 with 10 tasks resource profile 0
[2025-05-08T19:40:32.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 0.0 in stage 448.0 (TID 861) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.20.0.5:37427 (size: 78.8 KiB, free: 419.2 MiB)
[2025-05-08T19:40:32.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_0 in memory on 172.20.0.5:37427 (size: 50.5 KiB, free: 419.2 MiB)
[2025-05-08T19:40:32.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:59376
[2025-05-08T19:40:32.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 419.1 MiB)
[2025-05-08T19:40:32.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:59376
[2025-05-08T19:40:32.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 1.0 in stage 448.0 (TID 862) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 0.0 in stage 448.0 (TID 861) in 33 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:32.481+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_1 in memory on 172.20.0.5:37427 (size: 51.2 KiB, free: 419.0 MiB)
[2025-05-08T19:40:32.485+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 419.0 MiB)
[2025-05-08T19:40:32.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 2.0 in stage 448.0 (TID 863) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 1.0 in stage 448.0 (TID 862) in 21 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:32.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_2 in memory on 172.20.0.5:37427 (size: 54.2 KiB, free: 418.9 MiB)
[2025-05-08T19:40:32.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.9 MiB)
[2025-05-08T19:40:32.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 3.0 in stage 448.0 (TID 864) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 2.0 in stage 448.0 (TID 863) in 19 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:32.525+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_3 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.8 MiB)
[2025-05-08T19:40:32.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.8 MiB)
[2025-05-08T19:40:32.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 4.0 in stage 448.0 (TID 865) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 3.0 in stage 448.0 (TID 864) in 27 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:32.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_4 in memory on 172.20.0.5:37427 (size: 46.8 KiB, free: 418.7 MiB)
[2025-05-08T19:40:32.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.7 MiB)
[2025-05-08T19:40:32.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 5.0 in stage 448.0 (TID 866) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 4.0 in stage 448.0 (TID 865) in 20 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:32.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_5 in memory on 172.20.0.5:37427 (size: 53.5 KiB, free: 418.6 MiB)
[2025-05-08T19:40:32.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:32.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 6.0 in stage 448.0 (TID 867) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 5.0 in stage 448.0 (TID 866) in 21 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:32.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_6 in memory on 172.20.0.5:37427 (size: 50.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:32.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.4 MiB)
[2025-05-08T19:40:32.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 7.0 in stage 448.0 (TID 868) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 6.0 in stage 448.0 (TID 867) in 20 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:32.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_7 in memory on 172.20.0.5:37427 (size: 50.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:32.611+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.3 MiB)
[2025-05-08T19:40:32.620+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 8.0 in stage 448.0 (TID 869) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.620+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 7.0 in stage 448.0 (TID 868) in 24 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:32.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_8 in memory on 172.20.0.5:37427 (size: 48.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:32.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 9.0 in stage 448.0 (TID 870) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 8.0 in stage 448.0 (TID 869) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:32.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_602_9 in memory on 172.20.0.5:37427 (size: 55.5 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.648+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_612_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.1 MiB)
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 9.0 in stage 448.0 (TID 870) in 19 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Removed TaskSet 448.0, whose tasks have all completed, from pool
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: ShuffleMapStage 448 (mapPartitions at GraphImpl.scala:208) finished in 0.227 s
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 449, ResultStage 450)
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:32.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting ShuffleMapStage 449 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:32.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 12.0 KiB, free 419.1 MiB)
[2025-05-08T19:40:32.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 419.1 MiB)
[2025-05-08T19:40:32.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.7 MiB)
[2025-05-08T19:40:32.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:32.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 449 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:32.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Adding task set 449.0 with 10 tasks resource profile 0
[2025-05-08T19:40:32.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 0.0 in stage 449.0 (TID 871) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.20.0.5:37427 (size: 5.7 KiB, free: 418.1 MiB)
[2025-05-08T19:40:32.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:59376
[2025-05-08T19:40:32.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_95_piece0 on f2a432e4376a:35283 in memory (size: 5.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:32.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.20.0.5:37427 in memory (size: 5.0 KiB, free: 418.1 MiB)
[2025-05-08T19:40:32.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_93_piece0 on f2a432e4376a:35283 in memory (size: 77.8 KiB, free: 432.8 MiB)
[2025-05-08T19:40:32.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.20.0.5:37427 in memory (size: 77.8 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_96_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.9 MiB)
[2025-05-08T19:40:32.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.20.0.5:37427 in memory (size: 78.8 KiB, free: 418.3 MiB)
[2025-05-08T19:40:32.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_94_piece0 on f2a432e4376a:35283 in memory (size: 5.3 KiB, free: 432.9 MiB)
[2025-05-08T19:40:32.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.20.0.5:37427 in memory (size: 5.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:32.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 1.0 in stage 449.0 (TID 872) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 0.0 in stage 449.0 (TID 871) in 30 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:32.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 2.0 in stage 449.0 (TID 873) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 1.0 in stage 449.0 (TID 872) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:32.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 3.0 in stage 449.0 (TID 874) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 2.0 in stage 449.0 (TID 873) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:32.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 4.0 in stage 449.0 (TID 875) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 3.0 in stage 449.0 (TID 874) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:32.737+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 5.0 in stage 449.0 (TID 876) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 4.0 in stage 449.0 (TID 875) in 19 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:32.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 6.0 in stage 449.0 (TID 877) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 5.0 in stage 449.0 (TID 876) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:32.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 7.0 in stage 449.0 (TID 878) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 6.0 in stage 449.0 (TID 877) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:32.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 8.0 in stage 449.0 (TID 879) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.766+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 7.0 in stage 449.0 (TID 878) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:32.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.2 MiB)
[2025-05-08T19:40:32.775+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 9.0 in stage 449.0 (TID 880) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 8.0 in stage 449.0 (TID 879) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:32.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_622_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:32.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 9.0 in stage 449.0 (TID 880) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:32.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Removed TaskSet 449.0, whose tasks have all completed, from pool
[2025-05-08T19:40:32.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: ShuffleMapStage 449 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.128 s
[2025-05-08T19:40:32.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:32.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:32.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: waiting: Set(ResultStage 450)
[2025-05-08T19:40:32.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:32.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting ResultStage 450 (EdgeRDDImpl[629] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:32.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 238.3 KiB, free 419.5 MiB)
[2025-05-08T19:40:32.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 78.5 KiB, free 419.5 MiB)
[2025-05-08T19:40:32.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on f2a432e4376a:35283 (size: 78.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:32.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:32.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 450 (EdgeRDDImpl[629] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:32.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Adding task set 450.0 with 10 tasks resource profile 0
[2025-05-08T19:40:32.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 0.0 in stage 450.0 (TID 881) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.20.0.5:37427 (size: 78.5 KiB, free: 418.1 MiB)
[2025-05-08T19:40:32.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:59376
[2025-05-08T19:40:32.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:59376
[2025-05-08T19:40:32.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.0 MiB)
[2025-05-08T19:40:32.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 1.0 in stage 450.0 (TID 882) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 0.0 in stage 450.0 (TID 881) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:32.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.0 MiB)
[2025-05-08T19:40:32.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 2.0 in stage 450.0 (TID 883) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 1.0 in stage 450.0 (TID 882) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:32.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 417.9 MiB)
[2025-05-08T19:40:32.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 3.0 in stage 450.0 (TID 884) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 2.0 in stage 450.0 (TID 883) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:32.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 417.8 MiB)
[2025-05-08T19:40:32.847+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 4.0 in stage 450.0 (TID 885) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 3.0 in stage 450.0 (TID 884) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:32.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 417.8 MiB)
[2025-05-08T19:40:32.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 5.0 in stage 450.0 (TID 886) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 4.0 in stage 450.0 (TID 885) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:32.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 417.7 MiB)
[2025-05-08T19:40:32.876+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 6.0 in stage 450.0 (TID 887) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 5.0 in stage 450.0 (TID 886) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:32.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 417.7 MiB)
[2025-05-08T19:40:32.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 7.0 in stage 450.0 (TID 888) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 6.0 in stage 450.0 (TID 887) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:32.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 417.6 MiB)
[2025-05-08T19:40:32.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 8.0 in stage 450.0 (TID 889) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 7.0 in stage 450.0 (TID 888) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:32.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.5 MiB)
[2025-05-08T19:40:32.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 9.0 in stage 450.0 (TID 890) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 8.0 in stage 450.0 (TID 889) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:32.920+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added rdd_628_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.5 MiB)
[2025-05-08T19:40:32.922+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 9.0 in stage 450.0 (TID 890) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:32.922+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Removed TaskSet 450.0, whose tasks have all completed, from pool
[2025-05-08T19:40:32.922+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: ResultStage 450 (foreachPartition at PageRank.scala:199) finished in 0.135 s
[2025-05-08T19:40:32.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:32.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 450: Stage finished
[2025-05-08T19:40:32.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Job 46 finished: foreachPartition at PageRank.scala:199, took 0.871874 s
[2025-05-08T19:40:32.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO PageRank: PageRank finished iteration 0.
[2025-05-08T19:40:32.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapPartitionsRDD: Removing RDD 610 from persistence list
[2025-05-08T19:40:32.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManager: Removing RDD 610
[2025-05-08T19:40:32.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MapPartitionsRDD: Removing RDD 612 from persistence list
[2025-05-08T19:40:32.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManager: Removing RDD 612
[2025-05-08T19:40:32.935+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:32.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Registering RDD 630 (mapPartitions at GraphImpl.scala:208) as input to shuffle 77
[2025-05-08T19:40:32.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Registering RDD 638 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 76
[2025-05-08T19:40:32.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Got job 47 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:32.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Final stage: ResultStage 468 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:32.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 458, ShuffleMapStage 462, ShuffleMapStage 463, ShuffleMapStage 467, ShuffleMapStage 465)
[2025-05-08T19:40:32.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 467)
[2025-05-08T19:40:32.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting ShuffleMapStage 466 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:32.942+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 238.8 KiB, free 419.2 MiB)
[2025-05-08T19:40:32.944+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 78.7 KiB, free 419.1 MiB)
[2025-05-08T19:40:32.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on f2a432e4376a:35283 (size: 78.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:32.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:32.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 466 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:32.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSchedulerImpl: Adding task set 466.0 with 10 tasks resource profile 0
[2025-05-08T19:40:32.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 0.0 in stage 466.0 (TID 891) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.20.0.5:37427 (size: 78.7 KiB, free: 418.1 MiB)
[2025-05-08T19:40:32.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 1.0 in stage 466.0 (TID 892) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.976+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 0.0 in stage 466.0 (TID 891) in 28 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:32.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Starting task 2.0 in stage 466.0 (TID 893) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:32.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:32 INFO TaskSetManager: Finished task 1.0 in stage 466.0 (TID 892) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:33.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 3.0 in stage 466.0 (TID 894) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 2.0 in stage 466.0 (TID 893) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:33.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 4.0 in stage 466.0 (TID 895) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 3.0 in stage 466.0 (TID 894) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:33.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 5.0 in stage 466.0 (TID 896) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.040+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 4.0 in stage 466.0 (TID 895) in 19 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:33.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 6.0 in stage 466.0 (TID 897) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 5.0 in stage 466.0 (TID 896) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:33.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 7.0 in stage 466.0 (TID 898) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 6.0 in stage 466.0 (TID 897) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:33.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 8.0 in stage 466.0 (TID 899) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 7.0 in stage 466.0 (TID 898) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:33.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 9.0 in stage 466.0 (TID 900) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 8.0 in stage 466.0 (TID 899) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:33.108+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 9.0 in stage 466.0 (TID 900) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:33.108+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Removed TaskSet 466.0, whose tasks have all completed, from pool
[2025-05-08T19:40:33.108+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: ShuffleMapStage 466 (mapPartitions at GraphImpl.scala:208) finished in 0.171 s
[2025-05-08T19:40:33.108+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:33.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:33.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 467, ResultStage 468)
[2025-05-08T19:40:33.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:33.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting ShuffleMapStage 467 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:33.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 12.8 KiB, free 419.1 MiB)
[2025-05-08T19:40:33.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 419.1 MiB)
[2025-05-08T19:40:33.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.7 MiB)
[2025-05-08T19:40:33.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:33.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 467 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:33.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Adding task set 467.0 with 10 tasks resource profile 0
[2025-05-08T19:40:33.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 0.0 in stage 467.0 (TID 901) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.20.0.5:37427 (size: 5.9 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:59376
[2025-05-08T19:40:33.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 1.0 in stage 467.0 (TID 902) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 0.0 in stage 467.0 (TID 901) in 14 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:33.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 2.0 in stage 467.0 (TID 903) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 1.0 in stage 467.0 (TID 902) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:33.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 3.0 in stage 467.0 (TID 904) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 2.0 in stage 467.0 (TID 903) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:33.154+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 4.0 in stage 467.0 (TID 905) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 3.0 in stage 467.0 (TID 904) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:33.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 5.0 in stage 467.0 (TID 906) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 4.0 in stage 467.0 (TID 905) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:33.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 6.0 in stage 467.0 (TID 907) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 5.0 in stage 467.0 (TID 906) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:33.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 7.0 in stage 467.0 (TID 908) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 6.0 in stage 467.0 (TID 907) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:33.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 8.0 in stage 467.0 (TID 909) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 7.0 in stage 467.0 (TID 908) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:33.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 9.0 in stage 467.0 (TID 910) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 8.0 in stage 467.0 (TID 909) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:33.203+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_634_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 9.0 in stage 467.0 (TID 910) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:33.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Removed TaskSet 467.0, whose tasks have all completed, from pool
[2025-05-08T19:40:33.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: ShuffleMapStage 467 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.096 s
[2025-05-08T19:40:33.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:33.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:33.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: waiting: Set(ResultStage 468)
[2025-05-08T19:40:33.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:33.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting ResultStage 468 (EdgeRDDImpl[641] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:33.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 238.6 KiB, free 418.9 MiB)
[2025-05-08T19:40:33.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 78.5 KiB, free 418.8 MiB)
[2025-05-08T19:40:33.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on f2a432e4376a:35283 (size: 78.5 KiB, free: 432.7 MiB)
[2025-05-08T19:40:33.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:33.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 468 (EdgeRDDImpl[641] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:33.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Adding task set 468.0 with 10 tasks resource profile 0
[2025-05-08T19:40:33.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 0.0 in stage 468.0 (TID 911) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.20.0.5:37427 (size: 78.5 KiB, free: 417.9 MiB)
[2025-05-08T19:40:33.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:59376
[2025-05-08T19:40:33.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 417.9 MiB)
[2025-05-08T19:40:33.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 1.0 in stage 468.0 (TID 912) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 0.0 in stage 468.0 (TID 911) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:33.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 417.8 MiB)
[2025-05-08T19:40:33.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 2.0 in stage 468.0 (TID 913) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 1.0 in stage 468.0 (TID 912) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:33.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 417.7 MiB)
[2025-05-08T19:40:33.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 3.0 in stage 468.0 (TID 914) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 2.0 in stage 468.0 (TID 913) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:33.263+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 417.7 MiB)
[2025-05-08T19:40:33.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 4.0 in stage 468.0 (TID 915) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 3.0 in stage 468.0 (TID 914) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:33.280+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 417.6 MiB)
[2025-05-08T19:40:33.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 5.0 in stage 468.0 (TID 916) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 4.0 in stage 468.0 (TID 915) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:33.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 417.6 MiB)
[2025-05-08T19:40:33.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 6.0 in stage 468.0 (TID 917) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 5.0 in stage 468.0 (TID 916) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:33.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 417.5 MiB)
[2025-05-08T19:40:33.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 7.0 in stage 468.0 (TID 918) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 6.0 in stage 468.0 (TID 917) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:33.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 417.4 MiB)
[2025-05-08T19:40:33.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 8.0 in stage 468.0 (TID 919) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 7.0 in stage 468.0 (TID 918) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:33.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.4 MiB)
[2025-05-08T19:40:33.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 9.0 in stage 468.0 (TID 920) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 8.0 in stage 468.0 (TID 919) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:33.351+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_640_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.3 MiB)
[2025-05-08T19:40:33.353+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 9.0 in stage 468.0 (TID 920) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:33.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Removed TaskSet 468.0, whose tasks have all completed, from pool
[2025-05-08T19:40:33.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: ResultStage 468 (foreachPartition at PageRank.scala:199) finished in 0.148 s
[2025-05-08T19:40:33.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:33.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 468: Stage finished
[2025-05-08T19:40:33.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Job 47 finished: foreachPartition at PageRank.scala:199, took 0.419537 s
[2025-05-08T19:40:33.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO PageRank: PageRank finished iteration 1.
[2025-05-08T19:40:33.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO ZippedPartitionsRDD2: Removing RDD 622 from persistence list
[2025-05-08T19:40:33.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManager: Removing RDD 622
[2025-05-08T19:40:33.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO ZippedPartitionsRDD2: Removing RDD 628 from persistence list
[2025-05-08T19:40:33.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManager: Removing RDD 628
[2025-05-08T19:40:33.374+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:33.375+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Registering RDD 642 (mapPartitions at GraphImpl.scala:208) as input to shuffle 79
[2025-05-08T19:40:33.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Registering RDD 650 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 78
[2025-05-08T19:40:33.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Got job 48 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:33.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Final stage: ResultStage 488 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:33.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 476, ShuffleMapStage 481, ShuffleMapStage 485, ShuffleMapStage 483, ShuffleMapStage 480, ShuffleMapStage 487)
[2025-05-08T19:40:33.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 487)
[2025-05-08T19:40:33.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting ShuffleMapStage 486 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:33.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 239.1 KiB, free 418.6 MiB)
[2025-05-08T19:40:33.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 418.5 MiB)
[2025-05-08T19:40:33.398+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.6 MiB)
[2025-05-08T19:40:33.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:33.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 486 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:33.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Adding task set 486.0 with 10 tasks resource profile 0
[2025-05-08T19:40:33.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_99_piece0 on f2a432e4376a:35283 in memory (size: 78.7 KiB, free: 432.7 MiB)
[2025-05-08T19:40:33.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 0.0 in stage 486.0 (TID 921) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.412+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.20.0.5:37427 in memory (size: 78.7 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_98_piece0 on f2a432e4376a:35283 in memory (size: 78.5 KiB, free: 432.7 MiB)
[2025-05-08T19:40:33.430+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.20.0.5:37427 in memory (size: 78.5 KiB, free: 418.2 MiB)
[2025-05-08T19:40:33.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.20.0.5:37427 (size: 79.0 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_97_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:33.444+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.20.0.5:37427 in memory (size: 5.7 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 1.0 in stage 486.0 (TID 922) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.486+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_101_piece0 on f2a432e4376a:35283 in memory (size: 78.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:33.487+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 0.0 in stage 486.0 (TID 921) in 81 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:33.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.20.0.5:37427 in memory (size: 78.5 KiB, free: 418.2 MiB)
[2025-05-08T19:40:33.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_100_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:33.506+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.20.0.5:37427 in memory (size: 5.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:33.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManager: Removing RDD 583
[2025-05-08T19:40:33.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 2.0 in stage 486.0 (TID 923) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.517+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 1.0 in stage 486.0 (TID 922) in 35 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:33.536+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 3.0 in stage 486.0 (TID 924) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 2.0 in stage 486.0 (TID 923) in 22 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:33.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 4.0 in stage 486.0 (TID 925) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 3.0 in stage 486.0 (TID 924) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:33.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 5.0 in stage 486.0 (TID 926) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 4.0 in stage 486.0 (TID 925) in 21 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:33.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 6.0 in stage 486.0 (TID 927) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 5.0 in stage 486.0 (TID 926) in 19 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:33.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 7.0 in stage 486.0 (TID 928) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 6.0 in stage 486.0 (TID 927) in 25 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:33.650+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 8.0 in stage 486.0 (TID 929) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.650+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 7.0 in stage 486.0 (TID 928) in 34 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:33.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 9.0 in stage 486.0 (TID 930) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 8.0 in stage 486.0 (TID 929) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:33.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 9.0 in stage 486.0 (TID 930) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:33.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Removed TaskSet 486.0, whose tasks have all completed, from pool
[2025-05-08T19:40:33.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: ShuffleMapStage 486 (mapPartitions at GraphImpl.scala:208) finished in 0.302 s
[2025-05-08T19:40:33.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:33.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:33.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: waiting: Set(ResultStage 488, ShuffleMapStage 487)
[2025-05-08T19:40:33.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:33.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting ShuffleMapStage 487 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:33.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 13.5 KiB, free 419.5 MiB)
[2025-05-08T19:40:33.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 419.5 MiB)
[2025-05-08T19:40:33.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:33.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:33.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 487 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:33.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Adding task set 487.0 with 10 tasks resource profile 0
[2025-05-08T19:40:33.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 0.0 in stage 487.0 (TID 931) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.20.0.5:37427 (size: 6.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:33.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:59376
[2025-05-08T19:40:33.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:33.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 1.0 in stage 487.0 (TID 932) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 0.0 in stage 487.0 (TID 931) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:33.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 2.0 in stage 487.0 (TID 933) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 1.0 in stage 487.0 (TID 932) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:33.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 3.0 in stage 487.0 (TID 934) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 2.0 in stage 487.0 (TID 933) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:33.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:33.724+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 4.0 in stage 487.0 (TID 935) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.724+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 3.0 in stage 487.0 (TID 934) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:33.730+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:33.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 5.0 in stage 487.0 (TID 936) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 4.0 in stage 487.0 (TID 935) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:33.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:33.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 6.0 in stage 487.0 (TID 937) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 5.0 in stage 487.0 (TID 936) in 7 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:33.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:33.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 7.0 in stage 487.0 (TID 938) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 6.0 in stage 487.0 (TID 937) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:33.752+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:33.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 8.0 in stage 487.0 (TID 939) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 7.0 in stage 487.0 (TID 938) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:33.759+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:33.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 9.0 in stage 487.0 (TID 940) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 8.0 in stage 487.0 (TID 939) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:33.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_646_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:33.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 9.0 in stage 487.0 (TID 940) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:33.784+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Removed TaskSet 487.0, whose tasks have all completed, from pool
[2025-05-08T19:40:33.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: ShuffleMapStage 487 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.103 s
[2025-05-08T19:40:33.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:33.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:33.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: waiting: Set(ResultStage 488)
[2025-05-08T19:40:33.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:33.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting ResultStage 488 (EdgeRDDImpl[653] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:33.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 238.9 KiB, free 419.2 MiB)
[2025-05-08T19:40:33.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 78.7 KiB, free 419.1 MiB)
[2025-05-08T19:40:33.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on f2a432e4376a:35283 (size: 78.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:33.805+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:33.805+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 488 (EdgeRDDImpl[653] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:33.805+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Adding task set 488.0 with 10 tasks resource profile 0
[2025-05-08T19:40:33.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 0.0 in stage 488.0 (TID 941) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.20.0.5:37427 (size: 78.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:33.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:59376
[2025-05-08T19:40:33.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:33.822+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 1.0 in stage 488.0 (TID 942) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.822+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 0.0 in stage 488.0 (TID 941) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:33.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:33.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 2.0 in stage 488.0 (TID 943) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 1.0 in stage 488.0 (TID 942) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:33.847+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:33.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 3.0 in stage 488.0 (TID 944) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 2.0 in stage 488.0 (TID 943) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:33.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:33.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 4.0 in stage 488.0 (TID 945) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 3.0 in stage 488.0 (TID 944) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:33.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.2 MiB)
[2025-05-08T19:40:33.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 5.0 in stage 488.0 (TID 946) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 4.0 in stage 488.0 (TID 945) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:33.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:33.881+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 6.0 in stage 488.0 (TID 947) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.881+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 5.0 in stage 488.0 (TID 946) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:33.888+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.1 MiB)
[2025-05-08T19:40:33.890+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 7.0 in stage 488.0 (TID 948) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.890+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 6.0 in stage 488.0 (TID 947) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:33.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 8.0 in stage 488.0 (TID 949) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 7.0 in stage 488.0 (TID 948) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:33.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.0 MiB)
[2025-05-08T19:40:33.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 9.0 in stage 488.0 (TID 950) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 8.0 in stage 488.0 (TID 949) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:33.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added rdd_652_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.9 MiB)
[2025-05-08T19:40:33.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 9.0 in stage 488.0 (TID 950) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:33.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Removed TaskSet 488.0, whose tasks have all completed, from pool
[2025-05-08T19:40:33.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: ResultStage 488 (foreachPartition at PageRank.scala:199) finished in 0.138 s
[2025-05-08T19:40:33.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:33.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 488: Stage finished
[2025-05-08T19:40:33.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Job 48 finished: foreachPartition at PageRank.scala:199, took 0.552985 s
[2025-05-08T19:40:33.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO PageRank: PageRank finished iteration 2.
[2025-05-08T19:40:33.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO ZippedPartitionsRDD2: Removing RDD 634 from persistence list
[2025-05-08T19:40:33.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManager: Removing RDD 634
[2025-05-08T19:40:33.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO ZippedPartitionsRDD2: Removing RDD 640 from persistence list
[2025-05-08T19:40:33.933+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManager: Removing RDD 640
[2025-05-08T19:40:33.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:33.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Registering RDD 654 (mapPartitions at GraphImpl.scala:208) as input to shuffle 81
[2025-05-08T19:40:33.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Registering RDD 662 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 80
[2025-05-08T19:40:33.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Got job 49 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:33.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Final stage: ResultStage 510 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:33.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 509, ShuffleMapStage 503, ShuffleMapStage 507, ShuffleMapStage 496, ShuffleMapStage 500, ShuffleMapStage 501, ShuffleMapStage 505)
[2025-05-08T19:40:33.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 509)
[2025-05-08T19:40:33.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting ShuffleMapStage 508 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:33.973+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 239.4 KiB, free 418.9 MiB)
[2025-05-08T19:40:33.974+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 418.8 MiB)
[2025-05-08T19:40:33.974+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:33.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:33.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 508 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:33.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSchedulerImpl: Adding task set 508.0 with 10 tasks resource profile 0
[2025-05-08T19:40:33.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 0.0 in stage 508.0 (TID 951) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.20.0.5:37427 (size: 79.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:33.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Starting task 1.0 in stage 508.0 (TID 952) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:33.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:33 INFO TaskSetManager: Finished task 0.0 in stage 508.0 (TID 951) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:34.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 2.0 in stage 508.0 (TID 953) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 1.0 in stage 508.0 (TID 952) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:34.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 3.0 in stage 508.0 (TID 954) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 2.0 in stage 508.0 (TID 953) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:34.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 4.0 in stage 508.0 (TID 955) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 3.0 in stage 508.0 (TID 954) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:34.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 5.0 in stage 508.0 (TID 956) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 4.0 in stage 508.0 (TID 955) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:34.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 6.0 in stage 508.0 (TID 957) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 5.0 in stage 508.0 (TID 956) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:34.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 7.0 in stage 508.0 (TID 958) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 6.0 in stage 508.0 (TID 957) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:34.097+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 8.0 in stage 508.0 (TID 959) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 7.0 in stage 508.0 (TID 958) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:34.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 9.0 in stage 508.0 (TID 960) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 8.0 in stage 508.0 (TID 959) in 19 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:34.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 9.0 in stage 508.0 (TID 960) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:34.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Removed TaskSet 508.0, whose tasks have all completed, from pool
[2025-05-08T19:40:34.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: ShuffleMapStage 508 (mapPartitions at GraphImpl.scala:208) finished in 0.164 s
[2025-05-08T19:40:34.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:34.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:34.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 509, ResultStage 510)
[2025-05-08T19:40:34.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:34.132+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting ShuffleMapStage 509 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:34.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 14.2 KiB, free 418.8 MiB)
[2025-05-08T19:40:34.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 418.8 MiB)
[2025-05-08T19:40:34.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:34.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:34.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 509 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:34.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Adding task set 509.0 with 10 tasks resource profile 0
[2025-05-08T19:40:34.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 0.0 in stage 509.0 (TID 961) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.20.0.5:37427 (size: 6.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:59376
[2025-05-08T19:40:34.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 1.0 in stage 509.0 (TID 962) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 0.0 in stage 509.0 (TID 961) in 33 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:34.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 2.0 in stage 509.0 (TID 963) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 1.0 in stage 509.0 (TID 962) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:34.184+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 3.0 in stage 509.0 (TID 964) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 2.0 in stage 509.0 (TID 963) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:34.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.197+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 4.0 in stage 509.0 (TID 965) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.197+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 3.0 in stage 509.0 (TID 964) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:34.204+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 5.0 in stage 509.0 (TID 966) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 4.0 in stage 509.0 (TID 965) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:34.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 6.0 in stage 509.0 (TID 967) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 5.0 in stage 509.0 (TID 966) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:34.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 7.0 in stage 509.0 (TID 968) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 6.0 in stage 509.0 (TID 967) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:34.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 8.0 in stage 509.0 (TID 969) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 7.0 in stage 509.0 (TID 968) in 7 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:34.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.4 MiB)
[2025-05-08T19:40:34.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 9.0 in stage 509.0 (TID 970) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 8.0 in stage 509.0 (TID 969) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:34.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_658_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:34.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 9.0 in stage 509.0 (TID 970) in 7 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:34.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Removed TaskSet 509.0, whose tasks have all completed, from pool
[2025-05-08T19:40:34.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: ShuffleMapStage 509 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.111 s
[2025-05-08T19:40:34.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:34.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:34.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: waiting: Set(ResultStage 510)
[2025-05-08T19:40:34.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:34.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting ResultStage 510 (EdgeRDDImpl[665] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:34.248+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 239.2 KiB, free 418.6 MiB)
[2025-05-08T19:40:34.270+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 78.6 KiB, free 418.5 MiB)
[2025-05-08T19:40:34.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on f2a432e4376a:35283 (size: 78.6 KiB, free: 432.6 MiB)
[2025-05-08T19:40:34.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_103_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.6 MiB)
[2025-05-08T19:40:34.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.20.0.5:37427 in memory (size: 6.1 KiB, free: 418.4 MiB)
[2025-05-08T19:40:34.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:34.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 510 (EdgeRDDImpl[665] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:34.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Adding task set 510.0 with 10 tasks resource profile 0
[2025-05-08T19:40:34.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 0.0 in stage 510.0 (TID 971) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_105_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:34.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 172.20.0.5:37427 in memory (size: 79.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_102_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:34.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.20.0.5:37427 in memory (size: 79.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.20.0.5:37427 (size: 78.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_104_piece0 on f2a432e4376a:35283 in memory (size: 78.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:34.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.20.0.5:37427 in memory (size: 78.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:59376
[2025-05-08T19:40:34.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 1.0 in stage 510.0 (TID 972) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 0.0 in stage 510.0 (TID 971) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:34.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 2.0 in stage 510.0 (TID 973) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 1.0 in stage 510.0 (TID 972) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:34.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:34.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 3.0 in stage 510.0 (TID 974) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 2.0 in stage 510.0 (TID 973) in 30 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:34.351+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:34.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 4.0 in stage 510.0 (TID 975) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 3.0 in stage 510.0 (TID 974) in 21 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:34.363+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:34.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 5.0 in stage 510.0 (TID 976) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 4.0 in stage 510.0 (TID 975) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:34.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:34.374+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 6.0 in stage 510.0 (TID 977) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.375+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 5.0 in stage 510.0 (TID 976) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:34.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:34.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 7.0 in stage 510.0 (TID 978) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 6.0 in stage 510.0 (TID 977) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:34.394+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:34.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 8.0 in stage 510.0 (TID 979) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 7.0 in stage 510.0 (TID 978) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:34.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:34.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 9.0 in stage 510.0 (TID 980) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 8.0 in stage 510.0 (TID 979) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:34.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_664_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.0 MiB)
[2025-05-08T19:40:34.430+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 9.0 in stage 510.0 (TID 980) in 21 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:34.431+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Removed TaskSet 510.0, whose tasks have all completed, from pool
[2025-05-08T19:40:34.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: ResultStage 510 (foreachPartition at PageRank.scala:199) finished in 0.186 s
[2025-05-08T19:40:34.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:34.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 510: Stage finished
[2025-05-08T19:40:34.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Job 49 finished: foreachPartition at PageRank.scala:199, took 0.478408 s
[2025-05-08T19:40:34.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO PageRank: PageRank finished iteration 3.
[2025-05-08T19:40:34.444+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO ZippedPartitionsRDD2: Removing RDD 646 from persistence list
[2025-05-08T19:40:34.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManager: Removing RDD 646
[2025-05-08T19:40:34.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO ZippedPartitionsRDD2: Removing RDD 652 from persistence list
[2025-05-08T19:40:34.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManager: Removing RDD 652
[2025-05-08T19:40:34.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:34.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Registering RDD 666 (mapPartitions at GraphImpl.scala:208) as input to shuffle 83
[2025-05-08T19:40:34.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Registering RDD 674 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 82
[2025-05-08T19:40:34.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Got job 50 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:34.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Final stage: ResultStage 534 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:34.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 527, ShuffleMapStage 531, ShuffleMapStage 525, ShuffleMapStage 529, ShuffleMapStage 518, ShuffleMapStage 533, ShuffleMapStage 522, ShuffleMapStage 523)
[2025-05-08T19:40:34.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 533)
[2025-05-08T19:40:34.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting ShuffleMapStage 532 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:34.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 239.6 KiB, free 419.2 MiB)
[2025-05-08T19:40:34.536+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 419.1 MiB)
[2025-05-08T19:40:34.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:34.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:34.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 532 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:34.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Adding task set 532.0 with 10 tasks resource profile 0
[2025-05-08T19:40:34.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 0.0 in stage 532.0 (TID 981) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.20.0.5:37427 (size: 79.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 1.0 in stage 532.0 (TID 982) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 0.0 in stage 532.0 (TID 981) in 29 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:34.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 2.0 in stage 532.0 (TID 983) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 1.0 in stage 532.0 (TID 982) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:34.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 3.0 in stage 532.0 (TID 984) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 2.0 in stage 532.0 (TID 983) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:34.611+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 4.0 in stage 532.0 (TID 985) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.611+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 3.0 in stage 532.0 (TID 984) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:34.624+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 5.0 in stage 532.0 (TID 986) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 4.0 in stage 532.0 (TID 985) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:34.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 6.0 in stage 532.0 (TID 987) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 5.0 in stage 532.0 (TID 986) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:34.650+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 7.0 in stage 532.0 (TID 988) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 6.0 in stage 532.0 (TID 987) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:34.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 8.0 in stage 532.0 (TID 989) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 7.0 in stage 532.0 (TID 988) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:34.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 9.0 in stage 532.0 (TID 990) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 8.0 in stage 532.0 (TID 989) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 9.0 in stage 532.0 (TID 990) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Removed TaskSet 532.0, whose tasks have all completed, from pool
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: ShuffleMapStage 532 (mapPartitions at GraphImpl.scala:208) finished in 0.182 s
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 533, ResultStage 534)
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:34.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting ShuffleMapStage 533 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:34.696+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 14.9 KiB, free 419.1 MiB)
[2025-05-08T19:40:34.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 419.1 MiB)
[2025-05-08T19:40:34.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:34.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:34.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 533 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:34.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Adding task set 533.0 with 10 tasks resource profile 0
[2025-05-08T19:40:34.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 0.0 in stage 533.0 (TID 991) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.703+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.20.0.5:37427 (size: 6.3 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:59376
[2025-05-08T19:40:34.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 1.0 in stage 533.0 (TID 992) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 0.0 in stage 533.0 (TID 991) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:34.723+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 2.0 in stage 533.0 (TID 993) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 1.0 in stage 533.0 (TID 992) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:34.730+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 3.0 in stage 533.0 (TID 994) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 2.0 in stage 533.0 (TID 993) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:34.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 4.0 in stage 533.0 (TID 995) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 3.0 in stage 533.0 (TID 994) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:34.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 5.0 in stage 533.0 (TID 996) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 4.0 in stage 533.0 (TID 995) in 7 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:34.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:34.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 6.0 in stage 533.0 (TID 997) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 5.0 in stage 533.0 (TID 996) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:34.766+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 7.0 in stage 533.0 (TID 998) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.769+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 6.0 in stage 533.0 (TID 997) in 6 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:34.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 8.0 in stage 533.0 (TID 999) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 7.0 in stage 533.0 (TID 998) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:34.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.782+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 9.0 in stage 533.0 (TID 1000) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.782+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 8.0 in stage 533.0 (TID 999) in 6 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:34.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_670_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 9.0 in stage 533.0 (TID 1000) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:34.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Removed TaskSet 533.0, whose tasks have all completed, from pool
[2025-05-08T19:40:34.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: ShuffleMapStage 533 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.100 s
[2025-05-08T19:40:34.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:34.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:34.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: waiting: Set(ResultStage 534)
[2025-05-08T19:40:34.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:34.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting ResultStage 534 (EdgeRDDImpl[677] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:34.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 239.4 KiB, free 418.9 MiB)
[2025-05-08T19:40:34.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 418.8 MiB)
[2025-05-08T19:40:34.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.7 MiB)
[2025-05-08T19:40:34.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:34.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 534 (EdgeRDDImpl[677] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:34.802+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Adding task set 534.0 with 10 tasks resource profile 0
[2025-05-08T19:40:34.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 0.0 in stage 534.0 (TID 1001) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.20.0.5:37427 (size: 78.8 KiB, free: 418.4 MiB)
[2025-05-08T19:40:34.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:59376
[2025-05-08T19:40:34.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:34.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 1.0 in stage 534.0 (TID 1002) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 0.0 in stage 534.0 (TID 1001) in 14 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:34.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:34.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 2.0 in stage 534.0 (TID 1003) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 1.0 in stage 534.0 (TID 1002) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:34.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:34.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 3.0 in stage 534.0 (TID 1004) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 2.0 in stage 534.0 (TID 1003) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:34.842+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:34.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 4.0 in stage 534.0 (TID 1005) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 3.0 in stage 534.0 (TID 1004) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:34.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:34.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 5.0 in stage 534.0 (TID 1006) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 4.0 in stage 534.0 (TID 1005) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:34.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.1 MiB)
[2025-05-08T19:40:34.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 6.0 in stage 534.0 (TID 1007) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 5.0 in stage 534.0 (TID 1006) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:34.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.0 MiB)
[2025-05-08T19:40:34.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 7.0 in stage 534.0 (TID 1008) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 6.0 in stage 534.0 (TID 1007) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:34.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:34.884+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 8.0 in stage 534.0 (TID 1009) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.884+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 7.0 in stage 534.0 (TID 1008) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:34.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.9 MiB)
[2025-05-08T19:40:34.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 9.0 in stage 534.0 (TID 1010) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 8.0 in stage 534.0 (TID 1009) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:34.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added rdd_676_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.8 MiB)
[2025-05-08T19:40:34.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 9.0 in stage 534.0 (TID 1010) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:34.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Removed TaskSet 534.0, whose tasks have all completed, from pool
[2025-05-08T19:40:34.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: ResultStage 534 (foreachPartition at PageRank.scala:199) finished in 0.108 s
[2025-05-08T19:40:34.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:34.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 534: Stage finished
[2025-05-08T19:40:34.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Job 50 finished: foreachPartition at PageRank.scala:199, took 0.395910 s
[2025-05-08T19:40:34.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO PageRank: PageRank finished iteration 4.
[2025-05-08T19:40:34.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO ZippedPartitionsRDD2: Removing RDD 658 from persistence list
[2025-05-08T19:40:34.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManager: Removing RDD 658
[2025-05-08T19:40:34.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO ZippedPartitionsRDD2: Removing RDD 664 from persistence list
[2025-05-08T19:40:34.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManager: Removing RDD 664
[2025-05-08T19:40:34.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:34.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Registering RDD 678 (mapPartitions at GraphImpl.scala:208) as input to shuffle 85
[2025-05-08T19:40:34.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Registering RDD 686 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 84
[2025-05-08T19:40:34.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Got job 51 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:34.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Final stage: ResultStage 560 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:34.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 553, ShuffleMapStage 542, ShuffleMapStage 557, ShuffleMapStage 546, ShuffleMapStage 547, ShuffleMapStage 551, ShuffleMapStage 555, ShuffleMapStage 549, ShuffleMapStage 559)
[2025-05-08T19:40:34.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 559)
[2025-05-08T19:40:34.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting ShuffleMapStage 558 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:34.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 239.9 KiB, free 418.6 MiB)
[2025-05-08T19:40:34.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 418.5 MiB)
[2025-05-08T19:40:34.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.6 MiB)
[2025-05-08T19:40:34.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:34.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 558 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:34.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSchedulerImpl: Adding task set 558.0 with 10 tasks resource profile 0
[2025-05-08T19:40:34.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 0.0 in stage 558.0 (TID 1011) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.20.0.5:37427 (size: 79.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:34.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 1.0 in stage 558.0 (TID 1012) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 0.0 in stage 558.0 (TID 1011) in 14 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:34.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 2.0 in stage 558.0 (TID 1013) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 1.0 in stage 558.0 (TID 1012) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:34.964+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 3.0 in stage 558.0 (TID 1014) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 2.0 in stage 558.0 (TID 1013) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:34.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 4.0 in stage 558.0 (TID 1015) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.978+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 3.0 in stage 558.0 (TID 1014) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:34.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Starting task 5.0 in stage 558.0 (TID 1016) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:34.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:34 INFO TaskSetManager: Finished task 4.0 in stage 558.0 (TID 1015) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:35.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 6.0 in stage 558.0 (TID 1017) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 5.0 in stage 558.0 (TID 1016) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:35.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 7.0 in stage 558.0 (TID 1018) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 6.0 in stage 558.0 (TID 1017) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:35.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 8.0 in stage 558.0 (TID 1019) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 7.0 in stage 558.0 (TID 1018) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:35.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 9.0 in stage 558.0 (TID 1020) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 8.0 in stage 558.0 (TID 1019) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:35.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 9.0 in stage 558.0 (TID 1020) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:35.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSchedulerImpl: Removed TaskSet 558.0, whose tasks have all completed, from pool
[2025-05-08T19:40:35.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: ShuffleMapStage 558 (mapPartitions at GraphImpl.scala:208) finished in 0.141 s
[2025-05-08T19:40:35.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:35.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:35.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: waiting: Set(ResultStage 560, ShuffleMapStage 559)
[2025-05-08T19:40:35.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:35.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Submitting ShuffleMapStage 559 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:35.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 15.6 KiB, free 418.5 MiB)
[2025-05-08T19:40:35.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 418.5 MiB)
[2025-05-08T19:40:35.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.6 MiB)
[2025-05-08T19:40:35.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:35.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 559 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:35.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSchedulerImpl: Adding task set 559.0 with 10 tasks resource profile 0
[2025-05-08T19:40:35.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.20.0.5:37427 in memory (size: 6.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:35.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_106_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.6 MiB)
[2025-05-08T19:40:35.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 0.0 in stage 559.0 (TID 1021) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.20.0.5:37427 in memory (size: 78.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_107_piece0 on f2a432e4376a:35283 in memory (size: 78.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:35.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_109_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:35.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.20.0.5:37427 in memory (size: 6.3 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.082+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.20.0.5:37427 (size: 6.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_110_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.7 MiB)
[2025-05-08T19:40:35.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.20.0.5:37427 in memory (size: 78.8 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:59376
[2025-05-08T19:40:35.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_108_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:35.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.20.0.5:37427 in memory (size: 79.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:35.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:35.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 1.0 in stage 559.0 (TID 1022) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 0.0 in stage 559.0 (TID 1021) in 37 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:35.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:35.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 2.0 in stage 559.0 (TID 1023) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.141+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 1.0 in stage 559.0 (TID 1022) in 30 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:35.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:35.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 3.0 in stage 559.0 (TID 1024) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 2.0 in stage 559.0 (TID 1023) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:35.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:35.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 4.0 in stage 559.0 (TID 1025) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 3.0 in stage 559.0 (TID 1024) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:35.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:35.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 5.0 in stage 559.0 (TID 1026) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 4.0 in stage 559.0 (TID 1025) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:35.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 6.0 in stage 559.0 (TID 1027) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 5.0 in stage 559.0 (TID 1026) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:35.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 7.0 in stage 559.0 (TID 1028) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 6.0 in stage 559.0 (TID 1027) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:35.197+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 8.0 in stage 559.0 (TID 1029) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 7.0 in stage 559.0 (TID 1028) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:35.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 9.0 in stage 559.0 (TID 1030) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 8.0 in stage 559.0 (TID 1029) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:35.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_682_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:35.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 9.0 in stage 559.0 (TID 1030) in 23 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:35.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSchedulerImpl: Removed TaskSet 559.0, whose tasks have all completed, from pool
[2025-05-08T19:40:35.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: ShuffleMapStage 559 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.176 s
[2025-05-08T19:40:35.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:35.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:35.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: waiting: Set(ResultStage 560)
[2025-05-08T19:40:35.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:35.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Submitting ResultStage 560 (EdgeRDDImpl[689] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:35.266+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 239.7 KiB, free 419.2 MiB)
[2025-05-08T19:40:35.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 419.1 MiB)
[2025-05-08T19:40:35.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.7 MiB)
[2025-05-08T19:40:35.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:35.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 560 (EdgeRDDImpl[689] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:35.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSchedulerImpl: Adding task set 560.0 with 10 tasks resource profile 0
[2025-05-08T19:40:35.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 0.0 in stage 560.0 (TID 1031) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.20.0.5:37427 (size: 78.8 KiB, free: 418.5 MiB)
[2025-05-08T19:40:35.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:59376
[2025-05-08T19:40:35.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:35.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 1.0 in stage 560.0 (TID 1032) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 0.0 in stage 560.0 (TID 1031) in 95 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:35.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:35.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 2.0 in stage 560.0 (TID 1033) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.391+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 1.0 in stage 560.0 (TID 1032) in 8 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:35.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:35.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 3.0 in stage 560.0 (TID 1034) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 2.0 in stage 560.0 (TID 1033) in 9 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:35.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:35.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 4.0 in stage 560.0 (TID 1035) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 3.0 in stage 560.0 (TID 1034) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:35.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.2 MiB)
[2025-05-08T19:40:35.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 5.0 in stage 560.0 (TID 1036) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 4.0 in stage 560.0 (TID 1035) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:35.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:35.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 6.0 in stage 560.0 (TID 1037) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 5.0 in stage 560.0 (TID 1036) in 305 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:35.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.1 MiB)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 7.0 in stage 560.0 (TID 1038) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 6.0 in stage 560.0 (TID 1037) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 8.0 in stage 560.0 (TID 1039) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 7.0 in stage 560.0 (TID 1038) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.0 MiB)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 9.0 in stage 560.0 (TID 1040) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 8.0 in stage 560.0 (TID 1039) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added rdd_688_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.9 MiB)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Finished task 9.0 in stage 560.0 (TID 1040) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSchedulerImpl: Removed TaskSet 560.0, whose tasks have all completed, from pool
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: ResultStage 560 (foreachPartition at PageRank.scala:199) finished in 0.513 s
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:35.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 560: Stage finished
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Job 51 finished: foreachPartition at PageRank.scala:199, took 0.853347 s
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO PageRank: PageRank finished iteration 5.
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO ZippedPartitionsRDD2: Removing RDD 670 from persistence list
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO ZippedPartitionsRDD2: Removing RDD 676 from persistence list
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManager: Removing RDD 676
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManager: Removing RDD 670
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Registering RDD 690 (mapPartitions at GraphImpl.scala:208) as input to shuffle 87
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Registering RDD 698 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 86
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Got job 52 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Final stage: ResultStage 588 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 575, ShuffleMapStage 572, ShuffleMapStage 579, ShuffleMapStage 568, ShuffleMapStage 583, ShuffleMapStage 587, ShuffleMapStage 581, ShuffleMapStage 573, ShuffleMapStage 585, ShuffleMapStage 577)
[2025-05-08T19:40:35.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 587)
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Submitting ShuffleMapStage 586 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 240.2 KiB, free 418.9 MiB)
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 418.8 MiB)
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 586 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSchedulerImpl: Adding task set 586.0 with 10 tasks resource profile 0
[2025-05-08T19:40:35.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:35 INFO TaskSetManager: Starting task 0.0 in stage 586.0 (TID 1041) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.011+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.20.0.5:37427 (size: 79.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:36.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 1.0 in stage 586.0 (TID 1042) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 0.0 in stage 586.0 (TID 1041) in 111 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:36.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 2.0 in stage 586.0 (TID 1043) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 1.0 in stage 586.0 (TID 1042) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:36.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 3.0 in stage 586.0 (TID 1044) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 2.0 in stage 586.0 (TID 1043) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:36.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 4.0 in stage 586.0 (TID 1045) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 3.0 in stage 586.0 (TID 1044) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:36.097+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 5.0 in stage 586.0 (TID 1046) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.097+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 4.0 in stage 586.0 (TID 1045) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:36.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 6.0 in stage 586.0 (TID 1047) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 5.0 in stage 586.0 (TID 1046) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:36.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 7.0 in stage 586.0 (TID 1048) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 6.0 in stage 586.0 (TID 1047) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:36.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 8.0 in stage 586.0 (TID 1049) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 7.0 in stage 586.0 (TID 1048) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:36.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 9.0 in stage 586.0 (TID 1050) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 8.0 in stage 586.0 (TID 1049) in 51 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:36.219+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 9.0 in stage 586.0 (TID 1050) in 34 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:36.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSchedulerImpl: Removed TaskSet 586.0, whose tasks have all completed, from pool
[2025-05-08T19:40:36.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: ShuffleMapStage 586 (mapPartitions at GraphImpl.scala:208) finished in 0.345 s
[2025-05-08T19:40:36.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:36.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:36.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 587, ResultStage 588)
[2025-05-08T19:40:36.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:36.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Submitting ShuffleMapStage 587 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:36.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 16.4 KiB, free 418.8 MiB)
[2025-05-08T19:40:36.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 418.8 MiB)
[2025-05-08T19:40:36.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on f2a432e4376a:35283 (size: 6.5 KiB, free: 432.7 MiB)
[2025-05-08T19:40:36.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:36.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 587 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:36.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSchedulerImpl: Adding task set 587.0 with 10 tasks resource profile 0
[2025-05-08T19:40:36.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 0.0 in stage 587.0 (TID 1051) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.20.0.5:37427 (size: 6.5 KiB, free: 418.6 MiB)
[2025-05-08T19:40:36.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:59376
[2025-05-08T19:40:36.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 1.0 in stage 587.0 (TID 1052) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 0.0 in stage 587.0 (TID 1051) in 36 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:36.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 2.0 in stage 587.0 (TID 1053) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 1.0 in stage 587.0 (TID 1052) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:36.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.344+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 3.0 in stage 587.0 (TID 1054) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 2.0 in stage 587.0 (TID 1053) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:36.349+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.353+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 4.0 in stage 587.0 (TID 1055) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 3.0 in stage 587.0 (TID 1054) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:36.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 5.0 in stage 587.0 (TID 1056) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 4.0 in stage 587.0 (TID 1055) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:36.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 6.0 in stage 587.0 (TID 1057) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 5.0 in stage 587.0 (TID 1056) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:36.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.388+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 7.0 in stage 587.0 (TID 1058) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.388+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 6.0 in stage 587.0 (TID 1057) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:36.393+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 8.0 in stage 587.0 (TID 1059) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 7.0 in stage 587.0 (TID 1058) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:36.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.4 MiB)
[2025-05-08T19:40:36.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 9.0 in stage 587.0 (TID 1060) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 8.0 in stage 587.0 (TID 1059) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:36.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_694_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:36.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 9.0 in stage 587.0 (TID 1060) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:36.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSchedulerImpl: Removed TaskSet 587.0, whose tasks have all completed, from pool
[2025-05-08T19:40:36.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: ShuffleMapStage 587 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.192 s
[2025-05-08T19:40:36.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:36.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:36.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: waiting: Set(ResultStage 588)
[2025-05-08T19:40:36.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:36.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Submitting ResultStage 588 (EdgeRDDImpl[701] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:36.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 240.0 KiB, free 418.6 MiB)
[2025-05-08T19:40:36.431+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 78.9 KiB, free 418.5 MiB)
[2025-05-08T19:40:36.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on f2a432e4376a:35283 (size: 78.9 KiB, free: 432.6 MiB)
[2025-05-08T19:40:36.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:36.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 588 (EdgeRDDImpl[701] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:36.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSchedulerImpl: Adding task set 588.0 with 10 tasks resource profile 0
[2025-05-08T19:40:36.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 0.0 in stage 588.0 (TID 1061) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.20.0.5:37427 (size: 78.9 KiB, free: 418.4 MiB)
[2025-05-08T19:40:36.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:59376
[2025-05-08T19:40:36.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_113_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.7 MiB)
[2025-05-08T19:40:36.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.20.0.5:37427 in memory (size: 78.8 KiB, free: 418.4 MiB)
[2025-05-08T19:40:36.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.20.0.5:37427 in memory (size: 79.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.525+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_114_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:36.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:36.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_112_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.7 MiB)
[2025-05-08T19:40:36.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.20.0.5:37427 in memory (size: 6.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 1.0 in stage 588.0 (TID 1062) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 0.0 in stage 588.0 (TID 1061) in 96 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:36.530+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_111_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:36.530+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.20.0.5:37427 in memory (size: 79.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_115_piece0 on f2a432e4376a:35283 in memory (size: 6.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:36.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.20.0.5:37427 in memory (size: 6.5 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.541+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:36.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 2.0 in stage 588.0 (TID 1063) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 1.0 in stage 588.0 (TID 1062) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:36.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:36.556+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 3.0 in stage 588.0 (TID 1064) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 2.0 in stage 588.0 (TID 1063) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:36.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.4 MiB)
[2025-05-08T19:40:36.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 4.0 in stage 588.0 (TID 1065) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 3.0 in stage 588.0 (TID 1064) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:36.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:36.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 5.0 in stage 588.0 (TID 1066) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 4.0 in stage 588.0 (TID 1065) in 30 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:36.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:36.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 6.0 in stage 588.0 (TID 1067) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 5.0 in stage 588.0 (TID 1066) in 20 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:36.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:36.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 7.0 in stage 588.0 (TID 1068) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 6.0 in stage 588.0 (TID 1067) in 17 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:36.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:36.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 8.0 in stage 588.0 (TID 1069) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 7.0 in stage 588.0 (TID 1068) in 22 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:36.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:36.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 9.0 in stage 588.0 (TID 1070) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:36.671+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 8.0 in stage 588.0 (TID 1069) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:36.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added rdd_700_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.0 MiB)
[2025-05-08T19:40:36.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Finished task 9.0 in stage 588.0 (TID 1070) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:36.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSchedulerImpl: Removed TaskSet 588.0, whose tasks have all completed, from pool
[2025-05-08T19:40:36.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: ResultStage 588 (foreachPartition at PageRank.scala:199) finished in 0.265 s
[2025-05-08T19:40:36.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:36.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 588: Stage finished
[2025-05-08T19:40:36.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Job 52 finished: foreachPartition at PageRank.scala:199, took 0.836237 s
[2025-05-08T19:40:36.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO PageRank: PageRank finished iteration 6.
[2025-05-08T19:40:36.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO ZippedPartitionsRDD2: Removing RDD 682 from persistence list
[2025-05-08T19:40:36.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManager: Removing RDD 682
[2025-05-08T19:40:36.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO ZippedPartitionsRDD2: Removing RDD 688 from persistence list
[2025-05-08T19:40:36.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManager: Removing RDD 688
[2025-05-08T19:40:36.840+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:36.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Registering RDD 702 (mapPartitions at GraphImpl.scala:208) as input to shuffle 89
[2025-05-08T19:40:36.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Registering RDD 710 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 88
[2025-05-08T19:40:36.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Got job 53 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:36.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Final stage: ResultStage 618 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:36.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 607, ShuffleMapStage 596, ShuffleMapStage 611, ShuffleMapStage 615, ShuffleMapStage 609, ShuffleMapStage 601, ShuffleMapStage 613, ShuffleMapStage 605, ShuffleMapStage 617, ShuffleMapStage 603, ShuffleMapStage 600)
[2025-05-08T19:40:36.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 617)
[2025-05-08T19:40:36.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Submitting ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:36.891+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 240.5 KiB, free 419.2 MiB)
[2025-05-08T19:40:36.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 419.2 MiB)
[2025-05-08T19:40:36.926+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:36.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:36.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 616 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:36.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSchedulerImpl: Adding task set 616.0 with 10 tasks resource profile 0
[2025-05-08T19:40:36.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:36 INFO TaskSetManager: Starting task 0.0 in stage 616.0 (TID 1071) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.032+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.20.0.5:37427 (size: 79.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.177+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 1.0 in stage 616.0 (TID 1072) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 0.0 in stage 616.0 (TID 1071) in 245 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:37.197+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 2.0 in stage 616.0 (TID 1073) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.197+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 1.0 in stage 616.0 (TID 1072) in 28 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:37.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 3.0 in stage 616.0 (TID 1074) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.220+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 2.0 in stage 616.0 (TID 1073) in 23 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:37.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 4.0 in stage 616.0 (TID 1075) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 3.0 in stage 616.0 (TID 1074) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:37.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 5.0 in stage 616.0 (TID 1076) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 4.0 in stage 616.0 (TID 1075) in 58 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:37.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 6.0 in stage 616.0 (TID 1077) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 5.0 in stage 616.0 (TID 1076) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:37.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 7.0 in stage 616.0 (TID 1078) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.315+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 6.0 in stage 616.0 (TID 1077) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:37.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 8.0 in stage 616.0 (TID 1079) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 7.0 in stage 616.0 (TID 1078) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:37.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 9.0 in stage 616.0 (TID 1080) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 8.0 in stage 616.0 (TID 1079) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:37.352+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 9.0 in stage 616.0 (TID 1080) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:37.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSchedulerImpl: Removed TaskSet 616.0, whose tasks have all completed, from pool
[2025-05-08T19:40:37.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: ShuffleMapStage 616 (mapPartitions at GraphImpl.scala:208) finished in 0.475 s
[2025-05-08T19:40:37.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:37.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:37.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 617, ResultStage 618)
[2025-05-08T19:40:37.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:37.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: Submitting ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:37.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 17.1 KiB, free 419.1 MiB)
[2025-05-08T19:40:37.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 419.1 MiB)
[2025-05-08T19:40:37.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:37.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:37.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 617 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:37.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSchedulerImpl: Adding task set 617.0 with 10 tasks resource profile 0
[2025-05-08T19:40:37.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 0.0 in stage 617.0 (TID 1081) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.478+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.20.0.5:37427 (size: 6.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:59376
[2025-05-08T19:40:37.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 1.0 in stage 617.0 (TID 1082) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 0.0 in stage 617.0 (TID 1081) in 46 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:37.517+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 2.0 in stage 617.0 (TID 1083) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 1.0 in stage 617.0 (TID 1082) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:37.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 3.0 in stage 617.0 (TID 1084) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 2.0 in stage 617.0 (TID 1083) in 107 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:37.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.660+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 4.0 in stage 617.0 (TID 1085) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 3.0 in stage 617.0 (TID 1084) in 42 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:37.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 5.0 in stage 617.0 (TID 1086) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 4.0 in stage 617.0 (TID 1085) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:37.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 6.0 in stage 617.0 (TID 1087) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 5.0 in stage 617.0 (TID 1086) in 18 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:37.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:37.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 7.0 in stage 617.0 (TID 1088) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 6.0 in stage 617.0 (TID 1087) in 61 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:37.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:37.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 8.0 in stage 617.0 (TID 1089) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 7.0 in stage 617.0 (TID 1088) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:37.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:37.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 9.0 in stage 617.0 (TID 1090) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 8.0 in stage 617.0 (TID 1089) in 6 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:37.766+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_706_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:37.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 9.0 in stage 617.0 (TID 1090) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:37.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSchedulerImpl: Removed TaskSet 617.0, whose tasks have all completed, from pool
[2025-05-08T19:40:37.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: ShuffleMapStage 617 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.397 s
[2025-05-08T19:40:37.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:37.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:37.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: waiting: Set(ResultStage 618)
[2025-05-08T19:40:37.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:37.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: Submitting ResultStage 618 (EdgeRDDImpl[713] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:37.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 240.3 KiB, free 418.9 MiB)
[2025-05-08T19:40:37.876+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 418.8 MiB)
[2025-05-08T19:40:37.878+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:37.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:37.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 618 (EdgeRDDImpl[713] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:37.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSchedulerImpl: Adding task set 618.0 with 10 tasks resource profile 0
[2025-05-08T19:40:37.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 0.0 in stage 618.0 (TID 1091) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.20.0.5:37427 (size: 79.0 KiB, free: 418.4 MiB)
[2025-05-08T19:40:37.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:59376
[2025-05-08T19:40:37.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_712_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:37.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 1.0 in stage 618.0 (TID 1092) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 0.0 in stage 618.0 (TID 1091) in 44 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:37.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_712_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:37.939+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 2.0 in stage 618.0 (TID 1093) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 1.0 in stage 618.0 (TID 1092) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:37.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_712_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:37.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 3.0 in stage 618.0 (TID 1094) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 2.0 in stage 618.0 (TID 1093) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:37.959+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_712_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:37.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 4.0 in stage 618.0 (TID 1095) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 3.0 in stage 618.0 (TID 1094) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:37.970+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_712_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:37.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 5.0 in stage 618.0 (TID 1096) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 4.0 in stage 618.0 (TID 1095) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:37.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_712_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.1 MiB)
[2025-05-08T19:40:37.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 6.0 in stage 618.0 (TID 1097) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 5.0 in stage 618.0 (TID 1096) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:37.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO BlockManagerInfo: Added rdd_712_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.0 MiB)
[2025-05-08T19:40:37.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Starting task 7.0 in stage 618.0 (TID 1098) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:37.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:37 INFO TaskSetManager: Finished task 6.0 in stage 618.0 (TID 1097) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:38.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO BlockManagerInfo: Added rdd_712_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:38.004+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Starting task 8.0 in stage 618.0 (TID 1099) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:38.004+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Finished task 7.0 in stage 618.0 (TID 1098) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:38.017+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO BlockManagerInfo: Added rdd_712_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.9 MiB)
[2025-05-08T19:40:38.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Starting task 9.0 in stage 618.0 (TID 1100) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:38.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Finished task 8.0 in stage 618.0 (TID 1099) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:38.026+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO BlockManagerInfo: Added rdd_712_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.8 MiB)
[2025-05-08T19:40:38.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Finished task 9.0 in stage 618.0 (TID 1100) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:38.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSchedulerImpl: Removed TaskSet 618.0, whose tasks have all completed, from pool
[2025-05-08T19:40:38.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: ResultStage 618 (foreachPartition at PageRank.scala:199) finished in 0.242 s
[2025-05-08T19:40:38.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:38.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 618: Stage finished
[2025-05-08T19:40:38.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Job 53 finished: foreachPartition at PageRank.scala:199, took 1.302284 s
[2025-05-08T19:40:38.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO PageRank: PageRank finished iteration 7.
[2025-05-08T19:40:38.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO ZippedPartitionsRDD2: Removing RDD 694 from persistence list
[2025-05-08T19:40:38.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO BlockManager: Removing RDD 694
[2025-05-08T19:40:38.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO ZippedPartitionsRDD2: Removing RDD 700 from persistence list
[2025-05-08T19:40:38.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO BlockManager: Removing RDD 700
[2025-05-08T19:40:38.845+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:38.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Registering RDD 714 (mapPartitions at GraphImpl.scala:208) as input to shuffle 91
[2025-05-08T19:40:38.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Registering RDD 722 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 90
[2025-05-08T19:40:38.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Got job 54 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:38.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Final stage: ResultStage 650 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:38.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 643, ShuffleMapStage 647, ShuffleMapStage 626, ShuffleMapStage 641, ShuffleMapStage 633, ShuffleMapStage 630, ShuffleMapStage 645, ShuffleMapStage 637, ShuffleMapStage 631, ShuffleMapStage 649, ShuffleMapStage 635, ShuffleMapStage 639)
[2025-05-08T19:40:38.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 649)
[2025-05-08T19:40:38.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Submitting ShuffleMapStage 648 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:38.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 240.8 KiB, free 418.6 MiB)
[2025-05-08T19:40:38.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 418.5 MiB)
[2025-05-08T19:40:38.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.6 MiB)
[2025-05-08T19:40:38.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:38.919+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 648 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:38.919+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSchedulerImpl: Adding task set 648.0 with 10 tasks resource profile 0
[2025-05-08T19:40:38.920+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Starting task 0.0 in stage 648.0 (TID 1101) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:38.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.20.0.5:37427 (size: 79.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:38.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Starting task 1.0 in stage 648.0 (TID 1102) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:38.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Finished task 0.0 in stage 648.0 (TID 1101) in 61 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:38.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Starting task 2.0 in stage 648.0 (TID 1103) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:38.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:38 INFO TaskSetManager: Finished task 1.0 in stage 648.0 (TID 1102) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:39.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 3.0 in stage 648.0 (TID 1104) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 2.0 in stage 648.0 (TID 1103) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:39.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 4.0 in stage 648.0 (TID 1105) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 3.0 in stage 648.0 (TID 1104) in 32 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:39.051+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 5.0 in stage 648.0 (TID 1106) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 4.0 in stage 648.0 (TID 1105) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:39.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 6.0 in stage 648.0 (TID 1107) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 5.0 in stage 648.0 (TID 1106) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:39.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 7.0 in stage 648.0 (TID 1108) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 6.0 in stage 648.0 (TID 1107) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:39.092+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 8.0 in stage 648.0 (TID 1109) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.092+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 7.0 in stage 648.0 (TID 1108) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:39.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 9.0 in stage 648.0 (TID 1110) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 8.0 in stage 648.0 (TID 1109) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:39.119+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 9.0 in stage 648.0 (TID 1110) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:39.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Removed TaskSet 648.0, whose tasks have all completed, from pool
[2025-05-08T19:40:39.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: ShuffleMapStage 648 (mapPartitions at GraphImpl.scala:208) finished in 0.254 s
[2025-05-08T19:40:39.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:39.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:39.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 649, ResultStage 650)
[2025-05-08T19:40:39.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:39.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting ShuffleMapStage 649 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:39.125+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 17.8 KiB, free 418.5 MiB)
[2025-05-08T19:40:39.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 418.5 MiB)
[2025-05-08T19:40:39.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.6 MiB)
[2025-05-08T19:40:39.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:39.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 649 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:39.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Adding task set 649.0 with 10 tasks resource profile 0
[2025-05-08T19:40:39.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 0.0 in stage 649.0 (TID 1111) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.132+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.20.0.5:37427 (size: 6.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:59376
[2025-05-08T19:40:39.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 172.20.0.5:37427 in memory (size: 6.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_118_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.6 MiB)
[2025-05-08T19:40:39.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_119_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:39.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.20.0.5:37427 in memory (size: 79.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_117_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:39.165+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.20.0.5:37427 in memory (size: 79.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 172.20.0.5:37427 in memory (size: 78.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_116_piece0 on f2a432e4376a:35283 in memory (size: 78.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:39.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_120_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.9 MiB)
[2025-05-08T19:40:39.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 1.0 in stage 649.0 (TID 1112) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 172.20.0.5:37427 in memory (size: 79.3 KiB, free: 418.8 MiB)
[2025-05-08T19:40:39.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 0.0 in stage 649.0 (TID 1111) in 45 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:39.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.8 MiB)
[2025-05-08T19:40:39.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 2.0 in stage 649.0 (TID 1113) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 1.0 in stage 649.0 (TID 1112) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:39.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.8 MiB)
[2025-05-08T19:40:39.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 3.0 in stage 649.0 (TID 1114) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 2.0 in stage 649.0 (TID 1113) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:39.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 4.0 in stage 649.0 (TID 1115) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.245+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 3.0 in stage 649.0 (TID 1114) in 38 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:39.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 5.0 in stage 649.0 (TID 1116) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 4.0 in stage 649.0 (TID 1115) in 14 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:39.264+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 6.0 in stage 649.0 (TID 1117) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 5.0 in stage 649.0 (TID 1116) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:39.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.282+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 7.0 in stage 649.0 (TID 1118) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 6.0 in stage 649.0 (TID 1117) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:39.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 8.0 in stage 649.0 (TID 1119) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 7.0 in stage 649.0 (TID 1118) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:39.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 9.0 in stage 649.0 (TID 1120) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 8.0 in stage 649.0 (TID 1119) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:39.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_718_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:39.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 9.0 in stage 649.0 (TID 1120) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:39.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Removed TaskSet 649.0, whose tasks have all completed, from pool
[2025-05-08T19:40:39.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: ShuffleMapStage 649 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.195 s
[2025-05-08T19:40:39.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:39.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:39.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: waiting: Set(ResultStage 650)
[2025-05-08T19:40:39.318+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:39.319+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting ResultStage 650 (EdgeRDDImpl[725] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:39.327+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 240.6 KiB, free 419.5 MiB)
[2025-05-08T19:40:39.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 419.4 MiB)
[2025-05-08T19:40:39.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:39.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:39.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 650 (EdgeRDDImpl[725] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:39.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Adding task set 650.0 with 10 tasks resource profile 0
[2025-05-08T19:40:39.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 0.0 in stage 650.0 (TID 1121) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.20.0.5:37427 (size: 79.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:59376
[2025-05-08T19:40:39.349+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.353+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 1.0 in stage 650.0 (TID 1122) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 0.0 in stage 650.0 (TID 1121) in 24 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:39.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 2.0 in stage 650.0 (TID 1123) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.374+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 1.0 in stage 650.0 (TID 1122) in 21 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:39.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:39.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 3.0 in stage 650.0 (TID 1124) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 2.0 in stage 650.0 (TID 1123) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:39.400+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:39.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 4.0 in stage 650.0 (TID 1125) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 3.0 in stage 650.0 (TID 1124) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:39.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:39.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 5.0 in stage 650.0 (TID 1126) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 4.0 in stage 650.0 (TID 1125) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:39.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:39.436+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 6.0 in stage 650.0 (TID 1127) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 5.0 in stage 650.0 (TID 1126) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:39.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:39.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 7.0 in stage 650.0 (TID 1128) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 6.0 in stage 650.0 (TID 1127) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:39.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:39.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 8.0 in stage 650.0 (TID 1129) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 7.0 in stage 650.0 (TID 1128) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:39.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:39.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 9.0 in stage 650.0 (TID 1130) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.477+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 8.0 in stage 650.0 (TID 1129) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:39.487+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_724_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.0 MiB)
[2025-05-08T19:40:39.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 9.0 in stage 650.0 (TID 1130) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:39.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Removed TaskSet 650.0, whose tasks have all completed, from pool
[2025-05-08T19:40:39.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: ResultStage 650 (foreachPartition at PageRank.scala:199) finished in 0.170 s
[2025-05-08T19:40:39.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:39.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 650: Stage finished
[2025-05-08T19:40:39.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Job 54 finished: foreachPartition at PageRank.scala:199, took 0.645070 s
[2025-05-08T19:40:39.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO PageRank: PageRank finished iteration 8.
[2025-05-08T19:40:39.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO ZippedPartitionsRDD2: Removing RDD 706 from persistence list
[2025-05-08T19:40:39.491+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManager: Removing RDD 706
[2025-05-08T19:40:39.491+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO ZippedPartitionsRDD2: Removing RDD 712 from persistence list
[2025-05-08T19:40:39.491+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManager: Removing RDD 712
[2025-05-08T19:40:39.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:39.506+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Registering RDD 726 (mapPartitions at GraphImpl.scala:208) as input to shuffle 93
[2025-05-08T19:40:39.506+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Registering RDD 734 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 92
[2025-05-08T19:40:39.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Got job 55 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:39.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Final stage: ResultStage 684 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:39.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 679, ShuffleMapStage 658, ShuffleMapStage 673, ShuffleMapStage 665, ShuffleMapStage 662, ShuffleMapStage 677, ShuffleMapStage 663, ShuffleMapStage 681, ShuffleMapStage 667, ShuffleMapStage 671, ShuffleMapStage 683, ShuffleMapStage 675, ShuffleMapStage 669)
[2025-05-08T19:40:39.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 683)
[2025-05-08T19:40:39.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting ShuffleMapStage 682 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:39.516+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 241.1 KiB, free 419.2 MiB)
[2025-05-08T19:40:39.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 419.1 MiB)
[2025-05-08T19:40:39.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:39.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:39.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 682 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:39.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Adding task set 682.0 with 10 tasks resource profile 0
[2025-05-08T19:40:39.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 0.0 in stage 682.0 (TID 1131) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.524+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.20.0.5:37427 (size: 79.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 1.0 in stage 682.0 (TID 1132) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 0.0 in stage 682.0 (TID 1131) in 30 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:39.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 2.0 in stage 682.0 (TID 1133) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 1.0 in stage 682.0 (TID 1132) in 30 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:39.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 3.0 in stage 682.0 (TID 1134) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 2.0 in stage 682.0 (TID 1133) in 28 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:39.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 4.0 in stage 682.0 (TID 1135) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.624+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 3.0 in stage 682.0 (TID 1134) in 18 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:39.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 5.0 in stage 682.0 (TID 1136) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 4.0 in stage 682.0 (TID 1135) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:39.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 6.0 in stage 682.0 (TID 1137) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 5.0 in stage 682.0 (TID 1136) in 26 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:39.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 7.0 in stage 682.0 (TID 1138) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 6.0 in stage 682.0 (TID 1137) in 22 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:39.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 8.0 in stage 682.0 (TID 1139) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 7.0 in stage 682.0 (TID 1138) in 23 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:39.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 9.0 in stage 682.0 (TID 1140) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 8.0 in stage 682.0 (TID 1139) in 22 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:39.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 9.0 in stage 682.0 (TID 1140) in 19 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:39.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Removed TaskSet 682.0, whose tasks have all completed, from pool
[2025-05-08T19:40:39.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: ShuffleMapStage 682 (mapPartitions at GraphImpl.scala:208) finished in 0.242 s
[2025-05-08T19:40:39.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:39.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:39.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: waiting: Set(ResultStage 684, ShuffleMapStage 683)
[2025-05-08T19:40:39.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:39.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting ShuffleMapStage 683 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:39.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 18.5 KiB, free 419.1 MiB)
[2025-05-08T19:40:39.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 419.1 MiB)
[2025-05-08T19:40:39.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on f2a432e4376a:35283 (size: 6.8 KiB, free: 432.7 MiB)
[2025-05-08T19:40:39.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:39.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 683 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:39.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Adding task set 683.0 with 10 tasks resource profile 0
[2025-05-08T19:40:39.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 0.0 in stage 683.0 (TID 1141) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.759+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.20.0.5:37427 (size: 6.8 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:59376
[2025-05-08T19:40:39.767+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 1.0 in stage 683.0 (TID 1142) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 0.0 in stage 683.0 (TID 1141) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:39.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 2.0 in stage 683.0 (TID 1143) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 1.0 in stage 683.0 (TID 1142) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:39.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 3.0 in stage 683.0 (TID 1144) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 2.0 in stage 683.0 (TID 1143) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:39.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 4.0 in stage 683.0 (TID 1145) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 3.0 in stage 683.0 (TID 1144) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:39.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 5.0 in stage 683.0 (TID 1146) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 4.0 in stage 683.0 (TID 1145) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:39.822+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:39.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 6.0 in stage 683.0 (TID 1147) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 5.0 in stage 683.0 (TID 1146) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:39.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.838+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 7.0 in stage 683.0 (TID 1148) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.839+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 6.0 in stage 683.0 (TID 1147) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:39.845+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 8.0 in stage 683.0 (TID 1149) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 7.0 in stage 683.0 (TID 1148) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:39.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 9.0 in stage 683.0 (TID 1150) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 8.0 in stage 683.0 (TID 1149) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:39.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_730_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:39.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 9.0 in stage 683.0 (TID 1150) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:39.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Removed TaskSet 683.0, whose tasks have all completed, from pool
[2025-05-08T19:40:39.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: ShuffleMapStage 683 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.120 s
[2025-05-08T19:40:39.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:39.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:39.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: waiting: Set(ResultStage 684)
[2025-05-08T19:40:39.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:39.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting ResultStage 684 (EdgeRDDImpl[737] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:39.878+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 240.9 KiB, free 418.9 MiB)
[2025-05-08T19:40:39.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 418.8 MiB)
[2025-05-08T19:40:39.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:39.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:39.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 684 (EdgeRDDImpl[737] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:39.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSchedulerImpl: Adding task set 684.0 with 10 tasks resource profile 0
[2025-05-08T19:40:39.881+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 0.0 in stage 684.0 (TID 1151) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.20.0.5:37427 (size: 79.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:39.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:59376
[2025-05-08T19:40:39.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:39.900+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 1.0 in stage 684.0 (TID 1152) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 0.0 in stage 684.0 (TID 1151) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:39.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:39.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 2.0 in stage 684.0 (TID 1153) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.918+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 1.0 in stage 684.0 (TID 1152) in 18 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:39.928+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:39.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 3.0 in stage 684.0 (TID 1154) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 2.0 in stage 684.0 (TID 1153) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:39.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:39.942+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 4.0 in stage 684.0 (TID 1155) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.942+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 3.0 in stage 684.0 (TID 1154) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:39.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:39.954+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 5.0 in stage 684.0 (TID 1156) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 4.0 in stage 684.0 (TID 1155) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:39.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.1 MiB)
[2025-05-08T19:40:39.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 6.0 in stage 684.0 (TID 1157) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 5.0 in stage 684.0 (TID 1156) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:39.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.0 MiB)
[2025-05-08T19:40:39.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 7.0 in stage 684.0 (TID 1158) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.978+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 6.0 in stage 684.0 (TID 1157) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:39.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:39.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 8.0 in stage 684.0 (TID 1159) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 7.0 in stage 684.0 (TID 1158) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:39.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO BlockManagerInfo: Added rdd_736_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.9 MiB)
[2025-05-08T19:40:39.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Starting task 9.0 in stage 684.0 (TID 1160) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:39.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:39 INFO TaskSetManager: Finished task 8.0 in stage 684.0 (TID 1159) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:40.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_736_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.8 MiB)
[2025-05-08T19:40:40.012+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 9.0 in stage 684.0 (TID 1160) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:40.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Removed TaskSet 684.0, whose tasks have all completed, from pool
[2025-05-08T19:40:40.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: ResultStage 684 (foreachPartition at PageRank.scala:199) finished in 0.141 s
[2025-05-08T19:40:40.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:40.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 684: Stage finished
[2025-05-08T19:40:40.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Job 55 finished: foreachPartition at PageRank.scala:199, took 0.509434 s
[2025-05-08T19:40:40.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO PageRank: PageRank finished iteration 9.
[2025-05-08T19:40:40.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO ZippedPartitionsRDD2: Removing RDD 718 from persistence list
[2025-05-08T19:40:40.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManager: Removing RDD 718
[2025-05-08T19:40:40.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO ZippedPartitionsRDD2: Removing RDD 724 from persistence list
[2025-05-08T19:40:40.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManager: Removing RDD 724
[2025-05-08T19:40:40.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:40.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Registering RDD 738 (mapPartitions at GraphImpl.scala:208) as input to shuffle 95
[2025-05-08T19:40:40.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Registering RDD 746 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 94
[2025-05-08T19:40:40.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Got job 56 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:40.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Final stage: ResultStage 720 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:40.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 713, ShuffleMapStage 692, ShuffleMapStage 699, ShuffleMapStage 715, ShuffleMapStage 707, ShuffleMapStage 701, ShuffleMapStage 709, ShuffleMapStage 717, ShuffleMapStage 696, ShuffleMapStage 703, ShuffleMapStage 697, ShuffleMapStage 719, ShuffleMapStage 711, ShuffleMapStage 705)
[2025-05-08T19:40:40.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 719)
[2025-05-08T19:40:40.035+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting ShuffleMapStage 718 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[738] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:40.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 241.4 KiB, free 418.6 MiB)
[2025-05-08T19:40:40.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_124_piece0 on f2a432e4376a:35283 in memory (size: 6.8 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 418.5 MiB)
[2025-05-08T19:40:40.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.6 MiB)
[2025-05-08T19:40:40.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.20.0.5:37427 in memory (size: 6.8 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:40.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 718 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[738] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:40.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Adding task set 718.0 with 10 tasks resource profile 0
[2025-05-08T19:40:40.067+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 0.0 in stage 718.0 (TID 1161) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.068+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_125_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 172.20.0.5:37427 in memory (size: 79.3 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_122_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 172.20.0.5:37427 in memory (size: 79.0 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.20.0.5:37427 (size: 79.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_123_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.8 MiB)
[2025-05-08T19:40:40.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.20.0.5:37427 in memory (size: 79.6 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_121_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.8 MiB)
[2025-05-08T19:40:40.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.20.0.5:37427 in memory (size: 6.6 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 1.0 in stage 718.0 (TID 1162) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 0.0 in stage 718.0 (TID 1161) in 25 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:40.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 2.0 in stage 718.0 (TID 1163) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 1.0 in stage 718.0 (TID 1162) in 23 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:40.137+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 3.0 in stage 718.0 (TID 1164) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.137+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 2.0 in stage 718.0 (TID 1163) in 24 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:40.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 4.0 in stage 718.0 (TID 1165) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.154+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 3.0 in stage 718.0 (TID 1164) in 17 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:40.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 5.0 in stage 718.0 (TID 1166) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 4.0 in stage 718.0 (TID 1165) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:40.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 6.0 in stage 718.0 (TID 1167) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 5.0 in stage 718.0 (TID 1166) in 18 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:40.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 7.0 in stage 718.0 (TID 1168) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.203+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 6.0 in stage 718.0 (TID 1167) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:40.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 8.0 in stage 718.0 (TID 1169) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 7.0 in stage 718.0 (TID 1168) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:40.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 9.0 in stage 718.0 (TID 1170) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 8.0 in stage 718.0 (TID 1169) in 66 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:40.297+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 9.0 in stage 718.0 (TID 1170) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:40.297+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Removed TaskSet 718.0, whose tasks have all completed, from pool
[2025-05-08T19:40:40.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: ShuffleMapStage 718 (mapPartitions at GraphImpl.scala:208) finished in 0.262 s
[2025-05-08T19:40:40.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:40.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:40.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: waiting: Set(ShuffleMapStage 719, ResultStage 720)
[2025-05-08T19:40:40.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:40.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting ShuffleMapStage 719 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[746] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:40.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 19.2 KiB, free 419.5 MiB)
[2025-05-08T19:40:40.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 419.4 MiB)
[2025-05-08T19:40:40.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on f2a432e4376a:35283 (size: 7.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:40.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:40.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 719 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[746] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:40.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Adding task set 719.0 with 10 tasks resource profile 0
[2025-05-08T19:40:40.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 0.0 in stage 719.0 (TID 1171) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.20.0.5:37427 (size: 7.0 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:59376
[2025-05-08T19:40:40.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 1.0 in stage 719.0 (TID 1172) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 0.0 in stage 719.0 (TID 1171) in 34 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:40.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.350+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 2.0 in stage 719.0 (TID 1173) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.350+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 1.0 in stage 719.0 (TID 1172) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:40.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 3.0 in stage 719.0 (TID 1174) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 2.0 in stage 719.0 (TID 1173) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:40.364+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 4.0 in stage 719.0 (TID 1175) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 3.0 in stage 719.0 (TID 1174) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:40.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 5.0 in stage 719.0 (TID 1176) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 4.0 in stage 719.0 (TID 1175) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:40.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 6.0 in stage 719.0 (TID 1177) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 5.0 in stage 719.0 (TID 1176) in 7 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:40.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 7.0 in stage 719.0 (TID 1178) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 6.0 in stage 719.0 (TID 1177) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:40.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 8.0 in stage 719.0 (TID 1179) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 7.0 in stage 719.0 (TID 1178) in 23 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:40.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 9.0 in stage 719.0 (TID 1180) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 8.0 in stage 719.0 (TID 1179) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:40.430+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_742_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 9.0 in stage 719.0 (TID 1180) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:40.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Removed TaskSet 719.0, whose tasks have all completed, from pool
[2025-05-08T19:40:40.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: ShuffleMapStage 719 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.132 s
[2025-05-08T19:40:40.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:40.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:40.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: waiting: Set(ResultStage 720)
[2025-05-08T19:40:40.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:40.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting ResultStage 720 (EdgeRDDImpl[749] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:40.441+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 241.2 KiB, free 419.2 MiB)
[2025-05-08T19:40:40.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 419.1 MiB)
[2025-05-08T19:40:40.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:40.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 720 (EdgeRDDImpl[749] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:40.444+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Adding task set 720.0 with 10 tasks resource profile 0
[2025-05-08T19:40:40.444+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 0.0 in stage 720.0 (TID 1181) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.20.0.5:37427 (size: 79.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:59376
[2025-05-08T19:40:40.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 1.0 in stage 720.0 (TID 1182) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 0.0 in stage 720.0 (TID 1181) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:40.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:40.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 2.0 in stage 720.0 (TID 1183) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 1.0 in stage 720.0 (TID 1182) in 13 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:40.482+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:40.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 3.0 in stage 720.0 (TID 1184) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 2.0 in stage 720.0 (TID 1183) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:40.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:40.495+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 4.0 in stage 720.0 (TID 1185) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.496+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 3.0 in stage 720.0 (TID 1184) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:40.506+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.2 MiB)
[2025-05-08T19:40:40.508+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 5.0 in stage 720.0 (TID 1186) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.508+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 4.0 in stage 720.0 (TID 1185) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:40.516+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:40.517+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 6.0 in stage 720.0 (TID 1187) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 5.0 in stage 720.0 (TID 1186) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:40.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.1 MiB)
[2025-05-08T19:40:40.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 7.0 in stage 720.0 (TID 1188) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 6.0 in stage 720.0 (TID 1187) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:40.541+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:40.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 8.0 in stage 720.0 (TID 1189) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 7.0 in stage 720.0 (TID 1188) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:40.556+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.0 MiB)
[2025-05-08T19:40:40.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 9.0 in stage 720.0 (TID 1190) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5287 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 8.0 in stage 720.0 (TID 1189) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:40.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_748_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.9 MiB)
[2025-05-08T19:40:40.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 9.0 in stage 720.0 (TID 1190) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:40.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Removed TaskSet 720.0, whose tasks have all completed, from pool
[2025-05-08T19:40:40.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: ResultStage 720 (foreachPartition at PageRank.scala:199) finished in 0.134 s
[2025-05-08T19:40:40.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:40.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 720: Stage finished
[2025-05-08T19:40:40.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Job 56 finished: foreachPartition at PageRank.scala:199, took 0.537799 s
[2025-05-08T19:40:40.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO PageRank: PageRank finished iteration 10.
[2025-05-08T19:40:40.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO ZippedPartitionsRDD2: Removing RDD 730 from persistence list
[2025-05-08T19:40:40.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManager: Removing RDD 730
[2025-05-08T19:40:40.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO ZippedPartitionsRDD2: Removing RDD 736 from persistence list
[2025-05-08T19:40:40.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManager: Removing RDD 736
[2025-05-08T19:40:40.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:40.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Registering RDD 750 (mapPartitions at GraphImpl.scala:208) as input to shuffle 97
[2025-05-08T19:40:40.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Registering RDD 758 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 96
[2025-05-08T19:40:40.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Got job 57 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:40.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Final stage: ResultStage 758 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:40.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 757, ShuffleMapStage 749, ShuffleMapStage 728, ShuffleMapStage 743, ShuffleMapStage 735, ShuffleMapStage 751, ShuffleMapStage 737, ShuffleMapStage 745, ShuffleMapStage 753, ShuffleMapStage 732, ShuffleMapStage 747, ShuffleMapStage 739, ShuffleMapStage 733, ShuffleMapStage 755, ShuffleMapStage 741)
[2025-05-08T19:40:40.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 757)
[2025-05-08T19:40:40.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting ShuffleMapStage 756 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[750] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:40.596+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 241.7 KiB, free 418.9 MiB)
[2025-05-08T19:40:40.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 418.8 MiB)
[2025-05-08T19:40:40.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:40.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 756 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[750] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:40.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Adding task set 756.0 with 10 tasks resource profile 0
[2025-05-08T19:40:40.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 0.0 in stage 756.0 (TID 1191) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.20.0.5:37427 (size: 79.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 1.0 in stage 756.0 (TID 1192) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 0.0 in stage 756.0 (TID 1191) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:40.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 2.0 in stage 756.0 (TID 1193) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 1.0 in stage 756.0 (TID 1192) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:40.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 3.0 in stage 756.0 (TID 1194) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 2.0 in stage 756.0 (TID 1193) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:40.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 4.0 in stage 756.0 (TID 1195) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 3.0 in stage 756.0 (TID 1194) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:40.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 5.0 in stage 756.0 (TID 1196) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 4.0 in stage 756.0 (TID 1195) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:40.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 6.0 in stage 756.0 (TID 1197) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 5.0 in stage 756.0 (TID 1196) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:40.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 7.0 in stage 756.0 (TID 1198) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 6.0 in stage 756.0 (TID 1197) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:40.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 8.0 in stage 756.0 (TID 1199) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 7.0 in stage 756.0 (TID 1198) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:40.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 9.0 in stage 756.0 (TID 1200) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 8.0 in stage 756.0 (TID 1199) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:40.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 9.0 in stage 756.0 (TID 1200) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:40.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Removed TaskSet 756.0, whose tasks have all completed, from pool
[2025-05-08T19:40:40.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: ShuffleMapStage 756 (mapPartitions at GraphImpl.scala:208) finished in 0.154 s
[2025-05-08T19:40:40.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:40.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:40.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: waiting: Set(ShuffleMapStage 757, ResultStage 758)
[2025-05-08T19:40:40.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:40.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting ShuffleMapStage 757 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[758] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:40.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 19.9 KiB, free 418.8 MiB)
[2025-05-08T19:40:40.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 418.8 MiB)
[2025-05-08T19:40:40.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on f2a432e4376a:35283 (size: 7.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:40.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 757 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[758] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:40.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Adding task set 757.0 with 10 tasks resource profile 0
[2025-05-08T19:40:40.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 0.0 in stage 757.0 (TID 1201) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.20.0.5:37427 (size: 7.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.752+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:59376
[2025-05-08T19:40:40.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 1.0 in stage 757.0 (TID 1202) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 0.0 in stage 757.0 (TID 1201) in 12 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:40.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 2.0 in stage 757.0 (TID 1203) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 1.0 in stage 757.0 (TID 1202) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:40.769+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 3.0 in stage 757.0 (TID 1204) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 2.0 in stage 757.0 (TID 1203) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:40.777+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 4.0 in stage 757.0 (TID 1205) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 3.0 in stage 757.0 (TID 1204) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:40.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 5.0 in stage 757.0 (TID 1206) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 4.0 in stage 757.0 (TID 1205) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:40.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 6.0 in stage 757.0 (TID 1207) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 5.0 in stage 757.0 (TID 1206) in 7 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:40.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 7.0 in stage 757.0 (TID 1208) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 6.0 in stage 757.0 (TID 1207) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:40.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 8.0 in stage 757.0 (TID 1209) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 7.0 in stage 757.0 (TID 1208) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:40.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.4 MiB)
[2025-05-08T19:40:40.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 9.0 in stage 757.0 (TID 1210) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 8.0 in stage 757.0 (TID 1209) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:40.827+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_754_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:40.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 9.0 in stage 757.0 (TID 1210) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:40.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Removed TaskSet 757.0, whose tasks have all completed, from pool
[2025-05-08T19:40:40.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: ShuffleMapStage 757 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.087 s
[2025-05-08T19:40:40.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:40.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:40.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: waiting: Set(ResultStage 758)
[2025-05-08T19:40:40.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:40.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting ResultStage 758 (EdgeRDDImpl[761] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:40.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 241.5 KiB, free 418.6 MiB)
[2025-05-08T19:40:40.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_126_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 418.8 MiB)
[2025-05-08T19:40:40.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 172.20.0.5:37427 in memory (size: 79.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:40.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 758 (EdgeRDDImpl[761] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:40.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Adding task set 758.0 with 10 tasks resource profile 0
[2025-05-08T19:40:40.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 0.0 in stage 758.0 (TID 1211) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_128_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:40.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.20.0.5:37427 in memory (size: 79.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_129_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.8 MiB)
[2025-05-08T19:40:40.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 172.20.0.5:37427 in memory (size: 79.4 KiB, free: 418.7 MiB)
[2025-05-08T19:40:40.858+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.20.0.5:37427 (size: 79.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.858+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_127_piece0 on f2a432e4376a:35283 in memory (size: 7.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:40.858+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.20.0.5:37427 in memory (size: 7.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:40.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 96 to 172.20.0.5:59376
[2025-05-08T19:40:40.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 1.0 in stage 758.0 (TID 1212) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 0.0 in stage 758.0 (TID 1211) in 22 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:40.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:40.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 2.0 in stage 758.0 (TID 1213) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.890+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 1.0 in stage 758.0 (TID 1212) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:40.903+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:40.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 3.0 in stage 758.0 (TID 1214) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 2.0 in stage 758.0 (TID 1213) in 17 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:40.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:40.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 4.0 in stage 758.0 (TID 1215) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 3.0 in stage 758.0 (TID 1214) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:40.928+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:40.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 5.0 in stage 758.0 (TID 1216) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 4.0 in stage 758.0 (TID 1215) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:40.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:40.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 6.0 in stage 758.0 (TID 1217) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 5.0 in stage 758.0 (TID 1216) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:40.947+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:40.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 7.0 in stage 758.0 (TID 1218) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.951+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 6.0 in stage 758.0 (TID 1217) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:40.959+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:40.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 8.0 in stage 758.0 (TID 1219) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 7.0 in stage 758.0 (TID 1218) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:40.970+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:40.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Starting task 9.0 in stage 758.0 (TID 1220) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5328 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:40.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 8.0 in stage 758.0 (TID 1219) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:40.980+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManagerInfo: Added rdd_760_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.0 MiB)
[2025-05-08T19:40:40.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSetManager: Finished task 9.0 in stage 758.0 (TID 1220) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:40.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Removed TaskSet 758.0, whose tasks have all completed, from pool
[2025-05-08T19:40:40.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: ResultStage 758 (foreachPartition at PageRank.scala:199) finished in 0.152 s
[2025-05-08T19:40:40.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:40.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 758: Stage finished
[2025-05-08T19:40:40.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Job 57 finished: foreachPartition at PageRank.scala:199, took 0.399005 s
[2025-05-08T19:40:40.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO PageRank: PageRank finished iteration 11.
[2025-05-08T19:40:40.984+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO ZippedPartitionsRDD2: Removing RDD 742 from persistence list
[2025-05-08T19:40:40.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManager: Removing RDD 742
[2025-05-08T19:40:40.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO ZippedPartitionsRDD2: Removing RDD 748 from persistence list
[2025-05-08T19:40:40.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO BlockManager: Removing RDD 748
[2025-05-08T19:40:40.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:40.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Registering RDD 762 (mapPartitions at GraphImpl.scala:208) as input to shuffle 99
[2025-05-08T19:40:40.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Registering RDD 770 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 98
[2025-05-08T19:40:40.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Got job 58 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:40.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Final stage: ResultStage 798 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:40.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 793, ShuffleMapStage 785, ShuffleMapStage 779, ShuffleMapStage 771, ShuffleMapStage 787, ShuffleMapStage 766, ShuffleMapStage 773, ShuffleMapStage 795, ShuffleMapStage 789, ShuffleMapStage 781, ShuffleMapStage 775, ShuffleMapStage 797, ShuffleMapStage 783, ShuffleMapStage 791, ShuffleMapStage 770, ShuffleMapStage 777)
[2025-05-08T19:40:40.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 797)
[2025-05-08T19:40:40.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:40 INFO DAGScheduler: Submitting ShuffleMapStage 796 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[762] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:41.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 241.9 KiB, free 419.2 MiB)
[2025-05-08T19:40:41.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 419.1 MiB)
[2025-05-08T19:40:41.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 796 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[762] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 796.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 796.0 (TID 1221) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.010+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.20.0.5:37427 (size: 79.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 796.0 (TID 1222) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 796.0 (TID 1221) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 796.0 (TID 1223) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 796.0 (TID 1222) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.051+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 796.0 (TID 1224) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 796.0 (TID 1223) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 796.0 (TID 1225) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 796.0 (TID 1224) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 796.0 (TID 1226) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 796.0 (TID 1225) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 796.0 (TID 1227) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 796.0 (TID 1226) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 796.0 (TID 1228) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 796.0 (TID 1227) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 796.0 (TID 1229) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 796.0 (TID 1228) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 796.0 (TID 1230) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 796.0 (TID 1229) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 796.0 (TID 1230) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:41.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 796.0, whose tasks have all completed, from pool
[2025-05-08T19:40:41.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: ShuffleMapStage 796 (mapPartitions at GraphImpl.scala:208) finished in 0.143 s
[2025-05-08T19:40:41.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:41.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:41.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 797, ResultStage 798)
[2025-05-08T19:40:41.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:41.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting ShuffleMapStage 797 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[770] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:41.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 20.7 KiB, free 419.1 MiB)
[2025-05-08T19:40:41.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 419.1 MiB)
[2025-05-08T19:40:41.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on f2a432e4376a:35283 (size: 7.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 797 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[770] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 797.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 797.0 (TID 1231) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.149+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.20.0.5:37427 (size: 7.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 99 to 172.20.0.5:59376
[2025-05-08T19:40:41.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 797.0 (TID 1232) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 797.0 (TID 1231) in 11 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 797.0 (TID 1233) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 797.0 (TID 1232) in 7 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 797.0 (TID 1234) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 797.0 (TID 1233) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 797.0 (TID 1235) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 797.0 (TID 1234) in 7 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 797.0 (TID 1236) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 797.0 (TID 1235) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 797.0 (TID 1237) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 797.0 (TID 1236) in 7 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.198+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 797.0 (TID 1238) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.203+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 797.0 (TID 1237) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 797.0 (TID 1239) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 797.0 (TID 1238) in 7 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 797.0 (TID 1240) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 797.0 (TID 1239) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_766_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 797.0 (TID 1240) in 8 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:41.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 797.0, whose tasks have all completed, from pool
[2025-05-08T19:40:41.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: ShuffleMapStage 797 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.082 s
[2025-05-08T19:40:41.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:41.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:41.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: waiting: Set(ResultStage 798)
[2025-05-08T19:40:41.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:41.226+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting ResultStage 798 (EdgeRDDImpl[773] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:41.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 241.7 KiB, free 418.9 MiB)
[2025-05-08T19:40:41.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 418.8 MiB)
[2025-05-08T19:40:41.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 798 (EdgeRDDImpl[773] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 798.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 798.0 (TID 1241) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.238+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.20.0.5:37427 (size: 79.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:41.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 98 to 172.20.0.5:59376
[2025-05-08T19:40:41.246+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:41.247+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 798.0 (TID 1242) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.247+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 798.0 (TID 1241) in 14 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.259+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:41.261+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 798.0 (TID 1243) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.261+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 798.0 (TID 1242) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.270+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:41.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 798.0 (TID 1244) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 798.0 (TID 1243) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.279+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:41.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 798.0 (TID 1245) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 798.0 (TID 1244) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:41.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 798.0 (TID 1246) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 798.0 (TID 1245) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.1 MiB)
[2025-05-08T19:40:41.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 798.0 (TID 1247) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 798.0 (TID 1246) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.0 MiB)
[2025-05-08T19:40:41.311+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 798.0 (TID 1248) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.311+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 798.0 (TID 1247) in 10 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:41.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 798.0 (TID 1249) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 798.0 (TID 1248) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.9 MiB)
[2025-05-08T19:40:41.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 798.0 (TID 1250) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5369 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 798.0 (TID 1249) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_772_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.8 MiB)
[2025-05-08T19:40:41.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 798.0 (TID 1250) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:41.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 798.0, whose tasks have all completed, from pool
[2025-05-08T19:40:41.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: ResultStage 798 (foreachPartition at PageRank.scala:199) finished in 0.115 s
[2025-05-08T19:40:41.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:41.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 798: Stage finished
[2025-05-08T19:40:41.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Job 58 finished: foreachPartition at PageRank.scala:199, took 0.345480 s
[2025-05-08T19:40:41.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO PageRank: PageRank finished iteration 12.
[2025-05-08T19:40:41.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO ZippedPartitionsRDD2: Removing RDD 754 from persistence list
[2025-05-08T19:40:41.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManager: Removing RDD 754
[2025-05-08T19:40:41.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO ZippedPartitionsRDD2: Removing RDD 760 from persistence list
[2025-05-08T19:40:41.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManager: Removing RDD 760
[2025-05-08T19:40:41.351+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:41.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Registering RDD 774 (mapPartitions at GraphImpl.scala:208) as input to shuffle 101
[2025-05-08T19:40:41.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Registering RDD 782 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 100
[2025-05-08T19:40:41.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Got job 59 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:41.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Final stage: ResultStage 840 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:41.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 829, ShuffleMapStage 815, ShuffleMapStage 837, ShuffleMapStage 823, ShuffleMapStage 817, ShuffleMapStage 839, ShuffleMapStage 831, ShuffleMapStage 810, ShuffleMapStage 825, ShuffleMapStage 811, ShuffleMapStage 833, ShuffleMapStage 819, ShuffleMapStage 835, ShuffleMapStage 827, ShuffleMapStage 806, ShuffleMapStage 821, ShuffleMapStage 813)
[2025-05-08T19:40:41.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 839)
[2025-05-08T19:40:41.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting ShuffleMapStage 838 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[774] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:41.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 242.2 KiB, free 418.6 MiB)
[2025-05-08T19:40:41.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 418.5 MiB)
[2025-05-08T19:40:41.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.6 MiB)
[2025-05-08T19:40:41.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 838 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[774] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 838.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 838.0 (TID 1251) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.364+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.20.0.5:37427 (size: 79.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 838.0 (TID 1252) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 838.0 (TID 1251) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.394+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 838.0 (TID 1253) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.394+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 838.0 (TID 1252) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 838.0 (TID 1254) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 838.0 (TID 1253) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 838.0 (TID 1255) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 838.0 (TID 1254) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 838.0 (TID 1256) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 838.0 (TID 1255) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 838.0 (TID 1257) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 838.0 (TID 1256) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 838.0 (TID 1258) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 838.0 (TID 1257) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.475+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 838.0 (TID 1259) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.475+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 838.0 (TID 1258) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 838.0 (TID 1260) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 838.0 (TID 1259) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 838.0 (TID 1260) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 838.0, whose tasks have all completed, from pool
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: ShuffleMapStage 838 (mapPartitions at GraphImpl.scala:208) finished in 0.147 s
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: waiting: Set(ResultStage 840, ShuffleMapStage 839)
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:41.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting ShuffleMapStage 839 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[782] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:41.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 21.4 KiB, free 418.5 MiB)
[2025-05-08T19:40:41.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 418.4 MiB)
[2025-05-08T19:40:41.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_132_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on f2a432e4376a:35283 (size: 7.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 172.20.0.5:37427 in memory (size: 79.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 839 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[782] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 839.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 839.0 (TID 1261) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_130_piece0 on f2a432e4376a:35283 in memory (size: 7.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 172.20.0.5:37427 in memory (size: 7.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.517+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_134_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 172.20.0.5:37427 in memory (size: 79.3 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.20.0.5:37427 (size: 7.3 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_131_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:41.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.20.0.5:37427 in memory (size: 79.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:41.522+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_133_piece0 on f2a432e4376a:35283 in memory (size: 7.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:41.522+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 172.20.0.5:37427 in memory (size: 7.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:41.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 101 to 172.20.0.5:59376
[2025-05-08T19:40:41.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:41.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 839.0 (TID 1262) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 839.0 (TID 1261) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:41.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 839.0 (TID 1263) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.539+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 839.0 (TID 1262) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:41.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 839.0 (TID 1264) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 839.0 (TID 1263) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:41.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 839.0 (TID 1265) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 839.0 (TID 1264) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:41.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 839.0 (TID 1266) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 839.0 (TID 1265) in 20 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 839.0 (TID 1267) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 839.0 (TID 1266) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 839.0 (TID 1268) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 839.0 (TID 1267) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 839.0 (TID 1269) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 839.0 (TID 1268) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.610+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.613+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 839.0 (TID 1270) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.613+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 839.0 (TID 1269) in 9 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.619+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_778_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 839.0 (TID 1270) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:41.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 839.0, whose tasks have all completed, from pool
[2025-05-08T19:40:41.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: ShuffleMapStage 839 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.119 s
[2025-05-08T19:40:41.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:41.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:41.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: waiting: Set(ResultStage 840)
[2025-05-08T19:40:41.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:41.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting ResultStage 840 (EdgeRDDImpl[785] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:41.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 242.0 KiB, free 419.2 MiB)
[2025-05-08T19:40:41.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 419.1 MiB)
[2025-05-08T19:40:41.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 840 (EdgeRDDImpl[785] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 840.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 840.0 (TID 1271) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.20.0.5:37427 (size: 79.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.642+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 100 to 172.20.0.5:59376
[2025-05-08T19:40:41.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 840.0 (TID 1272) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 840.0 (TID 1271) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:41.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 840.0 (TID 1273) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 840.0 (TID 1272) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:41.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 840.0 (TID 1274) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 840.0 (TID 1273) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:41.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 840.0 (TID 1275) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 840.0 (TID 1274) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.2 MiB)
[2025-05-08T19:40:41.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 840.0 (TID 1276) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 840.0 (TID 1275) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.702+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:41.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 840.0 (TID 1277) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 840.0 (TID 1276) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.1 MiB)
[2025-05-08T19:40:41.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 840.0 (TID 1278) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 840.0 (TID 1277) in 15 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:41.728+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 840.0 (TID 1279) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 840.0 (TID 1278) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.737+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.0 MiB)
[2025-05-08T19:40:41.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 840.0 (TID 1280) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5410 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 840.0 (TID 1279) in 12 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_784_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.9 MiB)
[2025-05-08T19:40:41.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 840.0 (TID 1280) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:41.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 840.0, whose tasks have all completed, from pool
[2025-05-08T19:40:41.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: ResultStage 840 (foreachPartition at PageRank.scala:199) finished in 0.127 s
[2025-05-08T19:40:41.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:41.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 840: Stage finished
[2025-05-08T19:40:41.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Job 59 finished: foreachPartition at PageRank.scala:199, took 0.399441 s
[2025-05-08T19:40:41.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO PageRank: PageRank finished iteration 13.
[2025-05-08T19:40:41.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO ZippedPartitionsRDD2: Removing RDD 766 from persistence list
[2025-05-08T19:40:41.752+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManager: Removing RDD 766
[2025-05-08T19:40:41.752+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO ZippedPartitionsRDD2: Removing RDD 772 from persistence list
[2025-05-08T19:40:41.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManager: Removing RDD 772
[2025-05-08T19:40:41.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:41.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Registering RDD 786 (mapPartitions at GraphImpl.scala:208) as input to shuffle 103
[2025-05-08T19:40:41.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Registering RDD 794 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 102
[2025-05-08T19:40:41.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Got job 60 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:41.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Final stage: ResultStage 884 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:41.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 879, ShuffleMapStage 865, ShuffleMapStage 881, ShuffleMapStage 873, ShuffleMapStage 852, ShuffleMapStage 867, ShuffleMapStage 859, ShuffleMapStage 853, ShuffleMapStage 875, ShuffleMapStage 861, ShuffleMapStage 883, ShuffleMapStage 877, ShuffleMapStage 869, ShuffleMapStage 848, ShuffleMapStage 863, ShuffleMapStage 855, ShuffleMapStage 871, ShuffleMapStage 857)
[2025-05-08T19:40:41.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 883)
[2025-05-08T19:40:41.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting ShuffleMapStage 882 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[786] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:41.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 242.5 KiB, free 418.9 MiB)
[2025-05-08T19:40:41.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 79.7 KiB, free 418.8 MiB)
[2025-05-08T19:40:41.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on f2a432e4376a:35283 (size: 79.7 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 882 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[786] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 882.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 882.0 (TID 1281) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.20.0.5:37427 (size: 79.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 882.0 (TID 1282) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 882.0 (TID 1281) in 17 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 882.0 (TID 1283) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 882.0 (TID 1282) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 882.0 (TID 1284) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 882.0 (TID 1283) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 882.0 (TID 1285) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 882.0 (TID 1284) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.846+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 882.0 (TID 1286) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.846+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 882.0 (TID 1285) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 882.0 (TID 1287) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 882.0 (TID 1286) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 882.0 (TID 1288) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 882.0 (TID 1287) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 882.0 (TID 1289) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.886+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 882.0 (TID 1288) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 882.0 (TID 1290) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 882.0 (TID 1289) in 14 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 882.0 (TID 1290) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 882.0, whose tasks have all completed, from pool
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: ShuffleMapStage 882 (mapPartitions at GraphImpl.scala:208) finished in 0.146 s
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 883, ResultStage 884)
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:41.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting ShuffleMapStage 883 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[794] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:41.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 22.1 KiB, free 418.8 MiB)
[2025-05-08T19:40:41.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 418.8 MiB)
[2025-05-08T19:40:41.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on f2a432e4376a:35283 (size: 7.5 KiB, free: 432.7 MiB)
[2025-05-08T19:40:41.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:41.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 883 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[794] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:41.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Adding task set 883.0 with 10 tasks resource profile 0
[2025-05-08T19:40:41.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 0.0 in stage 883.0 (TID 1291) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 172.20.0.5:37427 (size: 7.5 KiB, free: 418.6 MiB)
[2025-05-08T19:40:41.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 103 to 172.20.0.5:59376
[2025-05-08T19:40:41.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 1.0 in stage 883.0 (TID 1292) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.928+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 0.0 in stage 883.0 (TID 1291) in 13 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:41.933+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 2.0 in stage 883.0 (TID 1293) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.937+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 1.0 in stage 883.0 (TID 1292) in 9 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:41.941+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.943+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 3.0 in stage 883.0 (TID 1294) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.943+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 2.0 in stage 883.0 (TID 1293) in 7 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:41.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 4.0 in stage 883.0 (TID 1295) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 3.0 in stage 883.0 (TID 1294) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:41.959+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 5.0 in stage 883.0 (TID 1296) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 4.0 in stage 883.0 (TID 1295) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:41.968+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 6.0 in stage 883.0 (TID 1297) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 5.0 in stage 883.0 (TID 1296) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:41.976+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.979+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 7.0 in stage 883.0 (TID 1298) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.979+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 6.0 in stage 883.0 (TID 1297) in 7 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:41.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:41.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 8.0 in stage 883.0 (TID 1299) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.987+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 7.0 in stage 883.0 (TID 1298) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:41.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.4 MiB)
[2025-05-08T19:40:41.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Starting task 9.0 in stage 883.0 (TID 1300) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:41.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 8.0 in stage 883.0 (TID 1299) in 7 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:41.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO BlockManagerInfo: Added rdd_790_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.4 MiB)
[2025-05-08T19:40:41.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSetManager: Finished task 9.0 in stage 883.0 (TID 1300) in 6 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:41 INFO TaskSchedulerImpl: Removed TaskSet 883.0, whose tasks have all completed, from pool
[2025-05-08T19:40:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: ShuffleMapStage 883 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.087 s
[2025-05-08T19:40:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: waiting: Set(ResultStage 884)
[2025-05-08T19:40:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting ResultStage 884 (EdgeRDDImpl[797] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:42.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 242.3 KiB, free 418.5 MiB)
[2025-05-08T19:40:42.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 79.7 KiB, free 418.5 MiB)
[2025-05-08T19:40:42.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on f2a432e4376a:35283 (size: 79.7 KiB, free: 432.6 MiB)
[2025-05-08T19:40:42.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:42.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 884 (EdgeRDDImpl[797] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:42.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Adding task set 884.0 with 10 tasks resource profile 0
[2025-05-08T19:40:42.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 0.0 in stage 884.0 (TID 1301) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.011+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 172.20.0.5:37427 (size: 79.7 KiB, free: 418.3 MiB)
[2025-05-08T19:40:42.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 102 to 172.20.0.5:59376
[2025-05-08T19:40:42.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_136_piece0 on f2a432e4376a:35283 in memory (size: 7.3 KiB, free: 432.6 MiB)
[2025-05-08T19:40:42.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 172.20.0.5:37427 in memory (size: 7.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:42.032+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:42.033+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_139_piece0 on f2a432e4376a:35283 in memory (size: 7.5 KiB, free: 432.6 MiB)
[2025-05-08T19:40:42.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 172.20.0.5:37427 in memory (size: 7.5 KiB, free: 418.3 MiB)
[2025-05-08T19:40:42.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 1.0 in stage 884.0 (TID 1302) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_135_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:42.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 172.20.0.5:37427 in memory (size: 79.6 KiB, free: 418.4 MiB)
[2025-05-08T19:40:42.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 0.0 in stage 884.0 (TID 1301) in 30 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:42.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_138_piece0 on f2a432e4376a:35283 in memory (size: 79.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:42.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 172.20.0.5:37427 in memory (size: 79.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.040+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_137_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:42.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 172.20.0.5:37427 in memory (size: 79.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.049+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.050+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 2.0 in stage 884.0 (TID 1303) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.051+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 1.0 in stage 884.0 (TID 1302) in 15 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:42.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:42.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 3.0 in stage 884.0 (TID 1304) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 2.0 in stage 884.0 (TID 1303) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:42.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.4 MiB)
[2025-05-08T19:40:42.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 4.0 in stage 884.0 (TID 1305) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 3.0 in stage 884.0 (TID 1304) in 20 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:42.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:42.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 5.0 in stage 884.0 (TID 1306) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 4.0 in stage 884.0 (TID 1305) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:42.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:42.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 6.0 in stage 884.0 (TID 1307) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 5.0 in stage 884.0 (TID 1306) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:42.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:42.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 7.0 in stage 884.0 (TID 1308) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 6.0 in stage 884.0 (TID 1307) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:42.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:42.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 8.0 in stage 884.0 (TID 1309) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 7.0 in stage 884.0 (TID 1308) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:42.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:42.132+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 9.0 in stage 884.0 (TID 1310) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5451 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 8.0 in stage 884.0 (TID 1309) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:42.141+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_796_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.0 MiB)
[2025-05-08T19:40:42.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 9.0 in stage 884.0 (TID 1310) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:42.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Removed TaskSet 884.0, whose tasks have all completed, from pool
[2025-05-08T19:40:42.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: ResultStage 884 (foreachPartition at PageRank.scala:199) finished in 0.143 s
[2025-05-08T19:40:42.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:42.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 884: Stage finished
[2025-05-08T19:40:42.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Job 60 finished: foreachPartition at PageRank.scala:199, took 0.382637 s
[2025-05-08T19:40:42.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO PageRank: PageRank finished iteration 14.
[2025-05-08T19:40:42.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO ZippedPartitionsRDD2: Removing RDD 778 from persistence list
[2025-05-08T19:40:42.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManager: Removing RDD 778
[2025-05-08T19:40:42.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO ZippedPartitionsRDD2: Removing RDD 784 from persistence list
[2025-05-08T19:40:42.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManager: Removing RDD 784
[2025-05-08T19:40:42.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:42.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Registering RDD 798 (mapPartitions at GraphImpl.scala:208) as input to shuffle 105
[2025-05-08T19:40:42.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Registering RDD 806 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 104
[2025-05-08T19:40:42.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Got job 61 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:42.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Final stage: ResultStage 930 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:42.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 915, ShuffleMapStage 909, ShuffleMapStage 901, ShuffleMapStage 917, ShuffleMapStage 903, ShuffleMapStage 925, ShuffleMapStage 896, ShuffleMapStage 911, ShuffleMapStage 897, ShuffleMapStage 927, ShuffleMapStage 919, ShuffleMapStage 913, ShuffleMapStage 905, ShuffleMapStage 899, ShuffleMapStage 921, ShuffleMapStage 892, ShuffleMapStage 907, ShuffleMapStage 929, ShuffleMapStage 923)
[2025-05-08T19:40:42.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 929)
[2025-05-08T19:40:42.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting ShuffleMapStage 928 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[798] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:42.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 242.8 KiB, free 419.2 MiB)
[2025-05-08T19:40:42.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 419.2 MiB)
[2025-05-08T19:40:42.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.8 MiB)
[2025-05-08T19:40:42.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:42.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 928 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[798] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:42.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Adding task set 928.0 with 10 tasks resource profile 0
[2025-05-08T19:40:42.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 0.0 in stage 928.0 (TID 1311) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 172.20.0.5:37427 (size: 79.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 1.0 in stage 928.0 (TID 1312) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 0.0 in stage 928.0 (TID 1311) in 18 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:42.195+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 2.0 in stage 928.0 (TID 1313) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.196+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 1.0 in stage 928.0 (TID 1312) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:42.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 3.0 in stage 928.0 (TID 1314) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 2.0 in stage 928.0 (TID 1313) in 14 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:42.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 4.0 in stage 928.0 (TID 1315) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 3.0 in stage 928.0 (TID 1314) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:42.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 5.0 in stage 928.0 (TID 1316) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 4.0 in stage 928.0 (TID 1315) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:42.263+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 6.0 in stage 928.0 (TID 1317) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.264+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 5.0 in stage 928.0 (TID 1316) in 23 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:42.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 7.0 in stage 928.0 (TID 1318) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.279+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 6.0 in stage 928.0 (TID 1317) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:42.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 8.0 in stage 928.0 (TID 1319) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 7.0 in stage 928.0 (TID 1318) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:42.313+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 9.0 in stage 928.0 (TID 1320) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 8.0 in stage 928.0 (TID 1319) in 18 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:42.331+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 9.0 in stage 928.0 (TID 1320) in 18 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:42.331+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Removed TaskSet 928.0, whose tasks have all completed, from pool
[2025-05-08T19:40:42.331+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: ShuffleMapStage 928 (mapPartitions at GraphImpl.scala:208) finished in 0.174 s
[2025-05-08T19:40:42.331+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:42.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:42.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: waiting: Set(ResultStage 930, ShuffleMapStage 929)
[2025-05-08T19:40:42.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:42.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting ShuffleMapStage 929 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[806] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:42.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 22.8 KiB, free 419.1 MiB)
[2025-05-08T19:40:42.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 419.1 MiB)
[2025-05-08T19:40:42.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on f2a432e4376a:35283 (size: 7.4 KiB, free: 432.7 MiB)
[2025-05-08T19:40:42.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:42.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 929 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[806] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:42.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Adding task set 929.0 with 10 tasks resource profile 0
[2025-05-08T19:40:42.337+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 0.0 in stage 929.0 (TID 1321) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 172.20.0.5:37427 (size: 7.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.344+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 105 to 172.20.0.5:59376
[2025-05-08T19:40:42.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.351+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 1.0 in stage 929.0 (TID 1322) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.352+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 0.0 in stage 929.0 (TID 1321) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:42.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.363+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 2.0 in stage 929.0 (TID 1323) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.363+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 1.0 in stage 929.0 (TID 1322) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:42.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.375+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 3.0 in stage 929.0 (TID 1324) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.375+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 2.0 in stage 929.0 (TID 1323) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:42.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 4.0 in stage 929.0 (TID 1325) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.389+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 3.0 in stage 929.0 (TID 1324) in 15 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:42.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 5.0 in stage 929.0 (TID 1326) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 4.0 in stage 929.0 (TID 1325) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:42.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 6.0 in stage 929.0 (TID 1327) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 5.0 in stage 929.0 (TID 1326) in 13 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:42.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 7.0 in stage 929.0 (TID 1328) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 6.0 in stage 929.0 (TID 1327) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:42.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 8.0 in stage 929.0 (TID 1329) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 7.0 in stage 929.0 (TID 1328) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:42.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 9.0 in stage 929.0 (TID 1330) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 8.0 in stage 929.0 (TID 1329) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:42.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_802_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 9.0 in stage 929.0 (TID 1330) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:42.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Removed TaskSet 929.0, whose tasks have all completed, from pool
[2025-05-08T19:40:42.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: ShuffleMapStage 929 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.127 s
[2025-05-08T19:40:42.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:42.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:42.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: waiting: Set(ResultStage 930)
[2025-05-08T19:40:42.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:42.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting ResultStage 930 (EdgeRDDImpl[809] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:42.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 242.6 KiB, free 418.9 MiB)
[2025-05-08T19:40:42.479+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 79.5 KiB, free 418.8 MiB)
[2025-05-08T19:40:42.480+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on f2a432e4376a:35283 (size: 79.5 KiB, free: 432.7 MiB)
[2025-05-08T19:40:42.482+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:42.483+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 930 (EdgeRDDImpl[809] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:42.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Adding task set 930.0 with 10 tasks resource profile 0
[2025-05-08T19:40:42.485+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 0.0 in stage 930.0 (TID 1331) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 172.20.0.5:37427 (size: 79.5 KiB, free: 418.4 MiB)
[2025-05-08T19:40:42.510+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 104 to 172.20.0.5:59376
[2025-05-08T19:40:42.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:42.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 1.0 in stage 930.0 (TID 1332) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 0.0 in stage 930.0 (TID 1331) in 38 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:42.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:42.531+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 2.0 in stage 930.0 (TID 1333) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 1.0 in stage 930.0 (TID 1332) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:42.542+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:42.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 3.0 in stage 930.0 (TID 1334) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 2.0 in stage 930.0 (TID 1333) in 13 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:42.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:42.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 4.0 in stage 930.0 (TID 1335) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 3.0 in stage 930.0 (TID 1334) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:42.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:42.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 5.0 in stage 930.0 (TID 1336) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 4.0 in stage 930.0 (TID 1335) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:42.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.1 MiB)
[2025-05-08T19:40:42.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 6.0 in stage 930.0 (TID 1337) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 5.0 in stage 930.0 (TID 1336) in 12 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:42.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.0 MiB)
[2025-05-08T19:40:42.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 7.0 in stage 930.0 (TID 1338) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 6.0 in stage 930.0 (TID 1337) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:42.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:42.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 8.0 in stage 930.0 (TID 1339) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 7.0 in stage 930.0 (TID 1338) in 14 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:42.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.9 MiB)
[2025-05-08T19:40:42.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 9.0 in stage 930.0 (TID 1340) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5492 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 8.0 in stage 930.0 (TID 1339) in 18 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:42.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_808_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.8 MiB)
[2025-05-08T19:40:42.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 9.0 in stage 930.0 (TID 1340) in 15 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:42.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Removed TaskSet 930.0, whose tasks have all completed, from pool
[2025-05-08T19:40:42.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: ResultStage 930 (foreachPartition at PageRank.scala:199) finished in 0.172 s
[2025-05-08T19:40:42.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:42.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 930: Stage finished
[2025-05-08T19:40:42.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Job 61 finished: foreachPartition at PageRank.scala:199, took 0.485370 s
[2025-05-08T19:40:42.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO PageRank: PageRank finished iteration 15.
[2025-05-08T19:40:42.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO ZippedPartitionsRDD2: Removing RDD 790 from persistence list
[2025-05-08T19:40:42.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManager: Removing RDD 790
[2025-05-08T19:40:42.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO ZippedPartitionsRDD2: Removing RDD 796 from persistence list
[2025-05-08T19:40:42.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManager: Removing RDD 796
[2025-05-08T19:40:42.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:42.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Registering RDD 810 (mapPartitions at GraphImpl.scala:208) as input to shuffle 107
[2025-05-08T19:40:42.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Registering RDD 818 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 106
[2025-05-08T19:40:42.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Got job 62 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:42.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Final stage: ResultStage 978 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:42.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 951, ShuffleMapStage 945, ShuffleMapStage 967, ShuffleMapStage 938, ShuffleMapStage 953, ShuffleMapStage 975, ShuffleMapStage 969, ShuffleMapStage 961, ShuffleMapStage 955, ShuffleMapStage 947, ShuffleMapStage 977, ShuffleMapStage 963, ShuffleMapStage 949, ShuffleMapStage 971, ShuffleMapStage 942, ShuffleMapStage 957, ShuffleMapStage 943, ShuffleMapStage 973, ShuffleMapStage 965, ShuffleMapStage 959)
[2025-05-08T19:40:42.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 977)
[2025-05-08T19:40:42.666+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting ShuffleMapStage 976 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[810] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:42.675+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 243.1 KiB, free 418.6 MiB)
[2025-05-08T19:40:42.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 80.0 KiB, free 418.5 MiB)
[2025-05-08T19:40:42.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on f2a432e4376a:35283 (size: 80.0 KiB, free: 432.6 MiB)
[2025-05-08T19:40:42.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:42.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 976 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[810] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:42.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Adding task set 976.0 with 10 tasks resource profile 0
[2025-05-08T19:40:42.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 0.0 in stage 976.0 (TID 1341) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 172.20.0.5:37427 (size: 80.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.697+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 1.0 in stage 976.0 (TID 1342) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 0.0 in stage 976.0 (TID 1341) in 21 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:42.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 2.0 in stage 976.0 (TID 1343) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 1.0 in stage 976.0 (TID 1342) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:42.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 3.0 in stage 976.0 (TID 1344) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 2.0 in stage 976.0 (TID 1343) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:42.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 4.0 in stage 976.0 (TID 1345) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 3.0 in stage 976.0 (TID 1344) in 28 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:42.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 5.0 in stage 976.0 (TID 1346) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 4.0 in stage 976.0 (TID 1345) in 16 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:42.785+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 6.0 in stage 976.0 (TID 1347) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 5.0 in stage 976.0 (TID 1346) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:42.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 7.0 in stage 976.0 (TID 1348) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 6.0 in stage 976.0 (TID 1347) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:42.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 8.0 in stage 976.0 (TID 1349) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 7.0 in stage 976.0 (TID 1348) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:42.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 9.0 in stage 976.0 (TID 1350) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 8.0 in stage 976.0 (TID 1349) in 16 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:42.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 9.0 in stage 976.0 (TID 1350) in 23 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:42.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Removed TaskSet 976.0, whose tasks have all completed, from pool
[2025-05-08T19:40:42.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: ShuffleMapStage 976 (mapPartitions at GraphImpl.scala:208) finished in 0.186 s
[2025-05-08T19:40:42.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:42.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:42.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: waiting: Set(ResultStage 978, ShuffleMapStage 977)
[2025-05-08T19:40:42.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:42.853+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting ShuffleMapStage 977 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[818] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:42.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 23.5 KiB, free 418.5 MiB)
[2025-05-08T19:40:42.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 418.5 MiB)
[2025-05-08T19:40:42.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on f2a432e4376a:35283 (size: 7.5 KiB, free: 432.6 MiB)
[2025-05-08T19:40:42.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:42.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 977 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[818] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:42.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSchedulerImpl: Adding task set 977.0 with 10 tasks resource profile 0
[2025-05-08T19:40:42.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 0.0 in stage 977.0 (TID 1351) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 172.20.0.5:37427 (size: 7.5 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 107 to 172.20.0.5:59376
[2025-05-08T19:40:42.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_140_piece0 on f2a432e4376a:35283 in memory (size: 79.7 KiB, free: 432.7 MiB)
[2025-05-08T19:40:42.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 172.20.0.5:37427 in memory (size: 79.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_144_piece0 on f2a432e4376a:35283 in memory (size: 80.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:42.888+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:42.888+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 172.20.0.5:37427 in memory (size: 80.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:42.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_141_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.8 MiB)
[2025-05-08T19:40:42.890+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 172.20.0.5:37427 in memory (size: 79.6 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_142_piece0 on f2a432e4376a:35283 in memory (size: 7.4 KiB, free: 432.8 MiB)
[2025-05-08T19:40:42.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 1.0 in stage 977.0 (TID 1352) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 0.0 in stage 977.0 (TID 1351) in 36 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:42.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 172.20.0.5:37427 in memory (size: 7.4 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_143_piece0 on f2a432e4376a:35283 in memory (size: 79.5 KiB, free: 432.9 MiB)
[2025-05-08T19:40:42.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 172.20.0.5:37427 in memory (size: 79.5 KiB, free: 418.8 MiB)
[2025-05-08T19:40:42.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.8 MiB)
[2025-05-08T19:40:42.903+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 2.0 in stage 977.0 (TID 1353) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 1.0 in stage 977.0 (TID 1352) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:42.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.8 MiB)
[2025-05-08T19:40:42.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 3.0 in stage 977.0 (TID 1354) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 2.0 in stage 977.0 (TID 1353) in 8 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:42.918+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 4.0 in stage 977.0 (TID 1355) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 3.0 in stage 977.0 (TID 1354) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:42.928+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 5.0 in stage 977.0 (TID 1356) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 4.0 in stage 977.0 (TID 1355) in 10 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:42.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 6.0 in stage 977.0 (TID 1357) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 5.0 in stage 977.0 (TID 1356) in 29 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:42.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.971+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 7.0 in stage 977.0 (TID 1358) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.971+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 6.0 in stage 977.0 (TID 1357) in 12 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:42.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.980+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 8.0 in stage 977.0 (TID 1359) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 7.0 in stage 977.0 (TID 1358) in 10 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:42.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO BlockManagerInfo: Added rdd_814_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:42.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Starting task 9.0 in stage 977.0 (TID 1360) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:42.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:42 INFO TaskSetManager: Finished task 8.0 in stage 977.0 (TID 1359) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:43.003+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_814_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:43.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 9.0 in stage 977.0 (TID 1360) in 13 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:43.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSchedulerImpl: Removed TaskSet 977.0, whose tasks have all completed, from pool
[2025-05-08T19:40:43.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: ShuffleMapStage 977 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.155 s
[2025-05-08T19:40:43.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:43.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:43.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: waiting: Set(ResultStage 978)
[2025-05-08T19:40:43.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:43.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Submitting ResultStage 978 (EdgeRDDImpl[821] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:43.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 242.9 KiB, free 419.5 MiB)
[2025-05-08T19:40:43.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 80.0 KiB, free 419.4 MiB)
[2025-05-08T19:40:43.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on f2a432e4376a:35283 (size: 80.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:43.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:43.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 978 (EdgeRDDImpl[821] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:43.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSchedulerImpl: Adding task set 978.0 with 10 tasks resource profile 0
[2025-05-08T19:40:43.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 0.0 in stage 978.0 (TID 1361) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 172.20.0.5:37427 (size: 80.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:43.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 106 to 172.20.0.5:59376
[2025-05-08T19:40:43.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:43.315+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 1.0 in stage 978.0 (TID 1362) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.315+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 0.0 in stage 978.0 (TID 1361) in 253 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:43.328+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:43.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 2.0 in stage 978.0 (TID 1363) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 1.0 in stage 978.0 (TID 1362) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:43.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:43.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 3.0 in stage 978.0 (TID 1364) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 2.0 in stage 978.0 (TID 1363) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:43.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:43.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 4.0 in stage 978.0 (TID 1365) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 3.0 in stage 978.0 (TID 1364) in 8 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:43.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:43.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 5.0 in stage 978.0 (TID 1366) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 4.0 in stage 978.0 (TID 1365) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:43.363+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:43.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 6.0 in stage 978.0 (TID 1367) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 5.0 in stage 978.0 (TID 1366) in 9 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:43.371+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:43.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 7.0 in stage 978.0 (TID 1368) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 6.0 in stage 978.0 (TID 1367) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:43.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:43.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 8.0 in stage 978.0 (TID 1369) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 7.0 in stage 978.0 (TID 1368) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:43.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:43.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 9.0 in stage 978.0 (TID 1370) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5533 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 8.0 in stage 978.0 (TID 1369) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:43.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_820_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.0 MiB)
[2025-05-08T19:40:43.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 9.0 in stage 978.0 (TID 1370) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:43.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSchedulerImpl: Removed TaskSet 978.0, whose tasks have all completed, from pool
[2025-05-08T19:40:43.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: ResultStage 978 (foreachPartition at PageRank.scala:199) finished in 0.398 s
[2025-05-08T19:40:43.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:43.419+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 978: Stage finished
[2025-05-08T19:40:43.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Job 62 finished: foreachPartition at PageRank.scala:199, took 0.763300 s
[2025-05-08T19:40:43.424+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO PageRank: PageRank finished iteration 16.
[2025-05-08T19:40:43.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO ZippedPartitionsRDD2: Removing RDD 802 from persistence list
[2025-05-08T19:40:43.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManager: Removing RDD 802
[2025-05-08T19:40:43.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO ZippedPartitionsRDD2: Removing RDD 808 from persistence list
[2025-05-08T19:40:43.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManager: Removing RDD 808
[2025-05-08T19:40:43.583+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:43.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Registering RDD 822 (mapPartitions at GraphImpl.scala:208) as input to shuffle 109
[2025-05-08T19:40:43.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Registering RDD 830 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 108
[2025-05-08T19:40:43.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Got job 63 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:43.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Final stage: ResultStage 1028 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:43.588+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1017, ShuffleMapStage 1003, ShuffleMapStage 997, ShuffleMapStage 1025, ShuffleMapStage 1019, ShuffleMapStage 1011, ShuffleMapStage 990, ShuffleMapStage 1005, ShuffleMapStage 991, ShuffleMapStage 1027, ShuffleMapStage 1013, ShuffleMapStage 999, ShuffleMapStage 1021, ShuffleMapStage 1015, ShuffleMapStage 1007, ShuffleMapStage 986, ShuffleMapStage 1001, ShuffleMapStage 993, ShuffleMapStage 1023, ShuffleMapStage 1009, ShuffleMapStage 995)
[2025-05-08T19:40:43.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1027)
[2025-05-08T19:40:43.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Submitting ShuffleMapStage 1026 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[822] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:43.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 243.4 KiB, free 419.2 MiB)
[2025-05-08T19:40:43.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 80.0 KiB, free 419.1 MiB)
[2025-05-08T19:40:43.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on f2a432e4376a:35283 (size: 80.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:43.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:43.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1026 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[822] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:43.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSchedulerImpl: Adding task set 1026.0 with 10 tasks resource profile 0
[2025-05-08T19:40:43.692+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 0.0 in stage 1026.0 (TID 1371) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 172.20.0.5:37427 (size: 80.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:43.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 1.0 in stage 1026.0 (TID 1372) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 0.0 in stage 1026.0 (TID 1371) in 129 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:43.832+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 2.0 in stage 1026.0 (TID 1373) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 1.0 in stage 1026.0 (TID 1372) in 16 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:43.846+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 3.0 in stage 1026.0 (TID 1374) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.847+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 2.0 in stage 1026.0 (TID 1373) in 15 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:43.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 4.0 in stage 1026.0 (TID 1375) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 3.0 in stage 1026.0 (TID 1374) in 14 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:43.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 5.0 in stage 1026.0 (TID 1376) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 4.0 in stage 1026.0 (TID 1375) in 12 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:43.893+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 6.0 in stage 1026.0 (TID 1377) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.893+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 5.0 in stage 1026.0 (TID 1376) in 22 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:43.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 7.0 in stage 1026.0 (TID 1378) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 6.0 in stage 1026.0 (TID 1377) in 14 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:43.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 8.0 in stage 1026.0 (TID 1379) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.922+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 7.0 in stage 1026.0 (TID 1378) in 15 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:43.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 9.0 in stage 1026.0 (TID 1380) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 8.0 in stage 1026.0 (TID 1379) in 13 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:43.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 9.0 in stage 1026.0 (TID 1380) in 14 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:43.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSchedulerImpl: Removed TaskSet 1026.0, whose tasks have all completed, from pool
[2025-05-08T19:40:43.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: ShuffleMapStage 1026 (mapPartitions at GraphImpl.scala:208) finished in 0.358 s
[2025-05-08T19:40:43.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:43.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:43.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1027, ResultStage 1028)
[2025-05-08T19:40:43.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:43.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Submitting ShuffleMapStage 1027 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[830] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:43.953+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 24.3 KiB, free 419.1 MiB)
[2025-05-08T19:40:43.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 419.1 MiB)
[2025-05-08T19:40:43.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on f2a432e4376a:35283 (size: 7.6 KiB, free: 432.7 MiB)
[2025-05-08T19:40:43.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:43.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1027 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[830] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:43.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSchedulerImpl: Adding task set 1027.0 with 10 tasks resource profile 0
[2025-05-08T19:40:43.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 0.0 in stage 1027.0 (TID 1381) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 172.20.0.5:37427 (size: 7.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:43.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 109 to 172.20.0.5:59376
[2025-05-08T19:40:43.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_826_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:43.987+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 1.0 in stage 1027.0 (TID 1382) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 0.0 in stage 1027.0 (TID 1381) in 32 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:43.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO BlockManagerInfo: Added rdd_826_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:43.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Starting task 2.0 in stage 1027.0 (TID 1383) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:43.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:43 INFO TaskSetManager: Finished task 1.0 in stage 1027.0 (TID 1382) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:44.003+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 3.0 in stage 1027.0 (TID 1384) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 2.0 in stage 1027.0 (TID 1383) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:44.012+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 4.0 in stage 1027.0 (TID 1385) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 3.0 in stage 1027.0 (TID 1384) in 10 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:44.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 5.0 in stage 1027.0 (TID 1386) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 4.0 in stage 1027.0 (TID 1385) in 9 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:44.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.049+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 6.0 in stage 1027.0 (TID 1387) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.049+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 5.0 in stage 1027.0 (TID 1386) in 25 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:44.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:44.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 7.0 in stage 1027.0 (TID 1388) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 6.0 in stage 1027.0 (TID 1387) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:44.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.5 MiB)
[2025-05-08T19:40:44.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 8.0 in stage 1027.0 (TID 1389) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 7.0 in stage 1027.0 (TID 1388) in 8 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:44.068+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.5 MiB)
[2025-05-08T19:40:44.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 9.0 in stage 1027.0 (TID 1390) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 8.0 in stage 1027.0 (TID 1389) in 6 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:44.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_826_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.5 MiB)
[2025-05-08T19:40:44.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 9.0 in stage 1027.0 (TID 1390) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:44.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Removed TaskSet 1027.0, whose tasks have all completed, from pool
[2025-05-08T19:40:44.092+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: ShuffleMapStage 1027 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.137 s
[2025-05-08T19:40:44.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:44.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:44.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: waiting: Set(ResultStage 1028)
[2025-05-08T19:40:44.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:44.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting ResultStage 1028 (EdgeRDDImpl[833] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:44.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 243.2 KiB, free 418.9 MiB)
[2025-05-08T19:40:44.119+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 79.9 KiB, free 418.8 MiB)
[2025-05-08T19:40:44.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on f2a432e4376a:35283 (size: 79.9 KiB, free: 432.7 MiB)
[2025-05-08T19:40:44.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:44.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1028 (EdgeRDDImpl[833] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:44.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Adding task set 1028.0 with 10 tasks resource profile 0
[2025-05-08T19:40:44.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 0.0 in stage 1028.0 (TID 1391) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 172.20.0.5:37427 (size: 79.9 KiB, free: 418.4 MiB)
[2025-05-08T19:40:44.137+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 108 to 172.20.0.5:59376
[2025-05-08T19:40:44.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.4 MiB)
[2025-05-08T19:40:44.141+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 1.0 in stage 1028.0 (TID 1392) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 0.0 in stage 1028.0 (TID 1391) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:44.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:44.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 2.0 in stage 1028.0 (TID 1393) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 1.0 in stage 1028.0 (TID 1392) in 12 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:44.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:44.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 3.0 in stage 1028.0 (TID 1394) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 2.0 in stage 1028.0 (TID 1393) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:44.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.2 MiB)
[2025-05-08T19:40:44.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 4.0 in stage 1028.0 (TID 1395) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 3.0 in stage 1028.0 (TID 1394) in 11 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:44.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:44.184+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 5.0 in stage 1028.0 (TID 1396) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.184+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 4.0 in stage 1028.0 (TID 1395) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:44.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.1 MiB)
[2025-05-08T19:40:44.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 6.0 in stage 1028.0 (TID 1397) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 5.0 in stage 1028.0 (TID 1396) in 10 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:44.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.0 MiB)
[2025-05-08T19:40:44.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 7.0 in stage 1028.0 (TID 1398) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 6.0 in stage 1028.0 (TID 1397) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:44.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:44.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 8.0 in stage 1028.0 (TID 1399) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 7.0 in stage 1028.0 (TID 1398) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:44.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 417.9 MiB)
[2025-05-08T19:40:44.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 9.0 in stage 1028.0 (TID 1400) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5574 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 8.0 in stage 1028.0 (TID 1399) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:44.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_832_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.8 MiB)
[2025-05-08T19:40:44.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 9.0 in stage 1028.0 (TID 1400) in 10 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:44.234+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Removed TaskSet 1028.0, whose tasks have all completed, from pool
[2025-05-08T19:40:44.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: ResultStage 1028 (foreachPartition at PageRank.scala:199) finished in 0.138 s
[2025-05-08T19:40:44.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:44.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 1028: Stage finished
[2025-05-08T19:40:44.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Job 63 finished: foreachPartition at PageRank.scala:199, took 0.652502 s
[2025-05-08T19:40:44.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO PageRank: PageRank finished iteration 17.
[2025-05-08T19:40:44.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO ZippedPartitionsRDD2: Removing RDD 814 from persistence list
[2025-05-08T19:40:44.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManager: Removing RDD 814
[2025-05-08T19:40:44.242+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO ZippedPartitionsRDD2: Removing RDD 820 from persistence list
[2025-05-08T19:40:44.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManager: Removing RDD 820
[2025-05-08T19:40:44.279+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:44.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Registering RDD 834 (mapPartitions at GraphImpl.scala:208) as input to shuffle 111
[2025-05-08T19:40:44.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Registering RDD 842 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 110
[2025-05-08T19:40:44.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Got job 64 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:44.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Final stage: ResultStage 1080 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:44.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1053, ShuffleMapStage 1047, ShuffleMapStage 1069, ShuffleMapStage 1040, ShuffleMapStage 1055, ShuffleMapStage 1041, ShuffleMapStage 1077, ShuffleMapStage 1063, ShuffleMapStage 1057, ShuffleMapStage 1049, ShuffleMapStage 1043, ShuffleMapStage 1079, ShuffleMapStage 1071, ShuffleMapStage 1065, ShuffleMapStage 1036, ShuffleMapStage 1051, ShuffleMapStage 1073, ShuffleMapStage 1059, ShuffleMapStage 1045, ShuffleMapStage 1075, ShuffleMapStage 1067, ShuffleMapStage 1061)
[2025-05-08T19:40:44.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1079)
[2025-05-08T19:40:44.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting ShuffleMapStage 1078 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[834] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:44.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 243.7 KiB, free 418.5 MiB)
[2025-05-08T19:40:44.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 79.8 KiB, free 418.5 MiB)
[2025-05-08T19:40:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on f2a432e4376a:35283 (size: 79.8 KiB, free: 432.6 MiB)
[2025-05-08T19:40:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_148_piece0 on f2a432e4376a:35283 in memory (size: 7.6 KiB, free: 432.6 MiB)
[2025-05-08T19:40:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 172.20.0.5:37427 in memory (size: 7.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1078 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[834] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Adding task set 1078.0 with 10 tasks resource profile 0
[2025-05-08T19:40:44.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 0.0 in stage 1078.0 (TID 1401) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_145_piece0 on f2a432e4376a:35283 in memory (size: 7.5 KiB, free: 432.6 MiB)
[2025-05-08T19:40:44.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 172.20.0.5:37427 in memory (size: 7.5 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_146_piece0 on f2a432e4376a:35283 in memory (size: 80.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:44.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 172.20.0.5:37427 (size: 79.8 KiB, free: 418.5 MiB)
[2025-05-08T19:40:44.311+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 172.20.0.5:37427 in memory (size: 80.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_147_piece0 on f2a432e4376a:35283 in memory (size: 80.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:44.313+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 172.20.0.5:37427 in memory (size: 80.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_149_piece0 on f2a432e4376a:35283 in memory (size: 79.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:44.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 172.20.0.5:37427 in memory (size: 79.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:44.331+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 1.0 in stage 1078.0 (TID 1402) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 0.0 in stage 1078.0 (TID 1401) in 27 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:44.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 2.0 in stage 1078.0 (TID 1403) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.360+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 1.0 in stage 1078.0 (TID 1402) in 29 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:44.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 3.0 in stage 1078.0 (TID 1404) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 2.0 in stage 1078.0 (TID 1403) in 16 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:44.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 4.0 in stage 1078.0 (TID 1405) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 3.0 in stage 1078.0 (TID 1404) in 16 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:44.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 5.0 in stage 1078.0 (TID 1406) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 4.0 in stage 1078.0 (TID 1405) in 18 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:44.426+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 6.0 in stage 1078.0 (TID 1407) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 5.0 in stage 1078.0 (TID 1406) in 17 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:44.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 7.0 in stage 1078.0 (TID 1408) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 6.0 in stage 1078.0 (TID 1407) in 16 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:44.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 8.0 in stage 1078.0 (TID 1409) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 7.0 in stage 1078.0 (TID 1408) in 17 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:44.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 9.0 in stage 1078.0 (TID 1410) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5563 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 8.0 in stage 1078.0 (TID 1409) in 30 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:44.504+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 9.0 in stage 1078.0 (TID 1410) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:44.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Removed TaskSet 1078.0, whose tasks have all completed, from pool
[2025-05-08T19:40:44.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: ShuffleMapStage 1078 (mapPartitions at GraphImpl.scala:208) finished in 0.221 s
[2025-05-08T19:40:44.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:44.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:44.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: waiting: Set(ResultStage 1080, ShuffleMapStage 1079)
[2025-05-08T19:40:44.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:44.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting ShuffleMapStage 1079 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[842] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:44.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 25.0 KiB, free 419.4 MiB)
[2025-05-08T19:40:44.508+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 419.4 MiB)
[2025-05-08T19:40:44.508+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on f2a432e4376a:35283 (size: 7.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:44.508+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:44.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1079 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[842] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:44.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Adding task set 1079.0 with 10 tasks resource profile 0
[2025-05-08T19:40:44.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 0.0 in stage 1079.0 (TID 1411) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.20.0.5:37427 (size: 7.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:44.516+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 111 to 172.20.0.5:59376
[2025-05-08T19:40:44.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:44.525+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 1.0 in stage 1079.0 (TID 1412) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.525+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 0.0 in stage 1079.0 (TID 1411) in 16 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:44.531+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:44.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 2.0 in stage 1079.0 (TID 1413) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.535+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 1.0 in stage 1079.0 (TID 1412) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:44.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:44.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 3.0 in stage 1079.0 (TID 1414) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 2.0 in stage 1079.0 (TID 1413) in 10 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:44.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:44.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 4.0 in stage 1079.0 (TID 1415) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 3.0 in stage 1079.0 (TID 1414) in 9 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:44.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:44.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 5.0 in stage 1079.0 (TID 1416) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 4.0 in stage 1079.0 (TID 1415) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:44.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.568+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 6.0 in stage 1079.0 (TID 1417) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 5.0 in stage 1079.0 (TID 1416) in 8 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:44.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 7.0 in stage 1079.0 (TID 1418) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 6.0 in stage 1079.0 (TID 1417) in 9 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:44.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 8.0 in stage 1079.0 (TID 1419) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 7.0 in stage 1079.0 (TID 1418) in 9 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:44.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 9.0 in stage 1079.0 (TID 1420) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 6028 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 8.0 in stage 1079.0 (TID 1419) in 10 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:44.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_838_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 9.0 in stage 1079.0 (TID 1420) in 11 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:44.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Removed TaskSet 1079.0, whose tasks have all completed, from pool
[2025-05-08T19:40:44.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: ShuffleMapStage 1079 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.100 s
[2025-05-08T19:40:44.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:44.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:44.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: waiting: Set(ResultStage 1080)
[2025-05-08T19:40:44.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:44.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting ResultStage 1080 (EdgeRDDImpl[845] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:44.613+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 243.5 KiB, free 419.2 MiB)
[2025-05-08T19:40:44.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 80.0 KiB, free 419.1 MiB)
[2025-05-08T19:40:44.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on f2a432e4376a:35283 (size: 80.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:44.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:44.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1080 (EdgeRDDImpl[845] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:44.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Adding task set 1080.0 with 10 tasks resource profile 0
[2025-05-08T19:40:44.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 0.0 in stage 1080.0 (TID 1421) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.20.0.5:37427 (size: 80.0 KiB, free: 418.5 MiB)
[2025-05-08T19:40:44.632+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 110 to 172.20.0.5:59376
[2025-05-08T19:40:44.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:44.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 1.0 in stage 1080.0 (TID 1422) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 0.0 in stage 1080.0 (TID 1421) in 45 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:44.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:44.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 2.0 in stage 1080.0 (TID 1423) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 1.0 in stage 1080.0 (TID 1422) in 14 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:44.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.3 MiB)
[2025-05-08T19:40:44.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 3.0 in stage 1080.0 (TID 1424) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 2.0 in stage 1080.0 (TID 1423) in 11 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:44.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:44.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 4.0 in stage 1080.0 (TID 1425) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.696+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 3.0 in stage 1080.0 (TID 1424) in 13 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:44.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.2 MiB)
[2025-05-08T19:40:44.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 5.0 in stage 1080.0 (TID 1426) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 4.0 in stage 1080.0 (TID 1425) in 13 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:44.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:44.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 6.0 in stage 1080.0 (TID 1427) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 5.0 in stage 1080.0 (TID 1426) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:44.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.1 MiB)
[2025-05-08T19:40:44.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 7.0 in stage 1080.0 (TID 1428) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 6.0 in stage 1080.0 (TID 1427) in 13 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:44.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.0 MiB)
[2025-05-08T19:40:44.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 8.0 in stage 1080.0 (TID 1429) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.741+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 7.0 in stage 1080.0 (TID 1428) in 13 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:44.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.0 MiB)
[2025-05-08T19:40:44.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 9.0 in stage 1080.0 (TID 1430) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5615 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 8.0 in stage 1080.0 (TID 1429) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:44.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added rdd_844_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 417.9 MiB)
[2025-05-08T19:40:44.767+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 9.0 in stage 1080.0 (TID 1430) in 17 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:44.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Removed TaskSet 1080.0, whose tasks have all completed, from pool
[2025-05-08T19:40:44.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: ResultStage 1080 (foreachPartition at PageRank.scala:199) finished in 0.162 s
[2025-05-08T19:40:44.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:44.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 1080: Stage finished
[2025-05-08T19:40:44.769+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Job 64 finished: foreachPartition at PageRank.scala:199, took 0.489556 s
[2025-05-08T19:40:44.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO PageRank: PageRank finished iteration 18.
[2025-05-08T19:40:44.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO ZippedPartitionsRDD2: Removing RDD 826 from persistence list
[2025-05-08T19:40:44.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManager: Removing RDD 826
[2025-05-08T19:40:44.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO ZippedPartitionsRDD2: Removing RDD 832 from persistence list
[2025-05-08T19:40:44.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManager: Removing RDD 832
[2025-05-08T19:40:44.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-08T19:40:44.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Registering RDD 846 (mapPartitions at GraphImpl.scala:208) as input to shuffle 113
[2025-05-08T19:40:44.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Registering RDD 854 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 112
[2025-05-08T19:40:44.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Got job 65 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-08T19:40:44.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Final stage: ResultStage 1134 (foreachPartition at PageRank.scala:199)
[2025-05-08T19:40:44.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1097, ShuffleMapStage 1119, ShuffleMapStage 1105, ShuffleMapStage 1127, ShuffleMapStage 1121, ShuffleMapStage 1113, ShuffleMapStage 1092, ShuffleMapStage 1107, ShuffleMapStage 1099, ShuffleMapStage 1093, ShuffleMapStage 1129, ShuffleMapStage 1115, ShuffleMapStage 1101, ShuffleMapStage 1123, ShuffleMapStage 1117, ShuffleMapStage 1109, ShuffleMapStage 1088, ShuffleMapStage 1103, ShuffleMapStage 1095, ShuffleMapStage 1131, ShuffleMapStage 1125, ShuffleMapStage 1111, ShuffleMapStage 1133)
[2025-05-08T19:40:44.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1133)
[2025-05-08T19:40:44.797+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting ShuffleMapStage 1132 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[846] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:40:44.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 244.0 KiB, free 418.9 MiB)
[2025-05-08T19:40:44.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 80.1 KiB, free 418.8 MiB)
[2025-05-08T19:40:44.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on f2a432e4376a:35283 (size: 80.1 KiB, free: 432.7 MiB)
[2025-05-08T19:40:44.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:44.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1132 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[846] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:44.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSchedulerImpl: Adding task set 1132.0 with 10 tasks resource profile 0
[2025-05-08T19:40:44.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 0.0 in stage 1132.0 (TID 1431) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 172.20.0.5:37427 (size: 80.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:44.846+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 1.0 in stage 1132.0 (TID 1432) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.846+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 0.0 in stage 1132.0 (TID 1431) in 33 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:44.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 2.0 in stage 1132.0 (TID 1433) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 1.0 in stage 1132.0 (TID 1432) in 17 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:44.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 3.0 in stage 1132.0 (TID 1434) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 2.0 in stage 1132.0 (TID 1433) in 19 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:44.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 4.0 in stage 1132.0 (TID 1435) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 3.0 in stage 1132.0 (TID 1434) in 24 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:44.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 5.0 in stage 1132.0 (TID 1436) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 4.0 in stage 1132.0 (TID 1435) in 17 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:44.937+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 6.0 in stage 1132.0 (TID 1437) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 5.0 in stage 1132.0 (TID 1436) in 16 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:44.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 7.0 in stage 1132.0 (TID 1438) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 6.0 in stage 1132.0 (TID 1437) in 23 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:44.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 8.0 in stage 1132.0 (TID 1439) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 7.0 in stage 1132.0 (TID 1438) in 16 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:44.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Starting task 9.0 in stage 1132.0 (TID 1440) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5604 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:44.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:44 INFO TaskSetManager: Finished task 8.0 in stage 1132.0 (TID 1439) in 15 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:45.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 9.0 in stage 1132.0 (TID 1440) in 16 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:45.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Removed TaskSet 1132.0, whose tasks have all completed, from pool
[2025-05-08T19:40:45.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: ShuffleMapStage 1132 (mapPartitions at GraphImpl.scala:208) finished in 0.208 s
[2025-05-08T19:40:45.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:45.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:45.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: waiting: Set(ResultStage 1134, ShuffleMapStage 1133)
[2025-05-08T19:40:45.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:45.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting ShuffleMapStage 1133 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[854] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:40:45.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 25.7 KiB, free 418.8 MiB)
[2025-05-08T19:40:45.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 418.8 MiB)
[2025-05-08T19:40:45.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on f2a432e4376a:35283 (size: 7.9 KiB, free: 432.7 MiB)
[2025-05-08T19:40:45.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:45.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1133 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[854] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:45.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Adding task set 1133.0 with 10 tasks resource profile 0
[2025-05-08T19:40:45.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 0.0 in stage 1133.0 (TID 1441) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.012+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 172.20.0.5:37427 (size: 7.9 KiB, free: 418.6 MiB)
[2025-05-08T19:40:45.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 113 to 172.20.0.5:59376
[2025-05-08T19:40:45.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_151_piece0 on f2a432e4376a:35283 in memory (size: 7.7 KiB, free: 432.7 MiB)
[2025-05-08T19:40:45.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 172.20.0.5:37427 in memory (size: 7.7 KiB, free: 418.6 MiB)
[2025-05-08T19:40:45.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 172.20.0.5:37427 in memory (size: 80.0 KiB, free: 418.6 MiB)
[2025-05-08T19:40:45.032+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_152_piece0 on f2a432e4376a:35283 in memory (size: 80.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:45.033+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_0 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.6 MiB)
[2025-05-08T19:40:45.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_150_piece0 on f2a432e4376a:35283 in memory (size: 79.8 KiB, free: 432.8 MiB)
[2025-05-08T19:40:45.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 172.20.0.5:37427 in memory (size: 79.8 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.038+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 1.0 in stage 1133.0 (TID 1442) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 0.0 in stage 1133.0 (TID 1441) in 29 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:45.040+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_153_piece0 on f2a432e4376a:35283 in memory (size: 80.1 KiB, free: 432.9 MiB)
[2025-05-08T19:40:45.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 172.20.0.5:37427 in memory (size: 80.1 KiB, free: 418.8 MiB)
[2025-05-08T19:40:45.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_1 in memory on 172.20.0.5:37427 (size: 14.1 KiB, free: 418.8 MiB)
[2025-05-08T19:40:45.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 2.0 in stage 1133.0 (TID 1443) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 1.0 in stage 1133.0 (TID 1442) in 10 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:45.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_2 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.8 MiB)
[2025-05-08T19:40:45.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 3.0 in stage 1133.0 (TID 1444) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.067+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 2.0 in stage 1133.0 (TID 1443) in 18 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:45.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_3 in memory on 172.20.0.5:37427 (size: 12.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.089+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 4.0 in stage 1133.0 (TID 1445) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 3.0 in stage 1133.0 (TID 1444) in 23 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:45.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_4 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.097+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 5.0 in stage 1133.0 (TID 1446) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 4.0 in stage 1133.0 (TID 1445) in 8 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:45.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_5 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.108+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 6.0 in stage 1133.0 (TID 1447) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.108+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 5.0 in stage 1133.0 (TID 1446) in 11 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:45.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_6 in memory on 172.20.0.5:37427 (size: 13.4 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 7.0 in stage 1133.0 (TID 1448) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 6.0 in stage 1133.0 (TID 1447) in 8 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:45.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_7 in memory on 172.20.0.5:37427 (size: 13.6 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.126+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 8.0 in stage 1133.0 (TID 1449) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.126+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 7.0 in stage 1133.0 (TID 1448) in 11 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:45.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_8 in memory on 172.20.0.5:37427 (size: 13.7 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 9.0 in stage 1133.0 (TID 1450) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 6101 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 8.0 in stage 1133.0 (TID 1449) in 8 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:45.141+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_850_9 in memory on 172.20.0.5:37427 (size: 13.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 9.0 in stage 1133.0 (TID 1450) in 9 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Removed TaskSet 1133.0, whose tasks have all completed, from pool
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: ShuffleMapStage 1133 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.138 s
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: running: Set()
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: waiting: Set(ResultStage 1134)
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:45.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting ResultStage 1134 (EdgeRDDImpl[857] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-08T19:40:45.152+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 243.8 KiB, free 419.5 MiB)
[2025-05-08T19:40:45.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 80.1 KiB, free 419.4 MiB)
[2025-05-08T19:40:45.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on f2a432e4376a:35283 (size: 80.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:45.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:45.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1134 (EdgeRDDImpl[857] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:45.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Adding task set 1134.0 with 10 tasks resource profile 0
[2025-05-08T19:40:45.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 0.0 in stage 1134.0 (TID 1451) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 172.20.0.5:37427 (size: 80.1 KiB, free: 418.6 MiB)
[2025-05-08T19:40:45.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 112 to 172.20.0.5:59376
[2025-05-08T19:40:45.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_0 in memory on 172.20.0.5:37427 (size: 58.4 KiB, free: 418.5 MiB)
[2025-05-08T19:40:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 1.0 in stage 1134.0 (TID 1452) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 0.0 in stage 1134.0 (TID 1451) in 19 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:45.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_1 in memory on 172.20.0.5:37427 (size: 59.3 KiB, free: 418.5 MiB)
[2025-05-08T19:40:45.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 2.0 in stage 1134.0 (TID 1453) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 1.0 in stage 1134.0 (TID 1452) in 11 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:45.195+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_2 in memory on 172.20.0.5:37427 (size: 63.3 KiB, free: 418.4 MiB)
[2025-05-08T19:40:45.196+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 3.0 in stage 1134.0 (TID 1454) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.197+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 2.0 in stage 1134.0 (TID 1453) in 12 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:45.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_3 in memory on 172.20.0.5:37427 (size: 64.9 KiB, free: 418.3 MiB)
[2025-05-08T19:40:45.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 4.0 in stage 1134.0 (TID 1455) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.208+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 3.0 in stage 1134.0 (TID 1454) in 12 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:45.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_4 in memory on 172.20.0.5:37427 (size: 53.4 KiB, free: 418.3 MiB)
[2025-05-08T19:40:45.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 5.0 in stage 1134.0 (TID 1456) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.218+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 4.0 in stage 1134.0 (TID 1455) in 11 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:45.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_5 in memory on 172.20.0.5:37427 (size: 62.3 KiB, free: 418.2 MiB)
[2025-05-08T19:40:45.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 6.0 in stage 1134.0 (TID 1457) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 5.0 in stage 1134.0 (TID 1456) in 15 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:45.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_6 in memory on 172.20.0.5:37427 (size: 58.6 KiB, free: 418.2 MiB)
[2025-05-08T19:40:45.242+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 7.0 in stage 1134.0 (TID 1458) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 6.0 in stage 1134.0 (TID 1457) in 11 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:45.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_7 in memory on 172.20.0.5:37427 (size: 58.2 KiB, free: 418.1 MiB)
[2025-05-08T19:40:45.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 8.0 in stage 1134.0 (TID 1459) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 7.0 in stage 1134.0 (TID 1458) in 12 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:45.262+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_8 in memory on 172.20.0.5:37427 (size: 55.4 KiB, free: 418.1 MiB)
[2025-05-08T19:40:45.263+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 9.0 in stage 1134.0 (TID 1460) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 5656 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.264+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 8.0 in stage 1134.0 (TID 1459) in 11 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:45.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added rdd_856_9 in memory on 172.20.0.5:37427 (size: 65.0 KiB, free: 418.0 MiB)
[2025-05-08T19:40:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 9.0 in stage 1134.0 (TID 1460) in 12 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Removed TaskSet 1134.0, whose tasks have all completed, from pool
[2025-05-08T19:40:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: ResultStage 1134 (foreachPartition at PageRank.scala:199) finished in 0.130 s
[2025-05-08T19:40:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 1134: Stage finished
[2025-05-08T19:40:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Job 65 finished: foreachPartition at PageRank.scala:199, took 0.482504 s
[2025-05-08T19:40:45.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO PageRank: PageRank finished iteration 19.
[2025-05-08T19:40:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO ZippedPartitionsRDD2: Removing RDD 838 from persistence list
[2025-05-08T19:40:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManager: Removing RDD 838
[2025-05-08T19:40:45.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO ZippedPartitionsRDD2: Removing RDD 844 from persistence list
[2025-05-08T19:40:45.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManager: Removing RDD 844
[2025-05-08T19:40:45.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-08T19:40:45.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Got job 66 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-08T19:40:45.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Final stage: ResultStage 1187 (sum at PageRank.scala:503)
[2025-05-08T19:40:45.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1148, ShuffleMapStage 1184, ShuffleMapStage 1170, ShuffleMapStage 1156, ShuffleMapStage 1186, ShuffleMapStage 1178, ShuffleMapStage 1172, ShuffleMapStage 1164, ShuffleMapStage 1143, ShuffleMapStage 1158, ShuffleMapStage 1150, ShuffleMapStage 1144, ShuffleMapStage 1180, ShuffleMapStage 1166, ShuffleMapStage 1152, ShuffleMapStage 1174, ShuffleMapStage 1145, ShuffleMapStage 1160, ShuffleMapStage 1182, ShuffleMapStage 1176, ShuffleMapStage 1168, ShuffleMapStage 1162, ShuffleMapStage 1154)
[2025-05-08T19:40:45.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:45.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting ResultStage 1187 (MapPartitionsRDD[858] at values at PageRank.scala:503), which has no missing parents
[2025-05-08T19:40:45.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 26.1 KiB, free 419.4 MiB)
[2025-05-08T19:40:45.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 419.4 MiB)
[2025-05-08T19:40:45.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on f2a432e4376a:35283 (size: 8.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:45.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:45.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1187 (MapPartitionsRDD[858] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:45.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Adding task set 1187.0 with 10 tasks resource profile 0
[2025-05-08T19:40:45.309+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 0.0 in stage 1187.0 (TID 1461) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.313+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 172.20.0.5:37427 (size: 8.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 1.0 in stage 1187.0 (TID 1462) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 0.0 in stage 1187.0 (TID 1461) in 36 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:45.350+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 2.0 in stage 1187.0 (TID 1463) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.350+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 1.0 in stage 1187.0 (TID 1462) in 5 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:45.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 3.0 in stage 1187.0 (TID 1464) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 2.0 in stage 1187.0 (TID 1463) in 6 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:45.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 4.0 in stage 1187.0 (TID 1465) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.359+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 3.0 in stage 1187.0 (TID 1464) in 4 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:45.362+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 5.0 in stage 1187.0 (TID 1466) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.362+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 4.0 in stage 1187.0 (TID 1465) in 3 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:45.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 6.0 in stage 1187.0 (TID 1467) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 5.0 in stage 1187.0 (TID 1466) in 3 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:45.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 7.0 in stage 1187.0 (TID 1468) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 6.0 in stage 1187.0 (TID 1467) in 4 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:45.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 8.0 in stage 1187.0 (TID 1469) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 7.0 in stage 1187.0 (TID 1468) in 4 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:45.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 9.0 in stage 1187.0 (TID 1470) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 8.0 in stage 1187.0 (TID 1469) in 3 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:45.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 9.0 in stage 1187.0 (TID 1470) in 2 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:45.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Removed TaskSet 1187.0, whose tasks have all completed, from pool
[2025-05-08T19:40:45.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: ResultStage 1187 (sum at PageRank.scala:503) finished in 0.075 s
[2025-05-08T19:40:45.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:45.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 1187: Stage finished
[2025-05-08T19:40:45.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Job 66 finished: sum at PageRank.scala:503, took 0.083234 s
[2025-05-08T19:40:45.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-08T19:40:45.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Got job 67 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-08T19:40:45.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Final stage: ResultStage 1240 (fold at VertexRDDImpl.scala:90)
[2025-05-08T19:40:45.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1235, ShuffleMapStage 1221, ShuffleMapStage 1207, ShuffleMapStage 1237, ShuffleMapStage 1229, ShuffleMapStage 1223, ShuffleMapStage 1215, ShuffleMapStage 1209, ShuffleMapStage 1201, ShuffleMapStage 1231, ShuffleMapStage 1217, ShuffleMapStage 1203, ShuffleMapStage 1239, ShuffleMapStage 1225, ShuffleMapStage 1196, ShuffleMapStage 1211, ShuffleMapStage 1197, ShuffleMapStage 1233, ShuffleMapStage 1227, ShuffleMapStage 1219, ShuffleMapStage 1198, ShuffleMapStage 1213, ShuffleMapStage 1205)
[2025-05-08T19:40:45.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:45.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting ResultStage 1240 (MapPartitionsRDD[859] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-08T19:40:45.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 25.9 KiB, free 419.4 MiB)
[2025-05-08T19:40:45.391+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 419.4 MiB)
[2025-05-08T19:40:45.391+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on f2a432e4376a:35283 (size: 7.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:45.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:45.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1240 (MapPartitionsRDD[859] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:45.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Adding task set 1240.0 with 10 tasks resource profile 0
[2025-05-08T19:40:45.393+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 0.0 in stage 1240.0 (TID 1471) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 172.20.0.5:37427 (size: 7.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 1.0 in stage 1240.0 (TID 1472) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 0.0 in stage 1240.0 (TID 1471) in 7 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:45.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 2.0 in stage 1240.0 (TID 1473) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 1.0 in stage 1240.0 (TID 1472) in 5 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:45.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 3.0 in stage 1240.0 (TID 1474) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 2.0 in stage 1240.0 (TID 1473) in 4 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:45.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 4.0 in stage 1240.0 (TID 1475) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.410+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 3.0 in stage 1240.0 (TID 1474) in 4 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:45.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 5.0 in stage 1240.0 (TID 1476) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 4.0 in stage 1240.0 (TID 1475) in 3 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:45.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 6.0 in stage 1240.0 (TID 1477) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 5.0 in stage 1240.0 (TID 1476) in 4 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:45.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 7.0 in stage 1240.0 (TID 1478) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 6.0 in stage 1240.0 (TID 1477) in 6 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:45.426+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 8.0 in stage 1240.0 (TID 1479) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.426+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 7.0 in stage 1240.0 (TID 1478) in 4 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:45.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Starting task 9.0 in stage 1240.0 (TID 1480) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 6080 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:45.429+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 8.0 in stage 1240.0 (TID 1479) in 4 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSetManager: Finished task 9.0 in stage 1240.0 (TID 1480) in 4 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Removed TaskSet 1240.0, whose tasks have all completed, from pool
[2025-05-08T19:40:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: ResultStage 1240 (fold at VertexRDDImpl.scala:90) finished in 0.046 s
[2025-05-08T19:40:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 1240: Stage finished
[2025-05-08T19:40:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO DAGScheduler: Job 67 finished: fold at VertexRDDImpl.scala:90, took 0.051052 s
[2025-05-08T19:40:45.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_157_piece0 on f2a432e4376a:35283 in memory (size: 7.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:45.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 172.20.0.5:37427 in memory (size: 7.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_156_piece0 on f2a432e4376a:35283 in memory (size: 8.2 KiB, free: 432.8 MiB)
[2025-05-08T19:40:45.784+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 172.20.0.5:37427 in memory (size: 8.2 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 172.20.0.5:37427 in memory (size: 7.9 KiB, free: 418.7 MiB)
[2025-05-08T19:40:45.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_154_piece0 on f2a432e4376a:35283 in memory (size: 7.9 KiB, free: 432.8 MiB)
[2025-05-08T19:40:45.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_155_piece0 on f2a432e4376a:35283 in memory (size: 80.1 KiB, free: 432.9 MiB)
[2025-05-08T19:40:45.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:45 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 172.20.0.5:37427 in memory (size: 80.1 KiB, free: 418.8 MiB)
[2025-05-08T19:40:45.837+0000] {spark_submit.py:571} INFO - 2025-05-08 19:40:45,836 [INFO] Объединяем результаты
[2025-05-08T19:40:46.698+0000] {spark_submit.py:571} INFO - 2025-05-08 19:40:46,687 [INFO] Выбираем топ-500 влиятельных узлов
[2025-05-08T19:40:46.967+0000] {spark_submit.py:571} INFO - 2025-05-08 19:40:46,967 [INFO] Фильтруем ребра для топ-узлов
[2025-05-08T19:40:48.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T19:40:48.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T19:40:49.550+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Registering RDD 977 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 115
[2025-05-08T19:40:49.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got map stage job 68 (collect at /opt/airflow/spark/build_graph.py:229) with 1 output partitions
[2025-05-08T19:40:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1241 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:40:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ShuffleMapStage 1241 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 23.9 KiB, free 419.8 MiB)
[2025-05-08T19:40:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO CodeGenerator: Code generated in 18.129787 ms
[2025-05-08T19:40:49.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#1729) generates partition filter: ((id.count#4416 - id.nullCount#4415) > 0)
[2025-05-08T19:40:49.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 419.8 MiB)
[2025-05-08T19:40:49.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.9 MiB)
[2025-05-08T19:40:49.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1241 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:40:49.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1241.0 with 1 tasks resource profile 0
[2025-05-08T19:40:49.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Registering RDD 980 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 116
[2025-05-08T19:40:49.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got map stage job 69 (collect at /opt/airflow/spark/build_graph.py:229) with 1 output partitions
[2025-05-08T19:40:49.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1242 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:40:49.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ShuffleMapStage 1242 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSetManager: Starting task 0.0 in stage 1241.0 (TID 1481) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:49.599+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 22.4 KiB, free 419.7 MiB)
[2025-05-08T19:40:49.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 419.7 MiB)
[2025-05-08T19:40:49.610+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.9 MiB)
[2025-05-08T19:40:49.610+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.610+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1242 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:40:49.611+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1242.0 with 1 tasks resource profile 0
[2025-05-08T19:40:49.611+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Registering RDD 985 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 117
[2025-05-08T19:40:49.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got map stage job 70 (collect at /opt/airflow/spark/build_graph.py:229) with 1 output partitions
[2025-05-08T19:40:49.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1243 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:40:49.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.613+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ShuffleMapStage 1243 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 22.4 KiB, free 419.7 MiB)
[2025-05-08T19:40:49.619+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 419.7 MiB)
[2025-05-08T19:40:49.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.9 MiB)
[2025-05-08T19:40:49.624+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Starting job: collect at /opt/airflow/spark/build_graph.py:229
[2025-05-08T19:40:49.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1243 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:40:49.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1243.0 with 1 tasks resource profile 0
[2025-05-08T19:40:49.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Registering RDD 991 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 118
[2025-05-08T19:40:49.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got map stage job 71 (collect at /opt/airflow/spark/build_graph.py:229) with 1 output partitions
[2025-05-08T19:40:49.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1244 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List()
[2025-05-08T19:40:49.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ShuffleMapStage 1244 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 28.8 KiB, free 419.7 MiB)
[2025-05-08T19:40:49.652+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 419.6 MiB)
[2025-05-08T19:40:49.652+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.9 MiB)
[2025-05-08T19:40:49.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1244 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:40:49.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1244.0 with 1 tasks resource profile 0
[2025-05-08T19:40:49.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got job 72 (collect at /opt/airflow/spark/build_graph.py:229) with 10 output partitions
[2025-05-08T19:40:49.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ResultStage 1253 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1252)
[2025-05-08T19:40:49.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ResultStage 1253 (MapPartitionsRDD[988] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 95.4 KiB, free 419.6 MiB)
[2025-05-08T19:40:49.666+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 36.1 KiB, free 419.5 MiB)
[2025-05-08T19:40:49.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on f2a432e4376a:35283 (size: 36.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:49.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1253 (MapPartitionsRDD[988] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:49.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1253.0 with 10 tasks resource profile 0
[2025-05-08T19:40:49.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 172.20.0.5:37427 (size: 11.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:49.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO CodeGenerator: Code generated in 23.002488 ms
[2025-05-08T19:40:49.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Registering RDD 994 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 119
[2025-05-08T19:40:49.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got map stage job 73 (collect at /opt/airflow/spark/build_graph.py:229) with 10 output partitions
[2025-05-08T19:40:49.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1286 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1254, ShuffleMapStage 1279, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1273, ShuffleMapStage 1261, ShuffleMapStage 1258, ShuffleMapStage 1270, ShuffleMapStage 1285, ShuffleMapStage 1282, ShuffleMapStage 1267, ShuffleMapStage 1264)
[2025-05-08T19:40:49.696+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.697+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ShuffleMapStage 1286 (MapPartitionsRDD[994] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 29.8 KiB, free 419.5 MiB)
[2025-05-08T19:40:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 419.5 MiB)
[2025-05-08T19:40:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on f2a432e4376a:35283 (size: 11.3 KiB, free: 432.8 MiB)
[2025-05-08T19:40:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1286 (MapPartitionsRDD[994] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:49.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1286.0 with 10 tasks resource profile 0
[2025-05-08T19:40:49.724+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO CodeGenerator: Code generated in 26.633545 ms
[2025-05-08T19:40:49.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Registering RDD 997 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 120
[2025-05-08T19:40:49.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got map stage job 74 (collect at /opt/airflow/spark/build_graph.py:229) with 10 output partitions
[2025-05-08T19:40:49.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1329 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1322, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1294, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1296, ShuffleMapStage 1318, ShuffleMapStage 1304, ShuffleMapStage 1290, ShuffleMapStage 1326, ShuffleMapStage 1320, ShuffleMapStage 1254, ShuffleMapStage 1312, ShuffleMapStage 1255, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1292, ShuffleMapStage 1328, ShuffleMapStage 1314, ShuffleMapStage 1300)
[2025-05-08T19:40:49.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ShuffleMapStage 1329 (MapPartitionsRDD[997] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSetManager: Starting task 0.0 in stage 1242.0 (TID 1482) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:49.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSetManager: Finished task 0.0 in stage 1241.0 (TID 1481) in 154 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:40:49.752+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 38.7 KiB, free 419.4 MiB)
[2025-05-08T19:40:49.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 419.4 MiB)
[2025-05-08T19:40:49.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on f2a432e4376a:35283 (size: 13.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:49.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1329 (MapPartitionsRDD[997] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:49.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1329.0 with 10 tasks resource profile 0
[2025-05-08T19:40:49.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Removed TaskSet 1241.0, whose tasks have all completed, from pool
[2025-05-08T19:40:49.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: ShuffleMapStage 1241 (collect at /opt/airflow/spark/build_graph.py:229) finished in 0.206 s
[2025-05-08T19:40:49.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:49.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: running: Set(ResultStage 1253, ShuffleMapStage 1286, ShuffleMapStage 1242, ShuffleMapStage 1243, ShuffleMapStage 1244, ShuffleMapStage 1329)
[2025-05-08T19:40:49.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:40:49.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:49.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 418.8 MiB)
[2025-05-08T19:40:49.775+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO CodeGenerator: Code generated in 34.095883 ms
[2025-05-08T19:40:49.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Registering RDD 1000 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 121
[2025-05-08T19:40:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Got map stage job 75 (collect at /opt/airflow/spark/build_graph.py:229) with 10 output partitions
[2025-05-08T19:40:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1330 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:40:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1254, ShuffleMapStage 1279, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1273, ShuffleMapStage 1261, ShuffleMapStage 1258, ShuffleMapStage 1270, ShuffleMapStage 1285, ShuffleMapStage 1282, ShuffleMapStage 1267, ShuffleMapStage 1264)
[2025-05-08T19:40:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:40:49.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting ShuffleMapStage 1330 (MapPartitionsRDD[1000] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:40:49.827+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 30.4 KiB, free 419.4 MiB)
[2025-05-08T19:40:49.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 419.4 MiB)
[2025-05-08T19:40:49.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on f2a432e4376a:35283 (size: 11.5 KiB, free: 432.8 MiB)
[2025-05-08T19:40:49.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:40:49.838+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1330 (MapPartitionsRDD[1000] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:40:49.838+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Adding task set 1330.0 with 10 tasks resource profile 0
[2025-05-08T19:40:49.886+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSetManager: Starting task 0.0 in stage 1243.0 (TID 1483) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:49.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSetManager: Finished task 0.0 in stage 1242.0 (TID 1482) in 139 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:40:49.891+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Removed TaskSet 1242.0, whose tasks have all completed, from pool
[2025-05-08T19:40:49.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: ShuffleMapStage 1242 (collect at /opt/airflow/spark/build_graph.py:229) finished in 0.292 s
[2025-05-08T19:40:49.893+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:49.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: running: Set(ResultStage 1253, ShuffleMapStage 1286, ShuffleMapStage 1243, ShuffleMapStage 1330, ShuffleMapStage 1244, ShuffleMapStage 1329)
[2025-05-08T19:40:49.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:40:49.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:49.898+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 172.20.0.5:37427 (size: 11.0 KiB, free: 418.8 MiB)
[2025-05-08T19:40:49.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSetManager: Starting task 0.0 in stage 1244.0 (TID 1484) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSetManager: Finished task 0.0 in stage 1243.0 (TID 1483) in 104 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:40:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO TaskSchedulerImpl: Removed TaskSet 1243.0, whose tasks have all completed, from pool
[2025-05-08T19:40:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: ShuffleMapStage 1243 (collect at /opt/airflow/spark/build_graph.py:229) finished in 0.379 s
[2025-05-08T19:40:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:49.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: running: Set(ResultStage 1253, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1244, ShuffleMapStage 1329)
[2025-05-08T19:40:49.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:40:49.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:49.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:49 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 172.20.0.5:37427 (size: 13.8 KiB, free: 418.8 MiB)
[2025-05-08T19:40:50.046+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 0.0 in stage 1253.0 (TID 1485) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.047+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 0.0 in stage 1244.0 (TID 1484) in 57 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-08T19:40:50.047+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSchedulerImpl: Removed TaskSet 1244.0, whose tasks have all completed, from pool
[2025-05-08T19:40:50.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: ShuffleMapStage 1244 (collect at /opt/airflow/spark/build_graph.py:229) finished in 0.418 s
[2025-05-08T19:40:50.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:40:50.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: running: Set(ResultStage 1253, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1329)
[2025-05-08T19:40:50.049+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: waiting: Set()
[2025-05-08T19:40:50.049+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:40:50.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 172.20.0.5:37427 (size: 36.1 KiB, free: 418.7 MiB)
[2025-05-08T19:40:50.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T19:40:50.075+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 1.0 in stage 1253.0 (TID 1486) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 0.0 in stage 1253.0 (TID 1485) in 31 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:50.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 2.0 in stage 1253.0 (TID 1487) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.096+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 1.0 in stage 1253.0 (TID 1486) in 22 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:50.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 3.0 in stage 1253.0 (TID 1488) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 2.0 in stage 1253.0 (TID 1487) in 26 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:50.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 4.0 in stage 1253.0 (TID 1489) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 3.0 in stage 1253.0 (TID 1488) in 22 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:50.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 5.0 in stage 1253.0 (TID 1490) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 4.0 in stage 1253.0 (TID 1489) in 15 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:50.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 6.0 in stage 1253.0 (TID 1491) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 5.0 in stage 1253.0 (TID 1490) in 14 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:50.219+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 7.0 in stage 1253.0 (TID 1492) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 6.0 in stage 1253.0 (TID 1491) in 66 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:50.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 418.7 MiB)
[2025-05-08T19:40:50.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Removed broadcast_159_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:50.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 8.0 in stage 1253.0 (TID 1493) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.259+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 7.0 in stage 1253.0 (TID 1492) in 39 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:40:50.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 9.0 in stage 1253.0 (TID 1494) (172.20.0.5, executor 0, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 172.20.0.5:37427 in memory (size: 11.0 KiB, free: 418.7 MiB)
[2025-05-08T19:40:50.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 8.0 in stage 1253.0 (TID 1493) in 27 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:40:50.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Removed broadcast_160_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.8 MiB)
[2025-05-08T19:40:50.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Removed broadcast_161_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.8 MiB)
[2025-05-08T19:40:50.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 172.20.0.5:37427 in memory (size: 13.8 KiB, free: 418.8 MiB)
[2025-05-08T19:40:50.324+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 9.0 in stage 1253.0 (TID 1494) in 41 ms on 172.20.0.5 (executor 0) (10/10)
[2025-05-08T19:40:50.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSchedulerImpl: Removed TaskSet 1253.0, whose tasks have all completed, from pool
[2025-05-08T19:40:50.328+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 0.0 in stage 1286.0 (TID 1495) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.328+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: ResultStage 1253 (collect at /opt/airflow/spark/build_graph.py:229) finished in 0.669 s
[2025-05-08T19:40:50.328+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-08T19:40:50.328+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 1253: Stage finished
[2025-05-08T19:40:50.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO DAGScheduler: Job 72 finished: collect at /opt/airflow/spark/build_graph.py:229, took 0.706187 s
[2025-05-08T19:40:50.356+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 172.20.0.5:37427 (size: 11.3 KiB, free: 418.7 MiB)
[2025-05-08T19:40:50.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T19:40:50.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO CodeGenerator: Code generated in 48.933196 ms
[2025-05-08T19:40:50.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 2.1 MiB, free 417.4 MiB)
[2025-05-08T19:40:50.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 417.3 MiB)
[2025-05-08T19:40:50.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on f2a432e4376a:35283 (size: 89.0 KiB, free: 432.7 MiB)
[2025-05-08T19:40:50.506+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO SparkContext: Created broadcast 166 from collect at /opt/airflow/spark/build_graph.py:229
[2025-05-08T19:40:50.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 1.0 in stage 1286.0 (TID 1496) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 0.0 in stage 1286.0 (TID 1495) in 212 ms on 172.20.0.5 (executor 0) (1/10)
[2025-05-08T19:40:50.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 2.0 in stage 1286.0 (TID 1497) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 1.0 in stage 1286.0 (TID 1496) in 36 ms on 172.20.0.5 (executor 0) (2/10)
[2025-05-08T19:40:50.599+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 3.0 in stage 1286.0 (TID 1498) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 2.0 in stage 1286.0 (TID 1497) in 33 ms on 172.20.0.5 (executor 0) (3/10)
[2025-05-08T19:40:50.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Starting task 4.0 in stage 1286.0 (TID 1499) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:50.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO TaskSetManager: Finished task 3.0 in stage 1286.0 (TID 1498) in 269 ms on 172.20.0.5 (executor 0) (4/10)
[2025-05-08T19:40:50.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:50 INFO BlockManagerInfo: Removed broadcast_162_piece0 on f2a432e4376a:35283 in memory (size: 36.1 KiB, free: 432.8 MiB)
[2025-05-08T19:40:51.004+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:51 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 172.20.0.5:37427 in memory (size: 36.1 KiB, free: 418.8 MiB)
[2025-05-08T19:40:51.034+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:51 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 172.20.0.5:37427 in memory (size: 11.7 KiB, free: 418.8 MiB)
[2025-05-08T19:40:51.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:51 INFO BlockManagerInfo: Removed broadcast_158_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.8 MiB)
[2025-05-08T19:40:51.394+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:51 INFO TaskSetManager: Starting task 5.0 in stage 1286.0 (TID 1500) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:51.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:51 INFO CodeGenerator: Code generated in 259.906958 ms
[2025-05-08T19:40:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:51 INFO TaskSetManager: Finished task 4.0 in stage 1286.0 (TID 1499) in 480 ms on 172.20.0.5 (executor 0) (5/10)
[2025-05-08T19:40:52.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:52 INFO TaskSetManager: Starting task 6.0 in stage 1286.0 (TID 1501) (172.20.0.5, executor 0, partition 6, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:53.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:52 INFO TaskSetManager: Finished task 5.0 in stage 1286.0 (TID 1500) in 1601 ms on 172.20.0.5 (executor 0) (6/10)
[2025-05-08T19:40:53.258+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:53 INFO CodeGenerator: Code generated in 1818.206261 ms
[2025-05-08T19:40:55.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:55 INFO TaskSetManager: Starting task 7.0 in stage 1286.0 (TID 1502) (172.20.0.5, executor 0, partition 7, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:55.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:55 INFO TaskSetManager: Finished task 6.0 in stage 1286.0 (TID 1501) in 2767 ms on 172.20.0.5 (executor 0) (7/10)
[2025-05-08T19:40:57.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:57 INFO CodeGenerator: Code generated in 2193.706352 ms
[2025-05-08T19:40:58.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:58 INFO TaskSetManager: Starting task 8.0 in stage 1286.0 (TID 1503) (172.20.0.5, executor 0, partition 8, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:40:58.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:40:58 INFO TaskSetManager: Finished task 7.0 in stage 1286.0 (TID 1502) in 3110 ms on 172.20.0.5 (executor 0) (8/10)
[2025-05-08T19:43:31.841+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:31 INFO CodeGenerator: Code generated in 153365.21055 ms
[2025-05-08T19:43:31.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:31 WARN HeartbeatReceiver: Removing executor 0 with no recent heartbeats: 151822 ms exceeds timeout 120000 ms
[2025-05-08T19:43:31.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:31 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 0
[2025-05-08T19:43:31.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:31 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is 0
[2025-05-08T19:43:31.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:31 INFO CodeGenerator: Code generated in 22.213215 ms
[2025-05-08T19:43:31.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:31 INFO TaskSetManager: Finished task 8.0 in stage 1286.0 (TID 1503) in 153308 ms on 172.20.0.5 (executor 0) (9/10)
[2025-05-08T19:43:32.003+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 18.527309 ms
[2025-05-08T19:43:32.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 36.439504 ms
[2025-05-08T19:43:32.049+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 3.732139 ms
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 22.842119 ms
[2025-05-08T19:43:32.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 5.463474 ms
[2025-05-08T19:43:32.165+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Registering RDD 1066 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 122
[2025-05-08T19:43:32.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Got map stage job 76 (collect at /opt/airflow/spark/build_graph.py:229) with 41 output partitions
[2025-05-08T19:43:32.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Final stage: ShuffleMapStage 1335 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:43:32.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1334, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T19:43:32.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:43:32.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 1335 (MapPartitionsRDD[1066] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:32.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 107.7 KiB, free 417.4 MiB)
[2025-05-08T19:43:32.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 22.600583 ms
[2025-05-08T19:43:32.198+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 5.432842 ms
[2025-05-08T19:43:32.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 4.224254 ms
[2025-05-08T19:43:32.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.212+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.212+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.213+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.217+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.217+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.218+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 12.407839 ms
[2025-05-08T19:43:32.222+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.222+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.223+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.224+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.224+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.224+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.224+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.224+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.232+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.232+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.232+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.232+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.232+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.232+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.232+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.233+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.233+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.233+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.233+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.233+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.233+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.233+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 39.5 KiB, free 417.4 MiB)
[2025-05-08T19:43:32.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 37.972655 ms
[2025-05-08T19:43:32.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 5.710528 ms
[2025-05-08T19:43:32.276+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.277+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.277+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.279+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.280+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.280+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.281+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.281+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.281+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.282+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.282+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.284+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.284+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.284+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.284+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.293+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.294+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.294+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.296+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.298+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.300+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.301+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.302+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.305+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.307+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.310+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.312+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.313+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on f2a432e4376a:35283 (size: 39.5 KiB, free: 432.7 MiB)
[2025-05-08T19:43:32.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:32.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1335 (MapPartitionsRDD[1066] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:43:32.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO TaskSchedulerImpl: Adding task set 1335.0 with 41 tasks resource profile 0
[2025-05-08T19:43:32.332+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.332+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.332+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.341+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.342+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.345+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.348+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.359+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.363+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.368+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.370+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.373+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.376+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.378+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.380+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.381+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 45.537855 ms
[2025-05-08T19:43:32.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.386+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.388+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.390+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.390+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.390+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.390+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.391+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.391+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.391+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.391+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.391+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.396+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.398+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.401+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.406+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.407+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.408+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.408+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.409+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.413+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.414+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.414+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.414+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.414+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.414+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.414+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.414+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.415+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 32.687459 ms
[2025-05-08T19:43:32.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.415+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.415+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.417+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.419+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.419+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.419+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.419+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.419+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 10.415859 ms
[2025-05-08T19:43:32.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 5.137064 ms
[2025-05-08T19:43:32.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.425+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.427+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.430+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.438+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.441+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.446+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.454+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.481+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.495+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.505+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.518+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.519+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.536+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.537+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.537+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.537+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.546+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.546+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.551+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.554+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.555+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.557+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.560+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.562+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.563+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.563+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.563+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Registering RDD 1086 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 123
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Got map stage job 77 (collect at /opt/airflow/spark/build_graph.py:229) with 41 output partitions
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Final stage: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1334, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 40.14689 ms
[2025-05-08T19:43:32.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 109.8 KiB, free 417.3 MiB)
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 40.1 KiB, free 417.2 MiB)
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 9.244039 ms
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.565+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.566+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.566+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.566+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.566+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.566+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.568+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.568+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.569+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 13.387652 ms
[2025-05-08T19:43:32.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 9.905855 ms
[2025-05-08T19:43:32.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on f2a432e4376a:35283 (size: 40.1 KiB, free: 432.7 MiB)
[2025-05-08T19:43:32.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:32.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:43:32.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO TaskSchedulerImpl: Adding task set 1336.0 with 41 tasks resource profile 0
[2025-05-08T19:43:32.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 ERROR Inbox: Ignoring error
[2025-05-08T19:43:32.572+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T19:43:32.573+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T19:43:32.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T19:43:32.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T19:43:32.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T19:43:32.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T19:43:32.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T19:43:32.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T19:43:32.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T19:43:32.574+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T19:43:32.575+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T19:43:32.575+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:32.576+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:32.576+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:32.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 14.608421 ms
[2025-05-08T19:43:32.580+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 8.402018 ms
[2025-05-08T19:43:32.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 189.519396 ms
[2025-05-08T19:43:32.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 14.148106 ms
[2025-05-08T19:43:32.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 6.370437 ms
[2025-05-08T19:43:32.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 5.340153 ms
[2025-05-08T19:43:32.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Registering RDD 1106 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 124
[2025-05-08T19:43:32.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Got map stage job 78 (collect at /opt/airflow/spark/build_graph.py:229) with 41 output partitions
[2025-05-08T19:43:32.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Final stage: ShuffleMapStage 1337 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:43:32.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1334, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T19:43:32.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:43:32.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Submitting ShuffleMapStage 1337 (MapPartitionsRDD[1106] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:32.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 112.1 KiB, free 417.1 MiB)
[2025-05-08T19:43:32.881+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 40.6 KiB, free 417.1 MiB)
[2025-05-08T19:43:32.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on f2a432e4376a:35283 (size: 40.6 KiB, free: 432.7 MiB)
[2025-05-08T19:43:32.891+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:32.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 25.688636 ms
[2025-05-08T19:43:32.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1337 (MapPartitionsRDD[1106] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:43:32.895+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO TaskSchedulerImpl: Adding task set 1337.0 with 41 tasks resource profile 0
[2025-05-08T19:43:32.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 5.745999 ms
[2025-05-08T19:43:32.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 6.59602 ms
[2025-05-08T19:43:32.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 24.566771 ms
[2025-05-08T19:43:32.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 19.034858 ms
[2025-05-08T19:43:32.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:32 INFO CodeGenerator: Code generated in 23.867486 ms
[2025-05-08T19:43:33.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO CodeGenerator: Code generated in 17.127182 ms
[2025-05-08T19:43:33.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO CodeGenerator: Code generated in 8.387658 ms
[2025-05-08T19:43:33.132+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO CodeGenerator: Code generated in 23.647876 ms
[2025-05-08T19:43:33.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO CodeGenerator: Code generated in 8.489391 ms
[2025-05-08T19:43:33.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Registering RDD 1126 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 125
[2025-05-08T19:43:33.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Got map stage job 79 (collect at /opt/airflow/spark/build_graph.py:229) with 41 output partitions
[2025-05-08T19:43:33.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Final stage: ShuffleMapStage 1338 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:43:33.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1334, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T19:43:33.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:43:33.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Submitting ShuffleMapStage 1338 (MapPartitionsRDD[1126] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:33.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 104.2 KiB, free 417.0 MiB)
[2025-05-08T19:43:33.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 39.1 KiB, free 416.9 MiB)
[2025-05-08T19:43:33.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on f2a432e4376a:35283 (size: 39.1 KiB, free: 432.6 MiB)
[2025-05-08T19:43:33.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:33.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1338 (MapPartitionsRDD[1126] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:43:33.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO TaskSchedulerImpl: Adding task set 1338.0 with 41 tasks resource profile 0
[2025-05-08T19:43:33.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T19:43:33.521+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/0 is now LOST (worker lost)
[2025-05-08T19:43:33.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO StandaloneSchedulerBackend: Executor app-20250508193925-0005/0 removed: worker lost
[2025-05-08T19:43:33.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T19:43:33.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO StandaloneSchedulerBackend: Worker worker-20250508061515-172.20.0.5-45383 removed: Not receiving heartbeat for 60 seconds
[2025-05-08T19:43:33.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 ERROR TaskSchedulerImpl: Lost executor 0 on 172.20.0.5: worker lost
[2025-05-08T19:43:33.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO TaskSchedulerImpl: Handle removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T19:43:33.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 6), so marking it as still running.
[2025-05-08T19:43:33.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 5), so marking it as still running.
[2025-05-08T19:43:33.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 8), so marking it as still running.
[2025-05-08T19:43:33.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 2), so marking it as still running.
[2025-05-08T19:43:33.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 4), so marking it as still running.
[2025-05-08T19:43:33.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 7), so marking it as still running.
[2025-05-08T19:43:33.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 1), so marking it as still running.
[2025-05-08T19:43:33.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 0), so marking it as still running.
[2025-05-08T19:43:33.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Resubmitted ShuffleMapTask(1286, 3), so marking it as still running.
[2025-05-08T19:43:33.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Executor lost: 0 (epoch 118)
[2025-05-08T19:43:33.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2025-05-08T19:43:33.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_1 !
[2025-05-08T19:43:33.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_4 !
[2025-05-08T19:43:33.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_5 !
[2025-05-08T19:43:33.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_0 !
[2025-05-08T19:43:33.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_7 !
[2025-05-08T19:43:33.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_9 !
[2025-05-08T19:43:33.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_8 !
[2025-05-08T19:43:33.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_3 !
[2025-05-08T19:43:33.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_3 !
[2025-05-08T19:43:33.689+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_6 !
[2025-05-08T19:43:33.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_9 !
[2025-05-08T19:43:33.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_6 !
[2025-05-08T19:43:33.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_3 !
[2025-05-08T19:43:33.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_7 !
[2025-05-08T19:43:33.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_1 !
[2025-05-08T19:43:33.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_7 !
[2025-05-08T19:43:33.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_1 !
[2025-05-08T19:43:33.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_6 !
[2025-05-08T19:43:33.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_4 !
[2025-05-08T19:43:33.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_9 !
[2025-05-08T19:43:33.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_8 !
[2025-05-08T19:43:33.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_6 !
[2025-05-08T19:43:33.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_1 !
[2025-05-08T19:43:33.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_0 !
[2025-05-08T19:43:33.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_8 !
[2025-05-08T19:43:33.700+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_8 !
[2025-05-08T19:43:33.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_1 !
[2025-05-08T19:43:33.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_7 !
[2025-05-08T19:43:33.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_5 !
[2025-05-08T19:43:33.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_9 !
[2025-05-08T19:43:33.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_7 !
[2025-05-08T19:43:33.702+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_8 !
[2025-05-08T19:43:33.702+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_3 !
[2025-05-08T19:43:33.703+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_7 !
[2025-05-08T19:43:33.703+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_2 !
[2025-05-08T19:43:33.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_2 !
[2025-05-08T19:43:33.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_4 !
[2025-05-08T19:43:33.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_9 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_1 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_2 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_5 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_0 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_4 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_4 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_6 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_8 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_1 !
[2025-05-08T19:43:33.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_3 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_4 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_8 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_2 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_0 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_7 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_5 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_3 !
[2025-05-08T19:43:33.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_1 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_1 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_6 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_0 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_2 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_2 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_7 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_8 !
[2025-05-08T19:43:33.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_5 !
[2025-05-08T19:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_6 !
[2025-05-08T19:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_8 !
[2025-05-08T19:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_3 !
[2025-05-08T19:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_0 !
[2025-05-08T19:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_3 !
[2025-05-08T19:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_5 !
[2025-05-08T19:43:33.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_9 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_4 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_9 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_4 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_0 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_8 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_6 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_0 !
[2025-05-08T19:43:33.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_3 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_1 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_5 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_6 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_9 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_9 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_9 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_5 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_7 !
[2025-05-08T19:43:33.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_3 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_4 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_6 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_2 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_8 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_3 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_4 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_1 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_1 !
[2025-05-08T19:43:33.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_2 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_5 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_6 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_2 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_9 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_6 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_5 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_0 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_3 !
[2025-05-08T19:43:33.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_7 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_0 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_0 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_2 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_5 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_0 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_7 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_2 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_9 !
[2025-05-08T19:43:33.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_856_2 !
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_8 !
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_850_7 !
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_5 !
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_4 !
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_4 !
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.20.0.5, 37427, None)
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 118)
[2025-05-08T19:43:33.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO DAGScheduler: Shuffle files lost for worker worker-20250508061515-172.20.0.5-45383 on host 172.20.0.5
[2025-05-08T19:43:33.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2025-05-08T19:43:33.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO BlockManagerMaster: Removal of executor 0 requested
[2025-05-08T19:43:33.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:33 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 0
[2025-05-08T19:43:34.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250508193925-0005/1 on worker-20250508061515-172.20.0.5-45383 (172.20.0.5:45383) with 1 core(s)
[2025-05-08T19:43:34.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250508193925-0005/1 on hostPort 172.20.0.5:45383 with 1 core(s), 1024.0 MiB RAM
[2025-05-08T19:43:34.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/1 is now RUNNING
[2025-05-08T19:43:37.036+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:36758) with ID 1,  ResourceProfileId 0
[2025-05-08T19:43:37.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:36007 with 434.4 MiB RAM, BlockManagerId(1, 172.20.0.5, 36007, None)
[2025-05-08T19:43:37.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO TaskSetManager: Starting task 3.1 in stage 1286.0 (TID 1504) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:37.496+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 172.20.0.5:36007 (size: 11.3 KiB, free: 434.4 MiB)
[2025-05-08T19:43:37.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:36758
[2025-05-08T19:43:37.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO TaskSetManager: Starting task 0.1 in stage 1286.0 (TID 1505) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:37.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 WARN TaskSetManager: Lost task 3.1 in stage 1286.0 (TID 1504) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=3, message=
[2025-05-08T19:43:37.992+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 3
[2025-05-08T19:43:37.992+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:37.992+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:37.992+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:37.992+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:37.993+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:37.994+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:37.995+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:37.996+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.997+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.998+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:37.999+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.000+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.001+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.002+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.003+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.004+0000] {spark_submit.py:571} INFO - )
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO DAGScheduler: Marking ShuffleMapStage 1286 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1254 (map at GraphFrame.scala:187)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO TaskSetManager: task 3.1 in stage 1286.0 (TID 1504) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO DAGScheduler: ShuffleMapStage 1286 (collect at /opt/airflow/spark/build_graph.py:229) failed in 168.296 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 3
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.005+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.006+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.007+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.008+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.009+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.010+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.011+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.012+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.013+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.014+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:37 INFO DAGScheduler: Resubmitting ShuffleMapStage 1254 (map at GraphFrame.scala:187) and ShuffleMapStage 1286 (collect at /opt/airflow/spark/build_graph.py:229) due to fetch failure
[2025-05-08T19:43:38.015+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:36758
[2025-05-08T19:43:38.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: Starting task 0.0 in stage 1329.0 (TID 1506) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 6069 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 WARN TaskSetManager: Lost task 0.1 in stage 1286.0 (TID 1505) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-08T19:43:38.031+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 0
[2025-05-08T19:43:38.031+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:38.031+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:38.031+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.031+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.032+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.033+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.034+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.035+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.036+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.037+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.038+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.039+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.040+0000] {spark_submit.py:571} INFO - )
[2025-05-08T19:43:38.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: task 0.1 in stage 1286.0 (TID 1505) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T19:43:38.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSchedulerImpl: Removed TaskSet 1286.0, whose tasks have all completed, from pool
[2025-05-08T19:43:38.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 172.20.0.5:36007 (size: 13.7 KiB, free: 434.4 MiB)
[2025-05-08T19:43:38.101+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:36758
[2025-05-08T19:43:38.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: Starting task 1.0 in stage 1329.0 (TID 1507) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 6069 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:38.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 WARN TaskSetManager: Lost task 0.0 in stage 1329.0 (TID 1506) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-08T19:43:38.116+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 0
[2025-05-08T19:43:38.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:38.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:38.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.116+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:38.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.123+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.124+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.125+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.126+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.127+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.128+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.129+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.130+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.131+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.132+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - )
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: task 0.0 in stage 1329.0 (TID 1506) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Marking ShuffleMapStage 1329 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1254 (map at GraphFrame.scala:187)
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: ShuffleMapStage 1329 (collect at /opt/airflow/spark/build_graph.py:229) failed in 168.373 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 0
[2025-05-08T19:43:38.133+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:38.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.137+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.149+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.150+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.150+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.150+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Resubmitting ShuffleMapStage 1254 (map at GraphFrame.scala:187) and ShuffleMapStage 1329 (collect at /opt/airflow/spark/build_graph.py:229) due to fetch failure
[2025-05-08T19:43:38.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:36758
[2025-05-08T19:43:38.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: Starting task 0.0 in stage 1330.0 (TID 1508) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:38.169+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 WARN TaskSetManager: Lost task 1.0 in stage 1329.0 (TID 1507) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=1, message=
[2025-05-08T19:43:38.170+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 1
[2025-05-08T19:43:38.170+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:38.171+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:38.171+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.171+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:38.171+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:38.171+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:38.172+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:38.173+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.173+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.173+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.173+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.174+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.174+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.185+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.186+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.187+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.188+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.189+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.190+0000] {spark_submit.py:571} INFO - )
[2025-05-08T19:43:38.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: task 1.0 in stage 1329.0 (TID 1507) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T19:43:38.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSchedulerImpl: Removed TaskSet 1329.0, whose tasks have all completed, from pool
[2025-05-08T19:43:38.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 172.20.0.5:36007 (size: 11.5 KiB, free: 434.4 MiB)
[2025-05-08T19:43:38.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T19:43:38.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:36758
[2025-05-08T19:43:38.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:38.203+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 23.9 KiB, free 416.9 MiB)
[2025-05-08T19:43:38.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.9 MiB)
[2025-05-08T19:43:38.208+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T19:43:38.208+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:38.208+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:38.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSchedulerImpl: Adding task set 1245.0 with 1 tasks resource profile 0
[2025-05-08T19:43:38.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:38.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 22.4 KiB, free 416.9 MiB)
[2025-05-08T19:43:38.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.9 MiB)
[2025-05-08T19:43:38.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:38.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:38.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:38.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSchedulerImpl: Adding task set 1246.0 with 1 tasks resource profile 0
[2025-05-08T19:43:38.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:38.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 22.4 KiB, free 416.8 MiB)
[2025-05-08T19:43:38.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: Starting task 0.0 in stage 1245.0 (TID 1509) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:38.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 WARN TaskSetManager: Lost task 0.0 in stage 1330.0 (TID 1508) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 0
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:38.217+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.218+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.219+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.220+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.221+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.222+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.223+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.224+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.225+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.226+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.227+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.228+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - )
[2025-05-08T19:43:38.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSetManager: task 0.0 in stage 1330.0 (TID 1508) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSchedulerImpl: Removed TaskSet 1330.0, whose tasks have all completed, from pool
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.8 MiB)
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSchedulerImpl: Adding task set 1247.0 with 1 tasks resource profile 0
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:38.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 28.8 KiB, free 416.8 MiB)
[2025-05-08T19:43:38.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.8 MiB)
[2025-05-08T19:43:38.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T19:43:38.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:38.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:38.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO TaskSchedulerImpl: Adding task set 1248.0 with 1 tasks resource profile 0
[2025-05-08T19:43:38.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Marking ShuffleMapStage 1330 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1254 (map at GraphFrame.scala:187)
[2025-05-08T19:43:38.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: ShuffleMapStage 1330 (collect at /opt/airflow/spark/build_graph.py:229) failed in 168.433 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 0
[2025-05-08T19:43:38.252+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:38.253+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:38.253+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.253+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:38.253+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:38.253+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:38.253+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:38.253+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:38.254+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:38.254+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:38.254+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:38.254+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:38.254+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:38.254+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T19:43:38.254+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.255+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.256+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.256+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.256+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.256+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.256+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.256+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.256+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.257+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.258+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.258+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.259+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.259+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.260+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.261+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.262+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T19:43:38.263+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.graphx.VertexRDD.compute(VertexRDD.scala:69)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.264+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:38.265+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:38.266+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:38.267+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:38.267+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Resubmitting ShuffleMapStage 1254 (map at GraphFrame.scala:187) and ShuffleMapStage 1330 (collect at /opt/airflow/spark/build_graph.py:229) due to fetch failure
[2025-05-08T19:43:38.267+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T19:43:38.317+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:38 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T19:43:39.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSetManager: Starting task 0.0 in stage 1246.0 (TID 1510) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:39.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSetManager: Finished task 0.0 in stage 1245.0 (TID 1509) in 1321 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:43:39.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSchedulerImpl: Removed TaskSet 1245.0, whose tasks have all completed, from pool
[2025-05-08T19:43:39.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: ShuffleMapStage 1245 (rdd at GraphFrame.scala:187) finished in 1.335 s
[2025-05-08T19:43:39.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:39.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1338, ShuffleMapStage 1247, ShuffleMapStage 1248, ShuffleMapStage 1335, ShuffleMapStage 1336, ShuffleMapStage 1246)
[2025-05-08T19:43:39.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270, ShuffleMapStage 1249)
[2025-05-08T19:43:39.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:39.547+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 172.20.0.5:36007 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:43:39.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSetManager: Starting task 0.0 in stage 1247.0 (TID 1511) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:39.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSetManager: Finished task 0.0 in stage 1246.0 (TID 1510) in 272 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:43:39.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSchedulerImpl: Removed TaskSet 1246.0, whose tasks have all completed, from pool
[2025-05-08T19:43:39.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: ShuffleMapStage 1246 (rdd at GraphFrame.scala:187) finished in 1.600 s
[2025-05-08T19:43:39.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:39.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1338, ShuffleMapStage 1247, ShuffleMapStage 1248, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:43:39.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270, ShuffleMapStage 1249)
[2025-05-08T19:43:39.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:39.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 172.20.0.5:36007 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:43:39.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSetManager: Starting task 0.0 in stage 1248.0 (TID 1512) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:39.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSetManager: Finished task 0.0 in stage 1247.0 (TID 1511) in 108 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:43:39.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO TaskSchedulerImpl: Removed TaskSet 1247.0, whose tasks have all completed, from pool
[2025-05-08T19:43:39.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: ShuffleMapStage 1247 (rdd at GraphFrame.scala:187) finished in 1.703 s
[2025-05-08T19:43:39.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:39.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1338, ShuffleMapStage 1248, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:43:39.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270, ShuffleMapStage 1249)
[2025-05-08T19:43:39.918+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:39.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:39 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 172.20.0.5:36007 (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSetManager: Starting task 1.0 in stage 1335.0 (TID 1513) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:40.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSetManager: Finished task 0.0 in stage 1248.0 (TID 1512) in 445 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:43:40.361+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSchedulerImpl: Removed TaskSet 1248.0, whose tasks have all completed, from pool
[2025-05-08T19:43:40.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: ShuffleMapStage 1248 (rdd at GraphFrame.scala:187) finished in 2.144 s
[2025-05-08T19:43:40.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:40.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1338, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:43:40.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270, ShuffleMapStage 1249)
[2025-05-08T19:43:40.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:40.367+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:40.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 96.7 KiB, free 416.7 MiB)
[2025-05-08T19:43:40.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 416.7 MiB)
[2025-05-08T19:43:40.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_171_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on f2a432e4376a:35283 (size: 36.3 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:40.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:43:40.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSchedulerImpl: Adding task set 1249.0 with 41 tasks resource profile 0
[2025-05-08T19:43:40.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 172.20.0.5:36007 (size: 39.5 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 172.20.0.5:36007 in memory (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.411+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 172.20.0.5:36007 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_172_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_173_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 172.20.0.5:36007 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.532+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_164_piece0 on f2a432e4376a:35283 in memory (size: 13.7 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.536+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 172.20.0.5:36007 in memory (size: 13.7 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.541+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_163_piece0 on f2a432e4376a:35283 in memory (size: 11.3 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.544+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 172.20.0.5:36007 in memory (size: 11.3 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_165_piece0 on f2a432e4376a:35283 in memory (size: 11.5 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 172.20.0.5:36007 in memory (size: 11.5 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.596+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:43:40.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSetManager: Starting task 1.0 in stage 1249.0 (TID 1514) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:40.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 WARN TaskSetManager: Lost task 1.0 in stage 1335.0 (TID 1513) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=115, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-08T19:43:40.602+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 115 partition 0
[2025-05-08T19:43:40.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:40.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:40.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:40.602+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:40.602+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:40.602+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:40.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T19:43:40.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:40.607+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:40.608+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:40.608+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:40.608+0000] {spark_submit.py:571} INFO - )
[2025-05-08T19:43:40.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSetManager: task 1.0 in stage 1335.0 (TID 1513) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T19:43:40.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSchedulerImpl: Removed TaskSet 1335.0, whose tasks have all completed, from pool
[2025-05-08T19:43:40.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Marking ShuffleMapStage 1335 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:43:40.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: ShuffleMapStage 1335 (collect at /opt/airflow/spark/build_graph.py:229) failed in 8.426 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 115 partition 0
[2025-05-08T19:43:40.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T19:43:40.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T19:43:40.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T19:43:40.609+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T19:43:40.609+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T19:43:40.609+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T19:43:40.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T19:43:40.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T19:43:40.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T19:43:40.614+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T19:43:40.615+0000] {spark_submit.py:571} INFO - 
[2025-05-08T19:43:40.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Resubmitting ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229) and ShuffleMapStage 1335 (collect at /opt/airflow/spark/build_graph.py:229) due to fetch failure
[2025-05-08T19:43:40.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 172.20.0.5:36007 (size: 36.3 KiB, free: 434.3 MiB)
[2025-05-08T19:43:40.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:36758
[2025-05-08T19:43:40.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T19:43:40.805+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:40.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 23.9 KiB, free 416.9 MiB)
[2025-05-08T19:43:40.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.9 MiB)
[2025-05-08T19:43:40.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:40.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:40.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSchedulerImpl: Adding task set 1331.1 with 1 tasks resource profile 0
[2025-05-08T19:43:40.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:40.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 22.4 KiB, free 416.8 MiB)
[2025-05-08T19:43:40.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.8 MiB)
[2025-05-08T19:43:40.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:40.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:40.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSchedulerImpl: Adding task set 1332.1 with 1 tasks resource profile 0
[2025-05-08T19:43:40.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:40.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 22.4 KiB, free 416.8 MiB)
[2025-05-08T19:43:40.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.8 MiB)
[2025-05-08T19:43:40.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:40.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:40.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSchedulerImpl: Adding task set 1333.1 with 1 tasks resource profile 0
[2025-05-08T19:43:40.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:43:40.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 28.8 KiB, free 416.8 MiB)
[2025-05-08T19:43:40.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.7 MiB)
[2025-05-08T19:43:40.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T19:43:40.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:40.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:43:40.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:40 INFO TaskSchedulerImpl: Adding task set 1334.1 with 1 tasks resource profile 0
[2025-05-08T19:43:41.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:41 INFO TaskSetManager: Starting task 2.0 in stage 1249.0 (TID 1515) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:41.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:41 INFO TaskSetManager: Finished task 1.0 in stage 1249.0 (TID 1514) in 1220 ms on 172.20.0.5 (executor 1) (1/41)
[2025-05-08T19:43:41.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:41 INFO TaskSetManager: Starting task 3.0 in stage 1249.0 (TID 1516) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:41.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:41 INFO TaskSetManager: Finished task 2.0 in stage 1249.0 (TID 1515) in 84 ms on 172.20.0.5 (executor 1) (2/41)
[2025-05-08T19:43:41.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:41 INFO TaskSetManager: Starting task 6.0 in stage 1249.0 (TID 1517) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:41.946+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:41 INFO TaskSetManager: Finished task 3.0 in stage 1249.0 (TID 1516) in 42 ms on 172.20.0.5 (executor 1) (3/41)
[2025-05-08T19:43:42.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 7.0 in stage 1249.0 (TID 1518) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 6.0 in stage 1249.0 (TID 1517) in 61 ms on 172.20.0.5 (executor 1) (4/41)
[2025-05-08T19:43:42.096+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 8.0 in stage 1249.0 (TID 1519) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.097+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 7.0 in stage 1249.0 (TID 1518) in 90 ms on 172.20.0.5 (executor 1) (5/41)
[2025-05-08T19:43:42.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 9.0 in stage 1249.0 (TID 1520) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 8.0 in stage 1249.0 (TID 1519) in 79 ms on 172.20.0.5 (executor 1) (6/41)
[2025-05-08T19:43:42.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 10.0 in stage 1249.0 (TID 1521) (172.20.0.5, executor 1, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 9.0 in stage 1249.0 (TID 1520) in 36 ms on 172.20.0.5 (executor 1) (7/41)
[2025-05-08T19:43:42.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 11.0 in stage 1249.0 (TID 1522) (172.20.0.5, executor 1, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 10.0 in stage 1249.0 (TID 1521) in 58 ms on 172.20.0.5 (executor 1) (8/41)
[2025-05-08T19:43:42.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:36758
[2025-05-08T19:43:42.352+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 12.0 in stage 1249.0 (TID 1523) (172.20.0.5, executor 1, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.353+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 11.0 in stage 1249.0 (TID 1522) in 84 ms on 172.20.0.5 (executor 1) (9/41)
[2025-05-08T19:43:42.432+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 13.0 in stage 1249.0 (TID 1524) (172.20.0.5, executor 1, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.434+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 12.0 in stage 1249.0 (TID 1523) in 82 ms on 172.20.0.5 (executor 1) (10/41)
[2025-05-08T19:43:42.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 14.0 in stage 1249.0 (TID 1525) (172.20.0.5, executor 1, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 13.0 in stage 1249.0 (TID 1524) in 71 ms on 172.20.0.5 (executor 1) (11/41)
[2025-05-08T19:43:42.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 15.0 in stage 1249.0 (TID 1526) (172.20.0.5, executor 1, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 14.0 in stage 1249.0 (TID 1525) in 72 ms on 172.20.0.5 (executor 1) (12/41)
[2025-05-08T19:43:42.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 16.0 in stage 1249.0 (TID 1527) (172.20.0.5, executor 1, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.642+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 15.0 in stage 1249.0 (TID 1526) in 68 ms on 172.20.0.5 (executor 1) (13/41)
[2025-05-08T19:43:42.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 17.0 in stage 1249.0 (TID 1528) (172.20.0.5, executor 1, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 16.0 in stage 1249.0 (TID 1527) in 58 ms on 172.20.0.5 (executor 1) (14/41)
[2025-05-08T19:43:42.759+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 18.0 in stage 1249.0 (TID 1529) (172.20.0.5, executor 1, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.759+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 17.0 in stage 1249.0 (TID 1528) in 61 ms on 172.20.0.5 (executor 1) (15/41)
[2025-05-08T19:43:42.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 19.0 in stage 1249.0 (TID 1530) (172.20.0.5, executor 1, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 18.0 in stage 1249.0 (TID 1529) in 48 ms on 172.20.0.5 (executor 1) (16/41)
[2025-05-08T19:43:42.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 20.0 in stage 1249.0 (TID 1531) (172.20.0.5, executor 1, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 19.0 in stage 1249.0 (TID 1530) in 59 ms on 172.20.0.5 (executor 1) (17/41)
[2025-05-08T19:43:42.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 21.0 in stage 1249.0 (TID 1532) (172.20.0.5, executor 1, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 20.0 in stage 1249.0 (TID 1531) in 68 ms on 172.20.0.5 (executor 1) (18/41)
[2025-05-08T19:43:42.947+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:36758
[2025-05-08T19:43:42.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Starting task 22.0 in stage 1249.0 (TID 1533) (172.20.0.5, executor 1, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:42.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:42 INFO TaskSetManager: Finished task 21.0 in stage 1249.0 (TID 1532) in 61 ms on 172.20.0.5 (executor 1) (19/41)
[2025-05-08T19:43:43.033+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 23.0 in stage 1249.0 (TID 1534) (172.20.0.5, executor 1, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.033+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 22.0 in stage 1249.0 (TID 1533) in 44 ms on 172.20.0.5 (executor 1) (20/41)
[2025-05-08T19:43:43.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 24.0 in stage 1249.0 (TID 1535) (172.20.0.5, executor 1, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.070+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 23.0 in stage 1249.0 (TID 1534) in 38 ms on 172.20.0.5 (executor 1) (21/41)
[2025-05-08T19:43:43.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 25.0 in stage 1249.0 (TID 1536) (172.20.0.5, executor 1, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 24.0 in stage 1249.0 (TID 1535) in 34 ms on 172.20.0.5 (executor 1) (22/41)
[2025-05-08T19:43:43.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 26.0 in stage 1249.0 (TID 1537) (172.20.0.5, executor 1, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 25.0 in stage 1249.0 (TID 1536) in 33 ms on 172.20.0.5 (executor 1) (23/41)
[2025-05-08T19:43:43.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 27.0 in stage 1249.0 (TID 1538) (172.20.0.5, executor 1, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 26.0 in stage 1249.0 (TID 1537) in 42 ms on 172.20.0.5 (executor 1) (24/41)
[2025-05-08T19:43:43.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 28.0 in stage 1249.0 (TID 1539) (172.20.0.5, executor 1, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.212+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 27.0 in stage 1249.0 (TID 1538) in 36 ms on 172.20.0.5 (executor 1) (25/41)
[2025-05-08T19:43:43.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 29.0 in stage 1249.0 (TID 1540) (172.20.0.5, executor 1, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 28.0 in stage 1249.0 (TID 1539) in 57 ms on 172.20.0.5 (executor 1) (26/41)
[2025-05-08T19:43:43.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 30.0 in stage 1249.0 (TID 1541) (172.20.0.5, executor 1, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 29.0 in stage 1249.0 (TID 1540) in 34 ms on 172.20.0.5 (executor 1) (27/41)
[2025-05-08T19:43:43.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 31.0 in stage 1249.0 (TID 1542) (172.20.0.5, executor 1, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 30.0 in stage 1249.0 (TID 1541) in 46 ms on 172.20.0.5 (executor 1) (28/41)
[2025-05-08T19:43:43.363+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:36758
[2025-05-08T19:43:43.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 32.0 in stage 1249.0 (TID 1543) (172.20.0.5, executor 1, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.404+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 31.0 in stage 1249.0 (TID 1542) in 57 ms on 172.20.0.5 (executor 1) (29/41)
[2025-05-08T19:43:43.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 33.0 in stage 1249.0 (TID 1544) (172.20.0.5, executor 1, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 32.0 in stage 1249.0 (TID 1543) in 62 ms on 172.20.0.5 (executor 1) (30/41)
[2025-05-08T19:43:43.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 34.0 in stage 1249.0 (TID 1545) (172.20.0.5, executor 1, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.508+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 33.0 in stage 1249.0 (TID 1544) in 42 ms on 172.20.0.5 (executor 1) (31/41)
[2025-05-08T19:43:43.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 35.0 in stage 1249.0 (TID 1546) (172.20.0.5, executor 1, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.556+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 34.0 in stage 1249.0 (TID 1545) in 50 ms on 172.20.0.5 (executor 1) (32/41)
[2025-05-08T19:43:43.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 36.0 in stage 1249.0 (TID 1547) (172.20.0.5, executor 1, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 35.0 in stage 1249.0 (TID 1546) in 33 ms on 172.20.0.5 (executor 1) (33/41)
[2025-05-08T19:43:43.618+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 37.0 in stage 1249.0 (TID 1548) (172.20.0.5, executor 1, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.619+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 36.0 in stage 1249.0 (TID 1547) in 32 ms on 172.20.0.5 (executor 1) (34/41)
[2025-05-08T19:43:43.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 38.0 in stage 1249.0 (TID 1549) (172.20.0.5, executor 1, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 37.0 in stage 1249.0 (TID 1548) in 41 ms on 172.20.0.5 (executor 1) (35/41)
[2025-05-08T19:43:43.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 39.0 in stage 1249.0 (TID 1550) (172.20.0.5, executor 1, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 38.0 in stage 1249.0 (TID 1549) in 49 ms on 172.20.0.5 (executor 1) (36/41)
[2025-05-08T19:43:43.734+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 40.0 in stage 1249.0 (TID 1551) (172.20.0.5, executor 1, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 39.0 in stage 1249.0 (TID 1550) in 29 ms on 172.20.0.5 (executor 1) (37/41)
[2025-05-08T19:43:43.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 0.0 in stage 1249.0 (TID 1552) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 40.0 in stage 1249.0 (TID 1551) in 27 ms on 172.20.0.5 (executor 1) (38/41)
[2025-05-08T19:43:43.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 4.0 in stage 1249.0 (TID 1553) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.829+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 0.0 in stage 1249.0 (TID 1552) in 68 ms on 172.20.0.5 (executor 1) (39/41)
[2025-05-08T19:43:43.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 5.0 in stage 1249.0 (TID 1554) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.858+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 4.0 in stage 1249.0 (TID 1553) in 30 ms on 172.20.0.5 (executor 1) (40/41)
[2025-05-08T19:43:43.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 0.0 in stage 1331.1 (TID 1555) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 5.0 in stage 1249.0 (TID 1554) in 23 ms on 172.20.0.5 (executor 1) (41/41)
[2025-05-08T19:43:43.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSchedulerImpl: Removed TaskSet 1249.0, whose tasks have all completed, from pool
[2025-05-08T19:43:43.886+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: ShuffleMapStage 1249 (rdd at GraphFrame.scala:187) finished in 3.516 s
[2025-05-08T19:43:43.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:43.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1336, ShuffleMapStage 1333)
[2025-05-08T19:43:43.903+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:43.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:43.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: Submitting ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:43.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 70.3 KiB, free 416.7 MiB)
[2025-05-08T19:43:43.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T19:43:43.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 416.6 MiB)
[2025-05-08T19:43:43.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on f2a432e4376a:35283 (size: 28.3 KiB, free: 432.5 MiB)
[2025-05-08T19:43:43.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:43.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:43.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSchedulerImpl: Adding task set 1250.0 with 10 tasks resource profile 0
[2025-05-08T19:43:43.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: Submitting ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:43.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 70.6 KiB, free 416.6 MiB)
[2025-05-08T19:43:43.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 28.4 KiB, free 416.6 MiB)
[2025-05-08T19:43:43.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on f2a432e4376a:35283 (size: 28.4 KiB, free: 432.5 MiB)
[2025-05-08T19:43:43.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:43.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:43.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSchedulerImpl: Adding task set 1251.0 with 10 tasks resource profile 0
[2025-05-08T19:43:43.950+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Starting task 0.0 in stage 1250.0 (TID 1556) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:43.951+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSetManager: Finished task 0.0 in stage 1331.1 (TID 1555) in 72 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:43:43.951+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO TaskSchedulerImpl: Removed TaskSet 1331.1, whose tasks have all completed, from pool
[2025-05-08T19:43:43.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229) finished in 3.147 s
[2025-05-08T19:43:43.954+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:43.955+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: running: Set(ShuffleMapStage 1250, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1251, ShuffleMapStage 1332, ShuffleMapStage 1336, ShuffleMapStage 1333)
[2025-05-08T19:43:43.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:43.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:43.964+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 172.20.0.5:36007 (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T19:43:43.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:36758
[2025-05-08T19:43:44.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 1.0 in stage 1250.0 (TID 1557) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.046+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 0.0 in stage 1250.0 (TID 1556) in 95 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:44.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 2.0 in stage 1250.0 (TID 1558) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 1.0 in stage 1250.0 (TID 1557) in 28 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:44.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 3.0 in stage 1250.0 (TID 1559) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 2.0 in stage 1250.0 (TID 1558) in 38 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:44.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 4.0 in stage 1250.0 (TID 1560) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.149+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 3.0 in stage 1250.0 (TID 1559) in 37 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:44.184+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 5.0 in stage 1250.0 (TID 1561) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.185+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 4.0 in stage 1250.0 (TID 1560) in 36 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:44.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 6.0 in stage 1250.0 (TID 1562) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.217+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 5.0 in stage 1250.0 (TID 1561) in 33 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:44.248+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 7.0 in stage 1250.0 (TID 1563) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.249+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 6.0 in stage 1250.0 (TID 1562) in 32 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:44.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 8.0 in stage 1250.0 (TID 1564) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.279+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 7.0 in stage 1250.0 (TID 1563) in 31 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:44.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 9.0 in stage 1250.0 (TID 1565) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 8.0 in stage 1250.0 (TID 1564) in 20 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:44.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 0.0 in stage 1251.0 (TID 1566) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 9.0 in stage 1250.0 (TID 1565) in 24 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:44.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSchedulerImpl: Removed TaskSet 1250.0, whose tasks have all completed, from pool
[2025-05-08T19:43:44.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: ShuffleMapStage 1250 (rdd at GraphFrame.scala:187) finished in 0.441 s
[2025-05-08T19:43:44.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:44.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1251, ShuffleMapStage 1332, ShuffleMapStage 1336, ShuffleMapStage 1333)
[2025-05-08T19:43:44.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:44.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:44.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 172.20.0.5:36007 (size: 28.4 KiB, free: 434.2 MiB)
[2025-05-08T19:43:44.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 1.0 in stage 1251.0 (TID 1567) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 0.0 in stage 1251.0 (TID 1566) in 70 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:44.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 2.0 in stage 1251.0 (TID 1568) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.426+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 1.0 in stage 1251.0 (TID 1567) in 33 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:44.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 3.0 in stage 1251.0 (TID 1569) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 2.0 in stage 1251.0 (TID 1568) in 46 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:44.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 4.0 in stage 1251.0 (TID 1570) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 3.0 in stage 1251.0 (TID 1569) in 33 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:44.533+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 5.0 in stage 1251.0 (TID 1571) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.535+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 4.0 in stage 1251.0 (TID 1570) in 31 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:44.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 6.0 in stage 1251.0 (TID 1572) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 5.0 in stage 1251.0 (TID 1571) in 22 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:44.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 7.0 in stage 1251.0 (TID 1573) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 6.0 in stage 1251.0 (TID 1572) in 32 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:44.610+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 8.0 in stage 1251.0 (TID 1574) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.611+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 7.0 in stage 1251.0 (TID 1573) in 24 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:44.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 9.0 in stage 1251.0 (TID 1575) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 8.0 in stage 1251.0 (TID 1574) in 25 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:44.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 0.0 in stage 1332.1 (TID 1576) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 9.0 in stage 1251.0 (TID 1575) in 26 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:44.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSchedulerImpl: Removed TaskSet 1251.0, whose tasks have all completed, from pool
[2025-05-08T19:43:44.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: ShuffleMapStage 1251 (rdd at GraphFrame.scala:187) finished in 0.754 s
[2025-05-08T19:43:44.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:44.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1332, ShuffleMapStage 1336, ShuffleMapStage 1333)
[2025-05-08T19:43:44.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:44.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:44.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: Submitting ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:44.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 83.7 KiB, free 416.5 MiB)
[2025-05-08T19:43:44.666+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 32.0 KiB, free 416.4 MiB)
[2025-05-08T19:43:44.666+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on f2a432e4376a:35283 (size: 32.0 KiB, free: 432.5 MiB)
[2025-05-08T19:43:44.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:44.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: Submitting 20 missing tasks from ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:43:44.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSchedulerImpl: Adding task set 1252.0 with 20 tasks resource profile 0
[2025-05-08T19:43:44.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 172.20.0.5:36007 (size: 11.0 KiB, free: 434.2 MiB)
[2025-05-08T19:43:44.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 0.0 in stage 1252.0 (TID 1577) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 0.0 in stage 1332.1 (TID 1576) in 73 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:43:44.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSchedulerImpl: Removed TaskSet 1332.1, whose tasks have all completed, from pool
[2025-05-08T19:43:44.734+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: ShuffleMapStage 1332 (collect at /opt/airflow/spark/build_graph.py:229) finished in 3.924 s
[2025-05-08T19:43:44.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:44.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1252, ShuffleMapStage 1336, ShuffleMapStage 1333)
[2025-05-08T19:43:44.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:44.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:44.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 172.20.0.5:36007 (size: 32.0 KiB, free: 434.2 MiB)
[2025-05-08T19:43:44.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:36758
[2025-05-08T19:43:44.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 1.0 in stage 1252.0 (TID 1578) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 0.0 in stage 1252.0 (TID 1577) in 57 ms on 172.20.0.5 (executor 1) (1/20)
[2025-05-08T19:43:44.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 2.0 in stage 1252.0 (TID 1579) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 1.0 in stage 1252.0 (TID 1578) in 12 ms on 172.20.0.5 (executor 1) (2/20)
[2025-05-08T19:43:44.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 3.0 in stage 1252.0 (TID 1580) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 2.0 in stage 1252.0 (TID 1579) in 14 ms on 172.20.0.5 (executor 1) (3/20)
[2025-05-08T19:43:44.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 4.0 in stage 1252.0 (TID 1581) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 3.0 in stage 1252.0 (TID 1580) in 18 ms on 172.20.0.5 (executor 1) (4/20)
[2025-05-08T19:43:44.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 5.0 in stage 1252.0 (TID 1582) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 4.0 in stage 1252.0 (TID 1581) in 13 ms on 172.20.0.5 (executor 1) (5/20)
[2025-05-08T19:43:44.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 6.0 in stage 1252.0 (TID 1583) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 5.0 in stage 1252.0 (TID 1582) in 11 ms on 172.20.0.5 (executor 1) (6/20)
[2025-05-08T19:43:44.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 7.0 in stage 1252.0 (TID 1584) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 6.0 in stage 1252.0 (TID 1583) in 14 ms on 172.20.0.5 (executor 1) (7/20)
[2025-05-08T19:43:44.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 8.0 in stage 1252.0 (TID 1585) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.881+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 7.0 in stage 1252.0 (TID 1584) in 12 ms on 172.20.0.5 (executor 1) (8/20)
[2025-05-08T19:43:44.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 9.0 in stage 1252.0 (TID 1586) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 8.0 in stage 1252.0 (TID 1585) in 12 ms on 172.20.0.5 (executor 1) (9/20)
[2025-05-08T19:43:44.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 10.0 in stage 1252.0 (TID 1587) (172.20.0.5, executor 1, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 9.0 in stage 1252.0 (TID 1586) in 12 ms on 172.20.0.5 (executor 1) (10/20)
[2025-05-08T19:43:44.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:36758
[2025-05-08T19:43:44.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 11.0 in stage 1252.0 (TID 1588) (172.20.0.5, executor 1, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.928+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 10.0 in stage 1252.0 (TID 1587) in 24 ms on 172.20.0.5 (executor 1) (11/20)
[2025-05-08T19:43:44.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 12.0 in stage 1252.0 (TID 1589) (172.20.0.5, executor 1, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 11.0 in stage 1252.0 (TID 1588) in 13 ms on 172.20.0.5 (executor 1) (12/20)
[2025-05-08T19:43:44.951+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 13.0 in stage 1252.0 (TID 1590) (172.20.0.5, executor 1, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 12.0 in stage 1252.0 (TID 1589) in 11 ms on 172.20.0.5 (executor 1) (13/20)
[2025-05-08T19:43:44.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 14.0 in stage 1252.0 (TID 1591) (172.20.0.5, executor 1, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.963+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 13.0 in stage 1252.0 (TID 1590) in 12 ms on 172.20.0.5 (executor 1) (14/20)
[2025-05-08T19:43:44.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 15.0 in stage 1252.0 (TID 1592) (172.20.0.5, executor 1, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 14.0 in stage 1252.0 (TID 1591) in 15 ms on 172.20.0.5 (executor 1) (15/20)
[2025-05-08T19:43:44.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 16.0 in stage 1252.0 (TID 1593) (172.20.0.5, executor 1, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:44.988+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 15.0 in stage 1252.0 (TID 1592) in 11 ms on 172.20.0.5 (executor 1) (16/20)
[2025-05-08T19:43:44.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Starting task 17.0 in stage 1252.0 (TID 1594) (172.20.0.5, executor 1, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:44 INFO TaskSetManager: Finished task 16.0 in stage 1252.0 (TID 1593) in 11 ms on 172.20.0.5 (executor 1) (17/20)
[2025-05-08T19:43:45.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 18.0 in stage 1252.0 (TID 1595) (172.20.0.5, executor 1, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 17.0 in stage 1252.0 (TID 1594) in 17 ms on 172.20.0.5 (executor 1) (18/20)
[2025-05-08T19:43:45.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 19.0 in stage 1252.0 (TID 1596) (172.20.0.5, executor 1, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 18.0 in stage 1252.0 (TID 1595) in 14 ms on 172.20.0.5 (executor 1) (19/20)
[2025-05-08T19:43:45.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 0.0 in stage 1333.1 (TID 1597) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 19.0 in stage 1252.0 (TID 1596) in 11 ms on 172.20.0.5 (executor 1) (20/20)
[2025-05-08T19:43:45.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSchedulerImpl: Removed TaskSet 1252.0, whose tasks have all completed, from pool
[2025-05-08T19:43:45.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: ShuffleMapStage 1252 (rdd at GraphFrame.scala:187) finished in 0.380 s
[2025-05-08T19:43:45.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:45.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1336, ShuffleMapStage 1333)
[2025-05-08T19:43:45.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:45.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:45.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: Submitting ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-08T19:43:45.050+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 172.20.0.5:36007 (size: 11.0 KiB, free: 434.2 MiB)
[2025-05-08T19:43:45.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 189.5 KiB, free 416.3 MiB)
[2025-05-08T19:43:45.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 64.9 KiB, free 416.2 MiB)
[2025-05-08T19:43:45.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on f2a432e4376a:35283 (size: 64.9 KiB, free: 432.4 MiB)
[2025-05-08T19:43:45.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:45.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:45.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSchedulerImpl: Adding task set 1254.0 with 10 tasks resource profile 0
[2025-05-08T19:43:45.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: Submitting ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-08T19:43:45.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 232.9 KiB, free 416.0 MiB)
[2025-05-08T19:43:45.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 415.9 MiB)
[2025-05-08T19:43:45.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on f2a432e4376a:35283 (size: 77.4 KiB, free: 432.3 MiB)
[2025-05-08T19:43:45.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:45.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:45.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSchedulerImpl: Adding task set 1255.0 with 10 tasks resource profile 0
[2025-05-08T19:43:45.067+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: Submitting ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:43:45.075+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 235.8 KiB, free 415.7 MiB)
[2025-05-08T19:43:45.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 415.6 MiB)
[2025-05-08T19:43:45.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on f2a432e4376a:35283 (size: 77.8 KiB, free: 432.3 MiB)
[2025-05-08T19:43:45.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:45.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:45.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSchedulerImpl: Adding task set 1287.0 with 10 tasks resource profile 0
[2025-05-08T19:43:45.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 0.0 in stage 1254.0 (TID 1598) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 0.0 in stage 1333.1 (TID 1597) in 58 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:43:45.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSchedulerImpl: Removed TaskSet 1333.1, whose tasks have all completed, from pool
[2025-05-08T19:43:45.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: ShuffleMapStage 1333 (collect at /opt/airflow/spark/build_graph.py:229) finished in 4.286 s
[2025-05-08T19:43:45.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:45.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1254, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1255, ShuffleMapStage 1336)
[2025-05-08T19:43:45.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:45.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:45.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 172.20.0.5:36007 (size: 64.9 KiB, free: 434.1 MiB)
[2025-05-08T19:43:45.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:36758
[2025-05-08T19:43:45.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_0 in memory on 172.20.0.5:36007 (size: 8.5 KiB, free: 434.1 MiB)
[2025-05-08T19:43:45.419+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:36007 (size: 94.3 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 1.0 in stage 1254.0 (TID 1599) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 0.0 in stage 1254.0 (TID 1598) in 404 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:45.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_1 in memory on 172.20.0.5:36007 (size: 8.0 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 2.0 in stage 1254.0 (TID 1600) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 1.0 in stage 1254.0 (TID 1599) in 40 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:45.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_2 in memory on 172.20.0.5:36007 (size: 7.5 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 3.0 in stage 1254.0 (TID 1601) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 2.0 in stage 1254.0 (TID 1600) in 31 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:45.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_3 in memory on 172.20.0.5:36007 (size: 8.1 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 4.0 in stage 1254.0 (TID 1602) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 3.0 in stage 1254.0 (TID 1601) in 36 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:45.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_4 in memory on 172.20.0.5:36007 (size: 7.7 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 5.0 in stage 1254.0 (TID 1603) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 4.0 in stage 1254.0 (TID 1602) in 37 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:45.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_5 in memory on 172.20.0.5:36007 (size: 7.0 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 6.0 in stage 1254.0 (TID 1604) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 5.0 in stage 1254.0 (TID 1603) in 37 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:45.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_6 in memory on 172.20.0.5:36007 (size: 7.3 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 7.0 in stage 1254.0 (TID 1605) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 6.0 in stage 1254.0 (TID 1604) in 38 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:45.741+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_7 in memory on 172.20.0.5:36007 (size: 8.1 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 8.0 in stage 1254.0 (TID 1606) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 7.0 in stage 1254.0 (TID 1605) in 37 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:45.770+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_8 in memory on 172.20.0.5:36007 (size: 7.6 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 9.0 in stage 1254.0 (TID 1607) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 8.0 in stage 1254.0 (TID 1606) in 26 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:45.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added rdd_169_9 in memory on 172.20.0.5:36007 (size: 8.2 KiB, free: 434.0 MiB)
[2025-05-08T19:43:45.805+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Starting task 0.0 in stage 1255.0 (TID 1608) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:45.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSetManager: Finished task 9.0 in stage 1254.0 (TID 1607) in 27 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:45.806+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO TaskSchedulerImpl: Removed TaskSet 1254.0, whose tasks have all completed, from pool
[2025-05-08T19:43:45.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: ShuffleMapStage 1254 (map at GraphFrame.scala:187) finished in 0.762 s
[2025-05-08T19:43:45.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:45.807+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1255, ShuffleMapStage 1336)
[2025-05-08T19:43:45.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:45.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:45.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 172.20.0.5:36007 (size: 77.4 KiB, free: 433.9 MiB)
[2025-05-08T19:43:45.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:36007 (size: 80.3 KiB, free: 433.8 MiB)
[2025-05-08T19:43:45.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:45 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:36007 (size: 764.6 KiB, free: 433.1 MiB)
[2025-05-08T19:43:46.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 1.0 in stage 1255.0 (TID 1609) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 0.0 in stage 1255.0 (TID 1608) in 404 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:46.264+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 2.0 in stage 1255.0 (TID 1610) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.265+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 1.0 in stage 1255.0 (TID 1609) in 56 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:46.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 3.0 in stage 1255.0 (TID 1611) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 2.0 in stage 1255.0 (TID 1610) in 44 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:46.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 4.0 in stage 1255.0 (TID 1612) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.358+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 3.0 in stage 1255.0 (TID 1611) in 50 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:46.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 5.0 in stage 1255.0 (TID 1613) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 4.0 in stage 1255.0 (TID 1612) in 105 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:46.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 6.0 in stage 1255.0 (TID 1614) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.534+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 5.0 in stage 1255.0 (TID 1613) in 77 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:46.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 7.0 in stage 1255.0 (TID 1615) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 6.0 in stage 1255.0 (TID 1614) in 57 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:46.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 8.0 in stage 1255.0 (TID 1616) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.634+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 7.0 in stage 1255.0 (TID 1615) in 45 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:46.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 9.0 in stage 1255.0 (TID 1617) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 8.0 in stage 1255.0 (TID 1616) in 36 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:46.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 0.0 in stage 1287.0 (TID 1618) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 9.0 in stage 1255.0 (TID 1617) in 38 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:46.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSchedulerImpl: Removed TaskSet 1255.0, whose tasks have all completed, from pool
[2025-05-08T19:43:46.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: ShuffleMapStage 1255 (mapPartitions at VertexRDD.scala:356) finished in 1.651 s
[2025-05-08T19:43:46.707+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:46.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:46.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1256, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1257, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:46.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:46.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: Submitting ShuffleMapStage 1256 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[415] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:46.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 9.9 KiB, free 415.6 MiB)
[2025-05-08T19:43:46.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 415.6 MiB)
[2025-05-08T19:43:46.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on f2a432e4376a:35283 (size: 4.9 KiB, free: 432.3 MiB)
[2025-05-08T19:43:46.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:46.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 172.20.0.5:36007 (size: 77.8 KiB, free: 433.0 MiB)
[2025-05-08T19:43:46.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1256 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[415] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:46.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSchedulerImpl: Adding task set 1256.0 with 10 tasks resource profile 0
[2025-05-08T19:43:46.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: Submitting ShuffleMapStage 1257 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[411] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:46.718+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 10.3 KiB, free 415.6 MiB)
[2025-05-08T19:43:46.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 415.6 MiB)
[2025-05-08T19:43:46.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on f2a432e4376a:35283 (size: 5.0 KiB, free: 432.3 MiB)
[2025-05-08T19:43:46.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:46.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1257 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[411] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:46.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSchedulerImpl: Adding task set 1257.0 with 10 tasks resource profile 0
[2025-05-08T19:43:46.771+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_395_0 in memory on 172.20.0.5:36007 (size: 560.1 KiB, free: 432.4 MiB)
[2025-05-08T19:43:46.778+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.20.0.5:36007 (size: 560.1 KiB, free: 431.9 MiB)
[2025-05-08T19:43:46.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 0.0 in stage 1256.0 (TID 1619) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 0.0 in stage 1287.0 (TID 1618) in 109 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:46.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 172.20.0.5:36007 (size: 4.9 KiB, free: 431.9 MiB)
[2025-05-08T19:43:46.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:36758
[2025-05-08T19:43:46.829+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:36758
[2025-05-08T19:43:46.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_392_0 in memory on 172.20.0.5:36007 (size: 36.3 KiB, free: 431.9 MiB)
[2025-05-08T19:43:46.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_397_0 in memory on 172.20.0.5:36007 (size: 11.2 KiB, free: 431.8 MiB)
[2025-05-08T19:43:46.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_403_0 in memory on 172.20.0.5:36007 (size: 13.2 KiB, free: 431.8 MiB)
[2025-05-08T19:43:46.878+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 1.0 in stage 1256.0 (TID 1620) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.878+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 0.0 in stage 1256.0 (TID 1619) in 65 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:46.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_392_1 in memory on 172.20.0.5:36007 (size: 36.7 KiB, free: 431.8 MiB)
[2025-05-08T19:43:46.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_397_1 in memory on 172.20.0.5:36007 (size: 12.1 KiB, free: 431.8 MiB)
[2025-05-08T19:43:46.899+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_403_1 in memory on 172.20.0.5:36007 (size: 14.1 KiB, free: 431.8 MiB)
[2025-05-08T19:43:46.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 2.0 in stage 1256.0 (TID 1621) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 1.0 in stage 1256.0 (TID 1620) in 27 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:46.920+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_392_2 in memory on 172.20.0.5:36007 (size: 34.2 KiB, free: 431.7 MiB)
[2025-05-08T19:43:46.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_397_2 in memory on 172.20.0.5:36007 (size: 10.9 KiB, free: 431.7 MiB)
[2025-05-08T19:43:46.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_403_2 in memory on 172.20.0.5:36007 (size: 12.9 KiB, free: 431.7 MiB)
[2025-05-08T19:43:46.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 3.0 in stage 1256.0 (TID 1622) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 2.0 in stage 1256.0 (TID 1621) in 26 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:46.944+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_392_3 in memory on 172.20.0.5:36007 (size: 34.5 KiB, free: 431.7 MiB)
[2025-05-08T19:43:46.947+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_397_3 in memory on 172.20.0.5:36007 (size: 10.9 KiB, free: 431.7 MiB)
[2025-05-08T19:43:46.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_403_3 in memory on 172.20.0.5:36007 (size: 12.9 KiB, free: 431.7 MiB)
[2025-05-08T19:43:46.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 4.0 in stage 1256.0 (TID 1623) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 3.0 in stage 1256.0 (TID 1622) in 26 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:46.971+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_392_4 in memory on 172.20.0.5:36007 (size: 33.4 KiB, free: 431.6 MiB)
[2025-05-08T19:43:46.973+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_397_4 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 431.6 MiB)
[2025-05-08T19:43:46.976+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_403_4 in memory on 172.20.0.5:36007 (size: 13.7 KiB, free: 431.6 MiB)
[2025-05-08T19:43:46.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Starting task 5.0 in stage 1256.0 (TID 1624) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:46.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO TaskSetManager: Finished task 4.0 in stage 1256.0 (TID 1623) in 27 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:46.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:46 INFO BlockManagerInfo: Added rdd_392_5 in memory on 172.20.0.5:36007 (size: 34.7 KiB, free: 431.6 MiB)
[2025-05-08T19:43:47.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_397_5 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 431.5 MiB)
[2025-05-08T19:43:47.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_403_5 in memory on 172.20.0.5:36007 (size: 13.7 KiB, free: 431.5 MiB)
[2025-05-08T19:43:47.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 6.0 in stage 1256.0 (TID 1625) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 5.0 in stage 1256.0 (TID 1624) in 26 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:47.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_392_6 in memory on 172.20.0.5:36007 (size: 34.8 KiB, free: 431.5 MiB)
[2025-05-08T19:43:47.023+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_397_6 in memory on 172.20.0.5:36007 (size: 11.4 KiB, free: 431.5 MiB)
[2025-05-08T19:43:47.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_403_6 in memory on 172.20.0.5:36007 (size: 13.4 KiB, free: 431.5 MiB)
[2025-05-08T19:43:47.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 7.0 in stage 1256.0 (TID 1626) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 6.0 in stage 1256.0 (TID 1625) in 23 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:47.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_392_7 in memory on 172.20.0.5:36007 (size: 35.5 KiB, free: 431.4 MiB)
[2025-05-08T19:43:47.046+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_397_7 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 431.4 MiB)
[2025-05-08T19:43:47.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_403_7 in memory on 172.20.0.5:36007 (size: 13.6 KiB, free: 431.4 MiB)
[2025-05-08T19:43:47.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 8.0 in stage 1256.0 (TID 1627) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 7.0 in stage 1256.0 (TID 1626) in 23 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:47.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_392_8 in memory on 172.20.0.5:36007 (size: 36.5 KiB, free: 431.4 MiB)
[2025-05-08T19:43:47.068+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_397_8 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 431.4 MiB)
[2025-05-08T19:43:47.069+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_403_8 in memory on 172.20.0.5:36007 (size: 13.7 KiB, free: 431.4 MiB)
[2025-05-08T19:43:47.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 9.0 in stage 1256.0 (TID 1628) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.074+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 8.0 in stage 1256.0 (TID 1627) in 22 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:47.089+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_392_9 in memory on 172.20.0.5:36007 (size: 35.4 KiB, free: 431.3 MiB)
[2025-05-08T19:43:47.092+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_397_9 in memory on 172.20.0.5:36007 (size: 11.3 KiB, free: 431.3 MiB)
[2025-05-08T19:43:47.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_403_9 in memory on 172.20.0.5:36007 (size: 13.2 KiB, free: 431.3 MiB)
[2025-05-08T19:43:47.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 0.0 in stage 1257.0 (TID 1629) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 9.0 in stage 1256.0 (TID 1628) in 25 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:47.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSchedulerImpl: Removed TaskSet 1256.0, whose tasks have all completed, from pool
[2025-05-08T19:43:47.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: ShuffleMapStage 1256 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.389 s
[2025-05-08T19:43:47.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:47.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1257, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:47.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:47.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:47.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 172.20.0.5:36007 (size: 5.0 KiB, free: 431.3 MiB)
[2025-05-08T19:43:47.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 1.0 in stage 1257.0 (TID 1630) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 0.0 in stage 1257.0 (TID 1629) in 14 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:47.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 2.0 in stage 1257.0 (TID 1631) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 1.0 in stage 1257.0 (TID 1630) in 8 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:47.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 3.0 in stage 1257.0 (TID 1632) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 2.0 in stage 1257.0 (TID 1631) in 8 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:47.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 4.0 in stage 1257.0 (TID 1633) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 3.0 in stage 1257.0 (TID 1632) in 9 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:47.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 5.0 in stage 1257.0 (TID 1634) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 4.0 in stage 1257.0 (TID 1633) in 9 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:47.152+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 6.0 in stage 1257.0 (TID 1635) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 5.0 in stage 1257.0 (TID 1634) in 9 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:47.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 7.0 in stage 1257.0 (TID 1636) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 6.0 in stage 1257.0 (TID 1635) in 8 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:47.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 8.0 in stage 1257.0 (TID 1637) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 7.0 in stage 1257.0 (TID 1636) in 8 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:47.177+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 9.0 in stage 1257.0 (TID 1638) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.177+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 8.0 in stage 1257.0 (TID 1637) in 10 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:47.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 1.0 in stage 1287.0 (TID 1639) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 9.0 in stage 1257.0 (TID 1638) in 11 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSchedulerImpl: Removed TaskSet 1257.0, whose tasks have all completed, from pool
[2025-05-08T19:43:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: ShuffleMapStage 1257 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.471 s
[2025-05-08T19:43:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1258, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:47.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:47.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: Submitting ShuffleMapStage 1258 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[419] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:43:47.196+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 237.5 KiB, free 415.3 MiB)
[2025-05-08T19:43:47.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 415.2 MiB)
[2025-05-08T19:43:47.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.2 MiB)
[2025-05-08T19:43:47.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:47.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1258 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[419] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:47.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSchedulerImpl: Adding task set 1258.0 with 10 tasks resource profile 0
[2025-05-08T19:43:47.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_178_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.2 MiB)
[2025-05-08T19:43:47.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 172.20.0.5:36007 in memory (size: 11.0 KiB, free: 431.3 MiB)
[2025-05-08T19:43:47.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_182_piece0 on f2a432e4376a:35283 in memory (size: 32.0 KiB, free: 432.2 MiB)
[2025-05-08T19:43:47.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 172.20.0.5:36007 in memory (size: 32.0 KiB, free: 431.3 MiB)
[2025-05-08T19:43:47.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_176_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.2 MiB)
[2025-05-08T19:43:47.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 172.20.0.5:36007 in memory (size: 11.7 KiB, free: 431.3 MiB)
[2025-05-08T19:43:47.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_395_1 in memory on 172.20.0.5:36007 (size: 558.2 KiB, free: 430.8 MiB)
[2025-05-08T19:43:47.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_186_piece0 on f2a432e4376a:35283 in memory (size: 4.9 KiB, free: 432.2 MiB)
[2025-05-08T19:43:47.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 172.20.0.5:36007 in memory (size: 4.9 KiB, free: 430.8 MiB)
[2025-05-08T19:43:47.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_183_piece0 on f2a432e4376a:35283 in memory (size: 64.9 KiB, free: 432.3 MiB)
[2025-05-08T19:43:47.245+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.20.0.5:36007 (size: 558.2 KiB, free: 430.3 MiB)
[2025-05-08T19:43:47.246+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 172.20.0.5:36007 in memory (size: 64.9 KiB, free: 430.3 MiB)
[2025-05-08T19:43:47.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_175_piece0 on f2a432e4376a:35283 in memory (size: 36.3 KiB, free: 432.3 MiB)
[2025-05-08T19:43:47.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 172.20.0.5:36007 in memory (size: 36.3 KiB, free: 430.4 MiB)
[2025-05-08T19:43:47.258+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_177_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.4 MiB)
[2025-05-08T19:43:47.267+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 172.20.0.5:36007 in memory (size: 11.0 KiB, free: 430.4 MiB)
[2025-05-08T19:43:47.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_180_piece0 on f2a432e4376a:35283 in memory (size: 28.3 KiB, free: 432.4 MiB)
[2025-05-08T19:43:47.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 172.20.0.5:36007 in memory (size: 28.3 KiB, free: 430.4 MiB)
[2025-05-08T19:43:47.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 0.0 in stage 1258.0 (TID 1640) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.279+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 1.0 in stage 1287.0 (TID 1639) in 91 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:47.281+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_174_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.4 MiB)
[2025-05-08T19:43:47.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 172.20.0.5:36007 in memory (size: 13.8 KiB, free: 430.4 MiB)
[2025-05-08T19:43:47.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 172.20.0.5:36007 (size: 79.0 KiB, free: 430.3 MiB)
[2025-05-08T19:43:47.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_181_piece0 on f2a432e4376a:35283 in memory (size: 28.4 KiB, free: 432.4 MiB)
[2025-05-08T19:43:47.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 172.20.0.5:36007 in memory (size: 28.4 KiB, free: 430.4 MiB)
[2025-05-08T19:43:47.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_184_piece0 on f2a432e4376a:35283 in memory (size: 77.4 KiB, free: 432.5 MiB)
[2025-05-08T19:43:47.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 172.20.0.5:36007 in memory (size: 77.4 KiB, free: 430.4 MiB)
[2025-05-08T19:43:47.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_405_0 in memory on 172.20.0.5:36007 (size: 52.5 KiB, free: 430.4 MiB)
[2025-05-08T19:43:47.315+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:43:47.319+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:43:47.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 1.0 in stage 1258.0 (TID 1641) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 0.0 in stage 1258.0 (TID 1640) in 196 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:47.491+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_405_1 in memory on 172.20.0.5:36007 (size: 53.2 KiB, free: 430.3 MiB)
[2025-05-08T19:43:47.581+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 2.0 in stage 1258.0 (TID 1642) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 1.0 in stage 1258.0 (TID 1641) in 111 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:47.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_395_2 in memory on 172.20.0.5:36007 (size: 663.8 KiB, free: 429.7 MiB)
[2025-05-08T19:43:47.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.20.0.5:36007 (size: 663.8 KiB, free: 429.0 MiB)
[2025-05-08T19:43:47.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_405_2 in memory on 172.20.0.5:36007 (size: 56.0 KiB, free: 429.0 MiB)
[2025-05-08T19:43:47.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 3.0 in stage 1258.0 (TID 1643) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.711+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 2.0 in stage 1258.0 (TID 1642) in 130 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:47.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_395_3 in memory on 172.20.0.5:36007 (size: 695.0 KiB, free: 428.3 MiB)
[2025-05-08T19:43:47.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.20.0.5:36007 (size: 695.0 KiB, free: 427.6 MiB)
[2025-05-08T19:43:47.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_405_3 in memory on 172.20.0.5:36007 (size: 57.3 KiB, free: 427.6 MiB)
[2025-05-08T19:43:47.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 4.0 in stage 1258.0 (TID 1644) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 3.0 in stage 1258.0 (TID 1643) in 140 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:47.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_395_4 in memory on 172.20.0.5:36007 (size: 451.0 KiB, free: 427.1 MiB)
[2025-05-08T19:43:47.875+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.20.0.5:36007 (size: 451.0 KiB, free: 426.7 MiB)
[2025-05-08T19:43:47.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_405_4 in memory on 172.20.0.5:36007 (size: 48.7 KiB, free: 426.6 MiB)
[2025-05-08T19:43:47.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Starting task 5.0 in stage 1258.0 (TID 1645) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:47.941+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO TaskSetManager: Finished task 4.0 in stage 1258.0 (TID 1644) in 92 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:47.961+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_395_5 in memory on 172.20.0.5:36007 (size: 654.0 KiB, free: 426.0 MiB)
[2025-05-08T19:43:47.964+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.20.0.5:36007 (size: 654.0 KiB, free: 425.4 MiB)
[2025-05-08T19:43:47.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:47 INFO BlockManagerInfo: Added rdd_405_5 in memory on 172.20.0.5:36007 (size: 55.3 KiB, free: 425.3 MiB)
[2025-05-08T19:43:48.029+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 6.0 in stage 1258.0 (TID 1646) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 5.0 in stage 1258.0 (TID 1645) in 90 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:48.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_395_6 in memory on 172.20.0.5:36007 (size: 548.2 KiB, free: 424.8 MiB)
[2025-05-08T19:43:48.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.20.0.5:36007 (size: 548.2 KiB, free: 424.2 MiB)
[2025-05-08T19:43:48.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_405_6 in memory on 172.20.0.5:36007 (size: 52.5 KiB, free: 424.2 MiB)
[2025-05-08T19:43:48.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 7.0 in stage 1258.0 (TID 1647) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 6.0 in stage 1258.0 (TID 1646) in 80 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:48.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_395_7 in memory on 172.20.0.5:36007 (size: 557.0 KiB, free: 423.6 MiB)
[2025-05-08T19:43:48.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.20.0.5:36007 (size: 557.0 KiB, free: 423.1 MiB)
[2025-05-08T19:43:48.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_405_7 in memory on 172.20.0.5:36007 (size: 52.3 KiB, free: 423.1 MiB)
[2025-05-08T19:43:48.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 8.0 in stage 1258.0 (TID 1648) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 7.0 in stage 1258.0 (TID 1647) in 101 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:48.239+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_395_8 in memory on 172.20.0.5:36007 (size: 485.3 KiB, free: 422.6 MiB)
[2025-05-08T19:43:48.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.20.0.5:36007 (size: 485.3 KiB, free: 422.1 MiB)
[2025-05-08T19:43:48.245+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_405_8 in memory on 172.20.0.5:36007 (size: 50.1 KiB, free: 422.1 MiB)
[2025-05-08T19:43:48.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 9.0 in stage 1258.0 (TID 1649) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.290+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 8.0 in stage 1258.0 (TID 1648) in 81 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:48.315+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_395_9 in memory on 172.20.0.5:36007 (size: 694.0 KiB, free: 421.4 MiB)
[2025-05-08T19:43:48.319+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.20.0.5:36007 (size: 694.0 KiB, free: 420.7 MiB)
[2025-05-08T19:43:48.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added rdd_405_9 in memory on 172.20.0.5:36007 (size: 57.6 KiB, free: 420.6 MiB)
[2025-05-08T19:43:48.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 2.0 in stage 1287.0 (TID 1650) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 9.0 in stage 1258.0 (TID 1649) in 117 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:48.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSchedulerImpl: Removed TaskSet 1258.0, whose tasks have all completed, from pool
[2025-05-08T19:43:48.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: ShuffleMapStage 1258 (mapPartitions at GraphImpl.scala:208) finished in 1.217 s
[2025-05-08T19:43:48.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:48.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:48.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1260, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1259, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:48.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:48.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: Submitting ShuffleMapStage 1259 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[428] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:48.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 11.7 KiB, free 416.4 MiB)
[2025-05-08T19:43:48.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 416.4 MiB)
[2025-05-08T19:43:48.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on f2a432e4376a:35283 (size: 5.4 KiB, free: 432.5 MiB)
[2025-05-08T19:43:48.419+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:48.419+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1259 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[428] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:48.419+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSchedulerImpl: Adding task set 1259.0 with 10 tasks resource profile 0
[2025-05-08T19:43:48.420+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: Submitting ShuffleMapStage 1260 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[432] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:43:48.421+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 10.5 KiB, free 416.4 MiB)
[2025-05-08T19:43:48.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 416.4 MiB)
[2025-05-08T19:43:48.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on f2a432e4376a:35283 (size: 5.1 KiB, free: 432.5 MiB)
[2025-05-08T19:43:48.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:48.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1260 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[432] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:48.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSchedulerImpl: Adding task set 1260.0 with 10 tasks resource profile 0
[2025-05-08T19:43:48.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 0.0 in stage 1259.0 (TID 1651) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 2.0 in stage 1287.0 (TID 1650) in 34 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:48.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 172.20.0.5:36007 (size: 5.4 KiB, free: 420.6 MiB)
[2025-05-08T19:43:48.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:43:48.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 1.0 in stage 1259.0 (TID 1652) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 0.0 in stage 1259.0 (TID 1651) in 88 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:48.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 2.0 in stage 1259.0 (TID 1653) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 1.0 in stage 1259.0 (TID 1652) in 48 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:48.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Removed broadcast_188_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:48.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 172.20.0.5:36007 in memory (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T19:43:48.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 3.0 in stage 1259.0 (TID 1654) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 2.0 in stage 1259.0 (TID 1653) in 40 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:48.613+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Removed broadcast_187_piece0 on f2a432e4376a:35283 in memory (size: 5.0 KiB, free: 432.6 MiB)
[2025-05-08T19:43:48.618+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 172.20.0.5:36007 in memory (size: 5.0 KiB, free: 420.7 MiB)
[2025-05-08T19:43:48.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Removed broadcast_167_piece0 on f2a432e4376a:35283 in memory (size: 39.5 KiB, free: 432.6 MiB)
[2025-05-08T19:43:48.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 172.20.0.5:36007 in memory (size: 39.5 KiB, free: 420.8 MiB)
[2025-05-08T19:43:48.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 4.0 in stage 1259.0 (TID 1655) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 3.0 in stage 1259.0 (TID 1654) in 38 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:48.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 5.0 in stage 1259.0 (TID 1656) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.709+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 4.0 in stage 1259.0 (TID 1655) in 59 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:48.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 6.0 in stage 1259.0 (TID 1657) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 5.0 in stage 1259.0 (TID 1656) in 32 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:48.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 7.0 in stage 1259.0 (TID 1658) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 6.0 in stage 1259.0 (TID 1657) in 24 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:48.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 8.0 in stage 1259.0 (TID 1659) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 7.0 in stage 1259.0 (TID 1658) in 29 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:48.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 9.0 in stage 1259.0 (TID 1660) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4641 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 8.0 in stage 1259.0 (TID 1659) in 28 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:48.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 0.0 in stage 1260.0 (TID 1661) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 9.0 in stage 1259.0 (TID 1660) in 31 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:48.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSchedulerImpl: Removed TaskSet 1259.0, whose tasks have all completed, from pool
[2025-05-08T19:43:48.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: ShuffleMapStage 1259 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.435 s
[2025-05-08T19:43:48.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:48.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1260, ShuffleMapStage 1336)
[2025-05-08T19:43:48.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:48.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:48.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 172.20.0.5:36007 (size: 5.1 KiB, free: 420.8 MiB)
[2025-05-08T19:43:48.916+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 1.0 in stage 1260.0 (TID 1662) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 0.0 in stage 1260.0 (TID 1661) in 67 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:48.959+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 2.0 in stage 1260.0 (TID 1663) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 1.0 in stage 1260.0 (TID 1662) in 42 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:48.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Starting task 3.0 in stage 1260.0 (TID 1664) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:48.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:48 INFO TaskSetManager: Finished task 2.0 in stage 1260.0 (TID 1663) in 33 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:49.023+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 4.0 in stage 1260.0 (TID 1665) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.024+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 3.0 in stage 1260.0 (TID 1664) in 33 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:49.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 5.0 in stage 1260.0 (TID 1666) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 4.0 in stage 1260.0 (TID 1665) in 32 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:49.089+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 6.0 in stage 1260.0 (TID 1667) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 5.0 in stage 1260.0 (TID 1666) in 34 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:49.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 7.0 in stage 1260.0 (TID 1668) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.131+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 6.0 in stage 1260.0 (TID 1667) in 41 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:49.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 8.0 in stage 1260.0 (TID 1669) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.162+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 7.0 in stage 1260.0 (TID 1668) in 31 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:49.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 9.0 in stage 1260.0 (TID 1670) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4577 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 8.0 in stage 1260.0 (TID 1669) in 31 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:49.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 3.0 in stage 1287.0 (TID 1671) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 9.0 in stage 1260.0 (TID 1670) in 36 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSchedulerImpl: Removed TaskSet 1260.0, whose tasks have all completed, from pool
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: ShuffleMapStage 1260 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.809 s
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1261, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:49.229+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: Submitting ShuffleMapStage 1261 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[436] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:43:49.238+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 238.6 KiB, free 416.6 MiB)
[2025-05-08T19:43:49.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 78.9 KiB, free 416.5 MiB)
[2025-05-08T19:43:49.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on f2a432e4376a:35283 (size: 78.9 KiB, free: 432.5 MiB)
[2025-05-08T19:43:49.258+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:49.259+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1261 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[436] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:49.259+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSchedulerImpl: Adding task set 1261.0 with 10 tasks resource profile 0
[2025-05-08T19:43:49.259+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO BlockManagerInfo: Removed broadcast_189_piece0 on f2a432e4376a:35283 in memory (size: 5.4 KiB, free: 432.5 MiB)
[2025-05-08T19:43:49.260+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 172.20.0.5:36007 in memory (size: 5.4 KiB, free: 420.8 MiB)
[2025-05-08T19:43:49.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 0.0 in stage 1261.0 (TID 1672) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 3.0 in stage 1287.0 (TID 1671) in 44 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:49.280+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 172.20.0.5:36007 (size: 78.9 KiB, free: 420.7 MiB)
[2025-05-08T19:43:49.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:43:49.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:43:49.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:43:49.307+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:36758
[2025-05-08T19:43:49.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 1.0 in stage 1261.0 (TID 1673) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 0.0 in stage 1261.0 (TID 1672) in 100 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:49.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 2.0 in stage 1261.0 (TID 1674) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 1.0 in stage 1261.0 (TID 1673) in 86 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:49.506+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 3.0 in stage 1261.0 (TID 1675) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.507+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 2.0 in stage 1261.0 (TID 1674) in 57 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:49.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 4.0 in stage 1261.0 (TID 1676) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 3.0 in stage 1261.0 (TID 1675) in 69 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:49.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 5.0 in stage 1261.0 (TID 1677) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 4.0 in stage 1261.0 (TID 1676) in 41 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:49.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 6.0 in stage 1261.0 (TID 1678) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 5.0 in stage 1261.0 (TID 1677) in 37 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:49.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 7.0 in stage 1261.0 (TID 1679) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 6.0 in stage 1261.0 (TID 1678) in 31 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 8.0 in stage 1261.0 (TID 1680) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.716+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 7.0 in stage 1261.0 (TID 1679) in 34 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:49.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 9.0 in stage 1261.0 (TID 1681) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 8.0 in stage 1261.0 (TID 1680) in 34 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:49.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 4.0 in stage 1287.0 (TID 1682) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 9.0 in stage 1261.0 (TID 1681) in 63 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:49.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSchedulerImpl: Removed TaskSet 1261.0, whose tasks have all completed, from pool
[2025-05-08T19:43:49.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: ShuffleMapStage 1261 (mapPartitions at GraphImpl.scala:208) finished in 0.582 s
[2025-05-08T19:43:49.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:49.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:49.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1262, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1263, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:49.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:49.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: Submitting ShuffleMapStage 1262 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[445] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:49.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 12.3 KiB, free 416.5 MiB)
[2025-05-08T19:43:49.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 416.5 MiB)
[2025-05-08T19:43:49.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on f2a432e4376a:35283 (size: 5.6 KiB, free: 432.5 MiB)
[2025-05-08T19:43:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1262 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[445] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSchedulerImpl: Adding task set 1262.0 with 10 tasks resource profile 0
[2025-05-08T19:43:49.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: Submitting ShuffleMapStage 1263 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[449] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:43:49.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 11.6 KiB, free 416.5 MiB)
[2025-05-08T19:43:49.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 416.5 MiB)
[2025-05-08T19:43:49.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on f2a432e4376a:35283 (size: 5.4 KiB, free: 432.5 MiB)
[2025-05-08T19:43:49.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:49.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1263 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[449] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:49.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSchedulerImpl: Adding task set 1263.0 with 10 tasks resource profile 0
[2025-05-08T19:43:49.845+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 0.0 in stage 1262.0 (TID 1683) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.845+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 4.0 in stage 1287.0 (TID 1682) in 35 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:49.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 172.20.0.5:36007 (size: 5.6 KiB, free: 420.7 MiB)
[2025-05-08T19:43:49.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:43:49.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:43:49.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Starting task 1.0 in stage 1262.0 (TID 1684) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:49.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:49 INFO TaskSetManager: Finished task 0.0 in stage 1262.0 (TID 1683) in 79 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:50.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 2.0 in stage 1262.0 (TID 1685) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.017+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 1.0 in stage 1262.0 (TID 1684) in 93 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:50.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 3.0 in stage 1262.0 (TID 1686) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 2.0 in stage 1262.0 (TID 1685) in 46 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:50.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 4.0 in stage 1262.0 (TID 1687) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 3.0 in stage 1262.0 (TID 1686) in 36 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:50.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 5.0 in stage 1262.0 (TID 1688) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 4.0 in stage 1262.0 (TID 1687) in 50 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:50.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 6.0 in stage 1262.0 (TID 1689) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 5.0 in stage 1262.0 (TID 1688) in 45 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:50.238+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 7.0 in stage 1262.0 (TID 1690) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.238+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 6.0 in stage 1262.0 (TID 1689) in 46 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:50.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 8.0 in stage 1262.0 (TID 1691) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 7.0 in stage 1262.0 (TID 1690) in 48 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:50.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 9.0 in stage 1262.0 (TID 1692) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 8.0 in stage 1262.0 (TID 1691) in 49 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:50.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 0.0 in stage 1263.0 (TID 1693) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 9.0 in stage 1262.0 (TID 1692) in 42 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:50.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSchedulerImpl: Removed TaskSet 1262.0, whose tasks have all completed, from pool
[2025-05-08T19:43:50.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: ShuffleMapStage 1262 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.562 s
[2025-05-08T19:43:50.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:50.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1263, ShuffleMapStage 1336)
[2025-05-08T19:43:50.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:50.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:50.381+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 172.20.0.5:36007 (size: 5.4 KiB, free: 420.7 MiB)
[2025-05-08T19:43:50.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 1.0 in stage 1263.0 (TID 1694) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 0.0 in stage 1263.0 (TID 1693) in 33 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:50.440+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 2.0 in stage 1263.0 (TID 1695) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.440+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 1.0 in stage 1263.0 (TID 1694) in 31 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:50.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 3.0 in stage 1263.0 (TID 1696) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 2.0 in stage 1263.0 (TID 1695) in 28 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:50.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 4.0 in stage 1263.0 (TID 1697) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 3.0 in stage 1263.0 (TID 1696) in 21 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:50.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 5.0 in stage 1263.0 (TID 1698) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.515+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 4.0 in stage 1263.0 (TID 1697) in 25 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:50.539+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 6.0 in stage 1263.0 (TID 1699) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.539+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 5.0 in stage 1263.0 (TID 1698) in 25 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:50.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 7.0 in stage 1263.0 (TID 1700) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 6.0 in stage 1263.0 (TID 1699) in 21 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:50.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 8.0 in stage 1263.0 (TID 1701) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 7.0 in stage 1263.0 (TID 1700) in 26 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:50.611+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 9.0 in stage 1263.0 (TID 1702) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4650 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 8.0 in stage 1263.0 (TID 1701) in 25 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:50.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 5.0 in stage 1287.0 (TID 1703) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 9.0 in stage 1263.0 (TID 1702) in 24 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSchedulerImpl: Removed TaskSet 1263.0, whose tasks have all completed, from pool
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: ShuffleMapStage 1263 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.817 s
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1264, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:50.636+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: Submitting ShuffleMapStage 1264 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[453] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:43:50.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 238.9 KiB, free 416.3 MiB)
[2025-05-08T19:43:50.642+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 78.9 KiB, free 416.2 MiB)
[2025-05-08T19:43:50.642+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on f2a432e4376a:35283 (size: 78.9 KiB, free: 432.4 MiB)
[2025-05-08T19:43:50.643+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:50.643+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1264 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[453] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:50.643+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSchedulerImpl: Adding task set 1264.0 with 10 tasks resource profile 0
[2025-05-08T19:43:50.651+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 0.0 in stage 1264.0 (TID 1704) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.652+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 5.0 in stage 1287.0 (TID 1703) in 17 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:50.656+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 172.20.0.5:36007 (size: 78.9 KiB, free: 420.6 MiB)
[2025-05-08T19:43:50.662+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:43:50.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:43:50.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:43:50.666+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:43:50.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:36758
[2025-05-08T19:43:50.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 1.0 in stage 1264.0 (TID 1705) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.681+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 0.0 in stage 1264.0 (TID 1704) in 30 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:50.703+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 2.0 in stage 1264.0 (TID 1706) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 1.0 in stage 1264.0 (TID 1705) in 23 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:50.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 3.0 in stage 1264.0 (TID 1707) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 2.0 in stage 1264.0 (TID 1706) in 23 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:50.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 4.0 in stage 1264.0 (TID 1708) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.745+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 3.0 in stage 1264.0 (TID 1707) in 20 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:50.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 5.0 in stage 1264.0 (TID 1709) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 4.0 in stage 1264.0 (TID 1708) in 19 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:50.782+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 6.0 in stage 1264.0 (TID 1710) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.782+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 5.0 in stage 1264.0 (TID 1709) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:50.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 7.0 in stage 1264.0 (TID 1711) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 6.0 in stage 1264.0 (TID 1710) in 18 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:50.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 8.0 in stage 1264.0 (TID 1712) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 7.0 in stage 1264.0 (TID 1711) in 17 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:50.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 9.0 in stage 1264.0 (TID 1713) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 8.0 in stage 1264.0 (TID 1712) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:50.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 6.0 in stage 1287.0 (TID 1714) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 9.0 in stage 1264.0 (TID 1713) in 30 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:50.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSchedulerImpl: Removed TaskSet 1264.0, whose tasks have all completed, from pool
[2025-05-08T19:43:50.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: ShuffleMapStage 1264 (mapPartitions at GraphImpl.scala:208) finished in 0.227 s
[2025-05-08T19:43:50.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:50.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:50.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1266, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1265, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:50.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:50.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: Submitting ShuffleMapStage 1265 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[466] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:43:50.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 12.2 KiB, free 416.2 MiB)
[2025-05-08T19:43:50.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 416.2 MiB)
[2025-05-08T19:43:50.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on f2a432e4376a:35283 (size: 5.6 KiB, free: 432.4 MiB)
[2025-05-08T19:43:50.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:50.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1265 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[466] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:50.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSchedulerImpl: Adding task set 1265.0 with 10 tasks resource profile 0
[2025-05-08T19:43:50.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: Submitting ShuffleMapStage 1266 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[462] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:50.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 12.9 KiB, free 416.2 MiB)
[2025-05-08T19:43:50.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 416.1 MiB)
[2025-05-08T19:43:50.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.4 MiB)
[2025-05-08T19:43:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1266 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[462] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSchedulerImpl: Adding task set 1266.0 with 10 tasks resource profile 0
[2025-05-08T19:43:50.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 0.0 in stage 1265.0 (TID 1715) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 6.0 in stage 1287.0 (TID 1714) in 17 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:50.882+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 172.20.0.5:36007 (size: 5.6 KiB, free: 420.6 MiB)
[2025-05-08T19:43:50.884+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:43:50.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:43:50.915+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:43:50.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 1.0 in stage 1265.0 (TID 1716) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 0.0 in stage 1265.0 (TID 1715) in 47 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:50.968+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 2.0 in stage 1265.0 (TID 1717) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.968+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 1.0 in stage 1265.0 (TID 1716) in 43 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:50.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Starting task 3.0 in stage 1265.0 (TID 1718) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:50.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:50 INFO TaskSetManager: Finished task 2.0 in stage 1265.0 (TID 1717) in 30 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:51.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 4.0 in stage 1265.0 (TID 1719) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 3.0 in stage 1265.0 (TID 1718) in 27 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:51.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 5.0 in stage 1265.0 (TID 1720) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 4.0 in stage 1265.0 (TID 1719) in 35 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:51.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 6.0 in stage 1265.0 (TID 1721) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 5.0 in stage 1265.0 (TID 1720) in 35 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:51.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 7.0 in stage 1265.0 (TID 1722) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 6.0 in stage 1265.0 (TID 1721) in 30 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:51.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 8.0 in stage 1265.0 (TID 1723) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 7.0 in stage 1265.0 (TID 1722) in 41 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:51.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 9.0 in stage 1265.0 (TID 1724) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4723 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 8.0 in stage 1265.0 (TID 1723) in 36 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:51.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 0.0 in stage 1266.0 (TID 1725) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.236+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 9.0 in stage 1265.0 (TID 1724) in 37 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:51.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSchedulerImpl: Removed TaskSet 1265.0, whose tasks have all completed, from pool
[2025-05-08T19:43:51.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: ShuffleMapStage 1265 (mapPartitions at VertexRDDImpl.scala:251) finished in 0.372 s
[2025-05-08T19:43:51.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:51.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1266, ShuffleMapStage 1336)
[2025-05-08T19:43:51.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:51.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:51.242+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 172.20.0.5:36007 (size: 5.7 KiB, free: 420.6 MiB)
[2025-05-08T19:43:51.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 1.0 in stage 1266.0 (TID 1726) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 0.0 in stage 1266.0 (TID 1725) in 98 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:51.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 2.0 in stage 1266.0 (TID 1727) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.433+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 1.0 in stage 1266.0 (TID 1726) in 99 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:51.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 3.0 in stage 1266.0 (TID 1728) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 2.0 in stage 1266.0 (TID 1727) in 60 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:51.547+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 4.0 in stage 1266.0 (TID 1729) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 3.0 in stage 1266.0 (TID 1728) in 55 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:51.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 5.0 in stage 1266.0 (TID 1730) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 4.0 in stage 1266.0 (TID 1729) in 80 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:51.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 6.0 in stage 1266.0 (TID 1731) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 5.0 in stage 1266.0 (TID 1730) in 72 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:51.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 7.0 in stage 1266.0 (TID 1732) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 6.0 in stage 1266.0 (TID 1731) in 62 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:51.842+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 8.0 in stage 1266.0 (TID 1733) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.842+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 7.0 in stage 1266.0 (TID 1732) in 82 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:51.920+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 9.0 in stage 1266.0 (TID 1734) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 8.0 in stage 1266.0 (TID 1733) in 79 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:51.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 7.0 in stage 1287.0 (TID 1735) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 9.0 in stage 1266.0 (TID 1734) in 65 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSchedulerImpl: Removed TaskSet 1266.0, whose tasks have all completed, from pool
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: ShuffleMapStage 1266 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.118 s
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1267, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:51.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: Submitting ShuffleMapStage 1267 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[470] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:43:51.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 239.2 KiB, free 415.9 MiB)
[2025-05-08T19:43:51.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 415.8 MiB)
[2025-05-08T19:43:51.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.4 MiB)
[2025-05-08T19:43:51.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:51.994+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1267 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[470] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:51.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSchedulerImpl: Adding task set 1267.0 with 10 tasks resource profile 0
[2025-05-08T19:43:51.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Starting task 0.0 in stage 1267.0 (TID 1736) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:51.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:51 INFO TaskSetManager: Finished task 7.0 in stage 1287.0 (TID 1735) in 14 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:52.003+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 172.20.0.5:36007 (size: 79.2 KiB, free: 420.5 MiB)
[2025-05-08T19:43:52.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:43:52.011+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:43:52.012+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:43:52.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:43:52.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:36758
[2025-05-08T19:43:52.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:36758
[2025-05-08T19:43:52.026+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 1.0 in stage 1267.0 (TID 1737) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.026+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 0.0 in stage 1267.0 (TID 1736) in 27 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:52.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 2.0 in stage 1267.0 (TID 1738) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 1.0 in stage 1267.0 (TID 1737) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:52.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 3.0 in stage 1267.0 (TID 1739) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 2.0 in stage 1267.0 (TID 1738) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:52.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 4.0 in stage 1267.0 (TID 1740) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 3.0 in stage 1267.0 (TID 1739) in 17 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:52.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 5.0 in stage 1267.0 (TID 1741) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 4.0 in stage 1267.0 (TID 1740) in 26 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:52.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 6.0 in stage 1267.0 (TID 1742) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 5.0 in stage 1267.0 (TID 1741) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:52.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 7.0 in stage 1267.0 (TID 1743) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.137+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 6.0 in stage 1267.0 (TID 1742) in 17 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:52.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 8.0 in stage 1267.0 (TID 1744) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.154+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 7.0 in stage 1267.0 (TID 1743) in 18 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:52.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 9.0 in stage 1267.0 (TID 1745) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 8.0 in stage 1267.0 (TID 1744) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:52.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 8.0 in stage 1287.0 (TID 1746) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 9.0 in stage 1267.0 (TID 1745) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:52.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSchedulerImpl: Removed TaskSet 1267.0, whose tasks have all completed, from pool
[2025-05-08T19:43:52.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: ShuffleMapStage 1267 (mapPartitions at GraphImpl.scala:208) finished in 0.203 s
[2025-05-08T19:43:52.189+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:52.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:52.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1268, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1269, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:52.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:52.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: Submitting ShuffleMapStage 1268 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[479] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:52.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 13.6 KiB, free 415.8 MiB)
[2025-05-08T19:43:52.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 415.8 MiB)
[2025-05-08T19:43:52.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on f2a432e4376a:35283 (size: 5.8 KiB, free: 432.4 MiB)
[2025-05-08T19:43:52.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:52.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1268 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[479] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:52.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSchedulerImpl: Adding task set 1268.0 with 10 tasks resource profile 0
[2025-05-08T19:43:52.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: Submitting ShuffleMapStage 1269 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[483] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:43:52.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 12.9 KiB, free 415.8 MiB)
[2025-05-08T19:43:52.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 415.8 MiB)
[2025-05-08T19:43:52.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.3 MiB)
[2025-05-08T19:43:52.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:52.195+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1269 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[483] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:52.195+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSchedulerImpl: Adding task set 1269.0 with 10 tasks resource profile 0
[2025-05-08T19:43:52.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 0.0 in stage 1268.0 (TID 1747) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 8.0 in stage 1287.0 (TID 1746) in 17 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:52.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 172.20.0.5:36007 (size: 5.8 KiB, free: 420.5 MiB)
[2025-05-08T19:43:52.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:43:52.247+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:43:52.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:43:52.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:36758
[2025-05-08T19:43:52.440+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 1.0 in stage 1268.0 (TID 1748) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.441+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 0.0 in stage 1268.0 (TID 1747) in 235 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:52.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 2.0 in stage 1268.0 (TID 1749) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 1.0 in stage 1268.0 (TID 1748) in 232 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:52.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 3.0 in stage 1268.0 (TID 1750) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 2.0 in stage 1268.0 (TID 1749) in 138 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:52.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Starting task 4.0 in stage 1268.0 (TID 1751) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:52.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:52 INFO TaskSetManager: Finished task 3.0 in stage 1268.0 (TID 1750) in 111 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:53.092+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 5.0 in stage 1268.0 (TID 1752) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 4.0 in stage 1268.0 (TID 1751) in 171 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:53.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 6.0 in stage 1268.0 (TID 1753) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 5.0 in stage 1268.0 (TID 1752) in 143 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:53.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 7.0 in stage 1268.0 (TID 1754) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 6.0 in stage 1268.0 (TID 1753) in 132 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:53.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 8.0 in stage 1268.0 (TID 1755) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 7.0 in stage 1268.0 (TID 1754) in 191 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:53.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 9.0 in stage 1268.0 (TID 1756) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 8.0 in stage 1268.0 (TID 1755) in 162 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:53.858+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 0.0 in stage 1269.0 (TID 1757) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.858+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 9.0 in stage 1268.0 (TID 1756) in 139 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:53.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSchedulerImpl: Removed TaskSet 1268.0, whose tasks have all completed, from pool
[2025-05-08T19:43:53.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO DAGScheduler: ShuffleMapStage 1268 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.668 s
[2025-05-08T19:43:53.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:53.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1269, ShuffleMapStage 1336)
[2025-05-08T19:43:53.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:53.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:53.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 172.20.0.5:36007 (size: 5.7 KiB, free: 420.5 MiB)
[2025-05-08T19:43:53.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 1.0 in stage 1269.0 (TID 1758) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 0.0 in stage 1269.0 (TID 1757) in 66 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:53.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Starting task 2.0 in stage 1269.0 (TID 1759) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:53.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:53 INFO TaskSetManager: Finished task 1.0 in stage 1269.0 (TID 1758) in 67 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:54.036+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 3.0 in stage 1269.0 (TID 1760) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.036+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 2.0 in stage 1269.0 (TID 1759) in 45 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:54.075+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 4.0 in stage 1269.0 (TID 1761) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 3.0 in stage 1269.0 (TID 1760) in 39 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:54.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 5.0 in stage 1269.0 (TID 1762) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 4.0 in stage 1269.0 (TID 1761) in 67 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:54.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 6.0 in stage 1269.0 (TID 1763) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 5.0 in stage 1269.0 (TID 1762) in 59 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:54.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 7.0 in stage 1269.0 (TID 1764) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.250+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 6.0 in stage 1269.0 (TID 1763) in 49 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:54.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 8.0 in stage 1269.0 (TID 1765) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 7.0 in stage 1269.0 (TID 1764) in 63 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:54.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 9.0 in stage 1269.0 (TID 1766) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4796 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 8.0 in stage 1269.0 (TID 1765) in 69 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:54.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 9.0 in stage 1287.0 (TID 1767) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 9.0 in stage 1269.0 (TID 1766) in 57 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:54.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Removed TaskSet 1269.0, whose tasks have all completed, from pool
[2025-05-08T19:43:54.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: ShuffleMapStage 1269 (mapPartitions at VertexRDDImpl.scala:251) finished in 2.245 s
[2025-05-08T19:43:54.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:54.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:43:54.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278, ShuffleMapStage 1270)
[2025-05-08T19:43:54.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:54.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting ShuffleMapStage 1270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[487] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:43:54.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 239.5 KiB, free 415.6 MiB)
[2025-05-08T19:43:54.444+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 415.5 MiB)
[2025-05-08T19:43:54.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.3 MiB)
[2025-05-08T19:43:54.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:54.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1270 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[487] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:54.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Adding task set 1270.0 with 10 tasks resource profile 0
[2025-05-08T19:43:54.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 0.0 in stage 1270.0 (TID 1768) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 9.0 in stage 1287.0 (TID 1767) in 16 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:54.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Removed TaskSet 1287.0, whose tasks have all completed, from pool
[2025-05-08T19:43:54.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: ShuffleMapStage 1287 (mapPartitions at GraphImpl.scala:208) finished in 9.387 s
[2025-05-08T19:43:54.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:54.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1270, ShuffleMapStage 1336)
[2025-05-08T19:43:54.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:43:54.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:54.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:54.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 10.7 KiB, free 415.5 MiB)
[2025-05-08T19:43:54.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 415.5 MiB)
[2025-05-08T19:43:54.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on f2a432e4376a:35283 (size: 5.3 KiB, free: 432.3 MiB)
[2025-05-08T19:43:54.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:54.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:54.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Adding task set 1288.0 with 10 tasks resource profile 0
[2025-05-08T19:43:54.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:54.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 172.20.0.5:36007 (size: 79.2 KiB, free: 420.4 MiB)
[2025-05-08T19:43:54.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 10.1 KiB, free 415.5 MiB)
[2025-05-08T19:43:54.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 415.5 MiB)
[2025-05-08T19:43:54.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on f2a432e4376a:35283 (size: 5.0 KiB, free: 432.3 MiB)
[2025-05-08T19:43:54.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:54.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:54.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Adding task set 1289.0 with 10 tasks resource profile 0
[2025-05-08T19:43:54.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:43:54.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:43:54.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:43:54.473+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:43:54.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:36758
[2025-05-08T19:43:54.475+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:36758
[2025-05-08T19:43:54.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:36758
[2025-05-08T19:43:54.488+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 1.0 in stage 1270.0 (TID 1769) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.489+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 0.0 in stage 1270.0 (TID 1768) in 35 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:54.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 2.0 in stage 1270.0 (TID 1770) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 1.0 in stage 1270.0 (TID 1769) in 17 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:54.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 3.0 in stage 1270.0 (TID 1771) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 2.0 in stage 1270.0 (TID 1770) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:54.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 4.0 in stage 1270.0 (TID 1772) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.540+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 3.0 in stage 1270.0 (TID 1771) in 17 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:54.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 5.0 in stage 1270.0 (TID 1773) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 4.0 in stage 1270.0 (TID 1772) in 20 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:54.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 6.0 in stage 1270.0 (TID 1774) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 5.0 in stage 1270.0 (TID 1773) in 18 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:54.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 7.0 in stage 1270.0 (TID 1775) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 6.0 in stage 1270.0 (TID 1774) in 28 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:54.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 8.0 in stage 1270.0 (TID 1776) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 7.0 in stage 1270.0 (TID 1775) in 18 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:54.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 9.0 in stage 1270.0 (TID 1777) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 8.0 in stage 1270.0 (TID 1776) in 17 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:54.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 0.0 in stage 1288.0 (TID 1778) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 9.0 in stage 1270.0 (TID 1777) in 19 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:54.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Removed TaskSet 1270.0, whose tasks have all completed, from pool
[2025-05-08T19:43:54.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: ShuffleMapStage 1270 (mapPartitions at GraphImpl.scala:208) finished in 0.219 s
[2025-05-08T19:43:54.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:54.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:43:54.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1272, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1271, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:43:54.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:54.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting ShuffleMapStage 1271 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[500] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:43:54.660+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 13.5 KiB, free 415.4 MiB)
[2025-05-08T19:43:54.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 172.20.0.5:36007 (size: 5.3 KiB, free: 420.4 MiB)
[2025-05-08T19:43:54.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 415.4 MiB)
[2025-05-08T19:43:54.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on f2a432e4376a:35283 (size: 5.8 KiB, free: 432.3 MiB)
[2025-05-08T19:43:54.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:54.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:43:54.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1271 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[500] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:54.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Adding task set 1271.0 with 10 tasks resource profile 0
[2025-05-08T19:43:54.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting ShuffleMapStage 1272 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[496] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:54.666+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 14.2 KiB, free 415.4 MiB)
[2025-05-08T19:43:54.667+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 415.4 MiB)
[2025-05-08T19:43:54.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.2 MiB)
[2025-05-08T19:43:54.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:54.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1272 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[496] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:54.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSchedulerImpl: Adding task set 1272.0 with 10 tasks resource profile 0
[2025-05-08T19:43:54.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added rdd_600_0 in memory on 172.20.0.5:36007 (size: 11.2 KiB, free: 420.4 MiB)
[2025-05-08T19:43:54.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 0.0 in stage 1271.0 (TID 1779) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 0.0 in stage 1288.0 (TID 1778) in 22 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:54.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 172.20.0.5:36007 (size: 5.8 KiB, free: 420.4 MiB)
[2025-05-08T19:43:54.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:43:54.714+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:43:54.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:43:54.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:36758
[2025-05-08T19:43:54.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.20.0.5:36758
[2025-05-08T19:43:54.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 1.0 in stage 1271.0 (TID 1780) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 0.0 in stage 1271.0 (TID 1779) in 155 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:54.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Starting task 2.0 in stage 1271.0 (TID 1781) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:54.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:54 INFO TaskSetManager: Finished task 1.0 in stage 1271.0 (TID 1780) in 132 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:55.060+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 3.0 in stage 1271.0 (TID 1782) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 2.0 in stage 1271.0 (TID 1781) in 95 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:55.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 4.0 in stage 1271.0 (TID 1783) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 3.0 in stage 1271.0 (TID 1782) in 78 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:55.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 5.0 in stage 1271.0 (TID 1784) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.257+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 4.0 in stage 1271.0 (TID 1783) in 119 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:55.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 6.0 in stage 1271.0 (TID 1785) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 5.0 in stage 1271.0 (TID 1784) in 111 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:55.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 7.0 in stage 1271.0 (TID 1786) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 6.0 in stage 1271.0 (TID 1785) in 102 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:55.581+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 8.0 in stage 1271.0 (TID 1787) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 7.0 in stage 1271.0 (TID 1786) in 113 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:55.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 9.0 in stage 1271.0 (TID 1788) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4869 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 8.0 in stage 1271.0 (TID 1787) in 106 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:55.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Starting task 0.0 in stage 1272.0 (TID 1789) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:55.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSetManager: Finished task 9.0 in stage 1271.0 (TID 1788) in 108 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:55.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO TaskSchedulerImpl: Removed TaskSet 1271.0, whose tasks have all completed, from pool
[2025-05-08T19:43:55.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO DAGScheduler: ShuffleMapStage 1271 (mapPartitions at VertexRDDImpl.scala:251) finished in 1.136 s
[2025-05-08T19:43:55.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:55.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1272, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:43:55.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:43:55.796+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:55.798+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:55 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 172.20.0.5:36007 (size: 5.9 KiB, free: 420.4 MiB)
[2025-05-08T19:43:56.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Starting task 1.0 in stage 1272.0 (TID 1790) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:56.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Finished task 0.0 in stage 1272.0 (TID 1789) in 341 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:56.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Starting task 2.0 in stage 1272.0 (TID 1791) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:56.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Finished task 1.0 in stage 1272.0 (TID 1790) in 383 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:56.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Starting task 3.0 in stage 1272.0 (TID 1792) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:56.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Finished task 2.0 in stage 1272.0 (TID 1791) in 216 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:56.939+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Starting task 4.0 in stage 1272.0 (TID 1793) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:56.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:56 INFO TaskSetManager: Finished task 3.0 in stage 1272.0 (TID 1792) in 204 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:57.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:57 INFO TaskSetManager: Starting task 5.0 in stage 1272.0 (TID 1794) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:57.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:57 INFO TaskSetManager: Finished task 4.0 in stage 1272.0 (TID 1793) in 301 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:57.531+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:57 INFO TaskSetManager: Starting task 6.0 in stage 1272.0 (TID 1795) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:57.531+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:57 INFO TaskSetManager: Finished task 5.0 in stage 1272.0 (TID 1794) in 291 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:57.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:57 INFO TaskSetManager: Starting task 7.0 in stage 1272.0 (TID 1796) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:57.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:57 INFO TaskSetManager: Finished task 6.0 in stage 1272.0 (TID 1795) in 233 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:58.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 8.0 in stage 1272.0 (TID 1797) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 7.0 in stage 1272.0 (TID 1796) in 302 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:58.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 9.0 in stage 1272.0 (TID 1798) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 8.0 in stage 1272.0 (TID 1797) in 317 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:58.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 1.0 in stage 1288.0 (TID 1799) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 9.0 in stage 1272.0 (TID 1798) in 264 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:58.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSchedulerImpl: Removed TaskSet 1272.0, whose tasks have all completed, from pool
[2025-05-08T19:43:58.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: ShuffleMapStage 1272 (mapPartitions at VertexRDDImpl.scala:247) finished in 3.981 s
[2025-05-08T19:43:58.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:58.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:43:58.646+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1273, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:43:58.647+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:58.647+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: Submitting ShuffleMapStage 1273 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[504] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:43:58.648+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:43:58.652+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added rdd_600_1 in memory on 172.20.0.5:36007 (size: 12.1 KiB, free: 420.4 MiB)
[2025-05-08T19:43:58.652+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 239.8 KiB, free 415.2 MiB)
[2025-05-08T19:43:58.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 2.0 in stage 1288.0 (TID 1800) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 1.0 in stage 1288.0 (TID 1799) in 10 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:58.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 79.5 KiB, free 415.1 MiB)
[2025-05-08T19:43:58.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on f2a432e4376a:35283 (size: 79.5 KiB, free: 432.2 MiB)
[2025-05-08T19:43:58.657+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:58.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1273 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[504] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:58.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSchedulerImpl: Adding task set 1273.0 with 10 tasks resource profile 0
[2025-05-08T19:43:58.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added rdd_600_2 in memory on 172.20.0.5:36007 (size: 10.9 KiB, free: 420.4 MiB)
[2025-05-08T19:43:58.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 0.0 in stage 1273.0 (TID 1801) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 2.0 in stage 1288.0 (TID 1800) in 9 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:58.668+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 172.20.0.5:36007 (size: 79.5 KiB, free: 420.3 MiB)
[2025-05-08T19:43:58.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:43:58.674+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:43:58.675+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:43:58.676+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:43:58.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:36758
[2025-05-08T19:43:58.678+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:36758
[2025-05-08T19:43:58.679+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:36758
[2025-05-08T19:43:58.680+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:36758
[2025-05-08T19:43:58.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 1.0 in stage 1273.0 (TID 1802) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.690+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 0.0 in stage 1273.0 (TID 1801) in 27 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:43:58.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 2.0 in stage 1273.0 (TID 1803) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.706+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 1.0 in stage 1273.0 (TID 1802) in 16 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:43:58.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 3.0 in stage 1273.0 (TID 1804) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 2.0 in stage 1273.0 (TID 1803) in 21 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:43:58.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_193_piece0 on f2a432e4376a:35283 in memory (size: 5.4 KiB, free: 432.2 MiB)
[2025-05-08T19:43:58.729+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 172.20.0.5:36007 in memory (size: 5.4 KiB, free: 420.3 MiB)
[2025-05-08T19:43:58.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_196_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.2 MiB)
[2025-05-08T19:43:58.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 172.20.0.5:36007 in memory (size: 5.7 KiB, free: 420.3 MiB)
[2025-05-08T19:43:58.734+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_204_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.2 MiB)
[2025-05-08T19:43:58.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 172.20.0.5:36007 in memory (size: 5.9 KiB, free: 420.3 MiB)
[2025-05-08T19:43:58.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_200_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.3 MiB)
[2025-05-08T19:43:58.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 172.20.0.5:36007 in memory (size: 79.2 KiB, free: 420.4 MiB)
[2025-05-08T19:43:58.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_194_piece0 on f2a432e4376a:35283 in memory (size: 78.9 KiB, free: 432.3 MiB)
[2025-05-08T19:43:58.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 172.20.0.5:36007 in memory (size: 78.9 KiB, free: 420.5 MiB)
[2025-05-08T19:43:58.746+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_203_piece0 on f2a432e4376a:35283 in memory (size: 5.8 KiB, free: 432.3 MiB)
[2025-05-08T19:43:58.747+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 172.20.0.5:36007 in memory (size: 5.8 KiB, free: 420.5 MiB)
[2025-05-08T19:43:58.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_192_piece0 on f2a432e4376a:35283 in memory (size: 5.6 KiB, free: 432.4 MiB)
[2025-05-08T19:43:58.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 172.20.0.5:36007 in memory (size: 5.6 KiB, free: 420.5 MiB)
[2025-05-08T19:43:58.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 4.0 in stage 1273.0 (TID 1805) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 3.0 in stage 1273.0 (TID 1804) in 32 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:58.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_195_piece0 on f2a432e4376a:35283 in memory (size: 5.6 KiB, free: 432.4 MiB)
[2025-05-08T19:43:58.754+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 172.20.0.5:36007 in memory (size: 5.6 KiB, free: 420.5 MiB)
[2025-05-08T19:43:58.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_199_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.4 MiB)
[2025-05-08T19:43:58.758+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 172.20.0.5:36007 in memory (size: 5.7 KiB, free: 420.5 MiB)
[2025-05-08T19:43:58.760+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_198_piece0 on f2a432e4376a:35283 in memory (size: 5.8 KiB, free: 432.4 MiB)
[2025-05-08T19:43:58.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 172.20.0.5:36007 in memory (size: 5.8 KiB, free: 420.5 MiB)
[2025-05-08T19:43:58.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_197_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.4 MiB)
[2025-05-08T19:43:58.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 172.20.0.5:36007 in memory (size: 79.2 KiB, free: 420.6 MiB)
[2025-05-08T19:43:58.767+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_190_piece0 on f2a432e4376a:35283 in memory (size: 5.1 KiB, free: 432.5 MiB)
[2025-05-08T19:43:58.769+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 172.20.0.5:36007 in memory (size: 5.1 KiB, free: 420.6 MiB)
[2025-05-08T19:43:58.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_191_piece0 on f2a432e4376a:35283 in memory (size: 78.9 KiB, free: 432.5 MiB)
[2025-05-08T19:43:58.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 172.20.0.5:36007 in memory (size: 78.9 KiB, free: 420.6 MiB)
[2025-05-08T19:43:58.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 5.0 in stage 1273.0 (TID 1806) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.777+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 4.0 in stage 1273.0 (TID 1805) in 25 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:43:58.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 6.0 in stage 1273.0 (TID 1807) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 5.0 in stage 1273.0 (TID 1806) in 17 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:43:58.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 7.0 in stage 1273.0 (TID 1808) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 6.0 in stage 1273.0 (TID 1807) in 19 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:43:58.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 8.0 in stage 1273.0 (TID 1809) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 7.0 in stage 1273.0 (TID 1808) in 16 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:43:58.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 9.0 in stage 1273.0 (TID 1810) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 8.0 in stage 1273.0 (TID 1809) in 16 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:43:58.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 3.0 in stage 1288.0 (TID 1811) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 9.0 in stage 1273.0 (TID 1810) in 17 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:43:58.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSchedulerImpl: Removed TaskSet 1273.0, whose tasks have all completed, from pool
[2025-05-08T19:43:58.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: ShuffleMapStage 1273 (mapPartitions at GraphImpl.scala:208) finished in 0.215 s
[2025-05-08T19:43:58.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:43:58.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:43:58.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1275, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1274, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:43:58.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: failed: Set()
[2025-05-08T19:43:58.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: Submitting ShuffleMapStage 1274 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[513] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:43:58.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 14.8 KiB, free 416.5 MiB)
[2025-05-08T19:43:58.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 416.5 MiB)
[2025-05-08T19:43:58.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:43:58.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on f2a432e4376a:35283 (size: 6.0 KiB, free: 432.5 MiB)
[2025-05-08T19:43:58.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:58.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1274 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[513] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:58.865+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSchedulerImpl: Adding task set 1274.0 with 10 tasks resource profile 0
[2025-05-08T19:43:58.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: Submitting ShuffleMapStage 1275 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[517] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:43:58.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 14.1 KiB, free 416.5 MiB)
[2025-05-08T19:43:58.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 416.5 MiB)
[2025-05-08T19:43:58.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.5 MiB)
[2025-05-08T19:43:58.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:43:58.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1275 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[517] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:43:58.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSchedulerImpl: Adding task set 1275.0 with 10 tasks resource profile 0
[2025-05-08T19:43:58.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added rdd_600_3 in memory on 172.20.0.5:36007 (size: 10.9 KiB, free: 420.6 MiB)
[2025-05-08T19:43:58.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Starting task 0.0 in stage 1274.0 (TID 1812) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:58.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO TaskSetManager: Finished task 3.0 in stage 1288.0 (TID 1811) in 12 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:43:58.876+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 172.20.0.5:36007 (size: 6.0 KiB, free: 420.6 MiB)
[2025-05-08T19:43:58.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:43:58.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:43:58.939+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:43:58.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:36758
[2025-05-08T19:43:59.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.20.0.5:36758
[2025-05-08T19:43:59.603+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:36758
[2025-05-08T19:43:59.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:59 INFO TaskSetManager: Starting task 1.0 in stage 1274.0 (TID 1813) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:43:59.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:43:59 INFO TaskSetManager: Finished task 0.0 in stage 1274.0 (TID 1812) in 736 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:00.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:00 INFO TaskSetManager: Starting task 2.0 in stage 1274.0 (TID 1814) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:00.287+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:00 INFO TaskSetManager: Finished task 1.0 in stage 1274.0 (TID 1813) in 679 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:00.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:00 INFO TaskSetManager: Starting task 3.0 in stage 1274.0 (TID 1815) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:00.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:00 INFO TaskSetManager: Finished task 2.0 in stage 1274.0 (TID 1814) in 454 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:01.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:01 INFO TaskSetManager: Starting task 4.0 in stage 1274.0 (TID 1816) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:01.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:01 INFO TaskSetManager: Finished task 3.0 in stage 1274.0 (TID 1815) in 374 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:01.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:01 INFO TaskSetManager: Starting task 5.0 in stage 1274.0 (TID 1817) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:01.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:01 INFO TaskSetManager: Finished task 4.0 in stage 1274.0 (TID 1816) in 608 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:02.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:02 INFO TaskSetManager: Starting task 6.0 in stage 1274.0 (TID 1818) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:02.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:02 INFO TaskSetManager: Finished task 5.0 in stage 1274.0 (TID 1817) in 616 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:02.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:02 INFO TaskSetManager: Starting task 7.0 in stage 1274.0 (TID 1819) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:02.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:02 INFO TaskSetManager: Finished task 6.0 in stage 1274.0 (TID 1818) in 514 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:03.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:03 INFO TaskSetManager: Starting task 8.0 in stage 1274.0 (TID 1820) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:03.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:03 INFO TaskSetManager: Finished task 7.0 in stage 1274.0 (TID 1819) in 731 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:04.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO TaskSetManager: Starting task 9.0 in stage 1274.0 (TID 1821) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:04.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO TaskSetManager: Finished task 8.0 in stage 1274.0 (TID 1820) in 625 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:04.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO TaskSetManager: Starting task 0.0 in stage 1275.0 (TID 1822) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:04.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO TaskSetManager: Finished task 9.0 in stage 1274.0 (TID 1821) in 532 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:04.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO TaskSchedulerImpl: Removed TaskSet 1274.0, whose tasks have all completed, from pool
[2025-05-08T19:44:04.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO DAGScheduler: ShuffleMapStage 1274 (mapPartitions at VertexRDDImpl.scala:247) finished in 5.876 s
[2025-05-08T19:44:04.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:04.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1275, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:04.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:44:04.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:04.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 172.20.0.5:36007 (size: 5.9 KiB, free: 420.6 MiB)
[2025-05-08T19:44:04.987+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO TaskSetManager: Starting task 1.0 in stage 1275.0 (TID 1823) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:04.987+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:04 INFO TaskSetManager: Finished task 0.0 in stage 1275.0 (TID 1822) in 248 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:05.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Starting task 2.0 in stage 1275.0 (TID 1824) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:05.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Finished task 1.0 in stage 1275.0 (TID 1823) in 228 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:05.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Starting task 3.0 in stage 1275.0 (TID 1825) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:05.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Finished task 2.0 in stage 1275.0 (TID 1824) in 162 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:05.535+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Starting task 4.0 in stage 1275.0 (TID 1826) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:05.535+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Finished task 3.0 in stage 1275.0 (TID 1825) in 158 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:05.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Starting task 5.0 in stage 1275.0 (TID 1827) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:05.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Finished task 4.0 in stage 1275.0 (TID 1826) in 214 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:05.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Starting task 6.0 in stage 1275.0 (TID 1828) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:05.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:05 INFO TaskSetManager: Finished task 5.0 in stage 1275.0 (TID 1827) in 189 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:06.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 7.0 in stage 1275.0 (TID 1829) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 6.0 in stage 1275.0 (TID 1828) in 156 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:06.188+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 172.20.0.5:36007 in memory (size: 6.0 KiB, free: 420.6 MiB)
[2025-05-08T19:44:06.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Removed broadcast_206_piece0 on f2a432e4376a:35283 in memory (size: 6.0 KiB, free: 432.5 MiB)
[2025-05-08T19:44:06.311+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 8.0 in stage 1275.0 (TID 1830) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 7.0 in stage 1275.0 (TID 1829) in 219 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:06.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 9.0 in stage 1275.0 (TID 1831) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4942 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.524+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 8.0 in stage 1275.0 (TID 1830) in 212 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:06.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 4.0 in stage 1288.0 (TID 1832) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 9.0 in stage 1275.0 (TID 1831) in 189 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:06.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSchedulerImpl: Removed TaskSet 1275.0, whose tasks have all completed, from pool
[2025-05-08T19:44:06.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: ShuffleMapStage 1275 (mapPartitions at VertexRDDImpl.scala:251) finished in 7.846 s
[2025-05-08T19:44:06.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:06.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:06.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1276, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:44:06.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:06.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: Submitting ShuffleMapStage 1276 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[521] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:44:06.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:44:06.718+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Added rdd_600_4 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 420.6 MiB)
[2025-05-08T19:44:06.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 240.1 KiB, free 416.3 MiB)
[2025-05-08T19:44:06.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 416.2 MiB)
[2025-05-08T19:44:06.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.4 MiB)
[2025-05-08T19:44:06.720+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:06.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1276 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[521] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:06.721+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSchedulerImpl: Adding task set 1276.0 with 10 tasks resource profile 0
[2025-05-08T19:44:06.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 0.0 in stage 1276.0 (TID 1833) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 4.0 in stage 1288.0 (TID 1832) in 11 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:06.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 172.20.0.5:36007 (size: 79.2 KiB, free: 420.5 MiB)
[2025-05-08T19:44:06.732+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:44:06.733+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:44:06.734+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:44:06.735+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:44:06.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:36758
[2025-05-08T19:44:06.737+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:36758
[2025-05-08T19:44:06.739+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:36758
[2025-05-08T19:44:06.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:36758
[2025-05-08T19:44:06.741+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 57 to 172.20.0.5:36758
[2025-05-08T19:44:06.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 1.0 in stage 1276.0 (TID 1834) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 0.0 in stage 1276.0 (TID 1833) in 31 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:06.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 2.0 in stage 1276.0 (TID 1835) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.769+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 1.0 in stage 1276.0 (TID 1834) in 16 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:06.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 3.0 in stage 1276.0 (TID 1836) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 2.0 in stage 1276.0 (TID 1835) in 25 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:06.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 4.0 in stage 1276.0 (TID 1837) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 3.0 in stage 1276.0 (TID 1836) in 17 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:06.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 5.0 in stage 1276.0 (TID 1838) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 4.0 in stage 1276.0 (TID 1837) in 15 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:06.840+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 6.0 in stage 1276.0 (TID 1839) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.840+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 5.0 in stage 1276.0 (TID 1838) in 16 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:06.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 7.0 in stage 1276.0 (TID 1840) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.856+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 6.0 in stage 1276.0 (TID 1839) in 15 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:06.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 8.0 in stage 1276.0 (TID 1841) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 7.0 in stage 1276.0 (TID 1840) in 17 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:06.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 9.0 in stage 1276.0 (TID 1842) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 8.0 in stage 1276.0 (TID 1841) in 15 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:06.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 5.0 in stage 1288.0 (TID 1843) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 9.0 in stage 1276.0 (TID 1842) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:06.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSchedulerImpl: Removed TaskSet 1276.0, whose tasks have all completed, from pool
[2025-05-08T19:44:06.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: ShuffleMapStage 1276 (mapPartitions at GraphImpl.scala:208) finished in 0.192 s
[2025-05-08T19:44:06.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:06.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:06.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1277, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1278)
[2025-05-08T19:44:06.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:06.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: Submitting ShuffleMapStage 1277 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[534] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:44:06.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 14.8 KiB, free 416.2 MiB)
[2025-05-08T19:44:06.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 416.2 MiB)
[2025-05-08T19:44:06.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on f2a432e4376a:35283 (size: 6.0 KiB, free: 432.4 MiB)
[2025-05-08T19:44:06.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:06.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1277 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[534] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:06.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSchedulerImpl: Adding task set 1277.0 with 10 tasks resource profile 0
[2025-05-08T19:44:06.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: Submitting ShuffleMapStage 1278 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:44:06.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:44:06.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 15.5 KiB, free 416.1 MiB)
[2025-05-08T19:44:06.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.1 MiB)
[2025-05-08T19:44:06.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.4 MiB)
[2025-05-08T19:44:06.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:06.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1278 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[530] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:06.912+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSchedulerImpl: Adding task set 1278.0 with 10 tasks resource profile 0
[2025-05-08T19:44:06.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Added rdd_600_5 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 420.5 MiB)
[2025-05-08T19:44:06.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Starting task 0.0 in stage 1277.0 (TID 1844) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:06.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO TaskSetManager: Finished task 5.0 in stage 1288.0 (TID 1843) in 12 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:06.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 172.20.0.5:36007 (size: 6.0 KiB, free: 420.5 MiB)
[2025-05-08T19:44:06.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:44:06.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:44:06.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:44:07.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:36758
[2025-05-08T19:44:07.196+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.20.0.5:36758
[2025-05-08T19:44:07.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:36758
[2025-05-08T19:44:07.578+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:36758
[2025-05-08T19:44:07.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:07 INFO TaskSetManager: Starting task 1.0 in stage 1277.0 (TID 1845) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:07.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:07 INFO TaskSetManager: Finished task 0.0 in stage 1277.0 (TID 1844) in 678 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:08.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:08 INFO TaskSetManager: Starting task 2.0 in stage 1277.0 (TID 1846) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:08.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:08 INFO TaskSetManager: Finished task 1.0 in stage 1277.0 (TID 1845) in 550 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:08.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:08 INFO TaskSetManager: Starting task 3.0 in stage 1277.0 (TID 1847) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:08.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:08 INFO TaskSetManager: Finished task 2.0 in stage 1277.0 (TID 1846) in 311 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:08.718+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:08 INFO TaskSetManager: Starting task 4.0 in stage 1277.0 (TID 1848) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:08.718+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:08 INFO TaskSetManager: Finished task 3.0 in stage 1277.0 (TID 1847) in 262 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:09.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:09 INFO TaskSetManager: Starting task 5.0 in stage 1277.0 (TID 1849) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:09.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:09 INFO TaskSetManager: Finished task 4.0 in stage 1277.0 (TID 1848) in 420 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:09.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:09 INFO TaskSetManager: Starting task 6.0 in stage 1277.0 (TID 1850) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:09.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:09 INFO TaskSetManager: Finished task 5.0 in stage 1277.0 (TID 1849) in 423 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:09.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:09 INFO TaskSetManager: Starting task 7.0 in stage 1277.0 (TID 1851) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:09.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:09 INFO TaskSetManager: Finished task 6.0 in stage 1277.0 (TID 1850) in 306 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:10.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:10 INFO TaskSetManager: Starting task 8.0 in stage 1277.0 (TID 1852) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:10.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:10 INFO TaskSetManager: Finished task 7.0 in stage 1277.0 (TID 1851) in 402 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:10.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:10 INFO TaskSetManager: Starting task 9.0 in stage 1277.0 (TID 1853) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:10.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:10 INFO TaskSetManager: Finished task 8.0 in stage 1277.0 (TID 1852) in 443 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:11.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO TaskSetManager: Starting task 0.0 in stage 1278.0 (TID 1854) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:11.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO TaskSetManager: Finished task 9.0 in stage 1277.0 (TID 1853) in 353 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:11.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO TaskSchedulerImpl: Removed TaskSet 1277.0, whose tasks have all completed, from pool
[2025-05-08T19:44:11.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO DAGScheduler: ShuffleMapStage 1277 (mapPartitions at VertexRDDImpl.scala:251) finished in 4.157 s
[2025-05-08T19:44:11.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:11.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1278, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:11.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:44:11.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:11.066+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:11 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 172.20.0.5:36007 (size: 6.1 KiB, free: 420.5 MiB)
[2025-05-08T19:44:12.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:12 INFO TaskSetManager: Starting task 1.0 in stage 1278.0 (TID 1855) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:12.438+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:12 INFO TaskSetManager: Finished task 0.0 in stage 1278.0 (TID 1854) in 1374 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:13.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:13 INFO TaskSetManager: Starting task 2.0 in stage 1278.0 (TID 1856) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:13.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:13 INFO TaskSetManager: Finished task 1.0 in stage 1278.0 (TID 1855) in 1399 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:14.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:14 INFO TaskSetManager: Starting task 3.0 in stage 1278.0 (TID 1857) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:14.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:14 INFO TaskSetManager: Finished task 2.0 in stage 1278.0 (TID 1856) in 837 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:15.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:15 INFO TaskSetManager: Starting task 4.0 in stage 1278.0 (TID 1858) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:15.424+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:15 INFO TaskSetManager: Finished task 3.0 in stage 1278.0 (TID 1857) in 750 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:16.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:16 INFO TaskSetManager: Starting task 5.0 in stage 1278.0 (TID 1859) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:16.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:16 INFO TaskSetManager: Finished task 4.0 in stage 1278.0 (TID 1858) in 1215 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:17.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:17 INFO TaskSetManager: Starting task 6.0 in stage 1278.0 (TID 1860) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:17.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:17 INFO TaskSetManager: Finished task 5.0 in stage 1278.0 (TID 1859) in 1104 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:18.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:18 INFO TaskSetManager: Starting task 7.0 in stage 1278.0 (TID 1861) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:18.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:18 INFO TaskSetManager: Finished task 6.0 in stage 1278.0 (TID 1860) in 896 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:19.845+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:19 INFO TaskSetManager: Starting task 8.0 in stage 1278.0 (TID 1862) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:19.845+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:19 INFO TaskSetManager: Finished task 7.0 in stage 1278.0 (TID 1861) in 1207 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:21.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:21 INFO TaskSetManager: Starting task 9.0 in stage 1278.0 (TID 1863) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:21.064+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:21 INFO TaskSetManager: Finished task 8.0 in stage 1278.0 (TID 1862) in 1220 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:22.165+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 6.0 in stage 1288.0 (TID 1864) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 9.0 in stage 1278.0 (TID 1863) in 1102 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:22.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSchedulerImpl: Removed TaskSet 1278.0, whose tasks have all completed, from pool
[2025-05-08T19:44:22.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: ShuffleMapStage 1278 (mapPartitions at VertexRDDImpl.scala:247) finished in 15.256 s
[2025-05-08T19:44:22.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:22.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:22.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1279, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:44:22.167+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:22.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: Submitting ShuffleMapStage 1279 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[538] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:44:22.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:44:22.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added rdd_600_6 in memory on 172.20.0.5:36007 (size: 11.4 KiB, free: 420.5 MiB)
[2025-05-08T19:44:22.176+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 240.4 KiB, free 415.9 MiB)
[2025-05-08T19:44:22.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 7.0 in stage 1288.0 (TID 1865) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 6.0 in stage 1288.0 (TID 1864) in 14 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:22.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 415.8 MiB)
[2025-05-08T19:44:22.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.4 MiB)
[2025-05-08T19:44:22.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:22.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1279 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[538] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:22.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSchedulerImpl: Adding task set 1279.0 with 10 tasks resource profile 0
[2025-05-08T19:44:22.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added rdd_600_7 in memory on 172.20.0.5:36007 (size: 11.6 KiB, free: 420.5 MiB)
[2025-05-08T19:44:22.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 0.0 in stage 1279.0 (TID 1866) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.186+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 7.0 in stage 1288.0 (TID 1865) in 7 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:22.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 172.20.0.5:36007 (size: 79.3 KiB, free: 420.4 MiB)
[2025-05-08T19:44:22.196+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:44:22.198+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:44:22.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:44:22.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:44:22.204+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:36758
[2025-05-08T19:44:22.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:36758
[2025-05-08T19:44:22.208+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:36758
[2025-05-08T19:44:22.211+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:36758
[2025-05-08T19:44:22.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:36758
[2025-05-08T19:44:22.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 60 to 172.20.0.5:36758
[2025-05-08T19:44:22.237+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 1.0 in stage 1279.0 (TID 1867) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.238+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 0.0 in stage 1279.0 (TID 1866) in 52 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:22.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 2.0 in stage 1279.0 (TID 1868) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 1.0 in stage 1279.0 (TID 1867) in 19 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:22.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 3.0 in stage 1279.0 (TID 1869) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 2.0 in stage 1279.0 (TID 1868) in 20 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:22.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 4.0 in stage 1279.0 (TID 1870) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 3.0 in stage 1279.0 (TID 1869) in 20 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:22.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 5.0 in stage 1279.0 (TID 1871) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 4.0 in stage 1279.0 (TID 1870) in 19 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:22.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 6.0 in stage 1279.0 (TID 1872) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.341+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 5.0 in stage 1279.0 (TID 1871) in 29 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:22.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 7.0 in stage 1279.0 (TID 1873) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 6.0 in stage 1279.0 (TID 1872) in 41 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:22.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 8.0 in stage 1279.0 (TID 1874) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.402+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 7.0 in stage 1279.0 (TID 1873) in 23 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:22.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 9.0 in stage 1279.0 (TID 1875) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 8.0 in stage 1279.0 (TID 1874) in 22 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:22.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 8.0 in stage 1288.0 (TID 1876) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 9.0 in stage 1279.0 (TID 1875) in 23 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:22.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSchedulerImpl: Removed TaskSet 1279.0, whose tasks have all completed, from pool
[2025-05-08T19:44:22.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: ShuffleMapStage 1279 (mapPartitions at GraphImpl.scala:208) finished in 0.278 s
[2025-05-08T19:44:22.445+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:22.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:22.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1281, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1280, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:44:22.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:22.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: Submitting ShuffleMapStage 1280 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[547] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:44:22.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 16.1 KiB, free 415.8 MiB)
[2025-05-08T19:44:22.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:44:22.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 415.8 MiB)
[2025-05-08T19:44:22.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.4 MiB)
[2025-05-08T19:44:22.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:22.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1280 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[547] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:22.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSchedulerImpl: Adding task set 1280.0 with 10 tasks resource profile 0
[2025-05-08T19:44:22.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: Submitting ShuffleMapStage 1281 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[551] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:44:22.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added rdd_600_8 in memory on 172.20.0.5:36007 (size: 11.7 KiB, free: 420.4 MiB)
[2025-05-08T19:44:22.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 15.4 KiB, free 415.8 MiB)
[2025-05-08T19:44:22.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 415.8 MiB)
[2025-05-08T19:44:22.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Starting task 0.0 in stage 1280.0 (TID 1877) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:22.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_209_piece0 on f2a432e4376a:35283 in memory (size: 6.0 KiB, free: 432.4 MiB)
[2025-05-08T19:44:22.460+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSetManager: Finished task 8.0 in stage 1288.0 (TID 1876) in 16 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:22.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.4 MiB)
[2025-05-08T19:44:22.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:22.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1281 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[551] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:22.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO TaskSchedulerImpl: Adding task set 1281.0 with 10 tasks resource profile 0
[2025-05-08T19:44:22.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 172.20.0.5:36007 in memory (size: 6.0 KiB, free: 420.4 MiB)
[2025-05-08T19:44:22.464+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_210_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.4 MiB)
[2025-05-08T19:44:22.466+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 172.20.0.5:36007 in memory (size: 6.1 KiB, free: 420.4 MiB)
[2025-05-08T19:44:22.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 172.20.0.5:36007 (size: 6.3 KiB, free: 420.4 MiB)
[2025-05-08T19:44:22.468+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_207_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.4 MiB)
[2025-05-08T19:44:22.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 172.20.0.5:36007 in memory (size: 5.9 KiB, free: 420.4 MiB)
[2025-05-08T19:44:22.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_208_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.4 MiB)
[2025-05-08T19:44:22.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:44:22.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 172.20.0.5:36007 in memory (size: 79.2 KiB, free: 420.5 MiB)
[2025-05-08T19:44:22.505+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:44:22.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:44:22.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_185_piece0 on f2a432e4376a:35283 in memory (size: 77.8 KiB, free: 432.5 MiB)
[2025-05-08T19:44:22.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 172.20.0.5:36007 in memory (size: 77.8 KiB, free: 420.6 MiB)
[2025-05-08T19:44:22.562+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_205_piece0 on f2a432e4376a:35283 in memory (size: 79.5 KiB, free: 432.6 MiB)
[2025-05-08T19:44:22.563+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 172.20.0.5:36007 in memory (size: 79.5 KiB, free: 420.6 MiB)
[2025-05-08T19:44:22.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:36758
[2025-05-08T19:44:22.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.20.0.5:36758
[2025-05-08T19:44:23.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:36758
[2025-05-08T19:44:23.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:36758
[2025-05-08T19:44:25.328+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:36758
[2025-05-08T19:44:25.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:25 INFO TaskSetManager: Starting task 1.0 in stage 1280.0 (TID 1878) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:25.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:25 INFO TaskSetManager: Finished task 0.0 in stage 1280.0 (TID 1877) in 2872 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:28.104+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:28 INFO TaskSetManager: Starting task 2.0 in stage 1280.0 (TID 1879) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:28.105+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:28 INFO TaskSetManager: Finished task 1.0 in stage 1280.0 (TID 1878) in 2772 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:29.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:29 INFO TaskSetManager: Starting task 3.0 in stage 1280.0 (TID 1880) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:29.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:29 INFO TaskSetManager: Finished task 2.0 in stage 1280.0 (TID 1879) in 1748 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:31.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:31 INFO TaskSetManager: Starting task 4.0 in stage 1280.0 (TID 1881) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:31.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:31 INFO TaskSetManager: Finished task 3.0 in stage 1280.0 (TID 1880) in 1566 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:34.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:34 INFO TaskSetManager: Starting task 5.0 in stage 1280.0 (TID 1882) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:34.193+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:34 INFO TaskSetManager: Finished task 4.0 in stage 1280.0 (TID 1881) in 2776 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:36.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:36 INFO TaskSetManager: Starting task 6.0 in stage 1280.0 (TID 1883) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:36.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:36 INFO TaskSetManager: Finished task 5.0 in stage 1280.0 (TID 1882) in 2278 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:38.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:38 INFO TaskSetManager: Starting task 7.0 in stage 1280.0 (TID 1884) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:38.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:38 INFO TaskSetManager: Finished task 6.0 in stage 1280.0 (TID 1883) in 1982 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:40.958+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:40 INFO TaskSetManager: Starting task 8.0 in stage 1280.0 (TID 1885) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:40.958+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:40 INFO TaskSetManager: Finished task 7.0 in stage 1280.0 (TID 1884) in 2508 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:43.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:43 INFO TaskSetManager: Starting task 9.0 in stage 1280.0 (TID 1886) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:43.475+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:43 INFO TaskSetManager: Finished task 8.0 in stage 1280.0 (TID 1885) in 2517 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:45.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO TaskSetManager: Starting task 0.0 in stage 1281.0 (TID 1887) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:45.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO TaskSetManager: Finished task 9.0 in stage 1280.0 (TID 1886) in 2019 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:45.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO TaskSchedulerImpl: Removed TaskSet 1280.0, whose tasks have all completed, from pool
[2025-05-08T19:44:45.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO DAGScheduler: ShuffleMapStage 1280 (mapPartitions at VertexRDDImpl.scala:247) finished in 23.048 s
[2025-05-08T19:44:45.495+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:45.495+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1281, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:45.495+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:44:45.495+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:45.497+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:45 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 172.20.0.5:36007 (size: 6.1 KiB, free: 420.6 MiB)
[2025-05-08T19:44:46.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:46 INFO TaskSetManager: Starting task 1.0 in stage 1281.0 (TID 1888) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:46.382+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:46 INFO TaskSetManager: Finished task 0.0 in stage 1281.0 (TID 1887) in 889 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:47.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:47 INFO TaskSetManager: Starting task 2.0 in stage 1281.0 (TID 1889) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:47.334+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:47 INFO TaskSetManager: Finished task 1.0 in stage 1281.0 (TID 1888) in 951 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:47.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:47 INFO TaskSetManager: Starting task 3.0 in stage 1281.0 (TID 1890) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:47.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:47 INFO TaskSetManager: Finished task 2.0 in stage 1281.0 (TID 1889) in 590 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:48.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:48 INFO TaskSetManager: Starting task 4.0 in stage 1281.0 (TID 1891) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:48.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:48 INFO TaskSetManager: Finished task 3.0 in stage 1281.0 (TID 1890) in 519 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:49.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:49 INFO TaskSetManager: Starting task 5.0 in stage 1281.0 (TID 1892) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:49.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:49 INFO TaskSetManager: Finished task 4.0 in stage 1281.0 (TID 1891) in 827 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:50.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:50 INFO TaskSetManager: Starting task 6.0 in stage 1281.0 (TID 1893) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:50.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:50 INFO TaskSetManager: Finished task 5.0 in stage 1281.0 (TID 1892) in 751 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:50.643+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:50 INFO TaskSetManager: Starting task 7.0 in stage 1281.0 (TID 1894) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:50.643+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:50 INFO TaskSetManager: Finished task 6.0 in stage 1281.0 (TID 1893) in 624 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:51.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:51 INFO TaskSetManager: Starting task 8.0 in stage 1281.0 (TID 1895) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:51.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:51 INFO TaskSetManager: Finished task 7.0 in stage 1281.0 (TID 1894) in 811 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:52.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:52 INFO TaskSetManager: Starting task 9.0 in stage 1281.0 (TID 1896) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5088 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:52.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:52 INFO TaskSetManager: Finished task 8.0 in stage 1281.0 (TID 1895) in 893 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:53.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 9.0 in stage 1288.0 (TID 1897) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 9.0 in stage 1281.0 (TID 1896) in 740 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:53.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSchedulerImpl: Removed TaskSet 1281.0, whose tasks have all completed, from pool
[2025-05-08T19:44:53.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: ShuffleMapStage 1281 (mapPartitions at VertexRDDImpl.scala:251) finished in 30.635 s
[2025-05-08T19:44:53.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:53.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1288, ShuffleMapStage 1336)
[2025-05-08T19:44:53.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1282, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:44:53.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:53.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: Submitting ShuffleMapStage 1282 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[555] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:44:53.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:36758
[2025-05-08T19:44:53.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 240.7 KiB, free 416.5 MiB)
[2025-05-08T19:44:53.097+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO BlockManagerInfo: Added rdd_600_9 in memory on 172.20.0.5:36007 (size: 11.2 KiB, free: 420.6 MiB)
[2025-05-08T19:44:53.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 416.5 MiB)
[2025-05-08T19:44:53.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.5 MiB)
[2025-05-08T19:44:53.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:53.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1282 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[555] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:53.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSchedulerImpl: Adding task set 1282.0 with 10 tasks resource profile 0
[2025-05-08T19:44:53.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 0.0 in stage 1282.0 (TID 1898) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 9.0 in stage 1288.0 (TID 1897) in 16 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:53.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSchedulerImpl: Removed TaskSet 1288.0, whose tasks have all completed, from pool
[2025-05-08T19:44:53.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: ShuffleMapStage 1288 (mapPartitions at VertexRDDImpl.scala:247) finished in 58.645 s
[2025-05-08T19:44:53.101+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:53.101+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1336, ShuffleMapStage 1282)
[2025-05-08T19:44:53.101+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:44:53.101+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:53.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 172.20.0.5:36007 (size: 79.3 KiB, free: 420.6 MiB)
[2025-05-08T19:44:53.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:44:53.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:44:53.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:44:53.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:44:53.115+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:36758
[2025-05-08T19:44:53.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:36758
[2025-05-08T19:44:53.119+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:36758
[2025-05-08T19:44:53.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:36758
[2025-05-08T19:44:53.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:36758
[2025-05-08T19:44:53.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.20.0.5:36758
[2025-05-08T19:44:53.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 63 to 172.20.0.5:36758
[2025-05-08T19:44:53.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 1.0 in stage 1282.0 (TID 1899) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 0.0 in stage 1282.0 (TID 1898) in 45 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:53.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 2.0 in stage 1282.0 (TID 1900) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.161+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 1.0 in stage 1282.0 (TID 1899) in 16 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:44:53.178+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 3.0 in stage 1282.0 (TID 1901) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.178+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 2.0 in stage 1282.0 (TID 1900) in 17 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:44:53.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 4.0 in stage 1282.0 (TID 1902) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.194+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 3.0 in stage 1282.0 (TID 1901) in 16 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:44:53.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 5.0 in stage 1282.0 (TID 1903) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 4.0 in stage 1282.0 (TID 1902) in 15 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:44:53.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 6.0 in stage 1282.0 (TID 1904) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.225+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 5.0 in stage 1282.0 (TID 1903) in 17 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:44:53.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 7.0 in stage 1282.0 (TID 1905) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.240+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 6.0 in stage 1282.0 (TID 1904) in 16 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:44:53.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 8.0 in stage 1282.0 (TID 1906) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 7.0 in stage 1282.0 (TID 1905) in 16 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:44:53.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 9.0 in stage 1282.0 (TID 1907) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 8.0 in stage 1282.0 (TID 1906) in 19 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:44:53.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 0.0 in stage 1289.0 (TID 1908) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 9.0 in stage 1282.0 (TID 1907) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:44:53.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSchedulerImpl: Removed TaskSet 1282.0, whose tasks have all completed, from pool
[2025-05-08T19:44:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: ShuffleMapStage 1282 (mapPartitions at GraphImpl.scala:208) finished in 0.208 s
[2025-05-08T19:44:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:44:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:44:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1283, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1284, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:44:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:44:53.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: Submitting ShuffleMapStage 1283 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[564] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:44:53.296+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 16.7 KiB, free 416.4 MiB)
[2025-05-08T19:44:53.297+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 416.4 MiB)
[2025-05-08T19:44:53.297+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.5 MiB)
[2025-05-08T19:44:53.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:53.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1283 (ReplicatedVertexView.updateVertices - shippedVerts true true (broadcast) MapPartitionsRDD[564] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:53.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSchedulerImpl: Adding task set 1283.0 with 10 tasks resource profile 0
[2025-05-08T19:44:53.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: Submitting ShuffleMapStage 1284 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[568] at mapPartitions at VertexRDDImpl.scala:251), which has no missing parents
[2025-05-08T19:44:53.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 172.20.0.5:36007 (size: 5.0 KiB, free: 420.6 MiB)
[2025-05-08T19:44:53.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 16.0 KiB, free 416.4 MiB)
[2025-05-08T19:44:53.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 416.4 MiB)
[2025-05-08T19:44:53.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on f2a432e4376a:35283 (size: 6.2 KiB, free: 432.5 MiB)
[2025-05-08T19:44:53.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:44:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1284 (ReplicatedVertexView.withActiveSet - shippedActives (broadcast) MapPartitionsRDD[568] at mapPartitions at VertexRDDImpl.scala:251) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:44:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSchedulerImpl: Adding task set 1284.0 with 10 tasks resource profile 0
[2025-05-08T19:44:53.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Starting task 0.0 in stage 1283.0 (TID 1909) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:53.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO TaskSetManager: Finished task 0.0 in stage 1289.0 (TID 1908) in 10 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:44:53.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 172.20.0.5:36007 (size: 6.4 KiB, free: 420.5 MiB)
[2025-05-08T19:44:53.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:44:53.337+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:44:53.372+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:44:53.437+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:36758
[2025-05-08T19:44:53.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.20.0.5:36758
[2025-05-08T19:44:53.789+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:36758
[2025-05-08T19:44:54.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:36758
[2025-05-08T19:44:55.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:36758
[2025-05-08T19:44:58.622+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.20.0.5:36758
[2025-05-08T19:44:58.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:58 INFO TaskSetManager: Starting task 1.0 in stage 1283.0 (TID 1910) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:44:58.627+0000] {spark_submit.py:571} INFO - 25/05/08 19:44:58 INFO TaskSetManager: Finished task 0.0 in stage 1283.0 (TID 1909) in 5323 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:45:04.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:04 INFO TaskSetManager: Starting task 2.0 in stage 1283.0 (TID 1911) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:04.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:04 INFO TaskSetManager: Finished task 1.0 in stage 1283.0 (TID 1910) in 5508 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:45:07.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:07 INFO TaskSetManager: Starting task 3.0 in stage 1283.0 (TID 1912) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:07.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:07 INFO TaskSetManager: Finished task 2.0 in stage 1283.0 (TID 1911) in 3455 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:45:10.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:10 INFO TaskSetManager: Starting task 4.0 in stage 1283.0 (TID 1913) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:10.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:10 INFO TaskSetManager: Finished task 3.0 in stage 1283.0 (TID 1912) in 3265 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:45:15.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:15 INFO TaskSetManager: Starting task 5.0 in stage 1283.0 (TID 1914) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:15.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:15 INFO TaskSetManager: Finished task 4.0 in stage 1283.0 (TID 1913) in 4753 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:45:20.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:20 INFO TaskSetManager: Starting task 6.0 in stage 1283.0 (TID 1915) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:20.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:20 INFO TaskSetManager: Finished task 5.0 in stage 1283.0 (TID 1914) in 4408 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:45:23.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:23 INFO TaskSetManager: Starting task 7.0 in stage 1283.0 (TID 1916) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:23.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:23 INFO TaskSetManager: Finished task 6.0 in stage 1283.0 (TID 1915) in 3585 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:45:28.442+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:28 INFO TaskSetManager: Starting task 8.0 in stage 1283.0 (TID 1917) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:28.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:28 INFO TaskSetManager: Finished task 7.0 in stage 1283.0 (TID 1916) in 4841 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:45:33.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:33 INFO TaskSetManager: Starting task 9.0 in stage 1283.0 (TID 1918) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:33.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:33 INFO TaskSetManager: Finished task 8.0 in stage 1283.0 (TID 1917) in 4905 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:45:37.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO TaskSetManager: Starting task 0.0 in stage 1284.0 (TID 1919) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:37.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO TaskSetManager: Finished task 9.0 in stage 1283.0 (TID 1918) in 4167 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:45:37.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO TaskSchedulerImpl: Removed TaskSet 1283.0, whose tasks have all completed, from pool
[2025-05-08T19:45:37.513+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO DAGScheduler: ShuffleMapStage 1283 (mapPartitions at VertexRDDImpl.scala:247) finished in 44.218 s
[2025-05-08T19:45:37.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:45:37.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1284, ShuffleMapStage 1336)
[2025-05-08T19:45:37.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:45:37.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO DAGScheduler: failed: Set()
[2025-05-08T19:45:37.516+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:37 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 172.20.0.5:36007 (size: 6.2 KiB, free: 420.5 MiB)
[2025-05-08T19:45:39.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:39 INFO TaskSetManager: Starting task 1.0 in stage 1284.0 (TID 1920) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:39.327+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:39 INFO TaskSetManager: Finished task 0.0 in stage 1284.0 (TID 1919) in 1813 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:45:41.499+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:41 INFO TaskSetManager: Starting task 2.0 in stage 1284.0 (TID 1921) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:41.500+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:41 INFO TaskSetManager: Finished task 1.0 in stage 1284.0 (TID 1920) in 2173 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:45:42.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:42 INFO TaskSetManager: Starting task 3.0 in stage 1284.0 (TID 1922) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:42.672+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:42 INFO TaskSetManager: Finished task 2.0 in stage 1284.0 (TID 1921) in 1174 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:45:43.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:43 INFO TaskSetManager: Starting task 4.0 in stage 1284.0 (TID 1923) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:43.751+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:43 INFO TaskSetManager: Finished task 3.0 in stage 1284.0 (TID 1922) in 1079 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:45:45.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:45 INFO TaskSetManager: Starting task 5.0 in stage 1284.0 (TID 1924) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:45.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:45 INFO TaskSetManager: Finished task 4.0 in stage 1284.0 (TID 1923) in 1586 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:45:46.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:46 INFO TaskSetManager: Starting task 6.0 in stage 1284.0 (TID 1925) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:46.791+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:46 INFO TaskSetManager: Finished task 5.0 in stage 1284.0 (TID 1924) in 1455 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:45:47.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:47 INFO TaskSetManager: Starting task 7.0 in stage 1284.0 (TID 1926) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:47.973+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:47 INFO TaskSetManager: Finished task 6.0 in stage 1284.0 (TID 1925) in 1182 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:45:49.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:49 INFO TaskSetManager: Starting task 8.0 in stage 1284.0 (TID 1927) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:49.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:49 INFO TaskSetManager: Finished task 7.0 in stage 1284.0 (TID 1926) in 1653 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:45:51.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:51 INFO TaskSetManager: Starting task 9.0 in stage 1284.0 (TID 1928) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5161 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:51.234+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:51 INFO TaskSetManager: Finished task 8.0 in stage 1284.0 (TID 1927) in 1608 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:45:52.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 1.0 in stage 1289.0 (TID 1929) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 9.0 in stage 1284.0 (TID 1928) in 1364 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:45:52.597+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSchedulerImpl: Removed TaskSet 1284.0, whose tasks have all completed, from pool
[2025-05-08T19:45:52.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: ShuffleMapStage 1284 (mapPartitions at VertexRDDImpl.scala:251) finished in 59.298 s
[2025-05-08T19:45:52.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:45:52.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:45:52.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1285, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:45:52.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: failed: Set()
[2025-05-08T19:45:52.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: Submitting ShuffleMapStage 1285 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[572] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:45:52.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 2.0 in stage 1289.0 (TID 1930) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 1.0 in stage 1289.0 (TID 1929) in 5 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:45:52.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 240.9 KiB, free 416.2 MiB)
[2025-05-08T19:45:52.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 3.0 in stage 1289.0 (TID 1931) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.604+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 2.0 in stage 1289.0 (TID 1930) in 4 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:45:52.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 416.1 MiB)
[2025-05-08T19:45:52.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.4 MiB)
[2025-05-08T19:45:52.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:45:52.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1285 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[572] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:45:52.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSchedulerImpl: Adding task set 1285.0 with 10 tasks resource profile 0
[2025-05-08T19:45:52.608+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 4.0 in stage 1289.0 (TID 1932) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.609+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 3.0 in stage 1289.0 (TID 1931) in 5 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:45:52.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 0.0 in stage 1285.0 (TID 1933) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.613+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 4.0 in stage 1289.0 (TID 1932) in 4 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:45:52.615+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 172.20.0.5:36007 (size: 79.4 KiB, free: 420.5 MiB)
[2025-05-08T19:45:52.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:36758
[2025-05-08T19:45:52.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:36758
[2025-05-08T19:45:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:36758
[2025-05-08T19:45:52.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:36758
[2025-05-08T19:45:52.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:36758
[2025-05-08T19:45:52.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:36758
[2025-05-08T19:45:52.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:36758
[2025-05-08T19:45:52.635+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:36758
[2025-05-08T19:45:52.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 59 to 172.20.0.5:36758
[2025-05-08T19:45:52.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 62 to 172.20.0.5:36758
[2025-05-08T19:45:52.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 65 to 172.20.0.5:36758
[2025-05-08T19:45:52.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 66 to 172.20.0.5:36758
[2025-05-08T19:45:52.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 1.0 in stage 1285.0 (TID 1934) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 0.0 in stage 1285.0 (TID 1933) in 53 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:45:52.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 2.0 in stage 1285.0 (TID 1935) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 1.0 in stage 1285.0 (TID 1934) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:45:52.698+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 3.0 in stage 1285.0 (TID 1936) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 2.0 in stage 1285.0 (TID 1935) in 16 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:45:52.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 4.0 in stage 1285.0 (TID 1937) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 3.0 in stage 1285.0 (TID 1936) in 17 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:45:52.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 5.0 in stage 1285.0 (TID 1938) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.731+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 4.0 in stage 1285.0 (TID 1937) in 16 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:45:52.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 6.0 in stage 1285.0 (TID 1939) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 5.0 in stage 1285.0 (TID 1938) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:45:52.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 7.0 in stage 1285.0 (TID 1940) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 6.0 in stage 1285.0 (TID 1939) in 16 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:45:52.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 8.0 in stage 1285.0 (TID 1941) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 7.0 in stage 1285.0 (TID 1940) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:45:52.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 9.0 in stage 1285.0 (TID 1942) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 8.0 in stage 1285.0 (TID 1941) in 16 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:45:52.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 5.0 in stage 1289.0 (TID 1943) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 9.0 in stage 1285.0 (TID 1942) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSchedulerImpl: Removed TaskSet 1285.0, whose tasks have all completed, from pool
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: ShuffleMapStage 1285 (mapPartitions at GraphImpl.scala:208) finished in 0.217 s
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1336)
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1286, ShuffleMapStage 1330, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: failed: Set()
[2025-05-08T19:45:52.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: Submitting ShuffleMapStage 1286 (MapPartitionsRDD[994] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:45:52.818+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1286.
[2025-05-08T19:45:52.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 29.8 KiB, free 416.1 MiB)
[2025-05-08T19:45:52.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 6.0 in stage 1289.0 (TID 1944) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 416.1 MiB)
[2025-05-08T19:45:52.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 5.0 in stage 1289.0 (TID 1943) in 5 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:45:52.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on f2a432e4376a:35283 (size: 11.3 KiB, free: 432.4 MiB)
[2025-05-08T19:45:52.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:45:52.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1286 (MapPartitionsRDD[994] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:45:52.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSchedulerImpl: Adding task set 1286.1 with 10 tasks resource profile 0
[2025-05-08T19:45:52.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: Submitting ShuffleMapStage 1330 (MapPartitionsRDD[1000] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:45:52.821+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1330.
[2025-05-08T19:45:52.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 30.4 KiB, free 416.0 MiB)
[2025-05-08T19:45:52.823+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 416.0 MiB)
[2025-05-08T19:45:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on f2a432e4376a:35283 (size: 11.5 KiB, free: 432.4 MiB)
[2025-05-08T19:45:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:45:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1330 (MapPartitionsRDD[1000] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:45:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSchedulerImpl: Adding task set 1330.1 with 10 tasks resource profile 0
[2025-05-08T19:45:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Starting task 0.0 in stage 1286.1 (TID 1945) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:45:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO TaskSetManager: Finished task 6.0 in stage 1289.0 (TID 1944) in 5 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:45:52.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 172.20.0.5:36007 (size: 11.3 KiB, free: 420.4 MiB)
[2025-05-08T19:45:52.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:36758
[2025-05-08T19:45:52.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:36758
[2025-05-08T19:45:52.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:36758
[2025-05-08T19:45:52.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:36758
[2025-05-08T19:45:53.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 52 to 172.20.0.5:36758
[2025-05-08T19:45:53.299+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:36758
[2025-05-08T19:45:53.765+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 58 to 172.20.0.5:36758
[2025-05-08T19:45:54.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 61 to 172.20.0.5:36758
[2025-05-08T19:45:56.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 64 to 172.20.0.5:36758
[2025-05-08T19:45:59.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:45:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 67 to 172.20.0.5:36758
[2025-05-08T19:46:00.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:00 INFO BlockManagerInfo: Added rdd_577_0 in memory on 172.20.0.5:36007 (size: 13.2 KiB, free: 420.4 MiB)
[2025-05-08T19:46:00.027+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:00 INFO TaskSetManager: Starting task 1.0 in stage 1286.1 (TID 1946) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:00.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:00 INFO TaskSetManager: Finished task 0.0 in stage 1286.1 (TID 1945) in 7203 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:07.418+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:07 INFO BlockManagerInfo: Added rdd_577_1 in memory on 172.20.0.5:36007 (size: 14.1 KiB, free: 420.4 MiB)
[2025-05-08T19:46:07.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:07 INFO TaskSetManager: Starting task 2.0 in stage 1286.1 (TID 1947) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:07.424+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:07 INFO TaskSetManager: Finished task 1.0 in stage 1286.1 (TID 1946) in 7397 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:12.352+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:12 INFO BlockManagerInfo: Added rdd_577_2 in memory on 172.20.0.5:36007 (size: 12.9 KiB, free: 420.4 MiB)
[2025-05-08T19:46:12.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:12 INFO TaskSetManager: Starting task 3.0 in stage 1286.1 (TID 1948) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:12.357+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:12 INFO TaskSetManager: Finished task 2.0 in stage 1286.1 (TID 1947) in 4934 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:16.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:16 INFO BlockManagerInfo: Added rdd_577_3 in memory on 172.20.0.5:36007 (size: 12.9 KiB, free: 420.4 MiB)
[2025-05-08T19:46:16.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:16 INFO TaskSetManager: Starting task 4.0 in stage 1286.1 (TID 1949) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:16.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:16 INFO TaskSetManager: Finished task 3.0 in stage 1286.1 (TID 1948) in 4101 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:22.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:22 INFO BlockManagerInfo: Added rdd_577_4 in memory on 172.20.0.5:36007 (size: 13.7 KiB, free: 420.4 MiB)
[2025-05-08T19:46:22.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:22 INFO TaskSetManager: Starting task 5.0 in stage 1286.1 (TID 1950) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:22.786+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:22 INFO TaskSetManager: Finished task 4.0 in stage 1286.1 (TID 1949) in 6328 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:28.640+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:28 INFO BlockManagerInfo: Added rdd_577_5 in memory on 172.20.0.5:36007 (size: 13.7 KiB, free: 420.4 MiB)
[2025-05-08T19:46:28.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:28 INFO TaskSetManager: Starting task 6.0 in stage 1286.1 (TID 1951) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:28.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:28 INFO TaskSetManager: Finished task 5.0 in stage 1286.1 (TID 1950) in 5858 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:33.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:33 INFO BlockManagerInfo: Added rdd_577_6 in memory on 172.20.0.5:36007 (size: 13.4 KiB, free: 420.4 MiB)
[2025-05-08T19:46:33.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:33 INFO TaskSetManager: Starting task 7.0 in stage 1286.1 (TID 1952) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:33.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:33 INFO TaskSetManager: Finished task 6.0 in stage 1286.1 (TID 1951) in 4770 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:40.248+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:40 INFO BlockManagerInfo: Added rdd_577_7 in memory on 172.20.0.5:36007 (size: 13.6 KiB, free: 420.3 MiB)
[2025-05-08T19:46:40.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:40 INFO TaskSetManager: Starting task 8.0 in stage 1286.1 (TID 1953) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:40.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:40 INFO TaskSetManager: Finished task 7.0 in stage 1286.1 (TID 1952) in 6840 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:47.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:47 INFO BlockManagerInfo: Added rdd_577_8 in memory on 172.20.0.5:36007 (size: 13.7 KiB, free: 420.3 MiB)
[2025-05-08T19:46:47.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:47 INFO TaskSetManager: Starting task 9.0 in stage 1286.1 (TID 1954) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:47.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:47 INFO TaskSetManager: Finished task 8.0 in stage 1286.1 (TID 1953) in 6833 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:52.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_577_9 in memory on 172.20.0.5:36007 (size: 13.2 KiB, free: 420.3 MiB)
[2025-05-08T19:46:52.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 7.0 in stage 1289.0 (TID 1955) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 9.0 in stage 1286.1 (TID 1954) in 5567 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:52.653+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSchedulerImpl: Removed TaskSet 1286.1, whose tasks have all completed, from pool
[2025-05-08T19:46:52.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: ShuffleMapStage 1286 (collect at /opt/airflow/spark/build_graph.py:229) finished in 59.835 s
[2025-05-08T19:46:52.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:52.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:52.654+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:52.655+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:52.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 8.0 in stage 1289.0 (TID 1956) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.660+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 7.0 in stage 1289.0 (TID 1955) in 7 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:52.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 9.0 in stage 1289.0 (TID 1957) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 8.0 in stage 1289.0 (TID 1956) in 5 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:52.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 0.0 in stage 1330.1 (TID 1958) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 9.0 in stage 1289.0 (TID 1957) in 4 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:52.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSchedulerImpl: Removed TaskSet 1289.0, whose tasks have all completed, from pool
[2025-05-08T19:46:52.669+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: ShuffleMapStage 1289 (mapPartitions at VertexRDDImpl.scala:247) finished in 178.211 s
[2025-05-08T19:46:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: running: Set(ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Submitting ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:52.673+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 172.20.0.5:36007 (size: 11.5 KiB, free: 420.3 MiB)
[2025-05-08T19:46:52.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 238.4 KiB, free 415.8 MiB)
[2025-05-08T19:46:52.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T19:46:52.682+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 415.7 MiB)
[2025-05-08T19:46:52.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.3 MiB)
[2025-05-08T19:46:52.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:52.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:52.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSchedulerImpl: Adding task set 1290.0 with 10 tasks resource profile 0
[2025-05-08T19:46:52.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO ShufflePartitionsUtil: For shuffle(119), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:46:52.694+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 0.0 in stage 1290.0 (TID 1959) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 0.0 in stage 1330.1 (TID 1958) in 26 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:52.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 172.20.0.5:36007 (size: 78.8 KiB, free: 420.2 MiB)
[2025-05-08T19:46:52.712+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_602_0 in memory on 172.20.0.5:36007 (size: 50.5 KiB, free: 420.2 MiB)
[2025-05-08T19:46:52.713+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:52.726+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:52.748+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 1.0 in stage 1290.0 (TID 1960) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.749+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 0.0 in stage 1290.0 (TID 1959) in 55 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:52.761+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_602_1 in memory on 172.20.0.5:36007 (size: 51.2 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.772+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 2.0 in stage 1290.0 (TID 1961) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 1.0 in stage 1290.0 (TID 1960) in 25 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:52.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_212_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.3 MiB)
[2025-05-08T19:46:52.788+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_602_2 in memory on 172.20.0.5:36007 (size: 54.2 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 172.20.0.5:36007 in memory (size: 6.3 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_213_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.3 MiB)
[2025-05-08T19:46:52.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 172.20.0.5:36007 in memory (size: 6.1 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_218_piece0 on f2a432e4376a:35283 in memory (size: 11.3 KiB, free: 432.4 MiB)
[2025-05-08T19:46:52.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 172.20.0.5:36007 in memory (size: 11.3 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_215_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.4 MiB)
[2025-05-08T19:46:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 3.0 in stage 1290.0 (TID 1962) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 172.20.0.5:36007 in memory (size: 6.4 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 2.0 in stage 1290.0 (TID 1961) in 53 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:52.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_216_piece0 on f2a432e4376a:35283 in memory (size: 6.2 KiB, free: 432.4 MiB)
[2025-05-08T19:46:52.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 172.20.0.5:36007 in memory (size: 6.2 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.842+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_211_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.4 MiB)
[2025-05-08T19:46:52.843+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 172.20.0.5:36007 in memory (size: 79.3 KiB, free: 420.2 MiB)
[2025-05-08T19:46:52.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_602_3 in memory on 172.20.0.5:36007 (size: 55.4 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_217_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.5 MiB)
[2025-05-08T19:46:52.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 172.20.0.5:36007 in memory (size: 79.4 KiB, free: 420.2 MiB)
[2025-05-08T19:46:52.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO SparkContext: Starting job: collect at /opt/airflow/spark/build_graph.py:229
[2025-05-08T19:46:52.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_214_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.6 MiB)
[2025-05-08T19:46:52.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Got job 80 (collect at /opt/airflow/spark/build_graph.py:229) with 1 output partitions
[2025-05-08T19:46:52.862+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Final stage: ResultStage 1340 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:46:52.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1339)
[2025-05-08T19:46:52.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:46:52.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Submitting ResultStage 1340 (MapPartitionsRDD[1128] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:46:52.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 7.2 KiB, free 416.8 MiB)
[2025-05-08T19:46:52.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 172.20.0.5:36007 in memory (size: 79.3 KiB, free: 420.3 MiB)
[2025-05-08T19:46:52.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 416.8 MiB)
[2025-05-08T19:46:52.877+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on f2a432e4376a:35283 (size: 3.8 KiB, free: 432.6 MiB)
[2025-05-08T19:46:52.878+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:52.878+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1340 (MapPartitionsRDD[1128] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:46:52.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSchedulerImpl: Adding task set 1340.0 with 1 tasks resource profile 0
[2025-05-08T19:46:52.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 4.0 in stage 1290.0 (TID 1963) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 3.0 in stage 1290.0 (TID 1962) in 54 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:52.895+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_602_4 in memory on 172.20.0.5:36007 (size: 46.8 KiB, free: 420.2 MiB)
[2025-05-08T19:46:52.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 5.0 in stage 1290.0 (TID 1964) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 4.0 in stage 1290.0 (TID 1963) in 31 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:52.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_602_5 in memory on 172.20.0.5:36007 (size: 53.5 KiB, free: 420.2 MiB)
[2025-05-08T19:46:52.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 6.0 in stage 1290.0 (TID 1965) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.944+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 5.0 in stage 1290.0 (TID 1964) in 31 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:52.957+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO BlockManagerInfo: Added rdd_602_6 in memory on 172.20.0.5:36007 (size: 50.7 KiB, free: 420.1 MiB)
[2025-05-08T19:46:52.973+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Starting task 7.0 in stage 1290.0 (TID 1966) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:52.975+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:52 INFO TaskSetManager: Finished task 6.0 in stage 1290.0 (TID 1965) in 36 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:53.023+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added rdd_602_7 in memory on 172.20.0.5:36007 (size: 50.4 KiB, free: 420.1 MiB)
[2025-05-08T19:46:53.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Removed broadcast_201_piece0 on f2a432e4376a:35283 in memory (size: 5.3 KiB, free: 432.6 MiB)
[2025-05-08T19:46:53.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 172.20.0.5:36007 in memory (size: 5.3 KiB, free: 420.1 MiB)
[2025-05-08T19:46:53.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Removed broadcast_202_piece0 on f2a432e4376a:35283 in memory (size: 5.0 KiB, free: 432.6 MiB)
[2025-05-08T19:46:53.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 172.20.0.5:36007 in memory (size: 5.0 KiB, free: 420.1 MiB)
[2025-05-08T19:46:53.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 8.0 in stage 1290.0 (TID 1967) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 7.0 in stage 1290.0 (TID 1966) in 83 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:53.075+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added rdd_602_8 in memory on 172.20.0.5:36007 (size: 48.3 KiB, free: 420.1 MiB)
[2025-05-08T19:46:53.092+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 9.0 in stage 1290.0 (TID 1968) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 8.0 in stage 1290.0 (TID 1967) in 40 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:53.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added rdd_602_9 in memory on 172.20.0.5:36007 (size: 55.5 KiB, free: 420.0 MiB)
[2025-05-08T19:46:53.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 1.0 in stage 1330.1 (TID 1969) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 9.0 in stage 1290.0 (TID 1968) in 25 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:53.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Removed TaskSet 1290.0, whose tasks have all completed, from pool
[2025-05-08T19:46:53.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: ShuffleMapStage 1290 (mapPartitions at GraphImpl.scala:208) finished in 0.447 s
[2025-05-08T19:46:53.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:53.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:53.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:53.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:53.119+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:53.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 12.0 KiB, free 416.8 MiB)
[2025-05-08T19:46:53.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 416.8 MiB)
[2025-05-08T19:46:53.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.6 MiB)
[2025-05-08T19:46:53.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:53.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:53.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Adding task set 1291.0 with 10 tasks resource profile 0
[2025-05-08T19:46:53.125+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 0.0 in stage 1291.0 (TID 1970) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.126+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 1.0 in stage 1330.1 (TID 1969) in 9 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:53.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 172.20.0.5:36007 (size: 5.7 KiB, free: 420.0 MiB)
[2025-05-08T19:46:53.132+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:53.141+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 1.0 in stage 1291.0 (TID 1971) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 0.0 in stage 1291.0 (TID 1970) in 16 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:53.152+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 2.0 in stage 1291.0 (TID 1972) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 1.0 in stage 1291.0 (TID 1971) in 11 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:53.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 3.0 in stage 1291.0 (TID 1973) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 2.0 in stage 1291.0 (TID 1972) in 8 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:53.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 4.0 in stage 1291.0 (TID 1974) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.168+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 3.0 in stage 1291.0 (TID 1973) in 7 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:53.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 5.0 in stage 1291.0 (TID 1975) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.175+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 4.0 in stage 1291.0 (TID 1974) in 8 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:53.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 6.0 in stage 1291.0 (TID 1976) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 5.0 in stage 1291.0 (TID 1975) in 7 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:53.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 7.0 in stage 1291.0 (TID 1977) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.190+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 6.0 in stage 1291.0 (TID 1976) in 8 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:53.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 8.0 in stage 1291.0 (TID 1978) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 7.0 in stage 1291.0 (TID 1977) in 9 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:53.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 9.0 in stage 1291.0 (TID 1979) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 8.0 in stage 1291.0 (TID 1978) in 8 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:53.213+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 2.0 in stage 1330.1 (TID 1980) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 9.0 in stage 1291.0 (TID 1979) in 7 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:53.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Removed TaskSet 1291.0, whose tasks have all completed, from pool
[2025-05-08T19:46:53.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: ShuffleMapStage 1291 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.095 s
[2025-05-08T19:46:53.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:53.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:53.214+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:53.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:53.215+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:53.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 3.0 in stage 1330.1 (TID 1981) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 2.0 in stage 1330.1 (TID 1980) in 8 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:53.221+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 238.8 KiB, free 416.5 MiB)
[2025-05-08T19:46:53.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 416.5 MiB)
[2025-05-08T19:46:53.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.5 MiB)
[2025-05-08T19:46:53.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:53.223+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:53.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Adding task set 1292.0 with 10 tasks resource profile 0
[2025-05-08T19:46:53.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 0.0 in stage 1292.0 (TID 1982) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 3.0 in stage 1330.1 (TID 1981) in 8 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:53.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 172.20.0.5:36007 (size: 78.8 KiB, free: 419.9 MiB)
[2025-05-08T19:46:53.241+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:53.243+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:53.244+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:53.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 1.0 in stage 1292.0 (TID 1983) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.256+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 0.0 in stage 1292.0 (TID 1982) in 27 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:53.282+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 2.0 in stage 1292.0 (TID 1984) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 1.0 in stage 1292.0 (TID 1983) in 27 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 3.0 in stage 1292.0 (TID 1985) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 2.0 in stage 1292.0 (TID 1984) in 20 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:53.329+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 4.0 in stage 1292.0 (TID 1986) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 3.0 in stage 1292.0 (TID 1985) in 29 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:53.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 5.0 in stage 1292.0 (TID 1987) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 4.0 in stage 1292.0 (TID 1986) in 19 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:53.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 6.0 in stage 1292.0 (TID 1988) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.366+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 5.0 in stage 1292.0 (TID 1987) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:53.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 7.0 in stage 1292.0 (TID 1989) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 6.0 in stage 1292.0 (TID 1988) in 19 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:53.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 8.0 in stage 1292.0 (TID 1990) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 7.0 in stage 1292.0 (TID 1989) in 24 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:53.427+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 9.0 in stage 1292.0 (TID 1991) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 8.0 in stage 1292.0 (TID 1990) in 20 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:53.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 4.0 in stage 1330.1 (TID 1992) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 9.0 in stage 1292.0 (TID 1991) in 19 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:53.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Removed TaskSet 1292.0, whose tasks have all completed, from pool
[2025-05-08T19:46:53.446+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: ShuffleMapStage 1292 (mapPartitions at GraphImpl.scala:208) finished in 0.231 s
[2025-05-08T19:46:53.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:53.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:53.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:53.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:53.447+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:53.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 12.8 KiB, free 416.5 MiB)
[2025-05-08T19:46:53.448+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 416.5 MiB)
[2025-05-08T19:46:53.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.5 MiB)
[2025-05-08T19:46:53.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:53.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:53.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Adding task set 1293.0 with 10 tasks resource profile 0
[2025-05-08T19:46:53.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 0.0 in stage 1293.0 (TID 1993) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 4.0 in stage 1330.1 (TID 1992) in 8 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:53.456+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 172.20.0.5:36007 (size: 5.9 KiB, free: 419.9 MiB)
[2025-05-08T19:46:53.458+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:53.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:53.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 1.0 in stage 1293.0 (TID 1994) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 0.0 in stage 1293.0 (TID 1993) in 14 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:53.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 2.0 in stage 1293.0 (TID 1995) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 1.0 in stage 1293.0 (TID 1994) in 10 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:53.484+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 3.0 in stage 1293.0 (TID 1996) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.485+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 2.0 in stage 1293.0 (TID 1995) in 9 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:53.493+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 4.0 in stage 1293.0 (TID 1997) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 3.0 in stage 1293.0 (TID 1996) in 9 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:53.502+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 5.0 in stage 1293.0 (TID 1998) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.503+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 4.0 in stage 1293.0 (TID 1997) in 9 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:53.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 6.0 in stage 1293.0 (TID 1999) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.511+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 5.0 in stage 1293.0 (TID 1998) in 9 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:53.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 7.0 in stage 1293.0 (TID 2000) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.520+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 6.0 in stage 1293.0 (TID 1999) in 9 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:53.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 8.0 in stage 1293.0 (TID 2001) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 7.0 in stage 1293.0 (TID 2000) in 9 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:53.536+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 9.0 in stage 1293.0 (TID 2002) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.537+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 8.0 in stage 1293.0 (TID 2001) in 8 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:53.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 5.0 in stage 1330.1 (TID 2003) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 9.0 in stage 1293.0 (TID 2002) in 9 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:53.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Removed TaskSet 1293.0, whose tasks have all completed, from pool
[2025-05-08T19:46:53.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: ShuffleMapStage 1293 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.098 s
[2025-05-08T19:46:53.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:53.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:53.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:53.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:53.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:53.551+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 6.0 in stage 1330.1 (TID 2004) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 5.0 in stage 1330.1 (TID 2003) in 6 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:53.552+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 239.1 KiB, free 416.2 MiB)
[2025-05-08T19:46:53.553+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 416.1 MiB)
[2025-05-08T19:46:53.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.4 MiB)
[2025-05-08T19:46:53.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:53.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:53.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Adding task set 1294.0 with 10 tasks resource profile 0
[2025-05-08T19:46:53.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 0.0 in stage 1294.0 (TID 2005) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 6.0 in stage 1330.1 (TID 2004) in 9 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:53.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 172.20.0.5:36007 (size: 79.0 KiB, free: 419.8 MiB)
[2025-05-08T19:46:53.572+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:53.574+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:53.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:53.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:46:53.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 1.0 in stage 1294.0 (TID 2006) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.589+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 0.0 in stage 1294.0 (TID 2005) in 29 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:53.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 2.0 in stage 1294.0 (TID 2007) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.618+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 1.0 in stage 1294.0 (TID 2006) in 30 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:53.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 3.0 in stage 1294.0 (TID 2008) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 2.0 in stage 1294.0 (TID 2007) in 28 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:53.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 4.0 in stage 1294.0 (TID 2009) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.665+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 3.0 in stage 1294.0 (TID 2008) in 21 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:53.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 5.0 in stage 1294.0 (TID 2010) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 4.0 in stage 1294.0 (TID 2009) in 22 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:53.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 6.0 in stage 1294.0 (TID 2011) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.705+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 5.0 in stage 1294.0 (TID 2010) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:53.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 7.0 in stage 1294.0 (TID 2012) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.725+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 6.0 in stage 1294.0 (TID 2011) in 20 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:53.742+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 8.0 in stage 1294.0 (TID 2013) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 7.0 in stage 1294.0 (TID 2012) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:53.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 9.0 in stage 1294.0 (TID 2014) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 8.0 in stage 1294.0 (TID 2013) in 20 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:53.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 7.0 in stage 1330.1 (TID 2015) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 9.0 in stage 1294.0 (TID 2014) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:53.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Removed TaskSet 1294.0, whose tasks have all completed, from pool
[2025-05-08T19:46:53.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: ShuffleMapStage 1294 (mapPartitions at GraphImpl.scala:208) finished in 0.233 s
[2025-05-08T19:46:53.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:53.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:53.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:53.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:53.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:53.782+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 13.5 KiB, free 416.1 MiB)
[2025-05-08T19:46:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.1 MiB)
[2025-05-08T19:46:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.4 MiB)
[2025-05-08T19:46:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Adding task set 1295.0 with 10 tasks resource profile 0
[2025-05-08T19:46:53.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 0.0 in stage 1295.0 (TID 2016) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.787+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 7.0 in stage 1330.1 (TID 2015) in 8 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:53.790+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 172.20.0.5:36007 (size: 6.1 KiB, free: 419.8 MiB)
[2025-05-08T19:46:53.792+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:53.795+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:53.799+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:46:53.803+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 1.0 in stage 1295.0 (TID 2017) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 0.0 in stage 1295.0 (TID 2016) in 16 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:53.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 2.0 in stage 1295.0 (TID 2018) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 1.0 in stage 1295.0 (TID 2017) in 11 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:53.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 3.0 in stage 1295.0 (TID 2019) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 2.0 in stage 1295.0 (TID 2018) in 13 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:53.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 4.0 in stage 1295.0 (TID 2020) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 3.0 in stage 1295.0 (TID 2019) in 10 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:53.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 5.0 in stage 1295.0 (TID 2021) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 4.0 in stage 1295.0 (TID 2020) in 14 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:53.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 6.0 in stage 1295.0 (TID 2022) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 5.0 in stage 1295.0 (TID 2021) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:53.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 7.0 in stage 1295.0 (TID 2023) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.895+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 6.0 in stage 1295.0 (TID 2022) in 27 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:53.907+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 8.0 in stage 1295.0 (TID 2024) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 7.0 in stage 1295.0 (TID 2023) in 14 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:53.918+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 9.0 in stage 1295.0 (TID 2025) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.918+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 8.0 in stage 1295.0 (TID 2024) in 11 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:53.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 8.0 in stage 1330.1 (TID 2026) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 9.0 in stage 1295.0 (TID 2025) in 11 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:53.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Removed TaskSet 1295.0, whose tasks have all completed, from pool
[2025-05-08T19:46:53.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: ShuffleMapStage 1295 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.148 s
[2025-05-08T19:46:53.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:53.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1330, ShuffleMapStage 1336)
[2025-05-08T19:46:53.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:53.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:53.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:53.936+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 239.4 KiB, free 415.9 MiB)
[2025-05-08T19:46:53.937+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 415.8 MiB)
[2025-05-08T19:46:53.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 9.0 in stage 1330.1 (TID 2027) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5266 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 8.0 in stage 1330.1 (TID 2026) in 9 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:53.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.4 MiB)
[2025-05-08T19:46:53.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:53.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:53.938+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Adding task set 1296.0 with 10 tasks resource profile 0
[2025-05-08T19:46:53.944+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 0.0 in stage 1296.0 (TID 2028) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 9.0 in stage 1330.1 (TID 2027) in 7 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSchedulerImpl: Removed TaskSet 1330.1, whose tasks have all completed, from pool
[2025-05-08T19:46:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: ShuffleMapStage 1330 (collect at /opt/airflow/spark/build_graph.py:229) finished in 61.124 s
[2025-05-08T19:46:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ShuffleMapStage 1296, ShuffleMapStage 1336)
[2025-05-08T19:46:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:53.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 172.20.0.5:36007 (size: 79.1 KiB, free: 419.8 MiB)
[2025-05-08T19:46:53.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T19:46:53.962+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:53.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:53.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO ShufflePartitionsUtil: For shuffle(121), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T19:46:53.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:53.968+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:46:53.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:46:53.981+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Starting task 1.0 in stage 1296.0 (TID 2029) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:53.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:53 INFO TaskSetManager: Finished task 0.0 in stage 1296.0 (TID 2028) in 38 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:54.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 2.0 in stage 1296.0 (TID 2030) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 1.0 in stage 1296.0 (TID 2029) in 33 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:54.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 3.0 in stage 1296.0 (TID 2031) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.046+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 2.0 in stage 1296.0 (TID 2030) in 34 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:54.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 4.0 in stage 1296.0 (TID 2032) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 3.0 in stage 1296.0 (TID 2031) in 34 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:54.113+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 5.0 in stage 1296.0 (TID 2033) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_226_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.4 MiB)
[2025-05-08T19:46:54.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 4.0 in stage 1296.0 (TID 2032) in 36 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:54.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 172.20.0.5:36007 in memory (size: 6.1 KiB, free: 419.8 MiB)
[2025-05-08T19:46:54.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_224_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.4 MiB)
[2025-05-08T19:46:54.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 172.20.0.5:36007 in memory (size: 5.9 KiB, free: 419.8 MiB)
[2025-05-08T19:46:54.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_222_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.4 MiB)
[2025-05-08T19:46:54.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 172.20.0.5:36007 in memory (size: 5.7 KiB, free: 419.8 MiB)
[2025-05-08T19:46:54.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_225_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.4 MiB)
[2025-05-08T19:46:54.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 172.20.0.5:36007 in memory (size: 79.0 KiB, free: 419.8 MiB)
[2025-05-08T19:46:54.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 6.0 in stage 1296.0 (TID 2034) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_223_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.5 MiB)
[2025-05-08T19:46:54.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 5.0 in stage 1296.0 (TID 2033) in 34 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:54.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 172.20.0.5:36007 in memory (size: 78.8 KiB, free: 419.9 MiB)
[2025-05-08T19:46:54.157+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO SparkContext: Starting job: collect at /opt/airflow/spark/build_graph.py:229
[2025-05-08T19:46:54.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Got job 81 (collect at /opt/airflow/spark/build_graph.py:229) with 1 output partitions
[2025-05-08T19:46:54.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Final stage: ResultStage 1342 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T19:46:54.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1341)
[2025-05-08T19:46:54.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Missing parents: List()
[2025-05-08T19:46:54.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting ResultStage 1342 (MapPartitionsRDD[1130] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:46:54.159+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 7.2 KiB, free 416.5 MiB)
[2025-05-08T19:46:54.171+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 416.5 MiB)
[2025-05-08T19:46:54.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on f2a432e4376a:35283 (size: 3.8 KiB, free: 432.5 MiB)
[2025-05-08T19:46:54.172+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:54.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1342 (MapPartitionsRDD[1130] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T19:46:54.173+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Adding task set 1342.0 with 1 tasks resource profile 0
[2025-05-08T19:46:54.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 7.0 in stage 1296.0 (TID 2035) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 6.0 in stage 1296.0 (TID 2034) in 33 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:54.201+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 8.0 in stage 1296.0 (TID 2036) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.202+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 7.0 in stage 1296.0 (TID 2035) in 22 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:54.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 9.0 in stage 1296.0 (TID 2037) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.235+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 8.0 in stage 1296.0 (TID 2036) in 34 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:54.267+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 0.0 in stage 1334.1 (TID 2038) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 9.0 in stage 1296.0 (TID 2037) in 36 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:54.268+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Removed TaskSet 1296.0, whose tasks have all completed, from pool
[2025-05-08T19:46:54.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: ShuffleMapStage 1296 (mapPartitions at GraphImpl.scala:208) finished in 0.337 s
[2025-05-08T19:46:54.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:54.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T19:46:54.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:54.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:54.270+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:54.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 14.2 KiB, free 416.5 MiB)
[2025-05-08T19:46:54.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.5 MiB)
[2025-05-08T19:46:54.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T19:46:54.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:54.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:54.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Adding task set 1297.0 with 10 tasks resource profile 0
[2025-05-08T19:46:54.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_220_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.6 MiB)
[2025-05-08T19:46:54.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 172.20.0.5:36007 (size: 13.8 KiB, free: 419.9 MiB)
[2025-05-08T19:46:54.295+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 172.20.0.5:36007 in memory (size: 78.8 KiB, free: 420.0 MiB)
[2025-05-08T19:46:54.300+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_219_piece0 on f2a432e4376a:35283 in memory (size: 11.5 KiB, free: 432.6 MiB)
[2025-05-08T19:46:54.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 172.20.0.5:36007 in memory (size: 11.5 KiB, free: 420.0 MiB)
[2025-05-08T19:46:54.399+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 0.0 in stage 1297.0 (TID 2039) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 0.0 in stage 1334.1 (TID 2038) in 135 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-08T19:46:54.403+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Removed TaskSet 1334.1, whose tasks have all completed, from pool
[2025-05-08T19:46:54.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: ShuffleMapStage 1334 (collect at /opt/airflow/spark/build_graph.py:229) finished in 193.587 s
[2025-05-08T19:46:54.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:54.407+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336, ShuffleMapStage 1297)
[2025-05-08T19:46:54.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1335, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:54.409+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:54.413+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting ShuffleMapStage 1335 (MapPartitionsRDD[1066] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T19:46:54.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1335.
[2025-05-08T19:46:54.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 107.7 KiB, free 416.7 MiB)
[2025-05-08T19:46:54.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 39.5 KiB, free 416.7 MiB)
[2025-05-08T19:46:54.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on f2a432e4376a:35283 (size: 39.5 KiB, free: 432.6 MiB)
[2025-05-08T19:46:54.416+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:54.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1335 (MapPartitionsRDD[1066] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T19:46:54.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Adding task set 1335.1 with 41 tasks resource profile 0
[2025-05-08T19:46:54.422+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 172.20.0.5:36007 (size: 6.1 KiB, free: 420.0 MiB)
[2025-05-08T19:46:54.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:54.450+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:54.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:46:54.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:46:54.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 1.0 in stage 1297.0 (TID 2040) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.476+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 0.0 in stage 1297.0 (TID 2039) in 77 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:54.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 2.0 in stage 1297.0 (TID 2041) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.494+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 1.0 in stage 1297.0 (TID 2040) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:54.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 3.0 in stage 1297.0 (TID 2042) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.512+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 2.0 in stage 1297.0 (TID 2041) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:54.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 4.0 in stage 1297.0 (TID 2043) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.529+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 3.0 in stage 1297.0 (TID 2042) in 18 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:54.547+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 5.0 in stage 1297.0 (TID 2044) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.547+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 4.0 in stage 1297.0 (TID 2043) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:54.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 6.0 in stage 1297.0 (TID 2045) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 5.0 in stage 1297.0 (TID 2044) in 18 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:54.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 7.0 in stage 1297.0 (TID 2046) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 6.0 in stage 1297.0 (TID 2045) in 18 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:54.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 8.0 in stage 1297.0 (TID 2047) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 7.0 in stage 1297.0 (TID 2046) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:54.619+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 9.0 in stage 1297.0 (TID 2048) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.620+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 8.0 in stage 1297.0 (TID 2047) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:54.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 1.0 in stage 1335.1 (TID 2049) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 9.0 in stage 1297.0 (TID 2048) in 17 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:54.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Removed TaskSet 1297.0, whose tasks have all completed, from pool
[2025-05-08T19:46:54.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: ShuffleMapStage 1297 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.367 s
[2025-05-08T19:46:54.637+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:54.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:54.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:54.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:54.638+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:54.641+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 172.20.0.5:36007 (size: 39.5 KiB, free: 420.0 MiB)
[2025-05-08T19:46:54.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:54.645+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 239.6 KiB, free 416.4 MiB)
[2025-05-08T19:46:54.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 416.4 MiB)
[2025-05-08T19:46:54.649+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.5 MiB)
[2025-05-08T19:46:54.650+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:54.650+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:54.650+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Adding task set 1298.0 with 10 tasks resource profile 0
[2025-05-08T19:46:54.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 0.0 in stage 1298.0 (TID 2050) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.717+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 1.0 in stage 1335.1 (TID 2049) in 80 ms on 172.20.0.5 (executor 1) (1/41)
[2025-05-08T19:46:54.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 172.20.0.5:36007 (size: 79.3 KiB, free: 419.9 MiB)
[2025-05-08T19:46:54.736+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:54.740+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:54.753+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:54.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:46:54.756+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:46:54.758+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:46:54.778+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 1.0 in stage 1298.0 (TID 2051) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 0.0 in stage 1298.0 (TID 2050) in 64 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:54.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 2.0 in stage 1298.0 (TID 2052) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 1.0 in stage 1298.0 (TID 2051) in 33 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:54.832+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 3.0 in stage 1298.0 (TID 2053) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 2.0 in stage 1298.0 (TID 2052) in 22 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:54.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 4.0 in stage 1298.0 (TID 2054) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.855+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 3.0 in stage 1298.0 (TID 2053) in 24 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:54.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 5.0 in stage 1298.0 (TID 2055) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 4.0 in stage 1298.0 (TID 2054) in 26 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:54.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 6.0 in stage 1298.0 (TID 2056) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 5.0 in stage 1298.0 (TID 2055) in 32 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:54.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 7.0 in stage 1298.0 (TID 2057) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.931+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 6.0 in stage 1298.0 (TID 2056) in 21 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:54.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 8.0 in stage 1298.0 (TID 2058) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 7.0 in stage 1298.0 (TID 2057) in 22 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:54.972+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 9.0 in stage 1298.0 (TID 2059) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.973+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 8.0 in stage 1298.0 (TID 2058) in 21 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:54.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Starting task 2.0 in stage 1335.1 (TID 2060) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:54.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSetManager: Finished task 9.0 in stage 1298.0 (TID 2059) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:54.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Removed TaskSet 1298.0, whose tasks have all completed, from pool
[2025-05-08T19:46:54.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: ShuffleMapStage 1298 (mapPartitions at GraphImpl.scala:208) finished in 0.354 s
[2025-05-08T19:46:54.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:54.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:54.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T19:46:54.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:54.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:54.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 14.9 KiB, free 416.3 MiB)
[2025-05-08T19:46:54.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:54.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 416.3 MiB)
[2025-05-08T19:46:54.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.5 MiB)
[2025-05-08T19:46:54.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:54.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:54.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:54 INFO TaskSchedulerImpl: Adding task set 1299.0 with 10 tasks resource profile 0
[2025-05-08T19:46:55.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 0.0 in stage 1299.0 (TID 2061) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 2.0 in stage 1335.1 (TID 2060) in 27 ms on 172.20.0.5 (executor 1) (2/41)
[2025-05-08T19:46:55.022+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 172.20.0.5:36007 (size: 6.3 KiB, free: 419.9 MiB)
[2025-05-08T19:46:55.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:55.028+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:55.030+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:46:55.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:46:55.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:46:55.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 1.0 in stage 1299.0 (TID 2062) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.061+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 0.0 in stage 1299.0 (TID 2061) in 43 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:55.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 2.0 in stage 1299.0 (TID 2063) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 1.0 in stage 1299.0 (TID 2062) in 25 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:55.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 3.0 in stage 1299.0 (TID 2064) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 2.0 in stage 1299.0 (TID 2063) in 25 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:55.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 4.0 in stage 1299.0 (TID 2065) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.135+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 3.0 in stage 1299.0 (TID 2064) in 25 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:55.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 5.0 in stage 1299.0 (TID 2066) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 4.0 in stage 1299.0 (TID 2065) in 23 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:55.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 6.0 in stage 1299.0 (TID 2067) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 5.0 in stage 1299.0 (TID 2066) in 25 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:55.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 7.0 in stage 1299.0 (TID 2068) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.205+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 6.0 in stage 1299.0 (TID 2067) in 23 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:55.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 8.0 in stage 1299.0 (TID 2069) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 7.0 in stage 1299.0 (TID 2068) in 23 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:55.251+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 9.0 in stage 1299.0 (TID 2070) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.251+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 8.0 in stage 1299.0 (TID 2069) in 23 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:55.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 3.0 in stage 1335.1 (TID 2071) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 9.0 in stage 1299.0 (TID 2070) in 23 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSchedulerImpl: Removed TaskSet 1299.0, whose tasks have all completed, from pool
[2025-05-08T19:46:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: ShuffleMapStage 1299 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.279 s
[2025-05-08T19:46:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T19:46:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: Submitting ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:55.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:55.282+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 239.9 KiB, free 416.1 MiB)
[2025-05-08T19:46:55.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 416.0 MiB)
[2025-05-08T19:46:55.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.4 MiB)
[2025-05-08T19:46:55.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:55.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:55.285+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSchedulerImpl: Adding task set 1300.0 with 10 tasks resource profile 0
[2025-05-08T19:46:55.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 0.0 in stage 1300.0 (TID 2072) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 3.0 in stage 1335.1 (TID 2071) in 15 ms on 172.20.0.5 (executor 1) (3/41)
[2025-05-08T19:46:55.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 172.20.0.5:36007 (size: 79.0 KiB, free: 419.8 MiB)
[2025-05-08T19:46:55.305+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:55.308+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:55.310+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:55.313+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:46:55.314+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:46:55.316+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:46:55.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:46:55.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 1.0 in stage 1300.0 (TID 2073) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 0.0 in stage 1300.0 (TID 2072) in 57 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:55.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 2.0 in stage 1300.0 (TID 2074) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 1.0 in stage 1300.0 (TID 2073) in 40 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:55.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 3.0 in stage 1300.0 (TID 2075) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.414+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 2.0 in stage 1300.0 (TID 2074) in 32 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:55.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 4.0 in stage 1300.0 (TID 2076) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.443+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 3.0 in stage 1300.0 (TID 2075) in 30 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:55.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 5.0 in stage 1300.0 (TID 2077) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 4.0 in stage 1300.0 (TID 2076) in 19 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:55.479+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 6.0 in stage 1300.0 (TID 2078) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.480+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 5.0 in stage 1300.0 (TID 2077) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:55.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 7.0 in stage 1300.0 (TID 2079) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 6.0 in stage 1300.0 (TID 2078) in 19 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:55.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 8.0 in stage 1300.0 (TID 2080) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 7.0 in stage 1300.0 (TID 2079) in 22 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:55.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 9.0 in stage 1300.0 (TID 2081) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 8.0 in stage 1300.0 (TID 2080) in 20 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:55.556+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 6.0 in stage 1335.1 (TID 2082) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 9.0 in stage 1300.0 (TID 2081) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:55.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSchedulerImpl: Removed TaskSet 1300.0, whose tasks have all completed, from pool
[2025-05-08T19:46:55.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: ShuffleMapStage 1300 (mapPartitions at GraphImpl.scala:208) finished in 0.282 s
[2025-05-08T19:46:55.557+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:55.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:55.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T19:46:55.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:55.558+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: Submitting ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:55.559+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 15.6 KiB, free 416.0 MiB)
[2025-05-08T19:46:55.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 416.0 MiB)
[2025-05-08T19:46:55.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.4 MiB)
[2025-05-08T19:46:55.560+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:55.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:55.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSchedulerImpl: Adding task set 1301.0 with 10 tasks resource profile 0
[2025-05-08T19:46:55.561+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:55.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 0.0 in stage 1301.0 (TID 2083) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.577+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 6.0 in stage 1335.1 (TID 2082) in 21 ms on 172.20.0.5 (executor 1) (4/41)
[2025-05-08T19:46:55.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 172.20.0.5:36007 (size: 6.4 KiB, free: 419.8 MiB)
[2025-05-08T19:46:55.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:55.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:55.595+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:46:55.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:46:55.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:46:55.658+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:46:55.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 1.0 in stage 1301.0 (TID 2084) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.663+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 0.0 in stage 1301.0 (TID 2083) in 87 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:55.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 2.0 in stage 1301.0 (TID 2085) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 1.0 in stage 1301.0 (TID 2084) in 47 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:55.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 3.0 in stage 1301.0 (TID 2086) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.768+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 2.0 in stage 1301.0 (TID 2085) in 58 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:55.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 4.0 in stage 1301.0 (TID 2087) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 3.0 in stage 1301.0 (TID 2086) in 46 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:55.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 5.0 in stage 1301.0 (TID 2088) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.857+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 4.0 in stage 1301.0 (TID 2087) in 43 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:55.920+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 6.0 in stage 1301.0 (TID 2089) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.921+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 5.0 in stage 1301.0 (TID 2088) in 63 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:55.968+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Starting task 7.0 in stage 1301.0 (TID 2090) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:55.968+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:55 INFO TaskSetManager: Finished task 6.0 in stage 1301.0 (TID 2089) in 48 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:56.007+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 8.0 in stage 1301.0 (TID 2091) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 7.0 in stage 1301.0 (TID 2090) in 39 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:56.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 9.0 in stage 1301.0 (TID 2092) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 8.0 in stage 1301.0 (TID 2091) in 41 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:56.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 7.0 in stage 1335.1 (TID 2093) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 9.0 in stage 1301.0 (TID 2092) in 36 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:56.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSchedulerImpl: Removed TaskSet 1301.0, whose tasks have all completed, from pool
[2025-05-08T19:46:56.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: ShuffleMapStage 1301 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.526 s
[2025-05-08T19:46:56.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:56.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:56.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T19:46:56.087+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:56.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: Submitting ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:56.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:56.090+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 240.2 KiB, free 415.8 MiB)
[2025-05-08T19:46:56.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 415.7 MiB)
[2025-05-08T19:46:56.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.3 MiB)
[2025-05-08T19:46:56.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:56.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:56.091+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSchedulerImpl: Adding task set 1302.0 with 10 tasks resource profile 0
[2025-05-08T19:46:56.107+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 0.0 in stage 1302.0 (TID 2094) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.107+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 7.0 in stage 1335.1 (TID 2093) in 23 ms on 172.20.0.5 (executor 1) (5/41)
[2025-05-08T19:46:56.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 172.20.0.5:36007 (size: 79.1 KiB, free: 419.7 MiB)
[2025-05-08T19:46:56.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:56.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:56.121+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:56.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:46:56.123+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:46:56.124+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:46:56.125+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:46:56.138+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:46:56.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 1.0 in stage 1302.0 (TID 2095) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.155+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 0.0 in stage 1302.0 (TID 2094) in 48 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:56.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 2.0 in stage 1302.0 (TID 2096) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.174+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 1.0 in stage 1302.0 (TID 2095) in 19 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:56.191+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 3.0 in stage 1302.0 (TID 2097) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.192+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 2.0 in stage 1302.0 (TID 2096) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:56.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 4.0 in stage 1302.0 (TID 2098) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 3.0 in stage 1302.0 (TID 2097) in 18 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:56.227+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 5.0 in stage 1302.0 (TID 2099) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.228+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 4.0 in stage 1302.0 (TID 2098) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:56.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 6.0 in stage 1302.0 (TID 2100) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 5.0 in stage 1302.0 (TID 2099) in 27 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:56.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 7.0 in stage 1302.0 (TID 2101) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 6.0 in stage 1302.0 (TID 2100) in 19 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:56.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 8.0 in stage 1302.0 (TID 2102) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 7.0 in stage 1302.0 (TID 2101) in 29 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:56.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 9.0 in stage 1302.0 (TID 2103) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 8.0 in stage 1302.0 (TID 2102) in 19 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:56.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 8.0 in stage 1335.1 (TID 2104) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.339+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 9.0 in stage 1302.0 (TID 2103) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSchedulerImpl: Removed TaskSet 1302.0, whose tasks have all completed, from pool
[2025-05-08T19:46:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: ShuffleMapStage 1302 (mapPartitions at GraphImpl.scala:208) finished in 0.255 s
[2025-05-08T19:46:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T19:46:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:56.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: Submitting ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:56.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 16.4 KiB, free 415.7 MiB)
[2025-05-08T19:46:56.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 415.7 MiB)
[2025-05-08T19:46:56.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on f2a432e4376a:35283 (size: 6.5 KiB, free: 432.3 MiB)
[2025-05-08T19:46:56.343+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:56.343+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:56.343+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSchedulerImpl: Adding task set 1303.0 with 10 tasks resource profile 0
[2025-05-08T19:46:56.344+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:56.368+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 0.0 in stage 1303.0 (TID 2105) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.369+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 8.0 in stage 1335.1 (TID 2104) in 30 ms on 172.20.0.5 (executor 1) (6/41)
[2025-05-08T19:46:56.373+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 172.20.0.5:36007 (size: 6.5 KiB, free: 419.7 MiB)
[2025-05-08T19:46:56.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:56.379+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:56.383+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:46:56.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:46:56.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:46:56.423+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:46:56.474+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:46:56.478+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 1.0 in stage 1303.0 (TID 2106) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.478+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 0.0 in stage 1303.0 (TID 2105) in 110 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:56.554+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 2.0 in stage 1303.0 (TID 2107) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.555+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 1.0 in stage 1303.0 (TID 2106) in 77 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:56.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 3.0 in stage 1303.0 (TID 2108) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.631+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 2.0 in stage 1303.0 (TID 2107) in 77 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:56.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 4.0 in stage 1303.0 (TID 2109) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 3.0 in stage 1303.0 (TID 2108) in 68 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:56.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 5.0 in stage 1303.0 (TID 2110) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.762+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 4.0 in stage 1303.0 (TID 2109) in 63 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:56.849+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 6.0 in stage 1303.0 (TID 2111) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 5.0 in stage 1303.0 (TID 2110) in 87 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:56.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 7.0 in stage 1303.0 (TID 2112) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 6.0 in stage 1303.0 (TID 2111) in 64 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:56.976+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Starting task 8.0 in stage 1303.0 (TID 2113) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:56.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:56 INFO TaskSetManager: Finished task 7.0 in stage 1303.0 (TID 2112) in 63 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:57.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 9.0 in stage 1303.0 (TID 2114) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 8.0 in stage 1303.0 (TID 2113) in 81 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 9.0 in stage 1335.1 (TID 2115) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 9.0 in stage 1303.0 (TID 2114) in 64 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSchedulerImpl: Removed TaskSet 1303.0, whose tasks have all completed, from pool
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: ShuffleMapStage 1303 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.781 s
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:57.122+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: Submitting ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:57.125+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:57.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 240.5 KiB, free 415.4 MiB)
[2025-05-08T19:46:57.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 415.4 MiB)
[2025-05-08T19:46:57.128+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.2 MiB)
[2025-05-08T19:46:57.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:57.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:57.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSchedulerImpl: Adding task set 1304.0 with 10 tasks resource profile 0
[2025-05-08T19:46:57.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 0.0 in stage 1304.0 (TID 2116) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.133+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 9.0 in stage 1335.1 (TID 2115) in 12 ms on 172.20.0.5 (executor 1) (7/41)
[2025-05-08T19:46:57.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 172.20.0.5:36007 (size: 79.1 KiB, free: 419.6 MiB)
[2025-05-08T19:46:57.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:57.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:57.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:57.145+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:46:57.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:46:57.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:46:57.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:46:57.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:46:57.148+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:46:57.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 1.0 in stage 1304.0 (TID 2117) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.166+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 0.0 in stage 1304.0 (TID 2116) in 34 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:57.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 2.0 in stage 1304.0 (TID 2118) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 1.0 in stage 1304.0 (TID 2117) in 17 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:57.199+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 3.0 in stage 1304.0 (TID 2119) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.200+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 2.0 in stage 1304.0 (TID 2118) in 17 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:57.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 4.0 in stage 1304.0 (TID 2120) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.216+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 3.0 in stage 1304.0 (TID 2119) in 17 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:57.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 5.0 in stage 1304.0 (TID 2121) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 4.0 in stage 1304.0 (TID 2120) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:57.249+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 6.0 in stage 1304.0 (TID 2122) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.249+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 5.0 in stage 1304.0 (TID 2121) in 17 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:57.269+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 7.0 in stage 1304.0 (TID 2123) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.270+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 6.0 in stage 1304.0 (TID 2122) in 20 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:57.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 8.0 in stage 1304.0 (TID 2124) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.286+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 7.0 in stage 1304.0 (TID 2123) in 17 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:57.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 9.0 in stage 1304.0 (TID 2125) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.303+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 8.0 in stage 1304.0 (TID 2124) in 17 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:57.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 10.0 in stage 1335.1 (TID 2126) (172.20.0.5, executor 1, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 9.0 in stage 1304.0 (TID 2125) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:57.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSchedulerImpl: Removed TaskSet 1304.0, whose tasks have all completed, from pool
[2025-05-08T19:46:57.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: ShuffleMapStage 1304 (mapPartitions at GraphImpl.scala:208) finished in 0.198 s
[2025-05-08T19:46:57.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:57.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:57.320+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T19:46:57.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:57.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: Submitting ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:57.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 17.1 KiB, free 415.3 MiB)
[2025-05-08T19:46:57.322+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 415.3 MiB)
[2025-05-08T19:46:57.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.2 MiB)
[2025-05-08T19:46:57.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:57.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:57.323+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSchedulerImpl: Adding task set 1305.0 with 10 tasks resource profile 0
[2025-05-08T19:46:57.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T19:46:57.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 0.0 in stage 1305.0 (TID 2127) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 10.0 in stage 1335.1 (TID 2126) in 17 ms on 172.20.0.5 (executor 1) (8/41)
[2025-05-08T19:46:57.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 172.20.0.5:36007 (size: 6.6 KiB, free: 419.6 MiB)
[2025-05-08T19:46:57.343+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:57.347+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:57.351+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:46:57.358+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:46:57.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:46:57.391+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:46:57.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:46:57.519+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:46:57.523+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 1.0 in stage 1305.0 (TID 2128) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.524+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 0.0 in stage 1305.0 (TID 2127) in 187 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:57.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 2.0 in stage 1305.0 (TID 2129) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 1.0 in stage 1305.0 (TID 2128) in 165 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:57.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 3.0 in stage 1305.0 (TID 2130) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.827+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 2.0 in stage 1305.0 (TID 2129) in 138 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:57.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Starting task 4.0 in stage 1305.0 (TID 2131) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:57.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:57 INFO TaskSetManager: Finished task 3.0 in stage 1305.0 (TID 2130) in 139 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:58.098+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 5.0 in stage 1305.0 (TID 2132) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 4.0 in stage 1305.0 (TID 2131) in 133 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:58.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 6.0 in stage 1305.0 (TID 2133) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 5.0 in stage 1305.0 (TID 2132) in 126 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:58.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 7.0 in stage 1305.0 (TID 2134) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.365+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 6.0 in stage 1305.0 (TID 2133) in 142 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:58.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 8.0 in stage 1305.0 (TID 2135) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.514+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 7.0 in stage 1305.0 (TID 2134) in 148 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:58.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 9.0 in stage 1305.0 (TID 2136) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.639+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 8.0 in stage 1305.0 (TID 2135) in 126 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:58.773+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 11.0 in stage 1335.1 (TID 2137) (172.20.0.5, executor 1, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 9.0 in stage 1305.0 (TID 2136) in 134 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSchedulerImpl: Removed TaskSet 1305.0, whose tasks have all completed, from pool
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: ShuffleMapStage 1305 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.453 s
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:58.774+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: Submitting ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:46:58.777+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:46:58.778+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 240.8 KiB, free 415.1 MiB)
[2025-05-08T19:46:58.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 415.0 MiB)
[2025-05-08T19:46:58.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.2 MiB)
[2025-05-08T19:46:58.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:58.779+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:58.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSchedulerImpl: Adding task set 1306.0 with 10 tasks resource profile 0
[2025-05-08T19:46:58.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 0.0 in stage 1306.0 (TID 2138) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.801+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 11.0 in stage 1335.1 (TID 2137) in 27 ms on 172.20.0.5 (executor 1) (9/41)
[2025-05-08T19:46:58.804+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 172.20.0.5:36007 (size: 79.3 KiB, free: 419.5 MiB)
[2025-05-08T19:46:58.810+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:46:58.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:46:58.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:46:58.813+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:46:58.814+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:46:58.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:46:58.815+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:46:58.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:46:58.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:46:58.817+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:46:58.834+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 1.0 in stage 1306.0 (TID 2139) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.835+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 0.0 in stage 1306.0 (TID 2138) in 35 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:58.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 2.0 in stage 1306.0 (TID 2140) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.852+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 1.0 in stage 1306.0 (TID 2139) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:58.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 3.0 in stage 1306.0 (TID 2141) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 2.0 in stage 1306.0 (TID 2140) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:46:58.886+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 4.0 in stage 1306.0 (TID 2142) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 3.0 in stage 1306.0 (TID 2141) in 18 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:46:58.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 5.0 in stage 1306.0 (TID 2143) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 4.0 in stage 1306.0 (TID 2142) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:46:58.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 6.0 in stage 1306.0 (TID 2144) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.924+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 5.0 in stage 1306.0 (TID 2143) in 20 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:46:58.942+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 7.0 in stage 1306.0 (TID 2145) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.942+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 6.0 in stage 1306.0 (TID 2144) in 18 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:46:58.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 8.0 in stage 1306.0 (TID 2146) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.960+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 7.0 in stage 1306.0 (TID 2145) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:46:58.977+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 9.0 in stage 1306.0 (TID 2147) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.978+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 8.0 in stage 1306.0 (TID 2146) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:46:58.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Starting task 12.0 in stage 1335.1 (TID 2148) (172.20.0.5, executor 1, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:58.995+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSetManager: Finished task 9.0 in stage 1306.0 (TID 2147) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:46:58.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO TaskSchedulerImpl: Removed TaskSet 1306.0, whose tasks have all completed, from pool
[2025-05-08T19:46:58.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: ShuffleMapStage 1306 (mapPartitions at GraphImpl.scala:208) finished in 0.222 s
[2025-05-08T19:46:58.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:46:58.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:46:58.996+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:46:58.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: failed: Set()
[2025-05-08T19:46:58.997+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO DAGScheduler: Submitting ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:46:58.998+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:58 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 17.8 KiB, free 415.0 MiB)
[2025-05-08T19:46:59.001+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 415.0 MiB)
[2025-05-08T19:46:59.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.1 MiB)
[2025-05-08T19:46:59.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:46:59.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:46:59.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:46:59.002+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSchedulerImpl: Adding task set 1307.0 with 10 tasks resource profile 0
[2025-05-08T19:46:59.012+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Starting task 0.0 in stage 1307.0 (TID 2149) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:59.013+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Finished task 12.0 in stage 1335.1 (TID 2148) in 17 ms on 172.20.0.5 (executor 1) (10/41)
[2025-05-08T19:46:59.016+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 172.20.0.5:36007 (size: 6.6 KiB, free: 419.5 MiB)
[2025-05-08T19:46:59.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:46:59.022+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:46:59.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:46:59.041+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:46:59.053+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:46:59.067+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:46:59.093+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:46:59.146+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:46:59.375+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:46:59.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Starting task 1.0 in stage 1307.0 (TID 2150) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:59.380+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Finished task 0.0 in stage 1307.0 (TID 2149) in 368 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:46:59.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Starting task 2.0 in stage 1307.0 (TID 2151) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:59.691+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Finished task 1.0 in stage 1307.0 (TID 2150) in 312 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:46:59.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Starting task 3.0 in stage 1307.0 (TID 2152) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:46:59.970+0000] {spark_submit.py:571} INFO - 25/05/08 19:46:59 INFO TaskSetManager: Finished task 2.0 in stage 1307.0 (TID 2151) in 279 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:00.247+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:00 INFO TaskSetManager: Starting task 4.0 in stage 1307.0 (TID 2153) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:00.247+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:00 INFO TaskSetManager: Finished task 3.0 in stage 1307.0 (TID 2152) in 278 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:00.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:00 INFO TaskSetManager: Starting task 5.0 in stage 1307.0 (TID 2154) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:00.543+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:00 INFO TaskSetManager: Finished task 4.0 in stage 1307.0 (TID 2153) in 297 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:00.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:00 INFO TaskSetManager: Starting task 6.0 in stage 1307.0 (TID 2155) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:00.816+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:00 INFO TaskSetManager: Finished task 5.0 in stage 1307.0 (TID 2154) in 273 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:01.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 7.0 in stage 1307.0 (TID 2156) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 6.0 in stage 1307.0 (TID 2155) in 268 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:01.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 8.0 in stage 1307.0 (TID 2157) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 7.0 in stage 1307.0 (TID 2156) in 254 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:01.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 9.0 in stage 1307.0 (TID 2158) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.601+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 8.0 in stage 1307.0 (TID 2157) in 264 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:01.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 13.0 in stage 1335.1 (TID 2159) (172.20.0.5, executor 1, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 9.0 in stage 1307.0 (TID 2158) in 259 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:01.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSchedulerImpl: Removed TaskSet 1307.0, whose tasks have all completed, from pool
[2025-05-08T19:47:01.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO DAGScheduler: ShuffleMapStage 1307 (mapPartitions at VertexRDDImpl.scala:247) finished in 2.863 s
[2025-05-08T19:47:01.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:01.860+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:01.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:01.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:01.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO DAGScheduler: Submitting ShuffleMapStage 1308 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:47:01.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:01.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 241.1 KiB, free 414.8 MiB)
[2025-05-08T19:47:01.869+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 414.7 MiB)
[2025-05-08T19:47:01.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.1 MiB)
[2025-05-08T19:47:01.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:01.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1308 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:01.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSchedulerImpl: Adding task set 1308.0 with 10 tasks resource profile 0
[2025-05-08T19:47:01.879+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 0.0 in stage 1308.0 (TID 2160) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 13.0 in stage 1335.1 (TID 2159) in 19 ms on 172.20.0.5 (executor 1) (11/41)
[2025-05-08T19:47:01.883+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 172.20.0.5:36007 (size: 79.6 KiB, free: 419.5 MiB)
[2025-05-08T19:47:01.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:47:01.890+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:47:01.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:47:01.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:47:01.901+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:47:01.902+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:47:01.903+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:47:01.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:47:01.904+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:47:01.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:47:01.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T19:47:01.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 1.0 in stage 1308.0 (TID 2161) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.917+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 0.0 in stage 1308.0 (TID 2160) in 38 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:01.934+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 2.0 in stage 1308.0 (TID 2162) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.935+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 1.0 in stage 1308.0 (TID 2161) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:01.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 3.0 in stage 1308.0 (TID 2163) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.952+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 2.0 in stage 1308.0 (TID 2162) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:01.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 4.0 in stage 1308.0 (TID 2164) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.969+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 3.0 in stage 1308.0 (TID 2163) in 18 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:01.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Starting task 5.0 in stage 1308.0 (TID 2165) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:01.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:01 INFO TaskSetManager: Finished task 4.0 in stage 1308.0 (TID 2164) in 17 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:02.003+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Starting task 6.0 in stage 1308.0 (TID 2166) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:02.004+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Finished task 5.0 in stage 1308.0 (TID 2165) in 18 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:02.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Starting task 7.0 in stage 1308.0 (TID 2167) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:02.021+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Finished task 6.0 in stage 1308.0 (TID 2166) in 17 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:02.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Starting task 8.0 in stage 1308.0 (TID 2168) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:02.040+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Finished task 7.0 in stage 1308.0 (TID 2167) in 20 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:02.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Starting task 9.0 in stage 1308.0 (TID 2169) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:02.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Finished task 8.0 in stage 1308.0 (TID 2168) in 17 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:02.073+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Starting task 14.0 in stage 1335.1 (TID 2170) (172.20.0.5, executor 1, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:02.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Finished task 9.0 in stage 1308.0 (TID 2169) in 22 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:02.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSchedulerImpl: Removed TaskSet 1308.0, whose tasks have all completed, from pool
[2025-05-08T19:47:02.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_240_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.1 MiB)
[2025-05-08T19:47:02.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO DAGScheduler: ShuffleMapStage 1308 (mapPartitions at GraphImpl.scala:208) finished in 0.217 s
[2025-05-08T19:47:02.078+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:02.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:02.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:02.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:02.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO DAGScheduler: Submitting ShuffleMapStage 1309 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:47:02.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 172.20.0.5:36007 in memory (size: 6.6 KiB, free: 419.5 MiB)
[2025-05-08T19:47:02.080+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 18.5 KiB, free 414.7 MiB)
[2025-05-08T19:47:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 414.7 MiB)
[2025-05-08T19:47:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on f2a432e4376a:35283 (size: 6.8 KiB, free: 432.1 MiB)
[2025-05-08T19:47:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_231_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.1 MiB)
[2025-05-08T19:47:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1309 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSchedulerImpl: Adding task set 1309.0 with 10 tasks resource profile 0
[2025-05-08T19:47:02.082+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 172.20.0.5:36007 in memory (size: 79.3 KiB, free: 419.5 MiB)
[2025-05-08T19:47:02.083+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:02.084+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_239_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.2 MiB)
[2025-05-08T19:47:02.086+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 172.20.0.5:36007 in memory (size: 79.3 KiB, free: 419.6 MiB)
[2025-05-08T19:47:02.088+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_238_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.2 MiB)
[2025-05-08T19:47:02.089+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 172.20.0.5:36007 in memory (size: 6.6 KiB, free: 419.6 MiB)
[2025-05-08T19:47:02.095+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_233_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.3 MiB)
[2025-05-08T19:47:02.096+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 172.20.0.5:36007 in memory (size: 79.0 KiB, free: 419.7 MiB)
[2025-05-08T19:47:02.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_235_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.4 MiB)
[2025-05-08T19:47:02.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 172.20.0.5:36007 in memory (size: 79.1 KiB, free: 419.8 MiB)
[2025-05-08T19:47:02.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Starting task 0.0 in stage 1309.0 (TID 2171) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:02.102+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Finished task 14.0 in stage 1335.1 (TID 2170) in 30 ms on 172.20.0.5 (executor 1) (12/41)
[2025-05-08T19:47:02.103+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_236_piece0 on f2a432e4376a:35283 in memory (size: 6.5 KiB, free: 432.4 MiB)
[2025-05-08T19:47:02.106+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 172.20.0.5:36007 in memory (size: 6.5 KiB, free: 419.8 MiB)
[2025-05-08T19:47:02.107+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 172.20.0.5:36007 (size: 6.8 KiB, free: 419.8 MiB)
[2025-05-08T19:47:02.109+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_234_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.4 MiB)
[2025-05-08T19:47:02.110+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 172.20.0.5:36007 in memory (size: 6.4 KiB, free: 419.8 MiB)
[2025-05-08T19:47:02.112+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:47:02.114+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_232_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.4 MiB)
[2025-05-08T19:47:02.116+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 172.20.0.5:36007 in memory (size: 6.3 KiB, free: 419.8 MiB)
[2025-05-08T19:47:02.117+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:47:02.118+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_237_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T19:47:02.127+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 172.20.0.5:36007 in memory (size: 79.1 KiB, free: 419.9 MiB)
[2025-05-08T19:47:02.130+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:47:02.136+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:47:02.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:47:02.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:47:02.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:47:02.233+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:47:02.363+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:47:02.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T19:47:02.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Starting task 1.0 in stage 1309.0 (TID 2172) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:02.780+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:02 INFO TaskSetManager: Finished task 0.0 in stage 1309.0 (TID 2171) in 679 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:03.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:03 INFO TaskSetManager: Starting task 2.0 in stage 1309.0 (TID 2173) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:03.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:03 INFO TaskSetManager: Finished task 1.0 in stage 1309.0 (TID 2172) in 610 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:03.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:03 INFO TaskSetManager: Starting task 3.0 in stage 1309.0 (TID 2174) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:03.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:03 INFO TaskSetManager: Finished task 2.0 in stage 1309.0 (TID 2173) in 543 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:04.591+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:04 INFO TaskSetManager: Starting task 4.0 in stage 1309.0 (TID 2175) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:04.592+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:04 INFO TaskSetManager: Finished task 3.0 in stage 1309.0 (TID 2174) in 659 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:05.126+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:05 INFO TaskSetManager: Starting task 5.0 in stage 1309.0 (TID 2176) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:05.126+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:05 INFO TaskSetManager: Finished task 4.0 in stage 1309.0 (TID 2175) in 535 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:05.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:05 INFO TaskSetManager: Starting task 6.0 in stage 1309.0 (TID 2177) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:05.659+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:05 INFO TaskSetManager: Finished task 5.0 in stage 1309.0 (TID 2176) in 533 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:06.206+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:06 INFO TaskSetManager: Starting task 7.0 in stage 1309.0 (TID 2178) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:06.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:06 INFO TaskSetManager: Finished task 6.0 in stage 1309.0 (TID 2177) in 548 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:06.743+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:06 INFO TaskSetManager: Starting task 8.0 in stage 1309.0 (TID 2179) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:06.744+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:06 INFO TaskSetManager: Finished task 7.0 in stage 1309.0 (TID 2178) in 537 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:07.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 9.0 in stage 1309.0 (TID 2180) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.289+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 8.0 in stage 1309.0 (TID 2179) in 546 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:07.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 15.0 in stage 1335.1 (TID 2181) (172.20.0.5, executor 1, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 9.0 in stage 1309.0 (TID 2180) in 530 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:07.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSchedulerImpl: Removed TaskSet 1309.0, whose tasks have all completed, from pool
[2025-05-08T19:47:07.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO DAGScheduler: ShuffleMapStage 1309 (mapPartitions at VertexRDDImpl.scala:247) finished in 5.740 s
[2025-05-08T19:47:07.819+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:07.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:07.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:07.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:07.820+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO DAGScheduler: Submitting ShuffleMapStage 1310 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[738] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:47:07.824+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:07.828+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 241.4 KiB, free 416.1 MiB)
[2025-05-08T19:47:07.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 79.5 KiB, free 416.0 MiB)
[2025-05-08T19:47:07.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on f2a432e4376a:35283 (size: 79.5 KiB, free: 432.4 MiB)
[2025-05-08T19:47:07.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:07.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1310 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[738] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:07.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSchedulerImpl: Adding task set 1310.0 with 10 tasks resource profile 0
[2025-05-08T19:47:07.840+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 0.0 in stage 1310.0 (TID 2182) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.841+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 15.0 in stage 1335.1 (TID 2181) in 22 ms on 172.20.0.5 (executor 1) (13/41)
[2025-05-08T19:47:07.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 172.20.0.5:36007 (size: 79.5 KiB, free: 419.8 MiB)
[2025-05-08T19:47:07.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:47:07.861+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:47:07.863+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:47:07.864+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:47:07.866+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:47:07.867+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:47:07.868+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:47:07.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:47:07.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:47:07.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:47:07.875+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T19:47:07.875+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T19:47:07.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 1.0 in stage 1310.0 (TID 2183) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 0.0 in stage 1310.0 (TID 2182) in 54 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:07.910+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 2.0 in stage 1310.0 (TID 2184) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 1.0 in stage 1310.0 (TID 2183) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:07.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 3.0 in stage 1310.0 (TID 2185) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.937+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 2.0 in stage 1310.0 (TID 2184) in 27 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:07.937+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO BlockManagerInfo: Removed broadcast_242_piece0 on f2a432e4376a:35283 in memory (size: 6.8 KiB, free: 432.4 MiB)
[2025-05-08T19:47:07.940+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 172.20.0.5:36007 in memory (size: 6.8 KiB, free: 419.8 MiB)
[2025-05-08T19:47:07.948+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 4.0 in stage 1310.0 (TID 2186) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.949+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 3.0 in stage 1310.0 (TID 2185) in 22 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:07.965+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 5.0 in stage 1310.0 (TID 2187) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.966+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 4.0 in stage 1310.0 (TID 2186) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:07.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 6.0 in stage 1310.0 (TID 2188) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:07.983+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Finished task 5.0 in stage 1310.0 (TID 2187) in 18 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:07.999+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:07 INFO TaskSetManager: Starting task 7.0 in stage 1310.0 (TID 2189) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:08.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Finished task 6.0 in stage 1310.0 (TID 2188) in 18 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:08.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Starting task 8.0 in stage 1310.0 (TID 2190) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:08.020+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Finished task 7.0 in stage 1310.0 (TID 2189) in 21 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:08.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Starting task 9.0 in stage 1310.0 (TID 2191) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:08.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Finished task 8.0 in stage 1310.0 (TID 2190) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:08.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Starting task 16.0 in stage 1335.1 (TID 2192) (172.20.0.5, executor 1, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:08.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Finished task 9.0 in stage 1310.0 (TID 2191) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:08.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSchedulerImpl: Removed TaskSet 1310.0, whose tasks have all completed, from pool
[2025-05-08T19:47:08.055+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO DAGScheduler: ShuffleMapStage 1310 (mapPartitions at GraphImpl.scala:208) finished in 0.235 s
[2025-05-08T19:47:08.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:08.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:08.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:08.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:08.056+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO DAGScheduler: Submitting ShuffleMapStage 1311 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[746] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:47:08.057+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 19.2 KiB, free 416.0 MiB)
[2025-05-08T19:47:08.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 416.0 MiB)
[2025-05-08T19:47:08.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on f2a432e4376a:35283 (size: 7.0 KiB, free: 432.4 MiB)
[2025-05-08T19:47:08.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:08.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1311 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[746] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:08.058+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSchedulerImpl: Adding task set 1311.0 with 10 tasks resource profile 0
[2025-05-08T19:47:08.059+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:08.071+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Starting task 0.0 in stage 1311.0 (TID 2193) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:08.072+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO TaskSetManager: Finished task 16.0 in stage 1335.1 (TID 2192) in 16 ms on 172.20.0.5 (executor 1) (14/41)
[2025-05-08T19:47:08.075+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 172.20.0.5:36007 (size: 7.0 KiB, free: 419.8 MiB)
[2025-05-08T19:47:08.077+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:47:08.079+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:47:08.082+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:47:08.085+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:47:08.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:47:08.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:47:08.134+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:47:08.179+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:47:08.291+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:47:08.500+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T19:47:09.227+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T19:47:09.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:09 INFO TaskSetManager: Starting task 1.0 in stage 1311.0 (TID 2194) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:09.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:09 INFO TaskSetManager: Finished task 0.0 in stage 1311.0 (TID 2193) in 1160 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:10.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:10 INFO TaskSetManager: Starting task 2.0 in stage 1311.0 (TID 2195) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:10.326+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:10 INFO TaskSetManager: Finished task 1.0 in stage 1311.0 (TID 2194) in 1095 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:11.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:11 INFO TaskSetManager: Starting task 3.0 in stage 1311.0 (TID 2196) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:11.462+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:11 INFO TaskSetManager: Finished task 2.0 in stage 1311.0 (TID 2195) in 1135 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:12.526+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:12 INFO TaskSetManager: Starting task 4.0 in stage 1311.0 (TID 2197) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:12.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:12 INFO TaskSetManager: Finished task 3.0 in stage 1311.0 (TID 2196) in 1065 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:13.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:13 INFO TaskSetManager: Starting task 5.0 in stage 1311.0 (TID 2198) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:13.896+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:13 INFO TaskSetManager: Finished task 4.0 in stage 1311.0 (TID 2197) in 1370 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:15.026+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:15 INFO TaskSetManager: Starting task 6.0 in stage 1311.0 (TID 2199) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:15.027+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:15 INFO TaskSetManager: Finished task 5.0 in stage 1311.0 (TID 2198) in 1131 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:16.068+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:16 INFO TaskSetManager: Starting task 7.0 in stage 1311.0 (TID 2200) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:16.068+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:16 INFO TaskSetManager: Finished task 6.0 in stage 1311.0 (TID 2199) in 1042 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:17.163+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:17 INFO TaskSetManager: Starting task 8.0 in stage 1311.0 (TID 2201) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:17.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:17 INFO TaskSetManager: Finished task 7.0 in stage 1311.0 (TID 2200) in 1096 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:18.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:18 INFO TaskSetManager: Starting task 9.0 in stage 1311.0 (TID 2202) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:18.209+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:18 INFO TaskSetManager: Finished task 8.0 in stage 1311.0 (TID 2201) in 1046 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:19.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 17.0 in stage 1335.1 (TID 2203) (172.20.0.5, executor 1, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 9.0 in stage 1311.0 (TID 2202) in 1063 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:19.271+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSchedulerImpl: Removed TaskSet 1311.0, whose tasks have all completed, from pool
[2025-05-08T19:47:19.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: ShuffleMapStage 1311 (mapPartitions at VertexRDDImpl.scala:247) finished in 11.215 s
[2025-05-08T19:47:19.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:19.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:19.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:19.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:19.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: Submitting ShuffleMapStage 1312 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[750] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:47:19.283+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:19.284+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 241.7 KiB, free 415.8 MiB)
[2025-05-08T19:47:19.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 415.7 MiB)
[2025-05-08T19:47:19.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.3 MiB)
[2025-05-08T19:47:19.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:19.293+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1312 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[750] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:19.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSchedulerImpl: Adding task set 1312.0 with 10 tasks resource profile 0
[2025-05-08T19:47:19.311+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 0.0 in stage 1312.0 (TID 2204) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.312+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 17.0 in stage 1335.1 (TID 2203) in 41 ms on 172.20.0.5 (executor 1) (15/41)
[2025-05-08T19:47:19.315+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 172.20.0.5:36007 (size: 79.4 KiB, free: 419.7 MiB)
[2025-05-08T19:47:19.333+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:47:19.338+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:47:19.340+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:47:19.342+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:47:19.344+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:47:19.346+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:47:19.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:47:19.349+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:47:19.351+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:47:19.352+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:47:19.353+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T19:47:19.354+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T19:47:19.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:36758
[2025-05-08T19:47:19.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 1.0 in stage 1312.0 (TID 2205) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 0.0 in stage 1312.0 (TID 2204) in 66 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:19.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 2.0 in stage 1312.0 (TID 2206) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 1.0 in stage 1312.0 (TID 2205) in 20 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:19.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 3.0 in stage 1312.0 (TID 2207) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.415+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 2.0 in stage 1312.0 (TID 2206) in 19 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:19.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 4.0 in stage 1312.0 (TID 2208) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 3.0 in stage 1312.0 (TID 2207) in 20 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:19.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 5.0 in stage 1312.0 (TID 2209) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.454+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 4.0 in stage 1312.0 (TID 2208) in 19 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:19.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 6.0 in stage 1312.0 (TID 2210) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 5.0 in stage 1312.0 (TID 2209) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:19.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 7.0 in stage 1312.0 (TID 2211) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 6.0 in stage 1312.0 (TID 2210) in 19 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:19.510+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 8.0 in stage 1312.0 (TID 2212) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.510+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 7.0 in stage 1312.0 (TID 2211) in 20 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:19.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 9.0 in stage 1312.0 (TID 2213) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.528+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 8.0 in stage 1312.0 (TID 2212) in 19 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:19.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 18.0 in stage 1335.1 (TID 2214) (172.20.0.5, executor 1, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 9.0 in stage 1312.0 (TID 2213) in 18 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSchedulerImpl: Removed TaskSet 1312.0, whose tasks have all completed, from pool
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: ShuffleMapStage 1312 (mapPartitions at GraphImpl.scala:208) finished in 0.271 s
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1314, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:19.546+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: Submitting ShuffleMapStage 1313 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[758] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:47:19.547+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 19.9 KiB, free 415.7 MiB)
[2025-05-08T19:47:19.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 415.7 MiB)
[2025-05-08T19:47:19.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on f2a432e4376a:35283 (size: 7.1 KiB, free: 432.3 MiB)
[2025-05-08T19:47:19.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO SparkContext: Created broadcast 246 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:19.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1313 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[758] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:19.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSchedulerImpl: Adding task set 1313.0 with 10 tasks resource profile 0
[2025-05-08T19:47:19.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:19.563+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Starting task 0.0 in stage 1313.0 (TID 2215) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:19.564+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO TaskSetManager: Finished task 18.0 in stage 1335.1 (TID 2214) in 19 ms on 172.20.0.5 (executor 1) (16/41)
[2025-05-08T19:47:19.567+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 172.20.0.5:36007 (size: 7.1 KiB, free: 419.7 MiB)
[2025-05-08T19:47:19.570+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:47:19.573+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:47:19.576+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:47:19.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:47:19.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:47:19.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:47:19.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:47:19.677+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:47:19.776+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:47:19.968+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T19:47:20.348+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T19:47:21.905+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:36758
[2025-05-08T19:47:21.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:21 INFO TaskSetManager: Starting task 1.0 in stage 1313.0 (TID 2216) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:21.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:21 INFO TaskSetManager: Finished task 0.0 in stage 1313.0 (TID 2215) in 2345 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:24.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:24 INFO TaskSetManager: Starting task 2.0 in stage 1313.0 (TID 2217) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:24.144+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:24 INFO TaskSetManager: Finished task 1.0 in stage 1313.0 (TID 2216) in 2235 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:26.376+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:26 INFO TaskSetManager: Starting task 3.0 in stage 1313.0 (TID 2218) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:26.377+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:26 INFO TaskSetManager: Finished task 2.0 in stage 1313.0 (TID 2217) in 2233 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:28.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:28 INFO TaskSetManager: Starting task 4.0 in stage 1313.0 (TID 2219) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:28.582+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:28 INFO TaskSetManager: Finished task 3.0 in stage 1313.0 (TID 2218) in 2206 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:30.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:30 INFO TaskSetManager: Starting task 5.0 in stage 1313.0 (TID 2220) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:30.755+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:30 INFO TaskSetManager: Finished task 4.0 in stage 1313.0 (TID 2219) in 2173 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:32.992+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:32 INFO TaskSetManager: Starting task 6.0 in stage 1313.0 (TID 2221) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:32.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:32 INFO TaskSetManager: Finished task 5.0 in stage 1313.0 (TID 2220) in 2237 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:35.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:35 INFO TaskSetManager: Starting task 7.0 in stage 1313.0 (TID 2222) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:35.302+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:35 INFO TaskSetManager: Finished task 6.0 in stage 1313.0 (TID 2221) in 2309 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:37.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:37 INFO TaskSetManager: Starting task 8.0 in stage 1313.0 (TID 2223) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:37.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:37 INFO TaskSetManager: Finished task 7.0 in stage 1313.0 (TID 2222) in 2189 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:39.675+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:39 INFO TaskSetManager: Starting task 9.0 in stage 1313.0 (TID 2224) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:39.675+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:39 INFO TaskSetManager: Finished task 8.0 in stage 1313.0 (TID 2223) in 2185 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:41.989+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO TaskSetManager: Starting task 19.0 in stage 1335.1 (TID 2225) (172.20.0.5, executor 1, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:41.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO TaskSetManager: Finished task 9.0 in stage 1313.0 (TID 2224) in 2314 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:41.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO TaskSchedulerImpl: Removed TaskSet 1313.0, whose tasks have all completed, from pool
[2025-05-08T19:47:41.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO DAGScheduler: ShuffleMapStage 1313 (mapPartitions at VertexRDDImpl.scala:247) finished in 22.442 s
[2025-05-08T19:47:41.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:41.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:41.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1314, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:41.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:41.991+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO DAGScheduler: Submitting ShuffleMapStage 1314 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[762] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:47:41.993+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:42.000+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 241.9 KiB, free 415.4 MiB)
[2025-05-08T19:47:42.005+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 415.4 MiB)
[2025-05-08T19:47:42.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.2 MiB)
[2025-05-08T19:47:42.010+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:42.010+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1314 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[762] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:42.010+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSchedulerImpl: Adding task set 1314.0 with 10 tasks resource profile 0
[2025-05-08T19:47:42.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 0.0 in stage 1314.0 (TID 2226) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.014+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 19.0 in stage 1335.1 (TID 2225) in 25 ms on 172.20.0.5 (executor 1) (17/41)
[2025-05-08T19:47:42.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 172.20.0.5:36007 (size: 79.6 KiB, free: 419.6 MiB)
[2025-05-08T19:47:42.031+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:47:42.036+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:47:42.037+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:47:42.039+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:47:42.040+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:47:42.042+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:47:42.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:47:42.045+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:47:42.047+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:47:42.048+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:47:42.050+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T19:47:42.051+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T19:47:42.052+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:36758
[2025-05-08T19:47:42.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 96 to 172.20.0.5:36758
[2025-05-08T19:47:42.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 1.0 in stage 1314.0 (TID 2227) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.076+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 0.0 in stage 1314.0 (TID 2226) in 63 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:42.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 2.0 in stage 1314.0 (TID 2228) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 1.0 in stage 1314.0 (TID 2227) in 18 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:42.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 3.0 in stage 1314.0 (TID 2229) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.111+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 2.0 in stage 1314.0 (TID 2228) in 17 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:47:42.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 4.0 in stage 1314.0 (TID 2230) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.129+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 3.0 in stage 1314.0 (TID 2229) in 18 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:47:42.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 5.0 in stage 1314.0 (TID 2231) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.147+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 4.0 in stage 1314.0 (TID 2230) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:47:42.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 6.0 in stage 1314.0 (TID 2232) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.165+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 5.0 in stage 1314.0 (TID 2231) in 18 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:47:42.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 7.0 in stage 1314.0 (TID 2233) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.187+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 6.0 in stage 1314.0 (TID 2232) in 23 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:47:42.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 8.0 in stage 1314.0 (TID 2234) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.210+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 7.0 in stage 1314.0 (TID 2233) in 24 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:47:42.231+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 9.0 in stage 1314.0 (TID 2235) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5317 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.232+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 8.0 in stage 1314.0 (TID 2234) in 22 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:47:42.251+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 20.0 in stage 1335.1 (TID 2236) (172.20.0.5, executor 1, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.251+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 9.0 in stage 1314.0 (TID 2235) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:47:42.251+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSchedulerImpl: Removed TaskSet 1314.0, whose tasks have all completed, from pool
[2025-05-08T19:47:42.251+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: ShuffleMapStage 1314 (mapPartitions at GraphImpl.scala:208) finished in 0.259 s
[2025-05-08T19:47:42.251+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:47:42.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:47:42.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:47:42.252+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: failed: Set()
[2025-05-08T19:47:42.253+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: Submitting ShuffleMapStage 1315 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[770] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:47:42.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 20.7 KiB, free 415.3 MiB)
[2025-05-08T19:47:42.254+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:36758
[2025-05-08T19:47:42.272+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 415.3 MiB)
[2025-05-08T19:47:42.273+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on f2a432e4376a:35283 (size: 7.1 KiB, free: 432.2 MiB)
[2025-05-08T19:47:42.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:47:42.274+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1315 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[770] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:47:42.275+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSchedulerImpl: Adding task set 1315.0 with 10 tasks resource profile 0
[2025-05-08T19:47:42.277+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_244_piece0 on f2a432e4376a:35283 in memory (size: 7.0 KiB, free: 432.2 MiB)
[2025-05-08T19:47:42.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Starting task 0.0 in stage 1315.0 (TID 2237) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:42.278+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO TaskSetManager: Finished task 20.0 in stage 1335.1 (TID 2236) in 28 ms on 172.20.0.5 (executor 1) (18/41)
[2025-05-08T19:47:42.282+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 172.20.0.5:36007 in memory (size: 7.0 KiB, free: 419.6 MiB)
[2025-05-08T19:47:42.288+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 172.20.0.5:36007 (size: 7.1 KiB, free: 419.6 MiB)
[2025-05-08T19:47:42.292+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:47:42.294+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_246_piece0 on f2a432e4376a:35283 in memory (size: 7.1 KiB, free: 432.2 MiB)
[2025-05-08T19:47:42.298+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 172.20.0.5:36007 in memory (size: 7.1 KiB, free: 419.6 MiB)
[2025-05-08T19:47:42.301+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:47:42.304+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_245_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.3 MiB)
[2025-05-08T19:47:42.306+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:47:42.321+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 172.20.0.5:36007 in memory (size: 79.4 KiB, free: 419.7 MiB)
[2025-05-08T19:47:42.325+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_243_piece0 on f2a432e4376a:35283 in memory (size: 79.5 KiB, free: 432.4 MiB)
[2025-05-08T19:47:42.327+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 172.20.0.5:36007 in memory (size: 79.5 KiB, free: 419.8 MiB)
[2025-05-08T19:47:42.330+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:47:42.345+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:47:42.370+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:47:42.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_229_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.4 MiB)
[2025-05-08T19:47:42.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 172.20.0.5:36007 in memory (size: 6.1 KiB, free: 419.8 MiB)
[2025-05-08T19:47:42.390+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_241_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.5 MiB)
[2025-05-08T19:47:42.391+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 172.20.0.5:36007 in memory (size: 79.6 KiB, free: 419.9 MiB)
[2025-05-08T19:47:42.392+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_227_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.6 MiB)
[2025-05-08T19:47:42.393+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 172.20.0.5:36007 in memory (size: 79.1 KiB, free: 420.0 MiB)
[2025-05-08T19:47:42.395+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_179_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T19:47:42.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 172.20.0.5:36007 in memory (size: 13.8 KiB, free: 420.0 MiB)
[2025-05-08T19:47:42.408+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:47:42.470+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:47:42.579+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:47:42.793+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T19:47:43.178+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T19:47:44.011+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:36758
[2025-05-08T19:47:47.224+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 99 to 172.20.0.5:36758
[2025-05-08T19:47:47.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:47 INFO TaskSetManager: Starting task 1.0 in stage 1315.0 (TID 2238) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:47.230+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:47 INFO TaskSetManager: Finished task 0.0 in stage 1315.0 (TID 2237) in 4953 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:47:51.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:51 INFO TaskSetManager: Starting task 2.0 in stage 1315.0 (TID 2239) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:51.722+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:51 INFO TaskSetManager: Finished task 1.0 in stage 1315.0 (TID 2238) in 4492 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:47:56.180+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:56 INFO TaskSetManager: Starting task 3.0 in stage 1315.0 (TID 2240) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:47:56.181+0000] {spark_submit.py:571} INFO - 25/05/08 19:47:56 INFO TaskSetManager: Finished task 2.0 in stage 1315.0 (TID 2239) in 4459 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:48:00.548+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:00 INFO TaskSetManager: Starting task 4.0 in stage 1315.0 (TID 2241) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:00.549+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:00 INFO TaskSetManager: Finished task 3.0 in stage 1315.0 (TID 2240) in 4369 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:48:05.018+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:05 INFO TaskSetManager: Starting task 5.0 in stage 1315.0 (TID 2242) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:05.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:05 INFO TaskSetManager: Finished task 4.0 in stage 1315.0 (TID 2241) in 4470 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:48:09.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:09 INFO TaskSetManager: Starting task 6.0 in stage 1315.0 (TID 2243) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:09.417+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:09 INFO TaskSetManager: Finished task 5.0 in stage 1315.0 (TID 2242) in 4399 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:48:13.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:13 INFO TaskSetManager: Starting task 7.0 in stage 1315.0 (TID 2244) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:13.851+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:13 INFO TaskSetManager: Finished task 6.0 in stage 1315.0 (TID 2243) in 4434 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:48:18.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:18 INFO TaskSetManager: Starting task 8.0 in stage 1315.0 (TID 2245) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:18.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:18 INFO TaskSetManager: Finished task 7.0 in stage 1315.0 (TID 2244) in 4735 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:48:22.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:22 INFO TaskSetManager: Starting task 9.0 in stage 1315.0 (TID 2246) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5590 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:22.956+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:22 INFO TaskSetManager: Finished task 8.0 in stage 1315.0 (TID 2245) in 4370 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:48:27.384+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 21.0 in stage 1335.1 (TID 2247) (172.20.0.5, executor 1, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 9.0 in stage 1315.0 (TID 2246) in 4428 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:48:27.385+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSchedulerImpl: Removed TaskSet 1315.0, whose tasks have all completed, from pool
[2025-05-08T19:48:27.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: ShuffleMapStage 1315 (mapPartitions at VertexRDDImpl.scala:247) finished in 45.131 s
[2025-05-08T19:48:27.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:48:27.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:48:27.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:48:27.386+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: failed: Set()
[2025-05-08T19:48:27.387+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: Submitting ShuffleMapStage 1316 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[774] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:48:27.388+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T19:48:27.396+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 242.2 KiB, free 416.5 MiB)
[2025-05-08T19:48:27.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 416.4 MiB)
[2025-05-08T19:48:27.401+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.5 MiB)
[2025-05-08T19:48:27.405+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:48:27.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1316 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[774] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:48:27.406+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSchedulerImpl: Adding task set 1316.0 with 10 tasks resource profile 0
[2025-05-08T19:48:27.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 0.0 in stage 1316.0 (TID 2248) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.425+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 21.0 in stage 1335.1 (TID 2247) in 41 ms on 172.20.0.5 (executor 1) (19/41)
[2025-05-08T19:48:27.428+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 172.20.0.5:36007 (size: 79.6 KiB, free: 419.9 MiB)
[2025-05-08T19:48:27.435+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:48:27.439+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:48:27.449+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:48:27.451+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:48:27.453+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:48:27.455+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:48:27.457+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:48:27.459+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:48:27.461+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:48:27.463+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:48:27.465+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T19:48:27.467+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T19:48:27.469+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:36758
[2025-05-08T19:48:27.471+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 96 to 172.20.0.5:36758
[2025-05-08T19:48:27.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 98 to 172.20.0.5:36758
[2025-05-08T19:48:27.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 1.0 in stage 1316.0 (TID 2249) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.498+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 0.0 in stage 1316.0 (TID 2248) in 74 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:48:27.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 2.0 in stage 1316.0 (TID 2250) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.518+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 1.0 in stage 1316.0 (TID 2249) in 20 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:48:27.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 3.0 in stage 1316.0 (TID 2251) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 2.0 in stage 1316.0 (TID 2250) in 20 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:48:27.565+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 4.0 in stage 1316.0 (TID 2252) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.566+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 3.0 in stage 1316.0 (TID 2251) in 28 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:48:27.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 5.0 in stage 1316.0 (TID 2253) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.586+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 4.0 in stage 1316.0 (TID 2252) in 21 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:48:27.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 6.0 in stage 1316.0 (TID 2254) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.605+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 5.0 in stage 1316.0 (TID 2253) in 20 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:48:27.624+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 7.0 in stage 1316.0 (TID 2255) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 6.0 in stage 1316.0 (TID 2254) in 20 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:48:27.643+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 8.0 in stage 1316.0 (TID 2256) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.644+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 7.0 in stage 1316.0 (TID 2255) in 20 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:48:27.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 9.0 in stage 1316.0 (TID 2257) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5358 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.664+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 8.0 in stage 1316.0 (TID 2256) in 21 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:48:27.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 22.0 in stage 1335.1 (TID 2258) (172.20.0.5, executor 1, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.683+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 9.0 in stage 1316.0 (TID 2257) in 20 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:48:27.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSchedulerImpl: Removed TaskSet 1316.0, whose tasks have all completed, from pool
[2025-05-08T19:48:27.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: ShuffleMapStage 1316 (mapPartitions at GraphImpl.scala:208) finished in 0.296 s
[2025-05-08T19:48:27.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:48:27.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:48:27.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:48:27.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: failed: Set()
[2025-05-08T19:48:27.685+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: Submitting ShuffleMapStage 1317 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[782] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:48:27.686+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 21.4 KiB, free 416.4 MiB)
[2025-05-08T19:48:27.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T19:48:27.687+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 416.4 MiB)
[2025-05-08T19:48:27.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on f2a432e4376a:35283 (size: 7.3 KiB, free: 432.5 MiB)
[2025-05-08T19:48:27.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:48:27.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1317 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[782] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:48:27.688+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSchedulerImpl: Adding task set 1317.0 with 10 tasks resource profile 0
[2025-05-08T19:48:27.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Starting task 0.0 in stage 1317.0 (TID 2259) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:27.695+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO TaskSetManager: Finished task 22.0 in stage 1335.1 (TID 2258) in 12 ms on 172.20.0.5 (executor 1) (20/41)
[2025-05-08T19:48:27.697+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 172.20.0.5:36007 (size: 7.3 KiB, free: 419.9 MiB)
[2025-05-08T19:48:27.699+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:48:27.702+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:48:27.704+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:48:27.708+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:48:27.715+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:48:27.727+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:48:27.750+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:48:27.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:48:27.881+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:48:28.043+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T19:48:28.397+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T19:48:29.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:36758
[2025-05-08T19:48:30.545+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 99 to 172.20.0.5:36758
[2025-05-08T19:48:37.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 101 to 172.20.0.5:36758
[2025-05-08T19:48:37.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:37 INFO TaskSetManager: Starting task 1.0 in stage 1317.0 (TID 2260) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:37.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:37 INFO TaskSetManager: Finished task 0.0 in stage 1317.0 (TID 2259) in 9899 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:48:47.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:47 INFO TaskSetManager: Starting task 2.0 in stage 1317.0 (TID 2261) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:47.982+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:47 INFO TaskSetManager: Finished task 1.0 in stage 1317.0 (TID 2260) in 10388 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:48:57.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:57 INFO TaskSetManager: Starting task 3.0 in stage 1317.0 (TID 2262) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:48:57.800+0000] {spark_submit.py:571} INFO - 25/05/08 19:48:57 INFO TaskSetManager: Finished task 2.0 in stage 1317.0 (TID 2261) in 9821 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:49:07.556+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:07 INFO TaskSetManager: Starting task 4.0 in stage 1317.0 (TID 2263) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:49:07.556+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:07 INFO TaskSetManager: Finished task 3.0 in stage 1317.0 (TID 2262) in 9757 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:49:17.763+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:17 INFO TaskSetManager: Starting task 5.0 in stage 1317.0 (TID 2264) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:49:17.764+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:17 INFO TaskSetManager: Finished task 4.0 in stage 1317.0 (TID 2263) in 10208 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:49:27.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:27 INFO TaskSetManager: Starting task 6.0 in stage 1317.0 (TID 2265) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:49:27.571+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:27 INFO TaskSetManager: Finished task 5.0 in stage 1317.0 (TID 2264) in 9808 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:49:37.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:37 INFO TaskSetManager: Starting task 7.0 in stage 1317.0 (TID 2266) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:49:37.575+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:37 INFO TaskSetManager: Finished task 6.0 in stage 1317.0 (TID 2265) in 10004 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:49:48.335+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:48 INFO TaskSetManager: Starting task 8.0 in stage 1317.0 (TID 2267) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:49:48.336+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:48 INFO TaskSetManager: Finished task 7.0 in stage 1317.0 (TID 2266) in 10761 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:49:58.825+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:58 INFO TaskSetManager: Starting task 9.0 in stage 1317.0 (TID 2268) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5663 bytes) taskResourceAssignments Map()
[2025-05-08T19:49:58.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:49:58 INFO TaskSetManager: Finished task 8.0 in stage 1317.0 (TID 2267) in 10491 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:50:08.583+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 23.0 in stage 1335.1 (TID 2269) (172.20.0.5, executor 1, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 9.0 in stage 1317.0 (TID 2268) in 9759 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:50:08.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSchedulerImpl: Removed TaskSet 1317.0, whose tasks have all completed, from pool
[2025-05-08T19:50:08.584+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: ShuffleMapStage 1317 (mapPartitions at VertexRDDImpl.scala:247) finished in 100.899 s
[2025-05-08T19:50:08.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:50:08.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:50:08.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1319, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:50:08.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: failed: Set()
[2025-05-08T19:50:08.585+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: Submitting ShuffleMapStage 1318 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[786] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:50:08.587+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T19:50:08.590+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 242.5 KiB, free 416.1 MiB)
[2025-05-08T19:50:08.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 416.0 MiB)
[2025-05-08T19:50:08.593+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.4 MiB)
[2025-05-08T19:50:08.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:50:08.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1318 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[786] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:50:08.594+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSchedulerImpl: Adding task set 1318.0 with 10 tasks resource profile 0
[2025-05-08T19:50:08.598+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 0.0 in stage 1318.0 (TID 2270) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.599+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 23.0 in stage 1335.1 (TID 2269) in 15 ms on 172.20.0.5 (executor 1) (21/41)
[2025-05-08T19:50:08.602+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 172.20.0.5:36007 (size: 79.6 KiB, free: 419.8 MiB)
[2025-05-08T19:50:08.607+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:50:08.612+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:50:08.614+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:50:08.616+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:50:08.617+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:50:08.618+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:50:08.620+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:50:08.621+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:50:08.623+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:50:08.625+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:50:08.626+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T19:50:08.628+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T19:50:08.629+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:36758
[2025-05-08T19:50:08.630+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 96 to 172.20.0.5:36758
[2025-05-08T19:50:08.632+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 98 to 172.20.0.5:36758
[2025-05-08T19:50:08.633+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 100 to 172.20.0.5:36758
[2025-05-08T19:50:08.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 1.0 in stage 1318.0 (TID 2271) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.661+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 0.0 in stage 1318.0 (TID 2270) in 63 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:50:08.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 2.0 in stage 1318.0 (TID 2272) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.684+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 1.0 in stage 1318.0 (TID 2271) in 23 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:50:08.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 3.0 in stage 1318.0 (TID 2273) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.701+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 2.0 in stage 1318.0 (TID 2272) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:50:08.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 4.0 in stage 1318.0 (TID 2274) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.719+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 3.0 in stage 1318.0 (TID 2273) in 18 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:50:08.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 5.0 in stage 1318.0 (TID 2275) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.738+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 4.0 in stage 1318.0 (TID 2274) in 20 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:50:08.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 6.0 in stage 1318.0 (TID 2276) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.757+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 5.0 in stage 1318.0 (TID 2275) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:50:08.777+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 7.0 in stage 1318.0 (TID 2277) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.777+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 6.0 in stage 1318.0 (TID 2276) in 21 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:50:08.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 8.0 in stage 1318.0 (TID 2278) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.794+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 7.0 in stage 1318.0 (TID 2277) in 18 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:50:08.811+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 9.0 in stage 1318.0 (TID 2279) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5399 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.812+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 8.0 in stage 1318.0 (TID 2278) in 18 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:50:08.829+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 24.0 in stage 1335.1 (TID 2280) (172.20.0.5, executor 1, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 9.0 in stage 1318.0 (TID 2279) in 19 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:50:08.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSchedulerImpl: Removed TaskSet 1318.0, whose tasks have all completed, from pool
[2025-05-08T19:50:08.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: ShuffleMapStage 1318 (mapPartitions at GraphImpl.scala:208) finished in 0.245 s
[2025-05-08T19:50:08.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:50:08.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:50:08.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1320, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1319, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:50:08.830+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: failed: Set()
[2025-05-08T19:50:08.831+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: Submitting ShuffleMapStage 1319 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[794] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:50:08.832+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 22.1 KiB, free 416.0 MiB)
[2025-05-08T19:50:08.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 416.0 MiB)
[2025-05-08T19:50:08.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on f2a432e4376a:35283 (size: 7.5 KiB, free: 432.4 MiB)
[2025-05-08T19:50:08.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:50:08.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1319 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[794] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:50:08.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSchedulerImpl: Adding task set 1319.0 with 10 tasks resource profile 0
[2025-05-08T19:50:08.833+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T19:50:08.841+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Starting task 0.0 in stage 1319.0 (TID 2281) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:08.841+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO TaskSetManager: Finished task 24.0 in stage 1335.1 (TID 2280) in 12 ms on 172.20.0.5 (executor 1) (22/41)
[2025-05-08T19:50:08.844+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 172.20.0.5:36007 (size: 7.5 KiB, free: 419.8 MiB)
[2025-05-08T19:50:08.846+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:50:08.848+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:50:08.850+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:50:08.854+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:50:08.859+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:50:08.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:50:08.892+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:50:08.935+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:50:09.019+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:50:09.183+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T19:50:09.527+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T19:50:10.204+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:36758
[2025-05-08T19:50:11.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 99 to 172.20.0.5:36758
[2025-05-08T19:50:14.935+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 101 to 172.20.0.5:36758
[2025-05-08T19:50:32.693+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 103 to 172.20.0.5:36758
[2025-05-08T19:50:32.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:32 INFO TaskSetManager: Starting task 1.0 in stage 1319.0 (TID 2282) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:32.710+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:32 INFO TaskSetManager: Finished task 0.0 in stage 1319.0 (TID 2281) in 23869 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:50:57.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:57 INFO TaskSetManager: Starting task 2.0 in stage 1319.0 (TID 2283) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:50:57.490+0000] {spark_submit.py:571} INFO - 25/05/08 19:50:57 INFO TaskSetManager: Finished task 1.0 in stage 1319.0 (TID 2282) in 24780 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:51:21.062+0000] {spark_submit.py:571} INFO - 25/05/08 19:51:21 INFO TaskSetManager: Starting task 3.0 in stage 1319.0 (TID 2284) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:51:21.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:51:21 INFO TaskSetManager: Finished task 2.0 in stage 1319.0 (TID 2283) in 23575 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:51:44.808+0000] {spark_submit.py:571} INFO - 25/05/08 19:51:44 INFO TaskSetManager: Starting task 4.0 in stage 1319.0 (TID 2285) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:51:44.809+0000] {spark_submit.py:571} INFO - 25/05/08 19:51:44 INFO TaskSetManager: Finished task 3.0 in stage 1319.0 (TID 2284) in 23746 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:52:08.826+0000] {spark_submit.py:571} INFO - 25/05/08 19:52:08 INFO TaskSetManager: Starting task 5.0 in stage 1319.0 (TID 2286) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:52:08.827+0000] {spark_submit.py:571} INFO - 25/05/08 19:52:08 INFO TaskSetManager: Finished task 4.0 in stage 1319.0 (TID 2285) in 24018 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:52:32.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:52:32 INFO TaskSetManager: Starting task 6.0 in stage 1319.0 (TID 2287) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:52:32.990+0000] {spark_submit.py:571} INFO - 25/05/08 19:52:32 INFO TaskSetManager: Finished task 5.0 in stage 1319.0 (TID 2286) in 24164 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:52:57.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:52:57 INFO TaskSetManager: Starting task 7.0 in stage 1319.0 (TID 2288) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:52:57.906+0000] {spark_submit.py:571} INFO - 25/05/08 19:52:57 INFO TaskSetManager: Finished task 6.0 in stage 1319.0 (TID 2287) in 24917 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:53:21.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:53:21 INFO TaskSetManager: Starting task 8.0 in stage 1319.0 (TID 2289) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:53:21.501+0000] {spark_submit.py:571} INFO - 25/05/08 19:53:21 INFO TaskSetManager: Finished task 7.0 in stage 1319.0 (TID 2288) in 23594 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:53:45.836+0000] {spark_submit.py:571} INFO - 25/05/08 19:53:45 INFO TaskSetManager: Starting task 9.0 in stage 1319.0 (TID 2290) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5736 bytes) taskResourceAssignments Map()
[2025-05-08T19:53:45.837+0000] {spark_submit.py:571} INFO - 25/05/08 19:53:45 INFO TaskSetManager: Finished task 8.0 in stage 1319.0 (TID 2289) in 24336 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:54:09.870+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Starting task 25.0 in stage 1335.1 (TID 2291) (172.20.0.5, executor 1, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:09.871+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Finished task 9.0 in stage 1319.0 (TID 2290) in 24034 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:54:09.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSchedulerImpl: Removed TaskSet 1319.0, whose tasks have all completed, from pool
[2025-05-08T19:54:09.872+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO DAGScheduler: ShuffleMapStage 1319 (mapPartitions at VertexRDDImpl.scala:247) finished in 241.039 s
[2025-05-08T19:54:09.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:54:09.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:54:09.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1320, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:54:09.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO DAGScheduler: failed: Set()
[2025-05-08T19:54:09.873+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO DAGScheduler: Submitting ShuffleMapStage 1320 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[798] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T19:54:09.874+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T19:54:09.880+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 242.8 KiB, free 415.8 MiB)
[2025-05-08T19:54:09.884+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Starting task 26.0 in stage 1335.1 (TID 2292) (172.20.0.5, executor 1, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:09.885+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Finished task 25.0 in stage 1335.1 (TID 2291) in 15 ms on 172.20.0.5 (executor 1) (23/41)
[2025-05-08T19:54:09.886+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 415.7 MiB)
[2025-05-08T19:54:09.887+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.3 MiB)
[2025-05-08T19:54:09.889+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:54:09.890+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1320 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[798] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:54:09.890+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSchedulerImpl: Adding task set 1320.0 with 10 tasks resource profile 0
[2025-05-08T19:54:09.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Starting task 0.0 in stage 1320.0 (TID 2293) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:09.894+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Finished task 26.0 in stage 1335.1 (TID 2292) in 10 ms on 172.20.0.5 (executor 1) (24/41)
[2025-05-08T19:54:09.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 172.20.0.5:36007 (size: 79.6 KiB, free: 419.7 MiB)
[2025-05-08T19:54:09.903+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T19:54:09.908+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T19:54:09.909+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T19:54:09.911+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T19:54:09.913+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T19:54:09.914+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T19:54:09.918+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T19:54:09.920+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T19:54:09.922+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T19:54:09.923+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T19:54:09.925+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T19:54:09.927+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T19:54:09.929+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:36758
[2025-05-08T19:54:09.930+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 96 to 172.20.0.5:36758
[2025-05-08T19:54:09.932+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 98 to 172.20.0.5:36758
[2025-05-08T19:54:09.933+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 100 to 172.20.0.5:36758
[2025-05-08T19:54:09.935+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 102 to 172.20.0.5:36758
[2025-05-08T19:54:09.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Starting task 1.0 in stage 1320.0 (TID 2294) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:09.967+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Finished task 0.0 in stage 1320.0 (TID 2293) in 73 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:54:09.985+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Starting task 2.0 in stage 1320.0 (TID 2295) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:09.986+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:09 INFO TaskSetManager: Finished task 1.0 in stage 1320.0 (TID 2294) in 20 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:54:10.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 3.0 in stage 1320.0 (TID 2296) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.006+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 2.0 in stage 1320.0 (TID 2295) in 21 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:54:10.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 4.0 in stage 1320.0 (TID 2297) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.025+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 3.0 in stage 1320.0 (TID 2296) in 19 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T19:54:10.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 5.0 in stage 1320.0 (TID 2298) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.044+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 4.0 in stage 1320.0 (TID 2297) in 20 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T19:54:10.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 6.0 in stage 1320.0 (TID 2299) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.063+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 5.0 in stage 1320.0 (TID 2298) in 19 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T19:54:10.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 7.0 in stage 1320.0 (TID 2300) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.081+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 6.0 in stage 1320.0 (TID 2299) in 19 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T19:54:10.099+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 8.0 in stage 1320.0 (TID 2301) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 7.0 in stage 1320.0 (TID 2300) in 19 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T19:54:10.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 9.0 in stage 1320.0 (TID 2302) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5440 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.120+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 8.0 in stage 1320.0 (TID 2301) in 21 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T19:54:10.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 27.0 in stage 1335.1 (TID 2303) (172.20.0.5, executor 1, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.139+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 9.0 in stage 1320.0 (TID 2302) in 19 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T19:54:10.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSchedulerImpl: Removed TaskSet 1320.0, whose tasks have all completed, from pool
[2025-05-08T19:54:10.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO DAGScheduler: ShuffleMapStage 1320 (mapPartitions at GraphImpl.scala:208) finished in 0.267 s
[2025-05-08T19:54:10.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T19:54:10.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T19:54:10.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T19:54:10.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO DAGScheduler: failed: Set()
[2025-05-08T19:54:10.140+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO DAGScheduler: Submitting ShuffleMapStage 1321 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[806] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T19:54:10.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 22.8 KiB, free 415.7 MiB)
[2025-05-08T19:54:10.142+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 415.7 MiB)
[2025-05-08T19:54:10.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on f2a432e4376a:35283 (size: 7.4 KiB, free: 432.3 MiB)
[2025-05-08T19:54:10.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1474
[2025-05-08T19:54:10.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1321 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[806] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T19:54:10.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSchedulerImpl: Adding task set 1321.0 with 10 tasks resource profile 0
[2025-05-08T19:54:10.143+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T19:54:10.150+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Starting task 0.0 in stage 1321.0 (TID 2304) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:54:10.151+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO TaskSetManager: Finished task 27.0 in stage 1335.1 (TID 2303) in 11 ms on 172.20.0.5 (executor 1) (25/41)
[2025-05-08T19:54:10.153+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 172.20.0.5:36007 (size: 7.4 KiB, free: 419.7 MiB)
[2025-05-08T19:54:10.156+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T19:54:10.158+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T19:54:10.160+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T19:54:10.164+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T19:54:10.170+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T19:54:10.182+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T19:54:10.207+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T19:54:10.255+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T19:54:10.353+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T19:54:10.538+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T19:54:10.897+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T19:54:11.606+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:36758
[2025-05-08T19:54:13.065+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 99 to 172.20.0.5:36758
[2025-05-08T19:54:16.355+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 101 to 172.20.0.5:36758
[2025-05-08T19:54:24.054+0000] {spark_submit.py:571} INFO - 25/05/08 19:54:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 103 to 172.20.0.5:36758
[2025-05-08T19:55:20.094+0000] {spark_submit.py:571} INFO - 25/05/08 19:55:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 105 to 172.20.0.5:36758
[2025-05-08T19:55:20.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:55:20 INFO TaskSetManager: Starting task 1.0 in stage 1321.0 (TID 2305) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:55:20.100+0000] {spark_submit.py:571} INFO - 25/05/08 19:55:20 INFO TaskSetManager: Finished task 0.0 in stage 1321.0 (TID 2304) in 69950 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T19:56:32.509+0000] {spark_submit.py:571} INFO - 25/05/08 19:56:32 INFO TaskSetManager: Starting task 2.0 in stage 1321.0 (TID 2306) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:56:32.510+0000] {spark_submit.py:571} INFO - 25/05/08 19:56:32 INFO TaskSetManager: Finished task 1.0 in stage 1321.0 (TID 2305) in 72409 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T19:57:43.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:57:43 INFO TaskSetManager: Starting task 3.0 in stage 1321.0 (TID 2307) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:57:43.472+0000] {spark_submit.py:571} INFO - 25/05/08 19:57:43 INFO TaskSetManager: Finished task 2.0 in stage 1321.0 (TID 2306) in 70963 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T19:58:57.008+0000] {spark_submit.py:571} INFO - 25/05/08 19:58:57 INFO TaskSetManager: Starting task 4.0 in stage 1321.0 (TID 2308) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T19:58:57.009+0000] {spark_submit.py:571} INFO - 25/05/08 19:58:57 INFO TaskSetManager: Finished task 3.0 in stage 1321.0 (TID 2307) in 73536 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T20:00:07.486+0000] {spark_submit.py:571} INFO - 25/05/08 20:00:07 INFO TaskSetManager: Starting task 5.0 in stage 1321.0 (TID 2309) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T20:00:07.487+0000] {spark_submit.py:571} INFO - 25/05/08 20:00:07 INFO TaskSetManager: Finished task 4.0 in stage 1321.0 (TID 2308) in 70478 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T20:01:19.267+0000] {spark_submit.py:571} INFO - 25/05/08 20:01:19 INFO TaskSetManager: Starting task 6.0 in stage 1321.0 (TID 2310) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T20:01:19.268+0000] {spark_submit.py:571} INFO - 25/05/08 20:01:19 INFO TaskSetManager: Finished task 5.0 in stage 1321.0 (TID 2309) in 71783 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T20:02:33.186+0000] {spark_submit.py:571} INFO - 25/05/08 20:02:33 INFO TaskSetManager: Starting task 7.0 in stage 1321.0 (TID 2311) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T20:02:33.187+0000] {spark_submit.py:571} INFO - 25/05/08 20:02:33 INFO TaskSetManager: Finished task 6.0 in stage 1321.0 (TID 2310) in 73922 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T20:03:46.271+0000] {spark_submit.py:571} INFO - 25/05/08 20:03:46 INFO TaskSetManager: Starting task 8.0 in stage 1321.0 (TID 2312) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T20:03:46.273+0000] {spark_submit.py:571} INFO - 25/05/08 20:03:46 INFO TaskSetManager: Finished task 7.0 in stage 1321.0 (TID 2311) in 73087 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T20:04:58.197+0000] {spark_submit.py:571} INFO - 25/05/08 20:04:58 INFO TaskSetManager: Starting task 9.0 in stage 1321.0 (TID 2313) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5809 bytes) taskResourceAssignments Map()
[2025-05-08T20:04:58.201+0000] {spark_submit.py:571} INFO - 25/05/08 20:04:58 INFO TaskSetManager: Finished task 8.0 in stage 1321.0 (TID 2312) in 71932 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T20:06:12.782+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 28.0 in stage 1335.1 (TID 2314) (172.20.0.5, executor 1, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.784+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 9.0 in stage 1321.0 (TID 2313) in 74585 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T20:06:12.784+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSchedulerImpl: Removed TaskSet 1321.0, whose tasks have all completed, from pool
[2025-05-08T20:06:12.784+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO DAGScheduler: ShuffleMapStage 1321 (mapPartitions at VertexRDDImpl.scala:247) finished in 722.641 s
[2025-05-08T20:06:12.784+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T20:06:12.784+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T20:06:12.784+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1323, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T20:06:12.784+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO DAGScheduler: failed: Set()
[2025-05-08T20:06:12.788+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T20:06:12.790+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO DAGScheduler: Submitting ShuffleMapStage 1322 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[810] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T20:06:12.801+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 243.1 KiB, free 415.4 MiB)
[2025-05-08T20:06:12.806+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 29.0 in stage 1335.1 (TID 2315) (172.20.0.5, executor 1, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.807+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 79.9 KiB, free 415.3 MiB)
[2025-05-08T20:06:12.807+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 28.0 in stage 1335.1 (TID 2314) in 28 ms on 172.20.0.5 (executor 1) (26/41)
[2025-05-08T20:06:12.807+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on f2a432e4376a:35283 (size: 79.9 KiB, free: 432.2 MiB)
[2025-05-08T20:06:12.812+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:1474
[2025-05-08T20:06:12.812+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1322 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[810] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T20:06:12.813+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSchedulerImpl: Adding task set 1322.0 with 10 tasks resource profile 0
[2025-05-08T20:06:12.816+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 0.0 in stage 1322.0 (TID 2316) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.816+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 29.0 in stage 1335.1 (TID 2315) in 10 ms on 172.20.0.5 (executor 1) (27/41)
[2025-05-08T20:06:12.819+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 172.20.0.5:36007 (size: 79.9 KiB, free: 419.6 MiB)
[2025-05-08T20:06:12.826+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T20:06:12.831+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T20:06:12.833+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T20:06:12.834+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T20:06:12.836+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T20:06:12.838+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T20:06:12.840+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T20:06:12.841+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T20:06:12.843+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T20:06:12.844+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T20:06:12.846+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T20:06:12.848+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T20:06:12.849+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:36758
[2025-05-08T20:06:12.851+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 96 to 172.20.0.5:36758
[2025-05-08T20:06:12.853+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 98 to 172.20.0.5:36758
[2025-05-08T20:06:12.856+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 100 to 172.20.0.5:36758
[2025-05-08T20:06:12.860+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 102 to 172.20.0.5:36758
[2025-05-08T20:06:12.861+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 104 to 172.20.0.5:36758
[2025-05-08T20:06:12.892+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 1.0 in stage 1322.0 (TID 2317) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.892+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 0.0 in stage 1322.0 (TID 2316) in 76 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T20:06:12.916+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 2.0 in stage 1322.0 (TID 2318) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.917+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 1.0 in stage 1322.0 (TID 2317) in 24 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T20:06:12.934+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 3.0 in stage 1322.0 (TID 2319) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.934+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 2.0 in stage 1322.0 (TID 2318) in 18 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T20:06:12.955+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 4.0 in stage 1322.0 (TID 2320) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.955+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 3.0 in stage 1322.0 (TID 2319) in 21 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T20:06:12.972+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 5.0 in stage 1322.0 (TID 2321) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.973+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 4.0 in stage 1322.0 (TID 2320) in 18 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T20:06:12.993+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Starting task 6.0 in stage 1322.0 (TID 2322) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:12.994+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:12 INFO TaskSetManager: Finished task 5.0 in stage 1322.0 (TID 2321) in 22 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T20:06:13.013+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Starting task 7.0 in stage 1322.0 (TID 2323) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:13.014+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Finished task 6.0 in stage 1322.0 (TID 2322) in 20 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T20:06:13.033+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Starting task 8.0 in stage 1322.0 (TID 2324) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:13.034+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Finished task 7.0 in stage 1322.0 (TID 2323) in 20 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T20:06:13.051+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Starting task 9.0 in stage 1322.0 (TID 2325) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5481 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:13.052+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Finished task 8.0 in stage 1322.0 (TID 2324) in 19 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Starting task 30.0 in stage 1335.1 (TID 2326) (172.20.0.5, executor 1, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Finished task 9.0 in stage 1322.0 (TID 2325) in 23 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSchedulerImpl: Removed TaskSet 1322.0, whose tasks have all completed, from pool
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO DAGScheduler: ShuffleMapStage 1322 (mapPartitions at GraphImpl.scala:208) finished in 0.282 s
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1324, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1323, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T20:06:13.074+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO DAGScheduler: failed: Set()
[2025-05-08T20:06:13.075+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO DAGScheduler: Submitting ShuffleMapStage 1323 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[818] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T20:06:13.076+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 23.5 KiB, free 415.3 MiB)
[2025-05-08T20:06:13.076+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 415.3 MiB)
[2025-05-08T20:06:13.076+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on f2a432e4376a:35283 (size: 7.5 KiB, free: 432.2 MiB)
[2025-05-08T20:06:13.077+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:1474
[2025-05-08T20:06:13.077+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1323 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[818] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T20:06:13.077+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSchedulerImpl: Adding task set 1323.0 with 10 tasks resource profile 0
[2025-05-08T20:06:13.077+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:36758
[2025-05-08T20:06:13.085+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Starting task 0.0 in stage 1323.0 (TID 2327) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:06:13.085+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO TaskSetManager: Finished task 30.0 in stage 1335.1 (TID 2326) in 12 ms on 172.20.0.5 (executor 1) (28/41)
[2025-05-08T20:06:13.088+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 172.20.0.5:36007 (size: 7.5 KiB, free: 419.6 MiB)
[2025-05-08T20:06:13.090+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T20:06:13.092+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T20:06:13.094+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T20:06:13.098+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T20:06:13.106+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T20:06:13.117+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T20:06:13.141+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T20:06:13.188+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T20:06:13.286+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T20:06:13.479+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T20:06:13.839+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T20:06:14.559+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:36758
[2025-05-08T20:06:16.098+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 99 to 172.20.0.5:36758
[2025-05-08T20:06:19.506+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 101 to 172.20.0.5:36758
[2025-05-08T20:06:27.904+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 103 to 172.20.0.5:36758
[2025-05-08T20:06:51.234+0000] {spark_submit.py:571} INFO - 25/05/08 20:06:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 105 to 172.20.0.5:36758
[2025-05-08T20:09:25.803+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_255_piece0 on f2a432e4376a:35283 in memory (size: 79.9 KiB, free: 432.3 MiB)
[2025-05-08T20:09:25.809+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 172.20.0.5:36007 in memory (size: 79.9 KiB, free: 419.7 MiB)
[2025-05-08T20:09:25.811+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_248_piece0 on f2a432e4376a:35283 in memory (size: 7.1 KiB, free: 432.3 MiB)
[2025-05-08T20:09:25.812+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 172.20.0.5:36007 in memory (size: 7.1 KiB, free: 419.7 MiB)
[2025-05-08T20:09:25.815+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 172.20.0.5:36007 in memory (size: 79.6 KiB, free: 419.8 MiB)
[2025-05-08T20:09:25.816+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_251_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.4 MiB)
[2025-05-08T20:09:25.819+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_254_piece0 on f2a432e4376a:35283 in memory (size: 7.4 KiB, free: 432.4 MiB)
[2025-05-08T20:09:25.820+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 172.20.0.5:36007 in memory (size: 7.4 KiB, free: 419.8 MiB)
[2025-05-08T20:09:25.831+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_253_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.5 MiB)
[2025-05-08T20:09:25.832+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 172.20.0.5:36007 in memory (size: 79.6 KiB, free: 419.9 MiB)
[2025-05-08T20:09:25.837+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_247_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.6 MiB)
[2025-05-08T20:09:25.838+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 172.20.0.5:36007 in memory (size: 79.6 KiB, free: 420.0 MiB)
[2025-05-08T20:09:25.840+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_249_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.6 MiB)
[2025-05-08T20:09:25.842+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 172.20.0.5:36007 in memory (size: 79.6 KiB, free: 420.0 MiB)
[2025-05-08T20:09:25.844+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_252_piece0 on f2a432e4376a:35283 in memory (size: 7.5 KiB, free: 432.6 MiB)
[2025-05-08T20:09:25.846+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 172.20.0.5:36007 in memory (size: 7.5 KiB, free: 420.0 MiB)
[2025-05-08T20:09:25.850+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_250_piece0 on f2a432e4376a:35283 in memory (size: 7.3 KiB, free: 432.7 MiB)
[2025-05-08T20:09:25.852+0000] {spark_submit.py:571} INFO - 25/05/08 20:09:25 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 172.20.0.5:36007 in memory (size: 7.3 KiB, free: 420.0 MiB)
[2025-05-08T20:10:11.848+0000] {spark_submit.py:571} INFO - 25/05/08 20:10:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 107 to 172.20.0.5:36758
[2025-05-08T20:10:11.887+0000] {spark_submit.py:571} INFO - 25/05/08 20:10:11 INFO TaskSetManager: Starting task 1.0 in stage 1323.0 (TID 2328) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:10:11.887+0000] {spark_submit.py:571} INFO - 25/05/08 20:10:11 INFO TaskSetManager: Finished task 0.0 in stage 1323.0 (TID 2327) in 238803 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T20:14:00.387+0000] {spark_submit.py:571} INFO - 25/05/08 20:14:00 INFO TaskSetManager: Starting task 2.0 in stage 1323.0 (TID 2329) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:14:00.389+0000] {spark_submit.py:571} INFO - 25/05/08 20:14:00 INFO TaskSetManager: Finished task 1.0 in stage 1323.0 (TID 2328) in 228501 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T20:17:46.091+0000] {spark_submit.py:571} INFO - 25/05/08 20:17:46 INFO TaskSetManager: Starting task 3.0 in stage 1323.0 (TID 2330) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:17:46.092+0000] {spark_submit.py:571} INFO - 25/05/08 20:17:46 INFO TaskSetManager: Finished task 2.0 in stage 1323.0 (TID 2329) in 225707 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T20:21:29.094+0000] {spark_submit.py:571} INFO - 25/05/08 20:21:29 INFO TaskSetManager: Starting task 4.0 in stage 1323.0 (TID 2331) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:21:29.095+0000] {spark_submit.py:571} INFO - 25/05/08 20:21:29 INFO TaskSetManager: Finished task 3.0 in stage 1323.0 (TID 2330) in 223006 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T20:25:12.445+0000] {spark_submit.py:571} INFO - 25/05/08 20:25:12 INFO TaskSetManager: Starting task 5.0 in stage 1323.0 (TID 2332) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:25:12.446+0000] {spark_submit.py:571} INFO - 25/05/08 20:25:12 INFO TaskSetManager: Finished task 4.0 in stage 1323.0 (TID 2331) in 223354 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T20:28:58.218+0000] {spark_submit.py:571} INFO - 25/05/08 20:28:58 INFO TaskSetManager: Starting task 6.0 in stage 1323.0 (TID 2333) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:28:58.219+0000] {spark_submit.py:571} INFO - 25/05/08 20:28:58 INFO TaskSetManager: Finished task 5.0 in stage 1323.0 (TID 2332) in 225776 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T20:32:43.389+0000] {spark_submit.py:571} INFO - 25/05/08 20:32:43 INFO TaskSetManager: Starting task 7.0 in stage 1323.0 (TID 2334) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:32:43.390+0000] {spark_submit.py:571} INFO - 25/05/08 20:32:43 INFO TaskSetManager: Finished task 6.0 in stage 1323.0 (TID 2333) in 225173 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T20:36:29.502+0000] {spark_submit.py:571} INFO - 25/05/08 20:36:29 INFO TaskSetManager: Starting task 8.0 in stage 1323.0 (TID 2335) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:36:29.505+0000] {spark_submit.py:571} INFO - 25/05/08 20:36:29 INFO TaskSetManager: Finished task 7.0 in stage 1323.0 (TID 2334) in 226119 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T20:40:20.685+0000] {spark_submit.py:571} INFO - 25/05/08 20:40:20 INFO TaskSetManager: Starting task 9.0 in stage 1323.0 (TID 2336) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5882 bytes) taskResourceAssignments Map()
[2025-05-08T20:40:20.687+0000] {spark_submit.py:571} INFO - 25/05/08 20:40:20 INFO TaskSetManager: Finished task 8.0 in stage 1323.0 (TID 2335) in 231188 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T20:44:19.555+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 31.0 in stage 1335.1 (TID 2337) (172.20.0.5, executor 1, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.559+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 9.0 in stage 1323.0 (TID 2336) in 238874 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T20:44:19.559+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSchedulerImpl: Removed TaskSet 1323.0, whose tasks have all completed, from pool
[2025-05-08T20:44:19.561+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO DAGScheduler: ShuffleMapStage 1323 (mapPartitions at VertexRDDImpl.scala:247) finished in 2286.481 s
[2025-05-08T20:44:19.561+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T20:44:19.561+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T20:44:19.561+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1324, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T20:44:19.562+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO DAGScheduler: failed: Set()
[2025-05-08T20:44:19.562+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO DAGScheduler: Submitting ShuffleMapStage 1324 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[822] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T20:44:19.565+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 118 to 172.20.0.5:36758
[2025-05-08T20:44:19.623+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 32.0 in stage 1335.1 (TID 2338) (172.20.0.5, executor 1, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.623+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 31.0 in stage 1335.1 (TID 2337) in 81 ms on 172.20.0.5 (executor 1) (29/41)
[2025-05-08T20:44:19.638+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 33.0 in stage 1335.1 (TID 2339) (172.20.0.5, executor 1, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.641+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 32.0 in stage 1335.1 (TID 2338) in 19 ms on 172.20.0.5 (executor 1) (30/41)
[2025-05-08T20:44:19.685+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 34.0 in stage 1335.1 (TID 2340) (172.20.0.5, executor 1, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.687+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 33.0 in stage 1335.1 (TID 2339) in 50 ms on 172.20.0.5 (executor 1) (31/41)
[2025-05-08T20:44:19.709+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 35.0 in stage 1335.1 (TID 2341) (172.20.0.5, executor 1, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.710+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 34.0 in stage 1335.1 (TID 2340) in 24 ms on 172.20.0.5 (executor 1) (32/41)
[2025-05-08T20:44:19.724+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 36.0 in stage 1335.1 (TID 2342) (172.20.0.5, executor 1, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.724+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 35.0 in stage 1335.1 (TID 2341) in 15 ms on 172.20.0.5 (executor 1) (33/41)
[2025-05-08T20:44:19.741+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 37.0 in stage 1335.1 (TID 2343) (172.20.0.5, executor 1, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.741+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 36.0 in stage 1335.1 (TID 2342) in 18 ms on 172.20.0.5 (executor 1) (34/41)
[2025-05-08T20:44:19.752+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 38.0 in stage 1335.1 (TID 2344) (172.20.0.5, executor 1, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.752+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 37.0 in stage 1335.1 (TID 2343) in 11 ms on 172.20.0.5 (executor 1) (35/41)
[2025-05-08T20:44:19.762+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 39.0 in stage 1335.1 (TID 2345) (172.20.0.5, executor 1, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.762+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 38.0 in stage 1335.1 (TID 2344) in 9 ms on 172.20.0.5 (executor 1) (36/41)
[2025-05-08T20:44:19.771+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 40.0 in stage 1335.1 (TID 2346) (172.20.0.5, executor 1, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.772+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 39.0 in stage 1335.1 (TID 2345) in 10 ms on 172.20.0.5 (executor 1) (37/41)
[2025-05-08T20:44:19.782+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 0.0 in stage 1335.1 (TID 2347) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.783+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 40.0 in stage 1335.1 (TID 2346) in 11 ms on 172.20.0.5 (executor 1) (38/41)
[2025-05-08T20:44:19.791+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 243.4 KiB, free 416.8 MiB)
[2025-05-08T20:44:19.805+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 80.0 KiB, free 416.7 MiB)
[2025-05-08T20:44:19.805+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on f2a432e4376a:35283 (size: 80.0 KiB, free: 432.6 MiB)
[2025-05-08T20:44:19.806+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1474
[2025-05-08T20:44:19.809+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1324 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[822] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T20:44:19.809+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSchedulerImpl: Adding task set 1324.0 with 10 tasks resource profile 0
[2025-05-08T20:44:19.852+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Starting task 0.0 in stage 1324.0 (TID 2348) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:19.855+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO TaskSetManager: Finished task 0.0 in stage 1335.1 (TID 2347) in 70 ms on 172.20.0.5 (executor 1) (39/41)
[2025-05-08T20:44:19.867+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 172.20.0.5:36007 (size: 80.0 KiB, free: 420.0 MiB)
[2025-05-08T20:44:19.956+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:36758
[2025-05-08T20:44:19.962+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:36758
[2025-05-08T20:44:19.965+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:36758
[2025-05-08T20:44:19.967+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:36758
[2025-05-08T20:44:19.970+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:36758
[2025-05-08T20:44:19.973+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:36758
[2025-05-08T20:44:19.976+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:36758
[2025-05-08T20:44:19.978+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:36758
[2025-05-08T20:44:19.980+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:36758
[2025-05-08T20:44:19.987+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:36758
[2025-05-08T20:44:19.989+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:36758
[2025-05-08T20:44:19.991+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:36758
[2025-05-08T20:44:19.993+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:36758
[2025-05-08T20:44:19.995+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 96 to 172.20.0.5:36758
[2025-05-08T20:44:19.997+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 98 to 172.20.0.5:36758
[2025-05-08T20:44:19.999+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 100 to 172.20.0.5:36758
[2025-05-08T20:44:20.000+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 102 to 172.20.0.5:36758
[2025-05-08T20:44:20.002+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 104 to 172.20.0.5:36758
[2025-05-08T20:44:20.004+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 106 to 172.20.0.5:36758
[2025-05-08T20:44:20.046+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 1.0 in stage 1324.0 (TID 2349) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.046+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 0.0 in stage 1324.0 (TID 2348) in 195 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T20:44:20.090+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 2.0 in stage 1324.0 (TID 2350) (172.20.0.5, executor 1, partition 2, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.091+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 1.0 in stage 1324.0 (TID 2349) in 45 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-08T20:44:20.110+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Removed broadcast_256_piece0 on f2a432e4376a:35283 in memory (size: 7.5 KiB, free: 432.6 MiB)
[2025-05-08T20:44:20.111+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 172.20.0.5:36007 in memory (size: 7.5 KiB, free: 420.0 MiB)
[2025-05-08T20:44:20.120+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 3.0 in stage 1324.0 (TID 2351) (172.20.0.5, executor 1, partition 3, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.121+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 2.0 in stage 1324.0 (TID 2350) in 31 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-08T20:44:20.145+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 4.0 in stage 1324.0 (TID 2352) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.145+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 3.0 in stage 1324.0 (TID 2351) in 25 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-08T20:44:20.169+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 5.0 in stage 1324.0 (TID 2353) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.169+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 4.0 in stage 1324.0 (TID 2352) in 24 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-08T20:44:20.193+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 6.0 in stage 1324.0 (TID 2354) (172.20.0.5, executor 1, partition 6, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.193+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 5.0 in stage 1324.0 (TID 2353) in 24 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-08T20:44:20.217+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 7.0 in stage 1324.0 (TID 2355) (172.20.0.5, executor 1, partition 7, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.217+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 6.0 in stage 1324.0 (TID 2354) in 24 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-08T20:44:20.242+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 8.0 in stage 1324.0 (TID 2356) (172.20.0.5, executor 1, partition 8, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.243+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 7.0 in stage 1324.0 (TID 2355) in 27 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-08T20:44:20.266+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 9.0 in stage 1324.0 (TID 2357) (172.20.0.5, executor 1, partition 9, PROCESS_LOCAL, 5522 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.266+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 8.0 in stage 1324.0 (TID 2356) in 24 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-08T20:44:20.290+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 4.0 in stage 1335.1 (TID 2358) (172.20.0.5, executor 1, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.290+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 9.0 in stage 1324.0 (TID 2357) in 25 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-08T20:44:20.291+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSchedulerImpl: Removed TaskSet 1324.0, whose tasks have all completed, from pool
[2025-05-08T20:44:20.291+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: ShuffleMapStage 1324 (mapPartitions at GraphImpl.scala:208) finished in 0.728 s
[2025-05-08T20:44:20.291+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T20:44:20.291+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1335, ShuffleMapStage 1336)
[2025-05-08T20:44:20.291+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T20:44:20.291+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: failed: Set()
[2025-05-08T20:44:20.291+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Submitting ShuffleMapStage 1325 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[830] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T20:44:20.294+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:36758
[2025-05-08T20:44:20.298+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 5.0 in stage 1335.1 (TID 2359) (172.20.0.5, executor 1, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.299+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 4.0 in stage 1335.1 (TID 2358) in 8 ms on 172.20.0.5 (executor 1) (40/41)
[2025-05-08T20:44:20.301+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 24.3 KiB, free 416.7 MiB)
[2025-05-08T20:44:20.312+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 416.7 MiB)
[2025-05-08T20:44:20.313+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 1.0 in stage 1336.0 (TID 2360) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.313+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 5.0 in stage 1335.1 (TID 2359) in 14 ms on 172.20.0.5 (executor 1) (41/41)
[2025-05-08T20:44:20.313+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSchedulerImpl: Removed TaskSet 1335.1, whose tasks have all completed, from pool
[2025-05-08T20:44:20.313+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on f2a432e4376a:35283 (size: 7.6 KiB, free: 432.6 MiB)
[2025-05-08T20:44:20.313+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:1474
[2025-05-08T20:44:20.314+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1325 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[830] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T20:44:20.314+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSchedulerImpl: Adding task set 1325.0 with 10 tasks resource profile 0
[2025-05-08T20:44:20.314+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: ShuffleMapStage 1335 (collect at /opt/airflow/spark/build_graph.py:229) finished in 3445.907 s
[2025-05-08T20:44:20.315+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T20:44:20.315+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: running: Set(ShuffleMapStage 1325, ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T20:44:20.315+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T20:44:20.315+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: failed: Set()
[2025-05-08T20:44:20.319+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 172.20.0.5:36007 (size: 40.1 KiB, free: 419.9 MiB)
[2025-05-08T20:44:20.335+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T20:44:20.338+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO ShufflePartitionsUtil: For shuffle(122), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T20:44:20.340+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO ShufflePartitionsUtil: For shuffle(122), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T20:44:20.342+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO ShufflePartitionsUtil: For shuffle(122), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T20:44:20.343+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO ShufflePartitionsUtil: For shuffle(122), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T20:44:20.348+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO ShufflePartitionsUtil: For shuffle(122), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T20:44:20.349+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO ShufflePartitionsUtil: For shuffle(122), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-08T20:44:20.394+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Starting task 0.0 in stage 1325.0 (TID 2361) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T20:44:20.396+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSetManager: Finished task 1.0 in stage 1336.0 (TID 2360) in 83 ms on 172.20.0.5 (executor 1) (1/41)
[2025-05-08T20:44:20.402+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 172.20.0.5:36007 (size: 7.6 KiB, free: 419.9 MiB)
[2025-05-08T20:44:20.405+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:36758
[2025-05-08T20:44:20.410+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:36758
[2025-05-08T20:44:20.415+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:36758
[2025-05-08T20:44:20.438+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:36758
[2025-05-08T20:44:20.448+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:36758
[2025-05-08T20:44:20.480+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:36758
[2025-05-08T20:44:20.527+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T20:44:20.528+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-08T20:44:20.539+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:36758
[2025-05-08T20:44:20.550+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO CodeGenerator: Code generated in 18.498763 ms
[2025-05-08T20:44:20.558+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Registering RDD 1133 (collect at /opt/airflow/spark/build_graph.py:229) as input to shuffle 126
[2025-05-08T20:44:20.558+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Got map stage job 82 (collect at /opt/airflow/spark/build_graph.py:229) with 1 output partitions
[2025-05-08T20:44:20.558+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Final stage: ShuffleMapStage 1344 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T20:44:20.558+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1343)
[2025-05-08T20:44:20.559+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Missing parents: List()
[2025-05-08T20:44:20.559+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Submitting ShuffleMapStage 1344 (MapPartitionsRDD[1133] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T20:44:20.564+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 87.6 KiB, free 416.6 MiB)
[2025-05-08T20:44:20.586+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 416.6 MiB)
[2025-05-08T20:44:20.586+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Removed broadcast_257_piece0 on f2a432e4376a:35283 in memory (size: 80.0 KiB, free: 432.7 MiB)
[2025-05-08T20:44:20.587+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on f2a432e4376a:35283 (size: 32.6 KiB, free: 432.6 MiB)
[2025-05-08T20:44:20.587+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1474
[2025-05-08T20:44:20.588+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1344 (MapPartitionsRDD[1133] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T20:44:20.588+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO TaskSchedulerImpl: Adding task set 1344.0 with 1 tasks resource profile 0
[2025-05-08T20:44:20.589+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 172.20.0.5:36007 in memory (size: 80.0 KiB, free: 420.0 MiB)
[2025-05-08T20:44:20.604+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-05-08T20:44:20.641+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:36758
[2025-05-08T20:44:20.702+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Removed broadcast_230_piece0 on f2a432e4376a:35283 in memory (size: 39.5 KiB, free: 432.7 MiB)
[2025-05-08T20:44:20.703+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 172.20.0.5:36007 in memory (size: 39.5 KiB, free: 420.0 MiB)
[2025-05-08T20:44:20.788+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:36758
[2025-05-08T20:44:21.017+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:36758
[2025-05-08T20:44:21.373+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:36758
[2025-05-08T20:44:22.081+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:36758
[2025-05-08T20:44:23.635+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 99 to 172.20.0.5:36758
[2025-05-08T20:44:27.330+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 101 to 172.20.0.5:36758
[2025-05-08T20:44:35.162+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 103 to 172.20.0.5:36758
[2025-05-08T20:44:57.398+0000] {spark_submit.py:571} INFO - 25/05/08 20:44:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 105 to 172.20.0.5:36758
[2025-05-08T20:46:14.127+0000] {spark_submit.py:571} INFO - 25/05/08 20:46:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 107 to 172.20.0.5:36758
[2025-05-08T20:57:06.726+0000] {spark_submit.py:571} INFO - 25/05/08 20:57:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 109 to 172.20.0.5:36758
[2025-05-08T20:57:06.776+0000] {spark_submit.py:571} INFO - 25/05/08 20:57:06 INFO TaskSetManager: Starting task 1.0 in stage 1325.0 (TID 2362) (172.20.0.5, executor 1, partition 1, PROCESS_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T20:57:06.777+0000] {spark_submit.py:571} INFO - 25/05/08 20:57:06 INFO TaskSetManager: Finished task 0.0 in stage 1325.0 (TID 2361) in 766382 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-08T21:09:11.048+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:10 WARN HeartbeatReceiver: Removing executor 1 with no recent heartbeats: 266881 ms exceeds timeout 120000 ms
[2025-05-08T21:09:11.147+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:11 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 1
[2025-05-08T21:09:11.153+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:11 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is 1
[2025-05-08T21:09:12.058+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/1 is now LOST (worker lost)
[2025-05-08T21:09:12.059+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO StandaloneSchedulerBackend: Executor app-20250508193925-0005/1 removed: worker lost
[2025-05-08T21:09:12.059+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:09:12.059+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO StandaloneSchedulerBackend: Worker worker-20250508061515-172.20.0.5-45383 removed: Not receiving heartbeat for 60 seconds
[2025-05-08T21:09:12.064+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 ERROR TaskSchedulerImpl: Lost executor 1 on 172.20.0.5: worker lost
[2025-05-08T21:09:12.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 1), so marking it as still running.
[2025-05-08T21:09:12.126+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO DAGScheduler: Resubmitted ShuffleMapTask(1325, 0), so marking it as still running.
[2025-05-08T21:09:12.262+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250508193925-0005/2 on worker-20250508061515-172.20.0.5-45383 (172.20.0.5:45383) with 1 core(s)
[2025-05-08T21:09:12.267+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN TaskSetManager: Lost task 1.0 in stage 1325.0 (TID 2362) (172.20.0.5 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: worker lost
[2025-05-08T21:09:12.274+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO TaskSchedulerImpl: Handle removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:09:12.277+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO DAGScheduler: Executor lost: 1 (epoch 205)
[2025-05-08T21:09:12.278+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20250508193925-0005/2 on hostPort 172.20.0.5:45383 with 1 core(s), 1024.0 MiB RAM
[2025-05-08T21:09:12.287+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 ERROR Inbox: Ignoring error
[2025-05-08T21:09:12.290+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T21:09:12.290+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T21:09:12.290+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T21:09:12.290+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T21:09:12.290+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T21:09:12.290+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO BlockManagerMaster: Removal of executor 1 requested
[2025-05-08T21:09:12.291+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 1
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_1 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_4 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_5 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_0 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_7 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_9 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_8 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_3 !
[2025-05-08T21:09:12.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_3 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_9 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_6 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_7 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_1 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_7 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_6 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_4 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_8 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_6 !
[2025-05-08T21:09:12.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_1 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_8 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_1 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_5 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_7 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_8 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_3 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_7 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_2 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_2 !
[2025-05-08T21:09:12.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_4 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_9 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_1 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_2 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_5 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_0 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_4 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_4 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_6 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_8 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_1 !
[2025-05-08T21:09:12.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_3 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_4 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_8 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_2 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_0 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_7 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_1 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_1 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_6 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_2 !
[2025-05-08T21:09:12.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_2 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_7 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_8 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_5 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_6 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_8 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_3 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_0 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_3 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_5 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_9 !
[2025-05-08T21:09:12.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_4 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_9 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_4 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_0 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_8 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_6 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_0 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_3 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_5 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_6 !
[2025-05-08T21:09:12.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_9 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_9 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_9 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_7 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_3 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_6 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_2 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_3 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_1 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_1 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_2 !
[2025-05-08T21:09:12.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_5 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_6 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_2 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_405_9 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_5 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_0 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_3 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_7 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_0 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_0 !
[2025-05-08T21:09:12.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_2 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_5 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_577_0 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_7 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_9 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_8 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_5 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_4 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_403_4 !
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.20.0.5, 36007, None)
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
[2025-05-08T21:09:12.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
[2025-05-08T21:09:12.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 205)
[2025-05-08T21:09:12.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:12 INFO DAGScheduler: Shuffle files lost for worker worker-20250508061515-172.20.0.5-45383 on host 172.20.0.5
[2025-05-08T21:09:13.211+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/2 is now RUNNING
[2025-05-08T21:09:16.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:39008) with ID 2,  ResourceProfileId 0
[2025-05-08T21:09:16.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:38279 with 434.4 MiB RAM, BlockManagerId(2, 172.20.0.5, 38279, None)
[2025-05-08T21:09:16.852+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:16 INFO TaskSetManager: Starting task 1.1 in stage 1325.0 (TID 2363) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:17.060+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 172.20.0.5:38279 (size: 7.6 KiB, free: 434.4 MiB)
[2025-05-08T21:09:17.451+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:39008
[2025-05-08T21:09:17.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSetManager: Starting task 0.1 in stage 1325.0 (TID 2364) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 5955 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:17.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 WARN TaskSetManager: Lost task 1.1 in stage 1325.0 (TID 2363) (172.20.0.5 executor 2): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=1, message=
[2025-05-08T21:09:17.548+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 1
[2025-05-08T21:09:17.548+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:09:17.549+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:09:17.550+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:09:17.554+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:09:17.555+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:09:17.556+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:09:17.556+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:09:17.557+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:09:17.558+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:09:17.559+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:09:17.559+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:09:17.559+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:09:17.559+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:09:17.560+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:09:17.561+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.561+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.561+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.561+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.561+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.562+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.563+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.563+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.563+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.567+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.567+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.567+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.567+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.567+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.568+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.569+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.569+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.569+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.569+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.570+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.571+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.572+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.572+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.572+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.572+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.572+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.572+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.572+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.573+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.574+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.575+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.576+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.576+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.576+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.576+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.576+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.576+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.576+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.577+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.577+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:09:17.577+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:09:17.577+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:09:17.577+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:09:17.577+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:09:17.577+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:09:17.578+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:09:17.578+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:09:17.578+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:09:17.578+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:09:17.578+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:09:17.578+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:09:17.578+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSetManager: task 1.1 in stage 1325.0 (TID 2363) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Marking ShuffleMapStage 1325 (mapPartitions at VertexRDDImpl.scala:247) as failed due to a fetch failure from ShuffleMapStage 1254 (map at GraphFrame.scala:187)
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: ShuffleMapStage 1325 (mapPartitions at VertexRDDImpl.scala:247) failed in 1497.255 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 1
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:09:17.579+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:09:17.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:09:17.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:09:17.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:09:17.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:09:17.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:09:17.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:09:17.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:09:17.592+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:09:17.593+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:09:17.593+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:09:17.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Resubmitting ShuffleMapStage 1254 (map at GraphFrame.scala:187) and ShuffleMapStage 1325 (mapPartitions at VertexRDDImpl.scala:247) due to fetch failure
[2025-05-08T21:09:17.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:39008
[2025-05-08T21:09:17.605+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSetManager: Starting task 1.1 in stage 1336.0 (TID 2365) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:17.606+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 WARN TaskSetManager: Lost task 0.1 in stage 1325.0 (TID 2364) (172.20.0.5 executor 2): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-08T21:09:17.606+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 0
[2025-05-08T21:09:17.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:09:17.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:09:17.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:09:17.606+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:09:17.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:09:17.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:09:17.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:09:17.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.609+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:09:17.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:09:17.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:09:17.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:09:17.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:09:17.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.616+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.617+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.618+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.618+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.618+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.618+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.618+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.618+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.618+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.619+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:09:17.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.620+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:09:17.621+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:09:17.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSetManager: task 0.1 in stage 1325.0 (TID 2364) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:09:17.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSchedulerImpl: Removed TaskSet 1325.0, whose tasks have all completed, from pool
[2025-05-08T21:09:17.653+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 172.20.0.5:38279 (size: 40.1 KiB, free: 434.4 MiB)
[2025-05-08T21:09:17.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T21:09:17.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:17.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 23.9 KiB, free 417.0 MiB)
[2025-05-08T21:09:17.785+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 417.0 MiB)
[2025-05-08T21:09:17.796+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:09:17.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:17.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Removed broadcast_258_piece0 on f2a432e4376a:35283 in memory (size: 7.6 KiB, free: 432.7 MiB)
[2025-05-08T21:09:17.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:17.828+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSchedulerImpl: Adding task set 1245.1 with 1 tasks resource profile 0
[2025-05-08T21:09:17.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:17.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 22.4 KiB, free 417.0 MiB)
[2025-05-08T21:09:17.842+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 417.0 MiB)
[2025-05-08T21:09:17.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:17.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:17.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:17.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSchedulerImpl: Adding task set 1246.1 with 1 tasks resource profile 0
[2025-05-08T21:09:17.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:17.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 22.4 KiB, free 417.0 MiB)
[2025-05-08T21:09:17.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 417.0 MiB)
[2025-05-08T21:09:17.854+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:17.856+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:17.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:17.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSchedulerImpl: Adding task set 1247.1 with 1 tasks resource profile 0
[2025-05-08T21:09:17.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:17.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_263 stored as values in memory (estimated size 28.8 KiB, free 416.9 MiB)
[2025-05-08T21:09:17.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.9 MiB)
[2025-05-08T21:09:17.874+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:09:17.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:17.879+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:17.880+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 172.20.0.5:38279 in memory (size: 7.6 KiB, free: 434.4 MiB)
[2025-05-08T21:09:17.881+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:17 INFO TaskSchedulerImpl: Adding task set 1248.1 with 1 tasks resource profile 0
[2025-05-08T21:09:18.881+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:18.895+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO TaskSetManager: Starting task 0.0 in stage 1245.1 (TID 2366) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:18.895+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 WARN TaskSetManager: Lost task 1.1 in stage 1336.0 (TID 2365) (172.20.0.5 executor 2): FetchFailed(null, shuffleId=115, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 115 partition 0
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:09:18.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:09:18.899+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO TaskSetManager: task 1.1 in stage 1336.0 (TID 2365) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO TaskSchedulerImpl: Removed TaskSet 1336.0, whose tasks have all completed, from pool
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO DAGScheduler: Marking ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO DAGScheduler: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) failed in 5146.427 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 115 partition 0
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:09:18.900+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.902+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:09:18.903+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:09:18.904+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:09:18.904+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:09:18.904+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:09:18.904+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:09:18.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO DAGScheduler: Resubmitting ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229) and ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) due to fetch failure
[2025-05-08T21:09:18.911+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:18 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:09:19.096+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T21:09:19.096+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:09:19.098+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_264 stored as values in memory (estimated size 23.9 KiB, free 416.9 MiB)
[2025-05-08T21:09:19.110+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.9 MiB)
[2025-05-08T21:09:19.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:09:19.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:19.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:19.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO TaskSchedulerImpl: Adding task set 1331.2 with 1 tasks resource profile 0
[2025-05-08T21:09:19.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:09:19.113+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_265 stored as values in memory (estimated size 22.4 KiB, free 416.9 MiB)
[2025-05-08T21:09:19.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.9 MiB)
[2025-05-08T21:09:19.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:19.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO SparkContext: Created broadcast 265 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:19.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:19.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO TaskSchedulerImpl: Adding task set 1332.2 with 1 tasks resource profile 0
[2025-05-08T21:09:19.115+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:09:19.118+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_266 stored as values in memory (estimated size 22.4 KiB, free 416.8 MiB)
[2025-05-08T21:09:19.120+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.8 MiB)
[2025-05-08T21:09:19.120+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:19.121+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:19.121+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:19.122+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO TaskSchedulerImpl: Adding task set 1333.2 with 1 tasks resource profile 0
[2025-05-08T21:09:19.125+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:09:19.126+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_267 stored as values in memory (estimated size 28.8 KiB, free 416.8 MiB)
[2025-05-08T21:09:19.128+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.8 MiB)
[2025-05-08T21:09:19.129+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:09:19.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO SparkContext: Created broadcast 267 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:19.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:09:19.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO TaskSchedulerImpl: Adding task set 1334.2 with 1 tasks resource profile 0
[2025-05-08T21:09:19.240+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO BlockManagerInfo: Removed broadcast_168_piece0 on f2a432e4376a:35283 in memory (size: 40.1 KiB, free: 432.6 MiB)
[2025-05-08T21:09:19.249+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:19 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 172.20.0.5:38279 in memory (size: 40.1 KiB, free: 434.4 MiB)
[2025-05-08T21:09:20.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSetManager: Starting task 0.0 in stage 1246.1 (TID 2367) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:20.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSetManager: Finished task 0.0 in stage 1245.1 (TID 2366) in 1498 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:20.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSchedulerImpl: Removed TaskSet 1245.1, whose tasks have all completed, from pool
[2025-05-08T21:09:20.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: ShuffleMapStage 1245 (rdd at GraphFrame.scala:187) finished in 2.643 s
[2025-05-08T21:09:20.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:20.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1247, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1246, ShuffleMapStage 1333)
[2025-05-08T21:09:20.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:09:20.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:20.407+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 172.20.0.5:38279 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:09:20.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSetManager: Starting task 0.0 in stage 1247.1 (TID 2368) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:20.825+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSetManager: Finished task 0.0 in stage 1246.1 (TID 2367) in 431 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:20.826+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSchedulerImpl: Removed TaskSet 1246.1, whose tasks have all completed, from pool
[2025-05-08T21:09:20.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: ShuffleMapStage 1246 (rdd at GraphFrame.scala:187) finished in 2.995 s
[2025-05-08T21:09:20.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:20.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1247, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:09:20.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:09:20.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:20.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 172.20.0.5:38279 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:09:20.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSetManager: Starting task 0.0 in stage 1248.1 (TID 2369) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:20.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSetManager: Finished task 0.0 in stage 1247.1 (TID 2368) in 127 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:20.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO TaskSchedulerImpl: Removed TaskSet 1247.1, whose tasks have all completed, from pool
[2025-05-08T21:09:20.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: ShuffleMapStage 1247 (rdd at GraphFrame.scala:187) finished in 3.103 s
[2025-05-08T21:09:20.951+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:20.951+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:09:20.951+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:09:20.951+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:20.968+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:20 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 172.20.0.5:38279 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T21:09:21.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO TaskSetManager: Starting task 0.0 in stage 1331.2 (TID 2370) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:21.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO TaskSetManager: Finished task 0.0 in stage 1248.1 (TID 2369) in 644 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:21.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO TaskSchedulerImpl: Removed TaskSet 1248.1, whose tasks have all completed, from pool
[2025-05-08T21:09:21.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: ShuffleMapStage 1248 (rdd at GraphFrame.scala:187) finished in 3.734 s
[2025-05-08T21:09:21.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:21.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:09:21.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:09:21.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:21.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: Submitting ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:21.605+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:09:21.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO MemoryStore: Block broadcast_268 stored as values in memory (estimated size 96.7 KiB, free 416.8 MiB)
[2025-05-08T21:09:21.647+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 416.8 MiB)
[2025-05-08T21:09:21.650+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on f2a432e4376a:35283 (size: 36.3 KiB, free: 432.6 MiB)
[2025-05-08T21:09:21.652+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:21.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:09:21.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO TaskSchedulerImpl: Adding task set 1249.1 with 41 tasks resource profile 0
[2025-05-08T21:09:21.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Removed broadcast_262_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:21.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Removed broadcast_262_piece0 on 172.20.0.5:38279 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:09:21.666+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Removed broadcast_261_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:21.671+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 172.20.0.5:38279 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:09:21.681+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Removed broadcast_260_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:09:21.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 172.20.0.5:38279 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T21:09:21.683+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO TaskSetManager: Starting task 1.0 in stage 1249.1 (TID 2371) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:21.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO TaskSetManager: Finished task 0.0 in stage 1331.2 (TID 2370) in 92 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:21.685+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO TaskSchedulerImpl: Removed TaskSet 1331.2, whose tasks have all completed, from pool
[2025-05-08T21:09:21.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229) finished in 2.591 s
[2025-05-08T21:09:21.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:21.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1332, ShuffleMapStage 1249, ShuffleMapStage 1333)
[2025-05-08T21:09:21.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:21.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:21.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on 172.20.0.5:38279 (size: 36.3 KiB, free: 434.3 MiB)
[2025-05-08T21:09:21.787+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:39008
[2025-05-08T21:09:23.087+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 2.0 in stage 1249.1 (TID 2372) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.087+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 1.0 in stage 1249.1 (TID 2371) in 1404 ms on 172.20.0.5 (executor 2) (1/41)
[2025-05-08T21:09:23.169+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 3.0 in stage 1249.1 (TID 2373) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.170+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 2.0 in stage 1249.1 (TID 2372) in 83 ms on 172.20.0.5 (executor 2) (2/41)
[2025-05-08T21:09:23.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 6.0 in stage 1249.1 (TID 2374) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 3.0 in stage 1249.1 (TID 2373) in 36 ms on 172.20.0.5 (executor 2) (3/41)
[2025-05-08T21:09:23.257+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 7.0 in stage 1249.1 (TID 2375) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.258+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 6.0 in stage 1249.1 (TID 2374) in 52 ms on 172.20.0.5 (executor 2) (4/41)
[2025-05-08T21:09:23.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 8.0 in stage 1249.1 (TID 2376) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.333+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 7.0 in stage 1249.1 (TID 2375) in 75 ms on 172.20.0.5 (executor 2) (5/41)
[2025-05-08T21:09:23.402+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 9.0 in stage 1249.1 (TID 2377) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.403+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 8.0 in stage 1249.1 (TID 2376) in 70 ms on 172.20.0.5 (executor 2) (6/41)
[2025-05-08T21:09:23.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 10.0 in stage 1249.1 (TID 2378) (172.20.0.5, executor 2, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 9.0 in stage 1249.1 (TID 2377) in 37 ms on 172.20.0.5 (executor 2) (7/41)
[2025-05-08T21:09:23.486+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 11.0 in stage 1249.1 (TID 2379) (172.20.0.5, executor 2, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.486+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 10.0 in stage 1249.1 (TID 2378) in 48 ms on 172.20.0.5 (executor 2) (8/41)
[2025-05-08T21:09:23.499+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:39008
[2025-05-08T21:09:23.516+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO BlockManagerInfo: Removed broadcast_263_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:09:23.518+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO BlockManagerInfo: Removed broadcast_263_piece0 on 172.20.0.5:38279 in memory (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T21:09:23.527+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO BlockManagerInfo: Removed broadcast_264_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:09:23.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO BlockManagerInfo: Removed broadcast_264_piece0 on 172.20.0.5:38279 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T21:09:23.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 12.0 in stage 1249.1 (TID 2380) (172.20.0.5, executor 2, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.663+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 11.0 in stage 1249.1 (TID 2379) in 175 ms on 172.20.0.5 (executor 2) (9/41)
[2025-05-08T21:09:23.764+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 13.0 in stage 1249.1 (TID 2381) (172.20.0.5, executor 2, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 12.0 in stage 1249.1 (TID 2380) in 104 ms on 172.20.0.5 (executor 2) (10/41)
[2025-05-08T21:09:23.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 14.0 in stage 1249.1 (TID 2382) (172.20.0.5, executor 2, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.870+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 13.0 in stage 1249.1 (TID 2381) in 106 ms on 172.20.0.5 (executor 2) (11/41)
[2025-05-08T21:09:23.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Starting task 15.0 in stage 1249.1 (TID 2383) (172.20.0.5, executor 2, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:23.951+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:23 INFO TaskSetManager: Finished task 14.0 in stage 1249.1 (TID 2382) in 82 ms on 172.20.0.5 (executor 2) (12/41)
[2025-05-08T21:09:24.011+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 16.0 in stage 1249.1 (TID 2384) (172.20.0.5, executor 2, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.012+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 15.0 in stage 1249.1 (TID 2383) in 61 ms on 172.20.0.5 (executor 2) (13/41)
[2025-05-08T21:09:24.068+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 17.0 in stage 1249.1 (TID 2385) (172.20.0.5, executor 2, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.068+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 16.0 in stage 1249.1 (TID 2384) in 57 ms on 172.20.0.5 (executor 2) (14/41)
[2025-05-08T21:09:24.137+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 18.0 in stage 1249.1 (TID 2386) (172.20.0.5, executor 2, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.138+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 17.0 in stage 1249.1 (TID 2385) in 69 ms on 172.20.0.5 (executor 2) (15/41)
[2025-05-08T21:09:24.218+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 19.0 in stage 1249.1 (TID 2387) (172.20.0.5, executor 2, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.219+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 18.0 in stage 1249.1 (TID 2386) in 82 ms on 172.20.0.5 (executor 2) (16/41)
[2025-05-08T21:09:24.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 20.0 in stage 1249.1 (TID 2388) (172.20.0.5, executor 2, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.272+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 19.0 in stage 1249.1 (TID 2387) in 53 ms on 172.20.0.5 (executor 2) (17/41)
[2025-05-08T21:09:24.334+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 21.0 in stage 1249.1 (TID 2389) (172.20.0.5, executor 2, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 20.0 in stage 1249.1 (TID 2388) in 63 ms on 172.20.0.5 (executor 2) (18/41)
[2025-05-08T21:09:24.355+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:39008
[2025-05-08T21:09:24.453+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 22.0 in stage 1249.1 (TID 2390) (172.20.0.5, executor 2, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.454+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 21.0 in stage 1249.1 (TID 2389) in 117 ms on 172.20.0.5 (executor 2) (19/41)
[2025-05-08T21:09:24.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 23.0 in stage 1249.1 (TID 2391) (172.20.0.5, executor 2, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.534+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 22.0 in stage 1249.1 (TID 2390) in 83 ms on 172.20.0.5 (executor 2) (20/41)
[2025-05-08T21:09:24.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 24.0 in stage 1249.1 (TID 2392) (172.20.0.5, executor 2, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 23.0 in stage 1249.1 (TID 2391) in 46 ms on 172.20.0.5 (executor 2) (21/41)
[2025-05-08T21:09:24.633+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 25.0 in stage 1249.1 (TID 2393) (172.20.0.5, executor 2, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.634+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 24.0 in stage 1249.1 (TID 2392) in 56 ms on 172.20.0.5 (executor 2) (22/41)
[2025-05-08T21:09:24.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 26.0 in stage 1249.1 (TID 2394) (172.20.0.5, executor 2, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 25.0 in stage 1249.1 (TID 2393) in 39 ms on 172.20.0.5 (executor 2) (23/41)
[2025-05-08T21:09:24.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 27.0 in stage 1249.1 (TID 2395) (172.20.0.5, executor 2, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 26.0 in stage 1249.1 (TID 2394) in 36 ms on 172.20.0.5 (executor 2) (24/41)
[2025-05-08T21:09:24.739+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 28.0 in stage 1249.1 (TID 2396) (172.20.0.5, executor 2, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.739+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 27.0 in stage 1249.1 (TID 2395) in 33 ms on 172.20.0.5 (executor 2) (25/41)
[2025-05-08T21:09:24.783+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 29.0 in stage 1249.1 (TID 2397) (172.20.0.5, executor 2, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.783+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 28.0 in stage 1249.1 (TID 2396) in 42 ms on 172.20.0.5 (executor 2) (26/41)
[2025-05-08T21:09:24.835+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 30.0 in stage 1249.1 (TID 2398) (172.20.0.5, executor 2, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 29.0 in stage 1249.1 (TID 2397) in 55 ms on 172.20.0.5 (executor 2) (27/41)
[2025-05-08T21:09:24.895+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 31.0 in stage 1249.1 (TID 2399) (172.20.0.5, executor 2, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.896+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 30.0 in stage 1249.1 (TID 2398) in 60 ms on 172.20.0.5 (executor 2) (28/41)
[2025-05-08T21:09:24.905+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:39008
[2025-05-08T21:09:24.973+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Starting task 32.0 in stage 1249.1 (TID 2400) (172.20.0.5, executor 2, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:24.974+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:24 INFO TaskSetManager: Finished task 31.0 in stage 1249.1 (TID 2399) in 78 ms on 172.20.0.5 (executor 2) (29/41)
[2025-05-08T21:09:25.027+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 33.0 in stage 1249.1 (TID 2401) (172.20.0.5, executor 2, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.028+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 32.0 in stage 1249.1 (TID 2400) in 56 ms on 172.20.0.5 (executor 2) (30/41)
[2025-05-08T21:09:25.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 34.0 in stage 1249.1 (TID 2402) (172.20.0.5, executor 2, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.081+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 33.0 in stage 1249.1 (TID 2401) in 52 ms on 172.20.0.5 (executor 2) (31/41)
[2025-05-08T21:09:25.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 35.0 in stage 1249.1 (TID 2403) (172.20.0.5, executor 2, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.125+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 34.0 in stage 1249.1 (TID 2402) in 45 ms on 172.20.0.5 (executor 2) (32/41)
[2025-05-08T21:09:25.150+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 36.0 in stage 1249.1 (TID 2404) (172.20.0.5, executor 2, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.150+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 35.0 in stage 1249.1 (TID 2403) in 27 ms on 172.20.0.5 (executor 2) (33/41)
[2025-05-08T21:09:25.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 37.0 in stage 1249.1 (TID 2405) (172.20.0.5, executor 2, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 36.0 in stage 1249.1 (TID 2404) in 24 ms on 172.20.0.5 (executor 2) (34/41)
[2025-05-08T21:09:25.197+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 38.0 in stage 1249.1 (TID 2406) (172.20.0.5, executor 2, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.197+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 37.0 in stage 1249.1 (TID 2405) in 23 ms on 172.20.0.5 (executor 2) (35/41)
[2025-05-08T21:09:25.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 39.0 in stage 1249.1 (TID 2407) (172.20.0.5, executor 2, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 38.0 in stage 1249.1 (TID 2406) in 23 ms on 172.20.0.5 (executor 2) (36/41)
[2025-05-08T21:09:25.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 40.0 in stage 1249.1 (TID 2408) (172.20.0.5, executor 2, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.242+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 39.0 in stage 1249.1 (TID 2407) in 22 ms on 172.20.0.5 (executor 2) (37/41)
[2025-05-08T21:09:25.261+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 0.0 in stage 1249.1 (TID 2409) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.261+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 40.0 in stage 1249.1 (TID 2408) in 20 ms on 172.20.0.5 (executor 2) (38/41)
[2025-05-08T21:09:25.306+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 4.0 in stage 1249.1 (TID 2410) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.307+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 0.0 in stage 1249.1 (TID 2409) in 46 ms on 172.20.0.5 (executor 2) (39/41)
[2025-05-08T21:09:25.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 5.0 in stage 1249.1 (TID 2411) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 4.0 in stage 1249.1 (TID 2410) in 15 ms on 172.20.0.5 (executor 2) (40/41)
[2025-05-08T21:09:25.334+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 0.0 in stage 1332.2 (TID 2412) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 5.0 in stage 1249.1 (TID 2411) in 14 ms on 172.20.0.5 (executor 2) (41/41)
[2025-05-08T21:09:25.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSchedulerImpl: Removed TaskSet 1249.1, whose tasks have all completed, from pool
[2025-05-08T21:09:25.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: ShuffleMapStage 1249 (rdd at GraphFrame.scala:187) finished in 3.739 s
[2025-05-08T21:09:25.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:25.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:09:25.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:25.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:25.336+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: Submitting ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:25.338+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO MemoryStore: Block broadcast_269 stored as values in memory (estimated size 70.3 KiB, free 416.9 MiB)
[2025-05-08T21:09:25.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 416.9 MiB)
[2025-05-08T21:09:25.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Added broadcast_269_piece0 in memory on f2a432e4376a:35283 (size: 28.3 KiB, free: 432.6 MiB)
[2025-05-08T21:09:25.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO SparkContext: Created broadcast 269 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:25.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:25.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSchedulerImpl: Adding task set 1250.1 with 10 tasks resource profile 0
[2025-05-08T21:09:25.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: Submitting ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:25.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on 172.20.0.5:38279 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:09:25.346+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO MemoryStore: Block broadcast_270 stored as values in memory (estimated size 70.6 KiB, free 416.8 MiB)
[2025-05-08T21:09:25.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 28.4 KiB, free 416.8 MiB)
[2025-05-08T21:09:25.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Added broadcast_270_piece0 in memory on f2a432e4376a:35283 (size: 28.4 KiB, free: 432.6 MiB)
[2025-05-08T21:09:25.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO SparkContext: Created broadcast 270 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:25.360+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:25.360+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSchedulerImpl: Adding task set 1251.1 with 10 tasks resource profile 0
[2025-05-08T21:09:25.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 0.0 in stage 1250.1 (TID 2413) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 0.0 in stage 1332.2 (TID 2412) in 81 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:25.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSchedulerImpl: Removed TaskSet 1332.2, whose tasks have all completed, from pool
[2025-05-08T21:09:25.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: ShuffleMapStage 1332 (collect at /opt/airflow/spark/build_graph.py:229) finished in 6.305 s
[2025-05-08T21:09:25.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:25.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1250, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1251, ShuffleMapStage 1333)
[2025-05-08T21:09:25.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:25.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:25.428+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Added broadcast_269_piece0 in memory on 172.20.0.5:38279 (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T21:09:25.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:39008
[2025-05-08T21:09:25.528+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 1.0 in stage 1250.1 (TID 2414) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.529+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 0.0 in stage 1250.1 (TID 2413) in 113 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:25.560+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 2.0 in stage 1250.1 (TID 2415) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.561+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 1.0 in stage 1250.1 (TID 2414) in 32 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:25.585+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 3.0 in stage 1250.1 (TID 2416) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.586+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 2.0 in stage 1250.1 (TID 2415) in 25 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:25.610+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 4.0 in stage 1250.1 (TID 2417) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.610+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 3.0 in stage 1250.1 (TID 2416) in 25 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:25.631+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 5.0 in stage 1250.1 (TID 2418) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.631+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 4.0 in stage 1250.1 (TID 2417) in 21 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:25.652+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 6.0 in stage 1250.1 (TID 2419) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.652+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 5.0 in stage 1250.1 (TID 2418) in 22 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:25.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 7.0 in stage 1250.1 (TID 2420) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 6.0 in stage 1250.1 (TID 2419) in 20 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:25.796+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 8.0 in stage 1250.1 (TID 2421) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.797+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 7.0 in stage 1250.1 (TID 2420) in 125 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:25.797+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Removed broadcast_265_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:25.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Removed broadcast_265_piece0 on 172.20.0.5:38279 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:09:25.803+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Removed broadcast_268_piece0 on f2a432e4376a:35283 in memory (size: 36.3 KiB, free: 432.6 MiB)
[2025-05-08T21:09:25.804+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Removed broadcast_268_piece0 on 172.20.0.5:38279 in memory (size: 36.3 KiB, free: 434.4 MiB)
[2025-05-08T21:09:25.818+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 9.0 in stage 1250.1 (TID 2422) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.818+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 8.0 in stage 1250.1 (TID 2421) in 21 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:25.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 0.0 in stage 1251.1 (TID 2423) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 9.0 in stage 1250.1 (TID 2422) in 21 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:25.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSchedulerImpl: Removed TaskSet 1250.1, whose tasks have all completed, from pool
[2025-05-08T21:09:25.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: ShuffleMapStage 1250 (rdd at GraphFrame.scala:187) finished in 0.503 s
[2025-05-08T21:09:25.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:25.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1251, ShuffleMapStage 1333)
[2025-05-08T21:09:25.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:25.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:25.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO BlockManagerInfo: Added broadcast_270_piece0 in memory on 172.20.0.5:38279 (size: 28.4 KiB, free: 434.3 MiB)
[2025-05-08T21:09:25.898+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 1.0 in stage 1251.1 (TID 2424) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.898+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 0.0 in stage 1251.1 (TID 2423) in 60 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:25.923+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 2.0 in stage 1251.1 (TID 2425) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.924+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 1.0 in stage 1251.1 (TID 2424) in 25 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:25.940+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 3.0 in stage 1251.1 (TID 2426) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 2.0 in stage 1251.1 (TID 2425) in 17 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:25.961+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 4.0 in stage 1251.1 (TID 2427) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.961+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 3.0 in stage 1251.1 (TID 2426) in 20 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:25.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Starting task 5.0 in stage 1251.1 (TID 2428) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:25.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:25 INFO TaskSetManager: Finished task 4.0 in stage 1251.1 (TID 2427) in 23 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:26.002+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 6.0 in stage 1251.1 (TID 2429) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 5.0 in stage 1251.1 (TID 2428) in 20 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:26.019+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 7.0 in stage 1251.1 (TID 2430) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.019+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 6.0 in stage 1251.1 (TID 2429) in 17 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:26.043+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 8.0 in stage 1251.1 (TID 2431) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.044+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 7.0 in stage 1251.1 (TID 2430) in 24 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:26.065+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 9.0 in stage 1251.1 (TID 2432) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.065+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 8.0 in stage 1251.1 (TID 2431) in 22 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:26.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 0.0 in stage 1333.2 (TID 2433) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 9.0 in stage 1251.1 (TID 2432) in 14 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:26.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Removed TaskSet 1251.1, whose tasks have all completed, from pool
[2025-05-08T21:09:26.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: ShuffleMapStage 1251 (rdd at GraphFrame.scala:187) finished in 0.736 s
[2025-05-08T21:09:26.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:26.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1333)
[2025-05-08T21:09:26.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:26.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:26.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:26.083+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_271 stored as values in memory (estimated size 83.7 KiB, free 416.9 MiB)
[2025-05-08T21:09:26.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on 172.20.0.5:38279 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:09:26.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 416.8 MiB)
[2025-05-08T21:09:26.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_271_piece0 in memory on f2a432e4376a:35283 (size: 32.1 KiB, free: 432.6 MiB)
[2025-05-08T21:09:26.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO SparkContext: Created broadcast 271 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:26.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting 20 missing tasks from ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:09:26.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Adding task set 1252.1 with 20 tasks resource profile 0
[2025-05-08T21:09:26.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 0.0 in stage 1252.1 (TID 2434) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 0.0 in stage 1333.2 (TID 2433) in 44 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:26.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Removed TaskSet 1333.2, whose tasks have all completed, from pool
[2025-05-08T21:09:26.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: ShuffleMapStage 1333 (collect at /opt/airflow/spark/build_graph.py:229) finished in 7.006 s
[2025-05-08T21:09:26.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:26.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1252)
[2025-05-08T21:09:26.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:26.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:26.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_271_piece0 in memory on 172.20.0.5:38279 (size: 32.1 KiB, free: 434.3 MiB)
[2025-05-08T21:09:26.135+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:39008
[2025-05-08T21:09:26.167+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 1.0 in stage 1252.1 (TID 2435) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.168+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 0.0 in stage 1252.1 (TID 2434) in 44 ms on 172.20.0.5 (executor 2) (1/20)
[2025-05-08T21:09:26.183+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 2.0 in stage 1252.1 (TID 2436) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.183+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 1.0 in stage 1252.1 (TID 2435) in 16 ms on 172.20.0.5 (executor 2) (2/20)
[2025-05-08T21:09:26.195+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 3.0 in stage 1252.1 (TID 2437) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.196+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 2.0 in stage 1252.1 (TID 2436) in 12 ms on 172.20.0.5 (executor 2) (3/20)
[2025-05-08T21:09:26.207+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 4.0 in stage 1252.1 (TID 2438) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.207+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 3.0 in stage 1252.1 (TID 2437) in 12 ms on 172.20.0.5 (executor 2) (4/20)
[2025-05-08T21:09:26.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 5.0 in stage 1252.1 (TID 2439) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 4.0 in stage 1252.1 (TID 2438) in 17 ms on 172.20.0.5 (executor 2) (5/20)
[2025-05-08T21:09:26.240+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 6.0 in stage 1252.1 (TID 2440) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 5.0 in stage 1252.1 (TID 2439) in 17 ms on 172.20.0.5 (executor 2) (6/20)
[2025-05-08T21:09:26.255+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 7.0 in stage 1252.1 (TID 2441) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.256+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 6.0 in stage 1252.1 (TID 2440) in 16 ms on 172.20.0.5 (executor 2) (7/20)
[2025-05-08T21:09:26.272+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 8.0 in stage 1252.1 (TID 2442) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.272+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 7.0 in stage 1252.1 (TID 2441) in 17 ms on 172.20.0.5 (executor 2) (8/20)
[2025-05-08T21:09:26.287+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 9.0 in stage 1252.1 (TID 2443) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.287+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 8.0 in stage 1252.1 (TID 2442) in 16 ms on 172.20.0.5 (executor 2) (9/20)
[2025-05-08T21:09:26.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 10.0 in stage 1252.1 (TID 2444) (172.20.0.5, executor 2, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 9.0 in stage 1252.1 (TID 2443) in 17 ms on 172.20.0.5 (executor 2) (10/20)
[2025-05-08T21:09:26.310+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:39008
[2025-05-08T21:09:26.331+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 11.0 in stage 1252.1 (TID 2445) (172.20.0.5, executor 2, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.331+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 10.0 in stage 1252.1 (TID 2444) in 29 ms on 172.20.0.5 (executor 2) (11/20)
[2025-05-08T21:09:26.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 12.0 in stage 1252.1 (TID 2446) (172.20.0.5, executor 2, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 11.0 in stage 1252.1 (TID 2445) in 14 ms on 172.20.0.5 (executor 2) (12/20)
[2025-05-08T21:09:26.353+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 13.0 in stage 1252.1 (TID 2447) (172.20.0.5, executor 2, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.354+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 12.0 in stage 1252.1 (TID 2446) in 10 ms on 172.20.0.5 (executor 2) (13/20)
[2025-05-08T21:09:26.366+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 14.0 in stage 1252.1 (TID 2448) (172.20.0.5, executor 2, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.366+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 13.0 in stage 1252.1 (TID 2447) in 13 ms on 172.20.0.5 (executor 2) (14/20)
[2025-05-08T21:09:26.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 15.0 in stage 1252.1 (TID 2449) (172.20.0.5, executor 2, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.375+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 14.0 in stage 1252.1 (TID 2448) in 9 ms on 172.20.0.5 (executor 2) (15/20)
[2025-05-08T21:09:26.386+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 16.0 in stage 1252.1 (TID 2450) (172.20.0.5, executor 2, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.386+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 15.0 in stage 1252.1 (TID 2449) in 12 ms on 172.20.0.5 (executor 2) (16/20)
[2025-05-08T21:09:26.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 17.0 in stage 1252.1 (TID 2451) (172.20.0.5, executor 2, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 16.0 in stage 1252.1 (TID 2450) in 14 ms on 172.20.0.5 (executor 2) (17/20)
[2025-05-08T21:09:26.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 18.0 in stage 1252.1 (TID 2452) (172.20.0.5, executor 2, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 17.0 in stage 1252.1 (TID 2451) in 16 ms on 172.20.0.5 (executor 2) (18/20)
[2025-05-08T21:09:26.428+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 19.0 in stage 1252.1 (TID 2453) (172.20.0.5, executor 2, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.429+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 18.0 in stage 1252.1 (TID 2452) in 14 ms on 172.20.0.5 (executor 2) (19/20)
[2025-05-08T21:09:26.438+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 0.0 in stage 1334.2 (TID 2454) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.438+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 19.0 in stage 1252.1 (TID 2453) in 10 ms on 172.20.0.5 (executor 2) (20/20)
[2025-05-08T21:09:26.438+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Removed TaskSet 1252.1, whose tasks have all completed, from pool
[2025-05-08T21:09:26.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: ShuffleMapStage 1252 (rdd at GraphFrame.scala:187) finished in 0.358 s
[2025-05-08T21:09:26.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:26.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342)
[2025-05-08T21:09:26.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:26.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:26.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:09:26.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on 172.20.0.5:38279 (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T21:09:26.473+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_272 stored as values in memory (estimated size 189.5 KiB, free 416.6 MiB)
[2025-05-08T21:09:26.474+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_272_piece0 stored as bytes in memory (estimated size 64.9 KiB, free 416.6 MiB)
[2025-05-08T21:09:26.474+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_272_piece0 in memory on f2a432e4376a:35283 (size: 64.9 KiB, free: 432.5 MiB)
[2025-05-08T21:09:26.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO SparkContext: Created broadcast 272 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:26.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:26.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Adding task set 1254.1 with 10 tasks resource profile 0
[2025-05-08T21:09:26.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-08T21:09:26.492+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_273 stored as values in memory (estimated size 232.9 KiB, free 416.4 MiB)
[2025-05-08T21:09:26.506+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_273_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 416.3 MiB)
[2025-05-08T21:09:26.509+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_273_piece0 in memory on f2a432e4376a:35283 (size: 77.4 KiB, free: 432.5 MiB)
[2025-05-08T21:09:26.511+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO SparkContext: Created broadcast 273 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:26.511+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:26.511+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Adding task set 1255.1 with 10 tasks resource profile 0
[2025-05-08T21:09:26.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:26.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Starting task 0.0 in stage 1254.1 (TID 2455) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:26.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSetManager: Finished task 0.0 in stage 1334.2 (TID 2454) in 75 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-08T21:09:26.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Removed TaskSet 1334.2, whose tasks have all completed, from pool
[2025-05-08T21:09:26.520+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_272_piece0 in memory on 172.20.0.5:38279 (size: 64.9 KiB, free: 434.2 MiB)
[2025-05-08T21:09:26.529+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_274 stored as values in memory (estimated size 235.8 KiB, free 416.0 MiB)
[2025-05-08T21:09:26.531+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_274_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 416.0 MiB)
[2025-05-08T21:09:26.531+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_274_piece0 in memory on f2a432e4376a:35283 (size: 77.8 KiB, free: 432.4 MiB)
[2025-05-08T21:09:26.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO SparkContext: Created broadcast 274 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:26.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:26.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Adding task set 1287.1 with 10 tasks resource profile 0
[2025-05-08T21:09:26.534+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: ShuffleMapStage 1334 (collect at /opt/airflow/spark/build_graph.py:229) finished in 7.410 s
[2025-05-08T21:09:26.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:26.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1254, ShuffleMapStage 1338, ShuffleMapStage 1287, ShuffleMapStage 1255, ResultStage 1342)
[2025-05-08T21:09:26.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:26.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:26.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:09:26.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1336.
[2025-05-08T21:09:26.537+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_275 stored as values in memory (estimated size 109.8 KiB, free 415.9 MiB)
[2025-05-08T21:09:26.538+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MemoryStore: Block broadcast_275_piece0 stored as bytes in memory (estimated size 40.1 KiB, free 415.8 MiB)
[2025-05-08T21:09:26.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added broadcast_275_piece0 in memory on f2a432e4376a:35283 (size: 40.1 KiB, free: 432.3 MiB)
[2025-05-08T21:09:26.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO SparkContext: Created broadcast 275 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:26.540+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:09:26.540+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO TaskSchedulerImpl: Adding task set 1336.1 with 41 tasks resource profile 0
[2025-05-08T21:09:26.635+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_266_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.4 MiB)
[2025-05-08T21:09:26.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_266_piece0 on 172.20.0.5:38279 in memory (size: 11.0 KiB, free: 434.2 MiB)
[2025-05-08T21:09:26.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_269_piece0 on f2a432e4376a:35283 in memory (size: 28.3 KiB, free: 432.4 MiB)
[2025-05-08T21:09:26.660+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_269_piece0 on 172.20.0.5:38279 in memory (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T21:09:26.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_270_piece0 on f2a432e4376a:35283 in memory (size: 28.4 KiB, free: 432.4 MiB)
[2025-05-08T21:09:26.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_270_piece0 on 172.20.0.5:38279 in memory (size: 28.4 KiB, free: 434.3 MiB)
[2025-05-08T21:09:26.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:39008
[2025-05-08T21:09:26.842+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_271_piece0 on f2a432e4376a:35283 in memory (size: 32.1 KiB, free: 432.4 MiB)
[2025-05-08T21:09:26.844+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_271_piece0 on 172.20.0.5:38279 in memory (size: 32.1 KiB, free: 434.3 MiB)
[2025-05-08T21:09:26.969+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_267_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.5 MiB)
[2025-05-08T21:09:26.973+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Removed broadcast_267_piece0 on 172.20.0.5:38279 in memory (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T21:09:26.979+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:26 INFO BlockManagerInfo: Added rdd_169_0 in memory on 172.20.0.5:38279 (size: 8.5 KiB, free: 434.3 MiB)
[2025-05-08T21:09:27.049+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:38279 (size: 94.3 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 1.0 in stage 1254.1 (TID 2456) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 0.0 in stage 1254.1 (TID 2455) in 666 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:27.210+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_1 in memory on 172.20.0.5:38279 (size: 8.0 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 2.0 in stage 1254.1 (TID 2457) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.225+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 1.0 in stage 1254.1 (TID 2456) in 48 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:27.254+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_2 in memory on 172.20.0.5:38279 (size: 7.5 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.270+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 3.0 in stage 1254.1 (TID 2458) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 2.0 in stage 1254.1 (TID 2457) in 47 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:27.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_3 in memory on 172.20.0.5:38279 (size: 8.1 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.311+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 4.0 in stage 1254.1 (TID 2459) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.311+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 3.0 in stage 1254.1 (TID 2458) in 41 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:27.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_4 in memory on 172.20.0.5:38279 (size: 7.7 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 5.0 in stage 1254.1 (TID 2460) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 4.0 in stage 1254.1 (TID 2459) in 37 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:27.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_5 in memory on 172.20.0.5:38279 (size: 7.0 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 6.0 in stage 1254.1 (TID 2461) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 5.0 in stage 1254.1 (TID 2460) in 41 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:27.407+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_6 in memory on 172.20.0.5:38279 (size: 7.3 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 7.0 in stage 1254.1 (TID 2462) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 6.0 in stage 1254.1 (TID 2461) in 32 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:27.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_7 in memory on 172.20.0.5:38279 (size: 8.1 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.458+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 8.0 in stage 1254.1 (TID 2463) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.458+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 7.0 in stage 1254.1 (TID 2462) in 39 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:27.485+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_8 in memory on 172.20.0.5:38279 (size: 7.6 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 9.0 in stage 1254.1 (TID 2464) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.496+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 8.0 in stage 1254.1 (TID 2463) in 38 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:27.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added rdd_169_9 in memory on 172.20.0.5:38279 (size: 8.2 KiB, free: 434.2 MiB)
[2025-05-08T21:09:27.522+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Starting task 0.0 in stage 1255.1 (TID 2465) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:27.523+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSetManager: Finished task 9.0 in stage 1254.1 (TID 2464) in 28 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:27.523+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO TaskSchedulerImpl: Removed TaskSet 1254.1, whose tasks have all completed, from pool
[2025-05-08T21:09:27.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO DAGScheduler: ShuffleMapStage 1254 (map at GraphFrame.scala:187) finished in 1.084 s
[2025-05-08T21:09:27.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:27.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1255, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:27.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:27.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:27.533+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added broadcast_273_piece0 in memory on 172.20.0.5:38279 (size: 77.4 KiB, free: 434.1 MiB)
[2025-05-08T21:09:27.584+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:38279 (size: 80.3 KiB, free: 434.0 MiB)
[2025-05-08T21:09:27.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:27 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:38279 (size: 764.6 KiB, free: 433.3 MiB)
[2025-05-08T21:09:28.020+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 1.0 in stage 1255.1 (TID 2466) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.021+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 0.0 in stage 1255.1 (TID 2465) in 499 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:28.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 2.0 in stage 1255.1 (TID 2467) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 1.0 in stage 1255.1 (TID 2466) in 65 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:28.156+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 3.0 in stage 1255.1 (TID 2468) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.156+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 2.0 in stage 1255.1 (TID 2467) in 72 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:28.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 4.0 in stage 1255.1 (TID 2469) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.228+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 3.0 in stage 1255.1 (TID 2468) in 71 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:28.289+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 5.0 in stage 1255.1 (TID 2470) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.290+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 4.0 in stage 1255.1 (TID 2469) in 64 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:28.340+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 6.0 in stage 1255.1 (TID 2471) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 5.0 in stage 1255.1 (TID 2470) in 52 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:28.380+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 7.0 in stage 1255.1 (TID 2472) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 6.0 in stage 1255.1 (TID 2471) in 41 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:28.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 8.0 in stage 1255.1 (TID 2473) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.431+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 7.0 in stage 1255.1 (TID 2472) in 51 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:28.488+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 9.0 in stage 1255.1 (TID 2474) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 8.0 in stage 1255.1 (TID 2473) in 59 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:28.545+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 0.0 in stage 1287.1 (TID 2475) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 9.0 in stage 1255.1 (TID 2474) in 58 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:28.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSchedulerImpl: Removed TaskSet 1255.1, whose tasks have all completed, from pool
[2025-05-08T21:09:28.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO DAGScheduler: ShuffleMapStage 1255 (mapPartitions at VertexRDD.scala:356) finished in 2.072 s
[2025-05-08T21:09:28.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:28.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1287, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:28.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:28.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:28.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added broadcast_274_piece0 in memory on 172.20.0.5:38279 (size: 77.8 KiB, free: 433.2 MiB)
[2025-05-08T21:09:28.620+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_395_0 in memory on 172.20.0.5:38279 (size: 560.1 KiB, free: 432.6 MiB)
[2025-05-08T21:09:28.632+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.20.0.5:38279 (size: 560.1 KiB, free: 432.1 MiB)
[2025-05-08T21:09:28.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 1.0 in stage 1287.1 (TID 2476) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 0.0 in stage 1287.1 (TID 2475) in 128 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:28.703+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_395_1 in memory on 172.20.0.5:38279 (size: 558.2 KiB, free: 431.6 MiB)
[2025-05-08T21:09:28.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.20.0.5:38279 (size: 558.2 KiB, free: 431.0 MiB)
[2025-05-08T21:09:28.730+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 2.0 in stage 1287.1 (TID 2477) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 1.0 in stage 1287.1 (TID 2476) in 58 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:28.764+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_395_2 in memory on 172.20.0.5:38279 (size: 663.8 KiB, free: 430.4 MiB)
[2025-05-08T21:09:28.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.20.0.5:38279 (size: 663.8 KiB, free: 429.7 MiB)
[2025-05-08T21:09:28.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 3.0 in stage 1287.1 (TID 2478) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.811+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 2.0 in stage 1287.1 (TID 2477) in 81 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:28.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_395_3 in memory on 172.20.0.5:38279 (size: 695.0 KiB, free: 429.0 MiB)
[2025-05-08T21:09:28.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.20.0.5:38279 (size: 695.0 KiB, free: 428.4 MiB)
[2025-05-08T21:09:28.861+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 4.0 in stage 1287.1 (TID 2479) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.861+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 3.0 in stage 1287.1 (TID 2478) in 51 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:28.883+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_395_4 in memory on 172.20.0.5:38279 (size: 451.0 KiB, free: 427.9 MiB)
[2025-05-08T21:09:28.889+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.20.0.5:38279 (size: 451.0 KiB, free: 427.5 MiB)
[2025-05-08T21:09:28.914+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 5.0 in stage 1287.1 (TID 2480) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.915+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 4.0 in stage 1287.1 (TID 2479) in 55 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:28.946+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_395_5 in memory on 172.20.0.5:38279 (size: 654.0 KiB, free: 426.8 MiB)
[2025-05-08T21:09:28.952+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.20.0.5:38279 (size: 654.0 KiB, free: 426.2 MiB)
[2025-05-08T21:09:28.972+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Starting task 6.0 in stage 1287.1 (TID 2481) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:28.973+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:28 INFO TaskSetManager: Finished task 5.0 in stage 1287.1 (TID 2480) in 59 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:29.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_395_6 in memory on 172.20.0.5:38279 (size: 548.2 KiB, free: 425.7 MiB)
[2025-05-08T21:09:29.010+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.20.0.5:38279 (size: 548.2 KiB, free: 425.1 MiB)
[2025-05-08T21:09:29.026+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 7.0 in stage 1287.1 (TID 2482) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.027+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 6.0 in stage 1287.1 (TID 2481) in 54 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:29.048+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_395_7 in memory on 172.20.0.5:38279 (size: 557.0 KiB, free: 424.6 MiB)
[2025-05-08T21:09:29.052+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.20.0.5:38279 (size: 557.0 KiB, free: 424.0 MiB)
[2025-05-08T21:09:29.070+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 8.0 in stage 1287.1 (TID 2483) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.070+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 7.0 in stage 1287.1 (TID 2482) in 44 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:29.089+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_395_8 in memory on 172.20.0.5:38279 (size: 485.3 KiB, free: 423.6 MiB)
[2025-05-08T21:09:29.091+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.20.0.5:38279 (size: 485.3 KiB, free: 423.1 MiB)
[2025-05-08T21:09:29.107+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 9.0 in stage 1287.1 (TID 2484) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.108+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 8.0 in stage 1287.1 (TID 2483) in 39 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:29.136+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_395_9 in memory on 172.20.0.5:38279 (size: 694.0 KiB, free: 422.4 MiB)
[2025-05-08T21:09:29.138+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.20.0.5:38279 (size: 694.0 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.156+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 1.0 in stage 1336.1 (TID 2485) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.156+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 9.0 in stage 1287.1 (TID 2484) in 49 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:29.157+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSchedulerImpl: Removed TaskSet 1287.1, whose tasks have all completed, from pool
[2025-05-08T21:09:29.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: ShuffleMapStage 1287 (mapPartitions at GraphImpl.scala:208) finished in 2.647 s
[2025-05-08T21:09:29.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:29.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:29.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:29.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:29.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: Submitting ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:29.164+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added broadcast_275_piece0 in memory on 172.20.0.5:38279 (size: 40.1 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.170+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MemoryStore: Block broadcast_276 stored as values in memory (estimated size 10.7 KiB, free 416.2 MiB)
[2025-05-08T21:09:29.170+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:29.185+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MemoryStore: Block broadcast_276_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 416.2 MiB)
[2025-05-08T21:09:29.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added broadcast_276_piece0 in memory on f2a432e4376a:35283 (size: 5.3 KiB, free: 432.4 MiB)
[2025-05-08T21:09:29.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO SparkContext: Created broadcast 276 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:29.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:29.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSchedulerImpl: Adding task set 1288.1 with 10 tasks resource profile 0
[2025-05-08T21:09:29.188+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_273_piece0 on f2a432e4376a:35283 in memory (size: 77.4 KiB, free: 432.5 MiB)
[2025-05-08T21:09:29.189+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: Submitting ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:29.190+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MemoryStore: Block broadcast_277 stored as values in memory (estimated size 10.1 KiB, free 416.5 MiB)
[2025-05-08T21:09:29.190+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_273_piece0 on 172.20.0.5:38279 in memory (size: 77.4 KiB, free: 421.8 MiB)
[2025-05-08T21:09:29.191+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MemoryStore: Block broadcast_277_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 416.5 MiB)
[2025-05-08T21:09:29.191+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added broadcast_277_piece0 in memory on f2a432e4376a:35283 (size: 5.0 KiB, free: 432.5 MiB)
[2025-05-08T21:09:29.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO SparkContext: Created broadcast 277 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:29.194+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:29.196+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSchedulerImpl: Adding task set 1289.1 with 10 tasks resource profile 0
[2025-05-08T21:09:29.201+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_272_piece0 on f2a432e4376a:35283 in memory (size: 64.9 KiB, free: 432.6 MiB)
[2025-05-08T21:09:29.203+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_272_piece0 on 172.20.0.5:38279 in memory (size: 64.9 KiB, free: 421.8 MiB)
[2025-05-08T21:09:29.251+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 0.0 in stage 1288.1 (TID 2486) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.251+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 1.0 in stage 1336.1 (TID 2485) in 94 ms on 172.20.0.5 (executor 2) (1/41)
[2025-05-08T21:09:29.262+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added broadcast_276_piece0 in memory on 172.20.0.5:38279 (size: 5.3 KiB, free: 421.8 MiB)
[2025-05-08T21:09:29.270+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:39008
[2025-05-08T21:09:29.276+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:39008
[2025-05-08T21:09:29.316+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_0 in memory on 172.20.0.5:38279 (size: 36.3 KiB, free: 421.8 MiB)
[2025-05-08T21:09:29.321+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_0 in memory on 172.20.0.5:38279 (size: 11.2 KiB, free: 421.8 MiB)
[2025-05-08T21:09:29.323+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:39008
[2025-05-08T21:09:29.333+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_0 in memory on 172.20.0.5:38279 (size: 11.2 KiB, free: 421.8 MiB)
[2025-05-08T21:09:29.351+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 1.0 in stage 1288.1 (TID 2487) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.352+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 0.0 in stage 1288.1 (TID 2486) in 101 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:29.375+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_1 in memory on 172.20.0.5:38279 (size: 36.7 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.378+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_1 in memory on 172.20.0.5:38279 (size: 12.1 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_1 in memory on 172.20.0.5:38279 (size: 12.1 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.386+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 2.0 in stage 1288.1 (TID 2488) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.387+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 1.0 in stage 1288.1 (TID 2487) in 35 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:29.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_2 in memory on 172.20.0.5:38279 (size: 34.2 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.402+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_2 in memory on 172.20.0.5:38279 (size: 10.9 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.407+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_2 in memory on 172.20.0.5:38279 (size: 10.9 KiB, free: 421.7 MiB)
[2025-05-08T21:09:29.412+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 3.0 in stage 1288.1 (TID 2489) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 2.0 in stage 1288.1 (TID 2488) in 26 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:29.425+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_3 in memory on 172.20.0.5:38279 (size: 34.5 KiB, free: 421.6 MiB)
[2025-05-08T21:09:29.427+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_3 in memory on 172.20.0.5:38279 (size: 10.9 KiB, free: 421.6 MiB)
[2025-05-08T21:09:29.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_3 in memory on 172.20.0.5:38279 (size: 10.9 KiB, free: 421.6 MiB)
[2025-05-08T21:09:29.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 4.0 in stage 1288.1 (TID 2490) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 3.0 in stage 1288.1 (TID 2489) in 25 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:29.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_4 in memory on 172.20.0.5:38279 (size: 33.4 KiB, free: 421.6 MiB)
[2025-05-08T21:09:29.457+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_4 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 421.6 MiB)
[2025-05-08T21:09:29.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_4 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 421.5 MiB)
[2025-05-08T21:09:29.468+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 5.0 in stage 1288.1 (TID 2491) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.469+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 4.0 in stage 1288.1 (TID 2490) in 32 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:29.485+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_5 in memory on 172.20.0.5:38279 (size: 34.7 KiB, free: 421.5 MiB)
[2025-05-08T21:09:29.487+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_5 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 421.5 MiB)
[2025-05-08T21:09:29.492+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_5 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 421.5 MiB)
[2025-05-08T21:09:29.497+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 6.0 in stage 1288.1 (TID 2492) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.497+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 5.0 in stage 1288.1 (TID 2491) in 29 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:29.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_6 in memory on 172.20.0.5:38279 (size: 34.8 KiB, free: 421.5 MiB)
[2025-05-08T21:09:29.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_6 in memory on 172.20.0.5:38279 (size: 11.4 KiB, free: 421.4 MiB)
[2025-05-08T21:09:29.518+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_6 in memory on 172.20.0.5:38279 (size: 11.4 KiB, free: 421.4 MiB)
[2025-05-08T21:09:29.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 7.0 in stage 1288.1 (TID 2493) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 6.0 in stage 1288.1 (TID 2492) in 28 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:29.541+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_7 in memory on 172.20.0.5:38279 (size: 35.5 KiB, free: 421.4 MiB)
[2025-05-08T21:09:29.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_7 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 421.4 MiB)
[2025-05-08T21:09:29.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_7 in memory on 172.20.0.5:38279 (size: 11.6 KiB, free: 421.4 MiB)
[2025-05-08T21:09:29.552+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 8.0 in stage 1288.1 (TID 2494) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.552+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 7.0 in stage 1288.1 (TID 2493) in 29 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:29.569+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_8 in memory on 172.20.0.5:38279 (size: 36.5 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_8 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_8 in memory on 172.20.0.5:38279 (size: 11.7 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 9.0 in stage 1288.1 (TID 2495) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 8.0 in stage 1288.1 (TID 2494) in 29 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:29.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_392_9 in memory on 172.20.0.5:38279 (size: 35.4 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_397_9 in memory on 172.20.0.5:38279 (size: 11.3 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.598+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_600_9 in memory on 172.20.0.5:38279 (size: 11.2 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 0.0 in stage 1289.1 (TID 2496) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 9.0 in stage 1288.1 (TID 2495) in 22 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:29.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSchedulerImpl: Removed TaskSet 1288.1, whose tasks have all completed, from pool
[2025-05-08T21:09:29.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: ShuffleMapStage 1288 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.440 s
[2025-05-08T21:09:29.603+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:29.603+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:29.603+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:29.603+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:29.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added broadcast_277_piece0 in memory on 172.20.0.5:38279 (size: 5.0 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.619+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 1.0 in stage 1289.1 (TID 2497) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.619+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 0.0 in stage 1289.1 (TID 2496) in 17 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:29.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 2.0 in stage 1289.1 (TID 2498) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 1.0 in stage 1289.1 (TID 2497) in 10 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:29.634+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 3.0 in stage 1289.1 (TID 2499) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.635+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 2.0 in stage 1289.1 (TID 2498) in 7 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:29.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 4.0 in stage 1289.1 (TID 2500) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 3.0 in stage 1289.1 (TID 2499) in 9 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:29.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 5.0 in stage 1289.1 (TID 2501) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 4.0 in stage 1289.1 (TID 2500) in 9 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:29.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 6.0 in stage 1289.1 (TID 2502) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 5.0 in stage 1289.1 (TID 2501) in 10 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:29.669+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 7.0 in stage 1289.1 (TID 2503) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 6.0 in stage 1289.1 (TID 2502) in 8 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:29.679+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 8.0 in stage 1289.1 (TID 2504) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.680+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 7.0 in stage 1289.1 (TID 2503) in 10 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:29.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 9.0 in stage 1289.1 (TID 2505) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 8.0 in stage 1289.1 (TID 2504) in 9 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:29.698+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 2.0 in stage 1336.1 (TID 2506) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 9.0 in stage 1289.1 (TID 2505) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:29.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSchedulerImpl: Removed TaskSet 1289.1, whose tasks have all completed, from pool
[2025-05-08T21:09:29.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: ShuffleMapStage 1289 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.509 s
[2025-05-08T21:09:29.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:29.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:29.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:29.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:29.700+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: Submitting ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:29.705+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:29.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MemoryStore: Block broadcast_278 stored as values in memory (estimated size 238.4 KiB, free 416.5 MiB)
[2025-05-08T21:09:29.733+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MemoryStore: Block broadcast_278_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 416.4 MiB)
[2025-05-08T21:09:29.734+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added broadcast_278_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.5 MiB)
[2025-05-08T21:09:29.734+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO SparkContext: Created broadcast 278 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:29.734+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 3.0 in stage 1336.1 (TID 2507) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.734+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:29.734+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSchedulerImpl: Adding task set 1290.1 with 10 tasks resource profile 0
[2025-05-08T21:09:29.737+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_276_piece0 on f2a432e4376a:35283 in memory (size: 5.3 KiB, free: 432.5 MiB)
[2025-05-08T21:09:29.737+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 2.0 in stage 1336.1 (TID 2506) in 38 ms on 172.20.0.5 (executor 2) (2/41)
[2025-05-08T21:09:29.756+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_276_piece0 on 172.20.0.5:38279 in memory (size: 5.3 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.758+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 0.0 in stage 1290.1 (TID 2508) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.759+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 3.0 in stage 1336.1 (TID 2507) in 25 ms on 172.20.0.5 (executor 2) (3/41)
[2025-05-08T21:09:29.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_274_piece0 on f2a432e4376a:35283 in memory (size: 77.8 KiB, free: 432.6 MiB)
[2025-05-08T21:09:29.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Removed broadcast_274_piece0 on 172.20.0.5:38279 in memory (size: 77.8 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.777+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added broadcast_278_piece0 in memory on 172.20.0.5:38279 (size: 78.8 KiB, free: 421.3 MiB)
[2025-05-08T21:09:29.798+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_602_0 in memory on 172.20.0.5:38279 (size: 50.5 KiB, free: 421.2 MiB)
[2025-05-08T21:09:29.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:29.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:29.841+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 1.0 in stage 1290.1 (TID 2509) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 0.0 in stage 1290.1 (TID 2508) in 85 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:29.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_602_1 in memory on 172.20.0.5:38279 (size: 51.2 KiB, free: 421.2 MiB)
[2025-05-08T21:09:29.905+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 2.0 in stage 1290.1 (TID 2510) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.906+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 1.0 in stage 1290.1 (TID 2509) in 66 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:29.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_602_2 in memory on 172.20.0.5:38279 (size: 54.2 KiB, free: 421.1 MiB)
[2025-05-08T21:09:29.970+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Starting task 3.0 in stage 1290.1 (TID 2511) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:29.971+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO TaskSetManager: Finished task 2.0 in stage 1290.1 (TID 2510) in 67 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:29.990+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:29 INFO BlockManagerInfo: Added rdd_602_3 in memory on 172.20.0.5:38279 (size: 55.4 KiB, free: 421.1 MiB)
[2025-05-08T21:09:30.019+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 4.0 in stage 1290.1 (TID 2512) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.019+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 3.0 in stage 1290.1 (TID 2511) in 49 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:30.032+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added rdd_602_4 in memory on 172.20.0.5:38279 (size: 46.8 KiB, free: 421.0 MiB)
[2025-05-08T21:09:30.052+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 5.0 in stage 1290.1 (TID 2513) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.052+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 4.0 in stage 1290.1 (TID 2512) in 34 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:30.064+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added rdd_602_5 in memory on 172.20.0.5:38279 (size: 53.5 KiB, free: 421.0 MiB)
[2025-05-08T21:09:30.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 6.0 in stage 1290.1 (TID 2514) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 5.0 in stage 1290.1 (TID 2513) in 32 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:30.097+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added rdd_602_6 in memory on 172.20.0.5:38279 (size: 50.7 KiB, free: 420.9 MiB)
[2025-05-08T21:09:30.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 7.0 in stage 1290.1 (TID 2515) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.115+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 6.0 in stage 1290.1 (TID 2514) in 31 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:30.126+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added rdd_602_7 in memory on 172.20.0.5:38279 (size: 50.4 KiB, free: 420.9 MiB)
[2025-05-08T21:09:30.151+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 8.0 in stage 1290.1 (TID 2516) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.151+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 7.0 in stage 1290.1 (TID 2515) in 37 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:30.166+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added rdd_602_8 in memory on 172.20.0.5:38279 (size: 48.3 KiB, free: 420.8 MiB)
[2025-05-08T21:09:30.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 9.0 in stage 1290.1 (TID 2517) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.188+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 8.0 in stage 1290.1 (TID 2516) in 38 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:30.202+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added rdd_602_9 in memory on 172.20.0.5:38279 (size: 55.5 KiB, free: 420.8 MiB)
[2025-05-08T21:09:30.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 6.0 in stage 1336.1 (TID 2518) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 9.0 in stage 1290.1 (TID 2517) in 33 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:30.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Removed TaskSet 1290.1, whose tasks have all completed, from pool
[2025-05-08T21:09:30.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: ShuffleMapStage 1290 (mapPartitions at GraphImpl.scala:208) finished in 0.521 s
[2025-05-08T21:09:30.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:30.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:30.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:30.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:30.222+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:30.226+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_279 stored as values in memory (estimated size 12.0 KiB, free 416.7 MiB)
[2025-05-08T21:09:30.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_279_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 416.7 MiB)
[2025-05-08T21:09:30.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added broadcast_279_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.6 MiB)
[2025-05-08T21:09:30.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO SparkContext: Created broadcast 279 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:30.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:30.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Adding task set 1291.1 with 10 tasks resource profile 0
[2025-05-08T21:09:30.228+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:30.239+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 0.0 in stage 1291.1 (TID 2519) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 6.0 in stage 1336.1 (TID 2518) in 20 ms on 172.20.0.5 (executor 2) (4/41)
[2025-05-08T21:09:30.247+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added broadcast_279_piece0 in memory on 172.20.0.5:38279 (size: 5.7 KiB, free: 420.8 MiB)
[2025-05-08T21:09:30.251+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:30.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 1.0 in stage 1291.1 (TID 2520) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 0.0 in stage 1291.1 (TID 2519) in 25 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:30.276+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 2.0 in stage 1291.1 (TID 2521) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.276+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 1.0 in stage 1291.1 (TID 2520) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:30.287+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 3.0 in stage 1291.1 (TID 2522) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.288+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 2.0 in stage 1291.1 (TID 2521) in 12 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:30.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 4.0 in stage 1291.1 (TID 2523) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 3.0 in stage 1291.1 (TID 2522) in 13 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:30.314+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 5.0 in stage 1291.1 (TID 2524) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.315+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 4.0 in stage 1291.1 (TID 2523) in 14 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:30.327+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 6.0 in stage 1291.1 (TID 2525) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.328+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 5.0 in stage 1291.1 (TID 2524) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:30.338+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 7.0 in stage 1291.1 (TID 2526) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.338+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 6.0 in stage 1291.1 (TID 2525) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:30.348+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 8.0 in stage 1291.1 (TID 2527) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.348+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 7.0 in stage 1291.1 (TID 2526) in 10 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:30.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 9.0 in stage 1291.1 (TID 2528) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 8.0 in stage 1291.1 (TID 2527) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:30.367+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 7.0 in stage 1336.1 (TID 2529) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.367+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 9.0 in stage 1291.1 (TID 2528) in 9 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:30.367+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Removed TaskSet 1291.1, whose tasks have all completed, from pool
[2025-05-08T21:09:30.367+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: ShuffleMapStage 1291 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.144 s
[2025-05-08T21:09:30.368+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:30.368+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:30.368+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:30.368+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:30.368+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:30.373+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:30.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_280 stored as values in memory (estimated size 238.8 KiB, free 416.5 MiB)
[2025-05-08T21:09:30.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_280_piece0 stored as bytes in memory (estimated size 78.7 KiB, free 416.4 MiB)
[2025-05-08T21:09:30.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Removed broadcast_277_piece0 on f2a432e4376a:35283 in memory (size: 5.0 KiB, free: 432.6 MiB)
[2025-05-08T21:09:30.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added broadcast_280_piece0 in memory on f2a432e4376a:35283 (size: 78.7 KiB, free: 432.5 MiB)
[2025-05-08T21:09:30.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO SparkContext: Created broadcast 280 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:30.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:30.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Adding task set 1292.1 with 10 tasks resource profile 0
[2025-05-08T21:09:30.396+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Removed broadcast_277_piece0 on 172.20.0.5:38279 in memory (size: 5.0 KiB, free: 420.8 MiB)
[2025-05-08T21:09:30.402+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Removed broadcast_278_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.6 MiB)
[2025-05-08T21:09:30.404+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Removed broadcast_278_piece0 on 172.20.0.5:38279 in memory (size: 78.8 KiB, free: 420.8 MiB)
[2025-05-08T21:09:30.406+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 0.0 in stage 1292.1 (TID 2530) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.410+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 7.0 in stage 1336.1 (TID 2529) in 43 ms on 172.20.0.5 (executor 2) (5/41)
[2025-05-08T21:09:30.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added broadcast_280_piece0 in memory on 172.20.0.5:38279 (size: 78.7 KiB, free: 420.8 MiB)
[2025-05-08T21:09:30.426+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:30.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:30.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:30.452+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 1.0 in stage 1292.1 (TID 2531) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.453+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 0.0 in stage 1292.1 (TID 2530) in 46 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:30.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 2.0 in stage 1292.1 (TID 2532) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.482+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 1.0 in stage 1292.1 (TID 2531) in 29 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:30.521+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 3.0 in stage 1292.1 (TID 2533) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.522+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 2.0 in stage 1292.1 (TID 2532) in 41 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:30.559+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 4.0 in stage 1292.1 (TID 2534) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.560+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 3.0 in stage 1292.1 (TID 2533) in 38 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:30.589+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 5.0 in stage 1292.1 (TID 2535) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 4.0 in stage 1292.1 (TID 2534) in 32 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:30.616+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 6.0 in stage 1292.1 (TID 2536) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.616+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 5.0 in stage 1292.1 (TID 2535) in 27 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:30.652+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 7.0 in stage 1292.1 (TID 2537) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.653+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 6.0 in stage 1292.1 (TID 2536) in 38 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:30.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 8.0 in stage 1292.1 (TID 2538) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 7.0 in stage 1292.1 (TID 2537) in 35 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:30.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 9.0 in stage 1292.1 (TID 2539) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 8.0 in stage 1292.1 (TID 2538) in 45 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:30.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 8.0 in stage 1336.1 (TID 2540) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.768+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 9.0 in stage 1292.1 (TID 2539) in 38 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:30.768+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Removed TaskSet 1292.1, whose tasks have all completed, from pool
[2025-05-08T21:09:30.768+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: ShuffleMapStage 1292 (mapPartitions at GraphImpl.scala:208) finished in 0.400 s
[2025-05-08T21:09:30.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:30.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:30.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:30.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:30.770+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:30.771+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_281 stored as values in memory (estimated size 12.8 KiB, free 416.7 MiB)
[2025-05-08T21:09:30.772+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_281_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 416.7 MiB)
[2025-05-08T21:09:30.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added broadcast_281_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.6 MiB)
[2025-05-08T21:09:30.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO SparkContext: Created broadcast 281 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:30.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:30.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Adding task set 1293.1 with 10 tasks resource profile 0
[2025-05-08T21:09:30.779+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:30.805+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 0.0 in stage 1293.1 (TID 2541) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.806+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 8.0 in stage 1336.1 (TID 2540) in 38 ms on 172.20.0.5 (executor 2) (6/41)
[2025-05-08T21:09:30.816+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added broadcast_281_piece0 in memory on 172.20.0.5:38279 (size: 5.9 KiB, free: 420.7 MiB)
[2025-05-08T21:09:30.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:30.828+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:30.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 1.0 in stage 1293.1 (TID 2542) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 0.0 in stage 1293.1 (TID 2541) in 34 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:30.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 2.0 in stage 1293.1 (TID 2543) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 1.0 in stage 1293.1 (TID 2542) in 21 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:30.873+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 3.0 in stage 1293.1 (TID 2544) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.874+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 2.0 in stage 1293.1 (TID 2543) in 15 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:30.888+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 4.0 in stage 1293.1 (TID 2545) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.888+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 3.0 in stage 1293.1 (TID 2544) in 15 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:30.903+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 5.0 in stage 1293.1 (TID 2546) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.903+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 4.0 in stage 1293.1 (TID 2545) in 15 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:30.917+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 6.0 in stage 1293.1 (TID 2547) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.918+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 5.0 in stage 1293.1 (TID 2546) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:30.933+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 7.0 in stage 1293.1 (TID 2548) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.934+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 6.0 in stage 1293.1 (TID 2547) in 16 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:30.948+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 8.0 in stage 1293.1 (TID 2549) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.948+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 7.0 in stage 1293.1 (TID 2548) in 15 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:30.963+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 9.0 in stage 1293.1 (TID 2550) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 8.0 in stage 1293.1 (TID 2549) in 15 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:30.975+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Starting task 9.0 in stage 1336.1 (TID 2551) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:30.976+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSetManager: Finished task 9.0 in stage 1293.1 (TID 2550) in 13 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:30.976+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Removed TaskSet 1293.1, whose tasks have all completed, from pool
[2025-05-08T21:09:30.978+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: ShuffleMapStage 1293 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.207 s
[2025-05-08T21:09:30.978+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:30.979+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:30.979+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:30.980+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:30.981+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:30.988+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:30.991+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_282 stored as values in memory (estimated size 239.1 KiB, free 416.5 MiB)
[2025-05-08T21:09:30.992+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO MemoryStore: Block broadcast_282_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 416.4 MiB)
[2025-05-08T21:09:30.993+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO BlockManagerInfo: Added broadcast_282_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.5 MiB)
[2025-05-08T21:09:30.994+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO SparkContext: Created broadcast 282 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:30.994+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:30.995+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:30 INFO TaskSchedulerImpl: Adding task set 1294.1 with 10 tasks resource profile 0
[2025-05-08T21:09:31.000+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 0.0 in stage 1294.1 (TID 2552) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.000+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 9.0 in stage 1336.1 (TID 2551) in 25 ms on 172.20.0.5 (executor 2) (7/41)
[2025-05-08T21:09:31.005+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Added broadcast_282_piece0 in memory on 172.20.0.5:38279 (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T21:09:31.015+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:31.018+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:31.020+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:31.022+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:39008
[2025-05-08T21:09:31.039+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 1.0 in stage 1294.1 (TID 2553) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.040+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 0.0 in stage 1294.1 (TID 2552) in 40 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:31.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 2.0 in stage 1294.1 (TID 2554) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 1.0 in stage 1294.1 (TID 2553) in 27 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:31.092+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 3.0 in stage 1294.1 (TID 2555) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.093+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 2.0 in stage 1294.1 (TID 2554) in 26 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:31.138+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 4.0 in stage 1294.1 (TID 2556) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.140+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 3.0 in stage 1294.1 (TID 2555) in 48 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:31.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 5.0 in stage 1294.1 (TID 2557) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 4.0 in stage 1294.1 (TID 2556) in 38 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:31.203+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 6.0 in stage 1294.1 (TID 2558) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.204+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 5.0 in stage 1294.1 (TID 2557) in 30 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:31.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 7.0 in stage 1294.1 (TID 2559) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 6.0 in stage 1294.1 (TID 2558) in 35 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:31.268+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 8.0 in stage 1294.1 (TID 2560) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.268+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 7.0 in stage 1294.1 (TID 2559) in 30 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:31.304+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 9.0 in stage 1294.1 (TID 2561) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 8.0 in stage 1294.1 (TID 2560) in 37 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:31.331+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 10.0 in stage 1336.1 (TID 2562) (172.20.0.5, executor 2, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.331+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 9.0 in stage 1294.1 (TID 2561) in 27 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:31.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSchedulerImpl: Removed TaskSet 1294.1, whose tasks have all completed, from pool
[2025-05-08T21:09:31.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: ShuffleMapStage 1294 (mapPartitions at GraphImpl.scala:208) finished in 0.352 s
[2025-05-08T21:09:31.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:31.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:31.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:31.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:31.332+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: Submitting ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:31.333+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MemoryStore: Block broadcast_283 stored as values in memory (estimated size 13.5 KiB, free 416.4 MiB)
[2025-05-08T21:09:31.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:39008
[2025-05-08T21:09:31.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MemoryStore: Block broadcast_283_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.4 MiB)
[2025-05-08T21:09:31.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Added broadcast_283_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T21:09:31.343+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO SparkContext: Created broadcast 283 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:31.343+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:31.343+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSchedulerImpl: Adding task set 1295.1 with 10 tasks resource profile 0
[2025-05-08T21:09:31.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Removed broadcast_279_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.5 MiB)
[2025-05-08T21:09:31.348+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Removed broadcast_279_piece0 on 172.20.0.5:38279 in memory (size: 5.7 KiB, free: 420.7 MiB)
[2025-05-08T21:09:31.353+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Removed broadcast_280_piece0 on f2a432e4376a:35283 in memory (size: 78.7 KiB, free: 432.6 MiB)
[2025-05-08T21:09:31.355+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 0.0 in stage 1295.1 (TID 2563) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.355+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 10.0 in stage 1336.1 (TID 2562) in 24 ms on 172.20.0.5 (executor 2) (8/41)
[2025-05-08T21:09:31.356+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Removed broadcast_280_piece0 on 172.20.0.5:38279 in memory (size: 78.7 KiB, free: 420.8 MiB)
[2025-05-08T21:09:31.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Removed broadcast_281_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.6 MiB)
[2025-05-08T21:09:31.362+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Removed broadcast_281_piece0 on 172.20.0.5:38279 in memory (size: 5.9 KiB, free: 420.8 MiB)
[2025-05-08T21:09:31.364+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Added broadcast_283_piece0 in memory on 172.20.0.5:38279 (size: 6.1 KiB, free: 420.8 MiB)
[2025-05-08T21:09:31.369+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:31.375+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:31.386+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:39008
[2025-05-08T21:09:31.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 1.0 in stage 1295.1 (TID 2564) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 0.0 in stage 1295.1 (TID 2563) in 38 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:31.421+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 2.0 in stage 1295.1 (TID 2565) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 1.0 in stage 1295.1 (TID 2564) in 30 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:31.466+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 3.0 in stage 1295.1 (TID 2566) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.468+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 2.0 in stage 1295.1 (TID 2565) in 46 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:31.490+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 4.0 in stage 1295.1 (TID 2567) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.491+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 3.0 in stage 1295.1 (TID 2566) in 24 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:31.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 5.0 in stage 1295.1 (TID 2568) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 4.0 in stage 1295.1 (TID 2567) in 23 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:31.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 6.0 in stage 1295.1 (TID 2569) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 5.0 in stage 1295.1 (TID 2568) in 20 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:31.549+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 7.0 in stage 1295.1 (TID 2570) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.549+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 6.0 in stage 1295.1 (TID 2569) in 17 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:31.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 8.0 in stage 1295.1 (TID 2571) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 7.0 in stage 1295.1 (TID 2570) in 21 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:31.592+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 9.0 in stage 1295.1 (TID 2572) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 8.0 in stage 1295.1 (TID 2571) in 22 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:31.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 11.0 in stage 1336.1 (TID 2573) (172.20.0.5, executor 2, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.612+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 9.0 in stage 1295.1 (TID 2572) in 19 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:31.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSchedulerImpl: Removed TaskSet 1295.1, whose tasks have all completed, from pool
[2025-05-08T21:09:31.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: ShuffleMapStage 1295 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.279 s
[2025-05-08T21:09:31.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:31.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:31.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:31.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:31.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: Submitting ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:31.618+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:31.621+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MemoryStore: Block broadcast_284 stored as values in memory (estimated size 239.4 KiB, free 416.5 MiB)
[2025-05-08T21:09:31.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MemoryStore: Block broadcast_284_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.4 MiB)
[2025-05-08T21:09:31.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Added broadcast_284_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:09:31.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO SparkContext: Created broadcast 284 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:31.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:31.624+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSchedulerImpl: Adding task set 1296.1 with 10 tasks resource profile 0
[2025-05-08T21:09:31.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 0.0 in stage 1296.1 (TID 2574) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.664+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 11.0 in stage 1336.1 (TID 2573) in 52 ms on 172.20.0.5 (executor 2) (9/41)
[2025-05-08T21:09:31.668+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO BlockManagerInfo: Added broadcast_284_piece0 in memory on 172.20.0.5:38279 (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:09:31.702+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:31.708+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:31.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:31.716+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:39008
[2025-05-08T21:09:31.719+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:39008
[2025-05-08T21:09:31.758+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 1.0 in stage 1296.1 (TID 2575) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.759+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 0.0 in stage 1296.1 (TID 2574) in 98 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:31.787+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 2.0 in stage 1296.1 (TID 2576) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 1.0 in stage 1296.1 (TID 2575) in 29 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:31.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 3.0 in stage 1296.1 (TID 2577) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.814+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 2.0 in stage 1296.1 (TID 2576) in 26 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:31.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 4.0 in stage 1296.1 (TID 2578) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 3.0 in stage 1296.1 (TID 2577) in 25 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:31.867+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 5.0 in stage 1296.1 (TID 2579) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.868+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 4.0 in stage 1296.1 (TID 2578) in 31 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:31.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 6.0 in stage 1296.1 (TID 2580) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.901+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 5.0 in stage 1296.1 (TID 2579) in 34 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:31.936+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 7.0 in stage 1296.1 (TID 2581) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.936+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 6.0 in stage 1296.1 (TID 2580) in 36 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:31.968+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Starting task 8.0 in stage 1296.1 (TID 2582) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:31.968+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:31 INFO TaskSetManager: Finished task 7.0 in stage 1296.1 (TID 2581) in 32 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:32.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 9.0 in stage 1296.1 (TID 2583) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 8.0 in stage 1296.1 (TID 2582) in 35 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:32.032+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 12.0 in stage 1336.1 (TID 2584) (172.20.0.5, executor 2, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.033+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 9.0 in stage 1296.1 (TID 2583) in 30 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:32.033+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSchedulerImpl: Removed TaskSet 1296.1, whose tasks have all completed, from pool
[2025-05-08T21:09:32.035+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: ShuffleMapStage 1296 (mapPartitions at GraphImpl.scala:208) finished in 0.420 s
[2025-05-08T21:09:32.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:32.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:32.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:32.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:32.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: Submitting ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:32.038+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:32.041+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MemoryStore: Block broadcast_285 stored as values in memory (estimated size 14.2 KiB, free 416.4 MiB)
[2025-05-08T21:09:32.044+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MemoryStore: Block broadcast_285_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.4 MiB)
[2025-05-08T21:09:32.045+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Added broadcast_285_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T21:09:32.045+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO SparkContext: Created broadcast 285 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:32.046+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:32.046+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSchedulerImpl: Adding task set 1297.1 with 10 tasks resource profile 0
[2025-05-08T21:09:32.071+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 0.0 in stage 1297.1 (TID 2585) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.071+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 12.0 in stage 1336.1 (TID 2584) in 39 ms on 172.20.0.5 (executor 2) (10/41)
[2025-05-08T21:09:32.078+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Added broadcast_285_piece0 in memory on 172.20.0.5:38279 (size: 6.1 KiB, free: 420.7 MiB)
[2025-05-08T21:09:32.081+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:32.087+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:32.103+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:39008
[2025-05-08T21:09:32.119+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:39008
[2025-05-08T21:09:32.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 1.0 in stage 1297.1 (TID 2586) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 0.0 in stage 1297.1 (TID 2585) in 53 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:32.146+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 2.0 in stage 1297.1 (TID 2587) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.146+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 1.0 in stage 1297.1 (TID 2586) in 23 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:32.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 3.0 in stage 1297.1 (TID 2588) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 2.0 in stage 1297.1 (TID 2587) in 28 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:32.207+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 4.0 in stage 1297.1 (TID 2589) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.208+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 3.0 in stage 1297.1 (TID 2588) in 33 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:32.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 5.0 in stage 1297.1 (TID 2590) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.239+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 4.0 in stage 1297.1 (TID 2589) in 31 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:32.267+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 6.0 in stage 1297.1 (TID 2591) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.268+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 5.0 in stage 1297.1 (TID 2590) in 29 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:32.290+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 7.0 in stage 1297.1 (TID 2592) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.290+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 6.0 in stage 1297.1 (TID 2591) in 23 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:32.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 8.0 in stage 1297.1 (TID 2593) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 7.0 in stage 1297.1 (TID 2592) in 23 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:32.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 9.0 in stage 1297.1 (TID 2594) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.336+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 8.0 in stage 1297.1 (TID 2593) in 24 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:32.356+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 13.0 in stage 1336.1 (TID 2595) (172.20.0.5, executor 2, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 9.0 in stage 1297.1 (TID 2594) in 21 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:32.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSchedulerImpl: Removed TaskSet 1297.1, whose tasks have all completed, from pool
[2025-05-08T21:09:32.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: ShuffleMapStage 1297 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.321 s
[2025-05-08T21:09:32.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:32.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:32.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:32.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:32.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: Submitting ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:32.361+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:32.367+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MemoryStore: Block broadcast_286 stored as values in memory (estimated size 239.6 KiB, free 416.2 MiB)
[2025-05-08T21:09:32.369+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MemoryStore: Block broadcast_286_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 416.1 MiB)
[2025-05-08T21:09:32.369+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Added broadcast_286_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.4 MiB)
[2025-05-08T21:09:32.370+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO SparkContext: Created broadcast 286 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:32.370+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:32.370+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSchedulerImpl: Adding task set 1298.1 with 10 tasks resource profile 0
[2025-05-08T21:09:32.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 0.0 in stage 1298.1 (TID 2596) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 13.0 in stage 1336.1 (TID 2595) in 28 ms on 172.20.0.5 (executor 2) (11/41)
[2025-05-08T21:09:32.389+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Added broadcast_286_piece0 in memory on 172.20.0.5:38279 (size: 79.2 KiB, free: 420.6 MiB)
[2025-05-08T21:09:32.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:32.410+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:32.411+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:32.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:39008
[2025-05-08T21:09:32.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:39008
[2025-05-08T21:09:32.421+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:39008
[2025-05-08T21:09:32.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 1.0 in stage 1298.1 (TID 2597) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 0.0 in stage 1298.1 (TID 2596) in 53 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:32.459+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 2.0 in stage 1298.1 (TID 2598) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.459+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 1.0 in stage 1298.1 (TID 2597) in 23 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:32.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 3.0 in stage 1298.1 (TID 2599) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 2.0 in stage 1298.1 (TID 2598) in 22 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:32.501+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 4.0 in stage 1298.1 (TID 2600) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.502+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 3.0 in stage 1298.1 (TID 2599) in 22 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:32.526+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 5.0 in stage 1298.1 (TID 2601) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.526+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 4.0 in stage 1298.1 (TID 2600) in 25 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:32.546+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 6.0 in stage 1298.1 (TID 2602) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 5.0 in stage 1298.1 (TID 2601) in 20 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:32.569+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 7.0 in stage 1298.1 (TID 2603) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 6.0 in stage 1298.1 (TID 2602) in 24 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:32.589+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 8.0 in stage 1298.1 (TID 2604) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 7.0 in stage 1298.1 (TID 2603) in 21 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:32.608+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 9.0 in stage 1298.1 (TID 2605) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 8.0 in stage 1298.1 (TID 2604) in 20 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:32.627+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 14.0 in stage 1336.1 (TID 2606) (172.20.0.5, executor 2, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.627+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 9.0 in stage 1298.1 (TID 2605) in 19 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:32.627+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSchedulerImpl: Removed TaskSet 1298.1, whose tasks have all completed, from pool
[2025-05-08T21:09:32.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: ShuffleMapStage 1298 (mapPartitions at GraphImpl.scala:208) finished in 0.269 s
[2025-05-08T21:09:32.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:32.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:32.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:09:32.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:32.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: Submitting ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:32.629+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MemoryStore: Block broadcast_287 stored as values in memory (estimated size 14.9 KiB, free 416.1 MiB)
[2025-05-08T21:09:32.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:32.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MemoryStore: Block broadcast_287_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 416.1 MiB)
[2025-05-08T21:09:32.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Added broadcast_287_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.4 MiB)
[2025-05-08T21:09:32.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO SparkContext: Created broadcast 287 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:32.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_285_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.4 MiB)
[2025-05-08T21:09:32.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:32.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSchedulerImpl: Adding task set 1299.1 with 10 tasks resource profile 0
[2025-05-08T21:09:32.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_285_piece0 on 172.20.0.5:38279 in memory (size: 6.1 KiB, free: 420.6 MiB)
[2025-05-08T21:09:32.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 0.0 in stage 1299.1 (TID 2607) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_282_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.5 MiB)
[2025-05-08T21:09:32.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 14.0 in stage 1336.1 (TID 2606) in 47 ms on 172.20.0.5 (executor 2) (12/41)
[2025-05-08T21:09:32.677+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_282_piece0 on 172.20.0.5:38279 in memory (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T21:09:32.685+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_283_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T21:09:32.686+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Added broadcast_287_piece0 in memory on 172.20.0.5:38279 (size: 6.3 KiB, free: 420.7 MiB)
[2025-05-08T21:09:32.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_283_piece0 on 172.20.0.5:38279 in memory (size: 6.1 KiB, free: 420.7 MiB)
[2025-05-08T21:09:32.694+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_284_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.6 MiB)
[2025-05-08T21:09:32.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO BlockManagerInfo: Removed broadcast_284_piece0 on 172.20.0.5:38279 in memory (size: 79.1 KiB, free: 420.8 MiB)
[2025-05-08T21:09:32.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:32.724+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:32.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:39008
[2025-05-08T21:09:32.760+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:39008
[2025-05-08T21:09:32.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:39008
[2025-05-08T21:09:32.796+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 1.0 in stage 1299.1 (TID 2608) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.797+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 0.0 in stage 1299.1 (TID 2607) in 127 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:32.857+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 2.0 in stage 1299.1 (TID 2609) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.857+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 1.0 in stage 1299.1 (TID 2608) in 61 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:32.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 3.0 in stage 1299.1 (TID 2610) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 2.0 in stage 1299.1 (TID 2609) in 35 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:32.940+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 4.0 in stage 1299.1 (TID 2611) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 3.0 in stage 1299.1 (TID 2610) in 49 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:32.975+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Starting task 5.0 in stage 1299.1 (TID 2612) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:32.976+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:32 INFO TaskSetManager: Finished task 4.0 in stage 1299.1 (TID 2611) in 35 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:33.010+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 6.0 in stage 1299.1 (TID 2613) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.010+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 5.0 in stage 1299.1 (TID 2612) in 36 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:33.053+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 7.0 in stage 1299.1 (TID 2614) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.054+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 6.0 in stage 1299.1 (TID 2613) in 44 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:33.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 8.0 in stage 1299.1 (TID 2615) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 7.0 in stage 1299.1 (TID 2614) in 32 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:33.116+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 9.0 in stage 1299.1 (TID 2616) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.116+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 8.0 in stage 1299.1 (TID 2615) in 31 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:33.159+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 15.0 in stage 1336.1 (TID 2617) (172.20.0.5, executor 2, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 9.0 in stage 1299.1 (TID 2616) in 44 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:33.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSchedulerImpl: Removed TaskSet 1299.1, whose tasks have all completed, from pool
[2025-05-08T21:09:33.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: ShuffleMapStage 1299 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.532 s
[2025-05-08T21:09:33.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:33.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:33.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:09:33.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:33.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: Submitting ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:33.167+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:33.169+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MemoryStore: Block broadcast_288 stored as values in memory (estimated size 239.9 KiB, free 416.5 MiB)
[2025-05-08T21:09:33.170+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MemoryStore: Block broadcast_288_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.4 MiB)
[2025-05-08T21:09:33.171+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO BlockManagerInfo: Added broadcast_288_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:09:33.171+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO SparkContext: Created broadcast 288 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:33.171+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:33.171+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSchedulerImpl: Adding task set 1300.1 with 10 tasks resource profile 0
[2025-05-08T21:09:33.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 0.0 in stage 1300.1 (TID 2618) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 15.0 in stage 1336.1 (TID 2617) in 34 ms on 172.20.0.5 (executor 2) (13/41)
[2025-05-08T21:09:33.207+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO BlockManagerInfo: Added broadcast_288_piece0 in memory on 172.20.0.5:38279 (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:09:33.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:33.230+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:33.232+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:33.233+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:39008
[2025-05-08T21:09:33.235+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:39008
[2025-05-08T21:09:33.239+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:39008
[2025-05-08T21:09:33.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:39008
[2025-05-08T21:09:33.262+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 1.0 in stage 1300.1 (TID 2619) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 0.0 in stage 1300.1 (TID 2618) in 71 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:33.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 2.0 in stage 1300.1 (TID 2620) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 1.0 in stage 1300.1 (TID 2619) in 23 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:33.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 3.0 in stage 1300.1 (TID 2621) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.313+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 2.0 in stage 1300.1 (TID 2620) in 29 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:33.338+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 4.0 in stage 1300.1 (TID 2622) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.339+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 3.0 in stage 1300.1 (TID 2621) in 27 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:33.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 5.0 in stage 1300.1 (TID 2623) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 4.0 in stage 1300.1 (TID 2622) in 21 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:33.379+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 6.0 in stage 1300.1 (TID 2624) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.380+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 5.0 in stage 1300.1 (TID 2623) in 21 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:33.403+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 7.0 in stage 1300.1 (TID 2625) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.404+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 6.0 in stage 1300.1 (TID 2624) in 25 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:33.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 8.0 in stage 1300.1 (TID 2626) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 7.0 in stage 1300.1 (TID 2625) in 30 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:33.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 9.0 in stage 1300.1 (TID 2627) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 8.0 in stage 1300.1 (TID 2626) in 23 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:33.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 16.0 in stage 1336.1 (TID 2628) (172.20.0.5, executor 2, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 9.0 in stage 1300.1 (TID 2627) in 21 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSchedulerImpl: Removed TaskSet 1300.1, whose tasks have all completed, from pool
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: ShuffleMapStage 1300 (mapPartitions at GraphImpl.scala:208) finished in 0.315 s
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:33.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: Submitting ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:33.478+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MemoryStore: Block broadcast_289 stored as values in memory (estimated size 15.6 KiB, free 416.4 MiB)
[2025-05-08T21:09:33.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MemoryStore: Block broadcast_289_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 416.4 MiB)
[2025-05-08T21:09:33.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO BlockManagerInfo: Added broadcast_289_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.5 MiB)
[2025-05-08T21:09:33.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO SparkContext: Created broadcast 289 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:33.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:33.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSchedulerImpl: Adding task set 1301.1 with 10 tasks resource profile 0
[2025-05-08T21:09:33.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:33.500+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 0.0 in stage 1301.1 (TID 2629) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.501+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 16.0 in stage 1336.1 (TID 2628) in 25 ms on 172.20.0.5 (executor 2) (14/41)
[2025-05-08T21:09:33.504+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO BlockManagerInfo: Added broadcast_289_piece0 in memory on 172.20.0.5:38279 (size: 6.4 KiB, free: 420.7 MiB)
[2025-05-08T21:09:33.507+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:33.519+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:33.523+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:39008
[2025-05-08T21:09:33.527+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:39008
[2025-05-08T21:09:33.537+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:39008
[2025-05-08T21:09:33.580+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:39008
[2025-05-08T21:09:33.585+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 1.0 in stage 1301.1 (TID 2630) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.586+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 0.0 in stage 1301.1 (TID 2629) in 85 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:33.648+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 2.0 in stage 1301.1 (TID 2631) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.649+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 1.0 in stage 1301.1 (TID 2630) in 63 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:33.691+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 3.0 in stage 1301.1 (TID 2632) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.692+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 2.0 in stage 1301.1 (TID 2631) in 43 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:33.735+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 4.0 in stage 1301.1 (TID 2633) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.735+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 3.0 in stage 1301.1 (TID 2632) in 44 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:33.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 5.0 in stage 1301.1 (TID 2634) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 4.0 in stage 1301.1 (TID 2633) in 55 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:33.854+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 6.0 in stage 1301.1 (TID 2635) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.854+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 5.0 in stage 1301.1 (TID 2634) in 65 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:33.899+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 7.0 in stage 1301.1 (TID 2636) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.899+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 6.0 in stage 1301.1 (TID 2635) in 45 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:33.943+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 8.0 in stage 1301.1 (TID 2637) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.943+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 7.0 in stage 1301.1 (TID 2636) in 45 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:33.985+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Starting task 9.0 in stage 1301.1 (TID 2638) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:33.985+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:33 INFO TaskSetManager: Finished task 8.0 in stage 1301.1 (TID 2637) in 42 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:34.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 17.0 in stage 1336.1 (TID 2639) (172.20.0.5, executor 2, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 9.0 in stage 1301.1 (TID 2638) in 45 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:34.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSchedulerImpl: Removed TaskSet 1301.1, whose tasks have all completed, from pool
[2025-05-08T21:09:34.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: ShuffleMapStage 1301 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.553 s
[2025-05-08T21:09:34.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:34.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:34.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:09:34.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:34.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: Submitting ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:34.034+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:34.035+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MemoryStore: Block broadcast_290 stored as values in memory (estimated size 240.2 KiB, free 416.2 MiB)
[2025-05-08T21:09:34.037+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MemoryStore: Block broadcast_290_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.1 MiB)
[2025-05-08T21:09:34.037+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Added broadcast_290_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.4 MiB)
[2025-05-08T21:09:34.037+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO SparkContext: Created broadcast 290 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:34.037+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:34.037+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSchedulerImpl: Adding task set 1302.1 with 10 tasks resource profile 0
[2025-05-08T21:09:34.051+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 0.0 in stage 1302.1 (TID 2640) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.051+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 17.0 in stage 1336.1 (TID 2639) in 22 ms on 172.20.0.5 (executor 2) (15/41)
[2025-05-08T21:09:34.055+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Added broadcast_290_piece0 in memory on 172.20.0.5:38279 (size: 79.1 KiB, free: 420.6 MiB)
[2025-05-08T21:09:34.070+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:34.072+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:34.073+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:34.073+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:39008
[2025-05-08T21:09:34.074+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:39008
[2025-05-08T21:09:34.075+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:39008
[2025-05-08T21:09:34.076+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:39008
[2025-05-08T21:09:34.077+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:39008
[2025-05-08T21:09:34.086+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_287_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.4 MiB)
[2025-05-08T21:09:34.087+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_287_piece0 on 172.20.0.5:38279 in memory (size: 6.3 KiB, free: 420.6 MiB)
[2025-05-08T21:09:34.089+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_288_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:09:34.091+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_288_piece0 on 172.20.0.5:38279 in memory (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:09:34.093+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_286_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.6 MiB)
[2025-05-08T21:09:34.095+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_286_piece0 on 172.20.0.5:38279 in memory (size: 79.2 KiB, free: 420.8 MiB)
[2025-05-08T21:09:34.099+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_289_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.6 MiB)
[2025-05-08T21:09:34.100+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Removed broadcast_289_piece0 on 172.20.0.5:38279 in memory (size: 6.4 KiB, free: 420.8 MiB)
[2025-05-08T21:09:34.105+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 1.0 in stage 1302.1 (TID 2641) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.105+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 0.0 in stage 1302.1 (TID 2640) in 54 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:34.128+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 2.0 in stage 1302.1 (TID 2642) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 1.0 in stage 1302.1 (TID 2641) in 23 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:34.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 3.0 in stage 1302.1 (TID 2643) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 2.0 in stage 1302.1 (TID 2642) in 31 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:34.190+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 4.0 in stage 1302.1 (TID 2644) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.191+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 3.0 in stage 1302.1 (TID 2643) in 33 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:34.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 5.0 in stage 1302.1 (TID 2645) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.222+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 4.0 in stage 1302.1 (TID 2644) in 31 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:34.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 6.0 in stage 1302.1 (TID 2646) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 5.0 in stage 1302.1 (TID 2645) in 20 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:34.259+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 7.0 in stage 1302.1 (TID 2647) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.259+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 6.0 in stage 1302.1 (TID 2646) in 19 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:34.280+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 8.0 in stage 1302.1 (TID 2648) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.281+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 7.0 in stage 1302.1 (TID 2647) in 22 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:34.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 9.0 in stage 1302.1 (TID 2649) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 8.0 in stage 1302.1 (TID 2648) in 20 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:34.318+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 18.0 in stage 1336.1 (TID 2650) (172.20.0.5, executor 2, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 9.0 in stage 1302.1 (TID 2649) in 20 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:34.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSchedulerImpl: Removed TaskSet 1302.1, whose tasks have all completed, from pool
[2025-05-08T21:09:34.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: ShuffleMapStage 1302 (mapPartitions at GraphImpl.scala:208) finished in 0.288 s
[2025-05-08T21:09:34.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:34.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:34.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:09:34.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:34.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: Submitting ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:34.321+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MemoryStore: Block broadcast_291 stored as values in memory (estimated size 16.4 KiB, free 416.7 MiB)
[2025-05-08T21:09:34.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MemoryStore: Block broadcast_291_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 416.7 MiB)
[2025-05-08T21:09:34.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Added broadcast_291_piece0 in memory on f2a432e4376a:35283 (size: 6.5 KiB, free: 432.6 MiB)
[2025-05-08T21:09:34.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO SparkContext: Created broadcast 291 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:34.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:34.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSchedulerImpl: Adding task set 1303.1 with 10 tasks resource profile 0
[2025-05-08T21:09:34.324+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:34.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 0.0 in stage 1303.1 (TID 2651) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.348+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 18.0 in stage 1336.1 (TID 2650) in 29 ms on 172.20.0.5 (executor 2) (16/41)
[2025-05-08T21:09:34.351+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO BlockManagerInfo: Added broadcast_291_piece0 in memory on 172.20.0.5:38279 (size: 6.5 KiB, free: 420.8 MiB)
[2025-05-08T21:09:34.354+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:34.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:34.362+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:39008
[2025-05-08T21:09:34.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:39008
[2025-05-08T21:09:34.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:39008
[2025-05-08T21:09:34.398+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:39008
[2025-05-08T21:09:34.451+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:39008
[2025-05-08T21:09:34.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 1.0 in stage 1303.1 (TID 2652) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 0.0 in stage 1303.1 (TID 2651) in 108 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:34.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 2.0 in stage 1303.1 (TID 2653) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 1.0 in stage 1303.1 (TID 2652) in 84 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:34.625+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 3.0 in stage 1303.1 (TID 2654) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 2.0 in stage 1303.1 (TID 2653) in 86 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:34.708+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 4.0 in stage 1303.1 (TID 2655) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.708+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 3.0 in stage 1303.1 (TID 2654) in 83 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:34.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 5.0 in stage 1303.1 (TID 2656) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 4.0 in stage 1303.1 (TID 2655) in 81 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:34.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 6.0 in stage 1303.1 (TID 2657) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 5.0 in stage 1303.1 (TID 2656) in 84 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:34.976+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Starting task 7.0 in stage 1303.1 (TID 2658) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:34.976+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:34 INFO TaskSetManager: Finished task 6.0 in stage 1303.1 (TID 2657) in 104 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:35.076+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 8.0 in stage 1303.1 (TID 2659) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.077+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 7.0 in stage 1303.1 (TID 2658) in 102 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:35.167+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 9.0 in stage 1303.1 (TID 2660) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.167+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 8.0 in stage 1303.1 (TID 2659) in 91 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:35.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 19.0 in stage 1336.1 (TID 2661) (172.20.0.5, executor 2, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 9.0 in stage 1303.1 (TID 2660) in 96 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:35.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSchedulerImpl: Removed TaskSet 1303.1, whose tasks have all completed, from pool
[2025-05-08T21:09:35.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: ShuffleMapStage 1303 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.943 s
[2025-05-08T21:09:35.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:35.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:35.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:09:35.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:35.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: Submitting ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:35.268+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:35.269+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MemoryStore: Block broadcast_292 stored as values in memory (estimated size 240.5 KiB, free 416.5 MiB)
[2025-05-08T21:09:35.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MemoryStore: Block broadcast_292_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.4 MiB)
[2025-05-08T21:09:35.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Added broadcast_292_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:09:35.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO SparkContext: Created broadcast 292 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:35.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:35.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSchedulerImpl: Adding task set 1304.1 with 10 tasks resource profile 0
[2025-05-08T21:09:35.288+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 0.0 in stage 1304.1 (TID 2662) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.288+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 19.0 in stage 1336.1 (TID 2661) in 26 ms on 172.20.0.5 (executor 2) (17/41)
[2025-05-08T21:09:35.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Added broadcast_292_piece0 in memory on 172.20.0.5:38279 (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:09:35.308+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:35.311+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:35.333+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:35.334+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:39008
[2025-05-08T21:09:35.336+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:39008
[2025-05-08T21:09:35.338+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:39008
[2025-05-08T21:09:35.339+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:39008
[2025-05-08T21:09:35.340+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:39008
[2025-05-08T21:09:35.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:39008
[2025-05-08T21:09:35.364+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 1.0 in stage 1304.1 (TID 2663) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.364+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 0.0 in stage 1304.1 (TID 2662) in 76 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:35.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 2.0 in stage 1304.1 (TID 2664) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 1.0 in stage 1304.1 (TID 2663) in 30 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:35.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 3.0 in stage 1304.1 (TID 2665) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 2.0 in stage 1304.1 (TID 2664) in 23 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:35.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 4.0 in stage 1304.1 (TID 2666) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 3.0 in stage 1304.1 (TID 2665) in 21 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:35.460+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 5.0 in stage 1304.1 (TID 2667) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.461+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 4.0 in stage 1304.1 (TID 2666) in 24 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:35.482+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 6.0 in stage 1304.1 (TID 2668) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.482+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 5.0 in stage 1304.1 (TID 2667) in 22 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:35.504+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 7.0 in stage 1304.1 (TID 2669) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.505+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 6.0 in stage 1304.1 (TID 2668) in 24 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:35.529+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 8.0 in stage 1304.1 (TID 2670) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.530+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 7.0 in stage 1304.1 (TID 2669) in 25 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:35.552+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 9.0 in stage 1304.1 (TID 2671) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.553+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 8.0 in stage 1304.1 (TID 2670) in 24 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:35.574+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 20.0 in stage 1336.1 (TID 2672) (172.20.0.5, executor 2, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.574+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 9.0 in stage 1304.1 (TID 2671) in 22 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:35.575+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSchedulerImpl: Removed TaskSet 1304.1, whose tasks have all completed, from pool
[2025-05-08T21:09:35.575+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: ShuffleMapStage 1304 (mapPartitions at GraphImpl.scala:208) finished in 0.310 s
[2025-05-08T21:09:35.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:35.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:35.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:09:35.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:35.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: Submitting ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:35.577+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MemoryStore: Block broadcast_293 stored as values in memory (estimated size 17.1 KiB, free 416.4 MiB)
[2025-05-08T21:09:35.589+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:39008
[2025-05-08T21:09:35.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MemoryStore: Block broadcast_293_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 416.4 MiB)
[2025-05-08T21:09:35.591+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Added broadcast_293_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.5 MiB)
[2025-05-08T21:09:35.591+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO SparkContext: Created broadcast 293 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:35.592+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:35.592+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSchedulerImpl: Adding task set 1305.1 with 10 tasks resource profile 0
[2025-05-08T21:09:35.592+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Removed broadcast_290_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.6 MiB)
[2025-05-08T21:09:35.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Removed broadcast_290_piece0 on 172.20.0.5:38279 in memory (size: 79.1 KiB, free: 420.8 MiB)
[2025-05-08T21:09:35.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Removed broadcast_291_piece0 on f2a432e4376a:35283 in memory (size: 6.5 KiB, free: 432.6 MiB)
[2025-05-08T21:09:35.632+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Removed broadcast_291_piece0 on 172.20.0.5:38279 in memory (size: 6.5 KiB, free: 420.8 MiB)
[2025-05-08T21:09:35.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 0.0 in stage 1305.1 (TID 2673) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 20.0 in stage 1336.1 (TID 2672) in 67 ms on 172.20.0.5 (executor 2) (18/41)
[2025-05-08T21:09:35.655+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO BlockManagerInfo: Added broadcast_293_piece0 in memory on 172.20.0.5:38279 (size: 6.6 KiB, free: 420.8 MiB)
[2025-05-08T21:09:35.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:35.685+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:35.695+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:39008
[2025-05-08T21:09:35.722+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:39008
[2025-05-08T21:09:35.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:39008
[2025-05-08T21:09:35.757+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:39008
[2025-05-08T21:09:35.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:39008
[2025-05-08T21:09:35.927+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:39008
[2025-05-08T21:09:35.934+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Starting task 1.0 in stage 1305.1 (TID 2674) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:35.934+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:35 INFO TaskSetManager: Finished task 0.0 in stage 1305.1 (TID 2673) in 294 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:36.126+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Starting task 2.0 in stage 1305.1 (TID 2675) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:36.127+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Finished task 1.0 in stage 1305.1 (TID 2674) in 192 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:36.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Starting task 3.0 in stage 1305.1 (TID 2676) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:36.345+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Finished task 2.0 in stage 1305.1 (TID 2675) in 218 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:36.521+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Starting task 4.0 in stage 1305.1 (TID 2677) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:36.521+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Finished task 3.0 in stage 1305.1 (TID 2676) in 177 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:36.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Starting task 5.0 in stage 1305.1 (TID 2678) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:36.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Finished task 4.0 in stage 1305.1 (TID 2677) in 176 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:36.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Starting task 6.0 in stage 1305.1 (TID 2679) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:36.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:36 INFO TaskSetManager: Finished task 5.0 in stage 1305.1 (TID 2678) in 155 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:37.045+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 7.0 in stage 1305.1 (TID 2680) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.046+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 6.0 in stage 1305.1 (TID 2679) in 195 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:37.204+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 8.0 in stage 1305.1 (TID 2681) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 7.0 in stage 1305.1 (TID 2680) in 159 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:37.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 9.0 in stage 1305.1 (TID 2682) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.360+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 8.0 in stage 1305.1 (TID 2681) in 155 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:37.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 21.0 in stage 1336.1 (TID 2683) (172.20.0.5, executor 2, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 9.0 in stage 1305.1 (TID 2682) in 212 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSchedulerImpl: Removed TaskSet 1305.1, whose tasks have all completed, from pool
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: ShuffleMapStage 1305 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.995 s
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:37.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: Submitting ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:09:37.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:39008
[2025-05-08T21:09:37.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MemoryStore: Block broadcast_294 stored as values in memory (estimated size 240.8 KiB, free 416.5 MiB)
[2025-05-08T21:09:37.583+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MemoryStore: Block broadcast_294_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 416.4 MiB)
[2025-05-08T21:09:37.583+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Added broadcast_294_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.5 MiB)
[2025-05-08T21:09:37.583+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO SparkContext: Created broadcast 294 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:37.583+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:37.583+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSchedulerImpl: Adding task set 1306.1 with 10 tasks resource profile 0
[2025-05-08T21:09:37.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 0.0 in stage 1306.1 (TID 2684) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.612+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 21.0 in stage 1336.1 (TID 2683) in 40 ms on 172.20.0.5 (executor 2) (19/41)
[2025-05-08T21:09:37.620+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Added broadcast_294_piece0 in memory on 172.20.0.5:38279 (size: 79.3 KiB, free: 420.7 MiB)
[2025-05-08T21:09:37.632+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:39008
[2025-05-08T21:09:37.635+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:39008
[2025-05-08T21:09:37.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:39008
[2025-05-08T21:09:37.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:39008
[2025-05-08T21:09:37.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:39008
[2025-05-08T21:09:37.648+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:39008
[2025-05-08T21:09:37.649+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:39008
[2025-05-08T21:09:37.650+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:39008
[2025-05-08T21:09:37.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:39008
[2025-05-08T21:09:37.652+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:39008
[2025-05-08T21:09:37.666+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 1.0 in stage 1306.1 (TID 2685) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.667+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 0.0 in stage 1306.1 (TID 2684) in 57 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:37.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 2.0 in stage 1306.1 (TID 2686) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 1.0 in stage 1306.1 (TID 2685) in 22 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:37.709+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 3.0 in stage 1306.1 (TID 2687) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 2.0 in stage 1306.1 (TID 2686) in 22 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:37.732+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 4.0 in stage 1306.1 (TID 2688) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.732+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 3.0 in stage 1306.1 (TID 2687) in 23 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:37.753+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 5.0 in stage 1306.1 (TID 2689) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.753+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 4.0 in stage 1306.1 (TID 2688) in 22 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:37.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 6.0 in stage 1306.1 (TID 2690) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 5.0 in stage 1306.1 (TID 2689) in 21 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:37.795+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 7.0 in stage 1306.1 (TID 2691) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.795+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 6.0 in stage 1306.1 (TID 2690) in 23 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:09:37.817+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 8.0 in stage 1306.1 (TID 2692) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.817+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 7.0 in stage 1306.1 (TID 2691) in 23 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-08T21:09:37.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 9.0 in stage 1306.1 (TID 2693) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 8.0 in stage 1306.1 (TID 2692) in 20 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-08T21:09:37.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 22.0 in stage 1336.1 (TID 2694) (172.20.0.5, executor 2, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 9.0 in stage 1306.1 (TID 2693) in 21 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-08T21:09:37.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSchedulerImpl: Removed TaskSet 1306.1, whose tasks have all completed, from pool
[2025-05-08T21:09:37.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: ShuffleMapStage 1306 (mapPartitions at GraphImpl.scala:208) finished in 0.285 s
[2025-05-08T21:09:37.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:09:37.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:09:37.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:09:37.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: failed: Set()
[2025-05-08T21:09:37.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: Submitting ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:09:37.861+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MemoryStore: Block broadcast_295 stored as values in memory (estimated size 17.8 KiB, free 416.4 MiB)
[2025-05-08T21:09:37.874+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:39008
[2025-05-08T21:09:37.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MemoryStore: Block broadcast_295_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 416.4 MiB)
[2025-05-08T21:09:37.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Added broadcast_295_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.5 MiB)
[2025-05-08T21:09:37.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO SparkContext: Created broadcast 295 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:09:37.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:09:37.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSchedulerImpl: Adding task set 1307.1 with 10 tasks resource profile 0
[2025-05-08T21:09:37.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Removed broadcast_292_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.6 MiB)
[2025-05-08T21:09:37.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Removed broadcast_292_piece0 on 172.20.0.5:38279 in memory (size: 79.1 KiB, free: 420.8 MiB)
[2025-05-08T21:09:37.882+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Removed broadcast_293_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.6 MiB)
[2025-05-08T21:09:37.902+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Removed broadcast_293_piece0 on 172.20.0.5:38279 in memory (size: 6.6 KiB, free: 420.8 MiB)
[2025-05-08T21:09:37.908+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Starting task 0.0 in stage 1307.1 (TID 2695) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:37.912+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO TaskSetManager: Finished task 22.0 in stage 1336.1 (TID 2694) in 52 ms on 172.20.0.5 (executor 2) (20/41)
[2025-05-08T21:09:37.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO BlockManagerInfo: Added broadcast_295_piece0 in memory on 172.20.0.5:38279 (size: 6.6 KiB, free: 420.8 MiB)
[2025-05-08T21:09:37.926+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:39008
[2025-05-08T21:09:37.936+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:39008
[2025-05-08T21:09:37.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:39008
[2025-05-08T21:09:37.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:39008
[2025-05-08T21:09:37.991+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:39008
[2025-05-08T21:09:38.014+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:39008
[2025-05-08T21:09:38.061+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:39008
[2025-05-08T21:09:38.138+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:39008
[2025-05-08T21:09:38.370+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:39008
[2025-05-08T21:09:38.375+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO TaskSetManager: Starting task 1.0 in stage 1307.1 (TID 2696) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:38.376+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO TaskSetManager: Finished task 0.0 in stage 1307.1 (TID 2695) in 468 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-08T21:09:38.676+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO TaskSetManager: Starting task 2.0 in stage 1307.1 (TID 2697) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:38.676+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO TaskSetManager: Finished task 1.0 in stage 1307.1 (TID 2696) in 301 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-08T21:09:38.937+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO TaskSetManager: Starting task 3.0 in stage 1307.1 (TID 2698) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:38.937+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:38 INFO TaskSetManager: Finished task 2.0 in stage 1307.1 (TID 2697) in 261 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-08T21:09:39.240+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:39 INFO TaskSetManager: Starting task 4.0 in stage 1307.1 (TID 2699) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:39.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:39 INFO TaskSetManager: Finished task 3.0 in stage 1307.1 (TID 2698) in 304 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-08T21:09:39.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:39 INFO TaskSetManager: Starting task 5.0 in stage 1307.1 (TID 2700) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:39.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:39 INFO TaskSetManager: Finished task 4.0 in stage 1307.1 (TID 2699) in 273 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-08T21:09:39.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:39 INFO TaskSetManager: Starting task 6.0 in stage 1307.1 (TID 2701) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:39.828+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:39 INFO TaskSetManager: Finished task 5.0 in stage 1307.1 (TID 2700) in 314 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-08T21:09:40.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:40 INFO TaskSetManager: Starting task 7.0 in stage 1307.1 (TID 2702) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:09:40.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:09:40 INFO TaskSetManager: Finished task 6.0 in stage 1307.1 (TID 2701) in 473 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-08T21:12:51.121+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/2 is now LOST (worker lost)
[2025-05-08T21:12:51.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO StandaloneSchedulerBackend: Executor app-20250508193925-0005/2 removed: worker lost
[2025-05-08T21:12:51.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:12:51.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO StandaloneSchedulerBackend: Worker worker-20250508061515-172.20.0.5-45383 removed: Not receiving heartbeat for 60 seconds
[2025-05-08T21:12:51.180+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250508193925-0005/3 on worker-20250508061515-172.20.0.5-45383 (172.20.0.5:45383) with 1 core(s)
[2025-05-08T21:12:51.254+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 ERROR TaskSchedulerImpl: Lost executor 2 on 172.20.0.5: worker lost
[2025-05-08T21:12:51.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 22), so marking it as still running.
[2025-05-08T21:12:51.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 19), so marking it as still running.
[2025-05-08T21:12:51.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 16), so marking it as still running.
[2025-05-08T21:12:51.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 7), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 13), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 10), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 20), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 17), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 14), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 11), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 8), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 3), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 15), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 21), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 12), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 2), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 18), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 9), so marking it as still running.
[2025-05-08T21:12:51.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 6), so marking it as still running.
[2025-05-08T21:12:51.494+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN TaskSetManager: Lost task 7.0 in stage 1307.1 (TID 2702) (172.20.0.5 executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: worker lost
[2025-05-08T21:12:51.494+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20250508193925-0005/3 on hostPort 172.20.0.5:45383 with 1 core(s), 1024.0 MiB RAM
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 1), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1307, 2), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1307, 4), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1307, 1), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1307, 0), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1307, 3), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1307, 6), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Resubmitted ShuffleMapTask(1307, 5), so marking it as still running.
[2025-05-08T21:12:51.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Executor lost: 2 (epoch 241)
[2025-05-08T21:12:51.500+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO TaskSchedulerImpl: Handle removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:12:51.502+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
[2025-05-08T21:12:51.553+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_3 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_1 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_4 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_5 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_0 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_0 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_3 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_5 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_8 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_9 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_4 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_3 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_9 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_4 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_0 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_9 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_6 !
[2025-05-08T21:12:51.554+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_8 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_6 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_3 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_5 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_7 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_1 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_9 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_6 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_4 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_9 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_8 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_7 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_6 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_1 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_8 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_6 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_1 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_3 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_7 !
[2025-05-08T21:12:51.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_1 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_3 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_7 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_2 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_2 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_5 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_2 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_9 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_0 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_4 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_6 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_1 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_5 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_4 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_0 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_3 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_7 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_0 !
[2025-05-08T21:12:51.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_0 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_8 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_2 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_2 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_5 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_1 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_7 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_9 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_8 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_5 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_2 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_2 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_4 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_7 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_8 !
[2025-05-08T21:12:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_6 !
[2025-05-08T21:12:51.584+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, 172.20.0.5, 38279, None)
[2025-05-08T21:12:51.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO BlockManagerMaster: Removed 2 successfully in removeExecutor
[2025-05-08T21:12:51.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 241)
[2025-05-08T21:12:51.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO DAGScheduler: Shuffle files lost for worker worker-20250508061515-172.20.0.5-45383 on host 172.20.0.5
[2025-05-08T21:12:51.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/3 is now RUNNING
[2025-05-08T21:12:51.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 2702 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
[2025-05-08T21:12:51.801+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:51 WARN CoarseGrainedSchedulerBackend$DriverEndpoint: Ignored task status update (2702 state FAILED) from unknown executor with ID 2
[2025-05-08T21:12:55.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:55838) with ID 3,  ResourceProfileId 0
[2025-05-08T21:12:55.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:55 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:34029 with 434.4 MiB RAM, BlockManagerId(3, 172.20.0.5, 34029, None)
[2025-05-08T21:12:55.747+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:55 INFO TaskSetManager: Starting task 7.1 in stage 1307.1 (TID 2703) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:56.045+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Added broadcast_295_piece0 in memory on 172.20.0.5:34029 (size: 6.6 KiB, free: 434.4 MiB)
[2025-05-08T21:12:56.521+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:55838
[2025-05-08T21:12:56.577+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSetManager: Starting task 5.1 in stage 1307.1 (TID 2704) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:56.578+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 WARN TaskSetManager: Lost task 7.1 in stage 1307.1 (TID 2703) (172.20.0.5 executor 3): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=7, message=
[2025-05-08T21:12:56.578+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 7
[2025-05-08T21:12:56.578+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:12:56.578+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:12:56.579+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.580+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.581+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.582+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.583+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.584+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.585+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.586+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.587+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.588+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.589+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.590+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.591+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.592+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.593+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.593+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.593+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.593+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.593+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:12:56.593+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:12:56.594+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:12:56.595+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:12:56.595+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:12:56.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSetManager: task 7.1 in stage 1307.1 (TID 2703) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:12:56.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Marking ShuffleMapStage 1307 (mapPartitions at VertexRDDImpl.scala:247) as failed due to a fetch failure from ShuffleMapStage 1254 (map at GraphFrame.scala:187)
[2025-05-08T21:12:56.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: ShuffleMapStage 1307 (mapPartitions at VertexRDDImpl.scala:247) failed in 198.721 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 7
[2025-05-08T21:12:56.595+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:12:56.595+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:12:56.596+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:12:56.597+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:12:56.597+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:12:56.597+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:12:56.597+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:12:56.597+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.597+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.597+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.598+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.599+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.600+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.600+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.600+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.600+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.600+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.600+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.600+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.601+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.601+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.601+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.601+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.601+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.601+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.602+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:12:56.606+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:12:56.607+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:12:56.607+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:12:56.607+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Resubmitting ShuffleMapStage 1254 (map at GraphFrame.scala:187) and ShuffleMapStage 1307 (mapPartitions at VertexRDDImpl.scala:247) due to fetch failure
[2025-05-08T21:12:56.621+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:55838
[2025-05-08T21:12:56.636+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSetManager: Starting task 1.1 in stage 1336.1 (TID 2705) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:56.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 WARN TaskSetManager: Lost task 5.1 in stage 1307.1 (TID 2704) (172.20.0.5 executor 3): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=5, message=
[2025-05-08T21:12:56.637+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 5
[2025-05-08T21:12:56.637+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:12:56.637+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:12:56.637+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:12:56.637+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:12:56.637+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:12:56.638+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:12:56.639+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:12:56.639+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.639+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.639+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.640+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.641+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:12:56.642+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.643+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.644+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.645+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:12:56.646+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:12:56.647+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:12:56.647+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:12:56.647+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:12:56.647+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:12:56.647+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:12:56.647+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:12:56.647+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:12:56.648+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:12:56.648+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:12:56.648+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:12:56.648+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSetManager: task 5.1 in stage 1307.1 (TID 2704) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:12:56.648+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSchedulerImpl: Removed TaskSet 1307.1, whose tasks have all completed, from pool
[2025-05-08T21:12:56.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Added broadcast_275_piece0 in memory on 172.20.0.5:34029 (size: 40.1 KiB, free: 434.4 MiB)
[2025-05-08T21:12:56.782+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T21:12:56.785+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:12:56.787+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_296 stored as values in memory (estimated size 23.9 KiB, free 416.7 MiB)
[2025-05-08T21:12:56.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_296_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.7 MiB)
[2025-05-08T21:12:56.792+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Added broadcast_296_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:12:56.792+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO SparkContext: Created broadcast 296 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:56.793+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:56.793+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSchedulerImpl: Adding task set 1245.2 with 1 tasks resource profile 0
[2025-05-08T21:12:56.793+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:12:56.795+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_297 stored as values in memory (estimated size 22.4 KiB, free 416.7 MiB)
[2025-05-08T21:12:56.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_297_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.7 MiB)
[2025-05-08T21:12:56.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Added broadcast_297_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:12:56.814+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO SparkContext: Created broadcast 297 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:56.815+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:56.815+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSchedulerImpl: Adding task set 1246.2 with 1 tasks resource profile 0
[2025-05-08T21:12:56.816+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:12:56.817+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_298 stored as values in memory (estimated size 22.4 KiB, free 416.6 MiB)
[2025-05-08T21:12:56.817+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Removed broadcast_295_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.6 MiB)
[2025-05-08T21:12:56.822+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_298_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.6 MiB)
[2025-05-08T21:12:56.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Added broadcast_298_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:12:56.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO SparkContext: Created broadcast 298 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:56.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:56.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSchedulerImpl: Adding task set 1247.2 with 1 tasks resource profile 0
[2025-05-08T21:12:56.825+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:12:56.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_299 stored as values in memory (estimated size 28.8 KiB, free 416.6 MiB)
[2025-05-08T21:12:56.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO MemoryStore: Block broadcast_299_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.6 MiB)
[2025-05-08T21:12:56.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Added broadcast_299_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.5 MiB)
[2025-05-08T21:12:56.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO SparkContext: Created broadcast 299 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:56.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:56.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO TaskSchedulerImpl: Adding task set 1248.2 with 1 tasks resource profile 0
[2025-05-08T21:12:56.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Removed broadcast_295_piece0 on 172.20.0.5:34029 in memory (size: 6.6 KiB, free: 434.4 MiB)
[2025-05-08T21:12:56.856+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:56 INFO BlockManagerInfo: Removed broadcast_294_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.6 MiB)
[2025-05-08T21:12:57.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:12:57.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO TaskSetManager: Starting task 0.0 in stage 1245.2 (TID 2706) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:57.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 WARN TaskSetManager: Lost task 1.1 in stage 1336.1 (TID 2705) (172.20.0.5 executor 3): FetchFailed(null, shuffleId=115, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-08T21:12:57.301+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 115 partition 0
[2025-05-08T21:12:57.301+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:12:57.301+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:12:57.301+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:12:57.302+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:12:57.302+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:12:57.302+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:12:57.302+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:12:57.302+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:12:57.302+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:12:57.302+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.303+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.304+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.305+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:12:57.306+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:12:57.307+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:12:57.307+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:12:57.307+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:12:57.307+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO TaskSetManager: task 1.1 in stage 1336.1 (TID 2705) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:12:57.307+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO TaskSchedulerImpl: Removed TaskSet 1336.1, whose tasks have all completed, from pool
[2025-05-08T21:12:57.307+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Marking ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T21:12:57.307+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) failed in 210.767 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 115 partition 0
[2025-05-08T21:12:57.308+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:12:57.308+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:12:57.308+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:12:57.308+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:12:57.308+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:12:57.308+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:12:57.308+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:12:57.309+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.310+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.311+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.312+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.312+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.312+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.312+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:12:57.312+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:12:57.312+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:12:57.312+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:12:57.313+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:12:57.313+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:12:57.313+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:12:57.313+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:12:57.313+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:12:57.313+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:12:57.313+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:12:57.314+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:12:57.314+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:12:57.314+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:12:57.314+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Resubmitting ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229) and ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) due to fetch failure
[2025-05-08T21:12:57.316+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO BlockManagerInfo: Added broadcast_296_piece0 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:12:57.501+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T21:12:57.502+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:12:57.503+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_300 stored as values in memory (estimated size 23.9 KiB, free 416.9 MiB)
[2025-05-08T21:12:57.504+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_300_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.9 MiB)
[2025-05-08T21:12:57.505+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO BlockManagerInfo: Added broadcast_300_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:12:57.506+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO SparkContext: Created broadcast 300 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:57.508+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:57.509+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO TaskSchedulerImpl: Adding task set 1331.3 with 1 tasks resource profile 0
[2025-05-08T21:12:57.509+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:12:57.510+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_301 stored as values in memory (estimated size 22.4 KiB, free 416.9 MiB)
[2025-05-08T21:12:57.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_301_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.9 MiB)
[2025-05-08T21:12:57.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO BlockManagerInfo: Added broadcast_301_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:12:57.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO SparkContext: Created broadcast 301 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:57.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:57.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO TaskSchedulerImpl: Adding task set 1332.3 with 1 tasks resource profile 0
[2025-05-08T21:12:57.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:12:57.515+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_302 stored as values in memory (estimated size 22.4 KiB, free 416.8 MiB)
[2025-05-08T21:12:57.531+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_302_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.8 MiB)
[2025-05-08T21:12:57.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO BlockManagerInfo: Added broadcast_302_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:12:57.533+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO BlockManagerInfo: Removed broadcast_275_piece0 on f2a432e4376a:35283 in memory (size: 40.1 KiB, free: 432.6 MiB)
[2025-05-08T21:12:57.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO SparkContext: Created broadcast 302 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:57.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:57.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO TaskSchedulerImpl: Adding task set 1333.3 with 1 tasks resource profile 0
[2025-05-08T21:12:57.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:12:57.537+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_303 stored as values in memory (estimated size 28.8 KiB, free 416.9 MiB)
[2025-05-08T21:12:57.538+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO MemoryStore: Block broadcast_303_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.9 MiB)
[2025-05-08T21:12:57.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO BlockManagerInfo: Added broadcast_303_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:12:57.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO SparkContext: Created broadcast 303 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:57.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:12:57.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO TaskSchedulerImpl: Adding task set 1334.3 with 1 tasks resource profile 0
[2025-05-08T21:12:57.541+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:57 INFO BlockManagerInfo: Removed broadcast_275_piece0 on 172.20.0.5:34029 in memory (size: 40.1 KiB, free: 434.4 MiB)
[2025-05-08T21:12:58.439+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO TaskSetManager: Starting task 0.0 in stage 1246.2 (TID 2707) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:58.440+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO TaskSetManager: Finished task 0.0 in stage 1245.2 (TID 2706) in 1139 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:12:58.440+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO TaskSchedulerImpl: Removed TaskSet 1245.2, whose tasks have all completed, from pool
[2025-05-08T21:12:58.442+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: ShuffleMapStage 1245 (rdd at GraphFrame.scala:187) finished in 1.656 s
[2025-05-08T21:12:58.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:12:58.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1247, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1246, ShuffleMapStage 1333)
[2025-05-08T21:12:58.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:12:58.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: failed: Set()
[2025-05-08T21:12:58.451+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO BlockManagerInfo: Added broadcast_297_piece0 in memory on 172.20.0.5:34029 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:12:58.928+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO TaskSetManager: Starting task 0.0 in stage 1247.2 (TID 2708) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:58.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO TaskSetManager: Finished task 0.0 in stage 1246.2 (TID 2707) in 489 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:12:58.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO TaskSchedulerImpl: Removed TaskSet 1246.2, whose tasks have all completed, from pool
[2025-05-08T21:12:58.930+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: ShuffleMapStage 1246 (rdd at GraphFrame.scala:187) finished in 2.137 s
[2025-05-08T21:12:58.930+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:12:58.930+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1247, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:12:58.931+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:12:58.931+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO DAGScheduler: failed: Set()
[2025-05-08T21:12:58.946+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:58 INFO BlockManagerInfo: Added broadcast_298_piece0 in memory on 172.20.0.5:34029 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:12:59.057+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSetManager: Starting task 0.0 in stage 1248.2 (TID 2709) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:59.058+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSetManager: Finished task 0.0 in stage 1247.2 (TID 2708) in 130 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:12:59.058+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSchedulerImpl: Removed TaskSet 1247.2, whose tasks have all completed, from pool
[2025-05-08T21:12:59.058+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: ShuffleMapStage 1247 (rdd at GraphFrame.scala:187) finished in 2.243 s
[2025-05-08T21:12:59.058+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:12:59.059+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:12:59.059+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:12:59.059+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: failed: Set()
[2025-05-08T21:12:59.068+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO BlockManagerInfo: Added broadcast_299_piece0 in memory on 172.20.0.5:34029 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T21:12:59.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSetManager: Starting task 0.0 in stage 1331.3 (TID 2710) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:59.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSetManager: Finished task 0.0 in stage 1248.2 (TID 2709) in 639 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:12:59.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSchedulerImpl: Removed TaskSet 1248.2, whose tasks have all completed, from pool
[2025-05-08T21:12:59.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: ShuffleMapStage 1248 (rdd at GraphFrame.scala:187) finished in 2.873 s
[2025-05-08T21:12:59.697+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:12:59.697+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:12:59.697+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:12:59.697+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: failed: Set()
[2025-05-08T21:12:59.697+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: Submitting ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:12:59.704+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO MemoryStore: Block broadcast_304 stored as values in memory (estimated size 96.7 KiB, free 416.8 MiB)
[2025-05-08T21:12:59.706+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO MemoryStore: Block broadcast_304_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 416.8 MiB)
[2025-05-08T21:12:59.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO BlockManagerInfo: Added broadcast_304_piece0 in memory on f2a432e4376a:35283 (size: 36.3 KiB, free: 432.6 MiB)
[2025-05-08T21:12:59.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO SparkContext: Created broadcast 304 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:12:59.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:12:59.708+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSchedulerImpl: Adding task set 1249.2 with 41 tasks resource profile 0
[2025-05-08T21:12:59.713+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO BlockManagerInfo: Added broadcast_300_piece0 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:12:59.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSetManager: Starting task 1.0 in stage 1249.2 (TID 2711) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:12:59.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSetManager: Finished task 0.0 in stage 1331.3 (TID 2710) in 79 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:12:59.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO TaskSchedulerImpl: Removed TaskSet 1331.3, whose tasks have all completed, from pool
[2025-05-08T21:12:59.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229) finished in 2.273 s
[2025-05-08T21:12:59.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:12:59.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1332, ShuffleMapStage 1249, ShuffleMapStage 1333)
[2025-05-08T21:12:59.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:12:59.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO DAGScheduler: failed: Set()
[2025-05-08T21:12:59.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO BlockManagerInfo: Added broadcast_304_piece0 in memory on 172.20.0.5:34029 (size: 36.3 KiB, free: 434.3 MiB)
[2025-05-08T21:12:59.805+0000] {spark_submit.py:571} INFO - 25/05/08 21:12:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:55838
[2025-05-08T21:13:01.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 2.0 in stage 1249.2 (TID 2712) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.448+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 1.0 in stage 1249.2 (TID 2711) in 1674 ms on 172.20.0.5 (executor 3) (1/41)
[2025-05-08T21:13:01.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 3.0 in stage 1249.2 (TID 2713) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 2.0 in stage 1249.2 (TID 2712) in 101 ms on 172.20.0.5 (executor 3) (2/41)
[2025-05-08T21:13:01.589+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 6.0 in stage 1249.2 (TID 2714) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.589+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 3.0 in stage 1249.2 (TID 2713) in 42 ms on 172.20.0.5 (executor 3) (3/41)
[2025-05-08T21:13:01.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 7.0 in stage 1249.2 (TID 2715) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 6.0 in stage 1249.2 (TID 2714) in 55 ms on 172.20.0.5 (executor 3) (4/41)
[2025-05-08T21:13:01.745+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 8.0 in stage 1249.2 (TID 2716) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.745+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 7.0 in stage 1249.2 (TID 2715) in 101 ms on 172.20.0.5 (executor 3) (5/41)
[2025-05-08T21:13:01.818+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 9.0 in stage 1249.2 (TID 2717) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.818+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 8.0 in stage 1249.2 (TID 2716) in 74 ms on 172.20.0.5 (executor 3) (6/41)
[2025-05-08T21:13:01.855+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 10.0 in stage 1249.2 (TID 2718) (172.20.0.5, executor 3, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 9.0 in stage 1249.2 (TID 2717) in 40 ms on 172.20.0.5 (executor 3) (7/41)
[2025-05-08T21:13:01.903+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Starting task 11.0 in stage 1249.2 (TID 2719) (172.20.0.5, executor 3, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:01.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO TaskSetManager: Finished task 10.0 in stage 1249.2 (TID 2718) in 49 ms on 172.20.0.5 (executor 3) (8/41)
[2025-05-08T21:13:01.912+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:55838
[2025-05-08T21:13:02.002+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 12.0 in stage 1249.2 (TID 2720) (172.20.0.5, executor 3, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 11.0 in stage 1249.2 (TID 2719) in 100 ms on 172.20.0.5 (executor 3) (9/41)
[2025-05-08T21:13:02.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 13.0 in stage 1249.2 (TID 2721) (172.20.0.5, executor 3, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 12.0 in stage 1249.2 (TID 2720) in 77 ms on 172.20.0.5 (executor 3) (10/41)
[2025-05-08T21:13:02.150+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 14.0 in stage 1249.2 (TID 2722) (172.20.0.5, executor 3, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.151+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 13.0 in stage 1249.2 (TID 2721) in 71 ms on 172.20.0.5 (executor 3) (11/41)
[2025-05-08T21:13:02.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 15.0 in stage 1249.2 (TID 2723) (172.20.0.5, executor 3, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 14.0 in stage 1249.2 (TID 2722) in 55 ms on 172.20.0.5 (executor 3) (12/41)
[2025-05-08T21:13:02.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 16.0 in stage 1249.2 (TID 2724) (172.20.0.5, executor 3, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 15.0 in stage 1249.2 (TID 2723) in 92 ms on 172.20.0.5 (executor 3) (13/41)
[2025-05-08T21:13:02.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 17.0 in stage 1249.2 (TID 2725) (172.20.0.5, executor 3, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.363+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 16.0 in stage 1249.2 (TID 2724) in 67 ms on 172.20.0.5 (executor 3) (14/41)
[2025-05-08T21:13:02.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 18.0 in stage 1249.2 (TID 2726) (172.20.0.5, executor 3, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 17.0 in stage 1249.2 (TID 2725) in 117 ms on 172.20.0.5 (executor 3) (15/41)
[2025-05-08T21:13:02.542+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 19.0 in stage 1249.2 (TID 2727) (172.20.0.5, executor 3, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 18.0 in stage 1249.2 (TID 2726) in 67 ms on 172.20.0.5 (executor 3) (16/41)
[2025-05-08T21:13:02.621+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 20.0 in stage 1249.2 (TID 2728) (172.20.0.5, executor 3, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 19.0 in stage 1249.2 (TID 2727) in 81 ms on 172.20.0.5 (executor 3) (17/41)
[2025-05-08T21:13:02.706+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 21.0 in stage 1249.2 (TID 2729) (172.20.0.5, executor 3, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.708+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 20.0 in stage 1249.2 (TID 2728) in 84 ms on 172.20.0.5 (executor 3) (18/41)
[2025-05-08T21:13:02.724+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:55838
[2025-05-08T21:13:02.804+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 22.0 in stage 1249.2 (TID 2730) (172.20.0.5, executor 3, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.806+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 21.0 in stage 1249.2 (TID 2729) in 99 ms on 172.20.0.5 (executor 3) (19/41)
[2025-05-08T21:13:02.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 23.0 in stage 1249.2 (TID 2731) (172.20.0.5, executor 3, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.848+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 22.0 in stage 1249.2 (TID 2730) in 44 ms on 172.20.0.5 (executor 3) (20/41)
[2025-05-08T21:13:02.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 24.0 in stage 1249.2 (TID 2732) (172.20.0.5, executor 3, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 23.0 in stage 1249.2 (TID 2731) in 47 ms on 172.20.0.5 (executor 3) (21/41)
[2025-05-08T21:13:02.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 25.0 in stage 1249.2 (TID 2733) (172.20.0.5, executor 3, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.942+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 24.0 in stage 1249.2 (TID 2732) in 48 ms on 172.20.0.5 (executor 3) (22/41)
[2025-05-08T21:13:02.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Starting task 26.0 in stage 1249.2 (TID 2734) (172.20.0.5, executor 3, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:02.983+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:02 INFO TaskSetManager: Finished task 25.0 in stage 1249.2 (TID 2733) in 41 ms on 172.20.0.5 (executor 3) (23/41)
[2025-05-08T21:13:03.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 27.0 in stage 1249.2 (TID 2735) (172.20.0.5, executor 3, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 26.0 in stage 1249.2 (TID 2734) in 49 ms on 172.20.0.5 (executor 3) (24/41)
[2025-05-08T21:13:03.074+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 28.0 in stage 1249.2 (TID 2736) (172.20.0.5, executor 3, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.075+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 27.0 in stage 1249.2 (TID 2735) in 44 ms on 172.20.0.5 (executor 3) (25/41)
[2025-05-08T21:13:03.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 29.0 in stage 1249.2 (TID 2737) (172.20.0.5, executor 3, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 28.0 in stage 1249.2 (TID 2736) in 50 ms on 172.20.0.5 (executor 3) (26/41)
[2025-05-08T21:13:03.157+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 30.0 in stage 1249.2 (TID 2738) (172.20.0.5, executor 3, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 29.0 in stage 1249.2 (TID 2737) in 34 ms on 172.20.0.5 (executor 3) (27/41)
[2025-05-08T21:13:03.211+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 31.0 in stage 1249.2 (TID 2739) (172.20.0.5, executor 3, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.213+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 30.0 in stage 1249.2 (TID 2738) in 55 ms on 172.20.0.5 (executor 3) (28/41)
[2025-05-08T21:13:03.223+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:55838
[2025-05-08T21:13:03.281+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 32.0 in stage 1249.2 (TID 2740) (172.20.0.5, executor 3, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.283+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 31.0 in stage 1249.2 (TID 2739) in 73 ms on 172.20.0.5 (executor 3) (29/41)
[2025-05-08T21:13:03.336+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 33.0 in stage 1249.2 (TID 2741) (172.20.0.5, executor 3, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.337+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 32.0 in stage 1249.2 (TID 2740) in 55 ms on 172.20.0.5 (executor 3) (30/41)
[2025-05-08T21:13:03.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 34.0 in stage 1249.2 (TID 2742) (172.20.0.5, executor 3, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.386+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 33.0 in stage 1249.2 (TID 2741) in 49 ms on 172.20.0.5 (executor 3) (31/41)
[2025-05-08T21:13:03.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 35.0 in stage 1249.2 (TID 2743) (172.20.0.5, executor 3, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 34.0 in stage 1249.2 (TID 2742) in 60 ms on 172.20.0.5 (executor 3) (32/41)
[2025-05-08T21:13:03.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 36.0 in stage 1249.2 (TID 2744) (172.20.0.5, executor 3, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 35.0 in stage 1249.2 (TID 2743) in 36 ms on 172.20.0.5 (executor 3) (33/41)
[2025-05-08T21:13:03.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 37.0 in stage 1249.2 (TID 2745) (172.20.0.5, executor 3, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 36.0 in stage 1249.2 (TID 2744) in 57 ms on 172.20.0.5 (executor 3) (34/41)
[2025-05-08T21:13:03.573+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 38.0 in stage 1249.2 (TID 2746) (172.20.0.5, executor 3, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 37.0 in stage 1249.2 (TID 2745) in 40 ms on 172.20.0.5 (executor 3) (35/41)
[2025-05-08T21:13:03.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 39.0 in stage 1249.2 (TID 2747) (172.20.0.5, executor 3, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.628+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 38.0 in stage 1249.2 (TID 2746) in 55 ms on 172.20.0.5 (executor 3) (36/41)
[2025-05-08T21:13:03.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 40.0 in stage 1249.2 (TID 2748) (172.20.0.5, executor 3, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 39.0 in stage 1249.2 (TID 2747) in 34 ms on 172.20.0.5 (executor 3) (37/41)
[2025-05-08T21:13:03.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 0.0 in stage 1249.2 (TID 2749) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 40.0 in stage 1249.2 (TID 2748) in 27 ms on 172.20.0.5 (executor 3) (38/41)
[2025-05-08T21:13:03.758+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 4.0 in stage 1249.2 (TID 2750) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.759+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 0.0 in stage 1249.2 (TID 2749) in 71 ms on 172.20.0.5 (executor 3) (39/41)
[2025-05-08T21:13:03.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 5.0 in stage 1249.2 (TID 2751) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 4.0 in stage 1249.2 (TID 2750) in 31 ms on 172.20.0.5 (executor 3) (40/41)
[2025-05-08T21:13:03.807+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 0.0 in stage 1332.3 (TID 2752) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 5.0 in stage 1249.2 (TID 2751) in 20 ms on 172.20.0.5 (executor 3) (41/41)
[2025-05-08T21:13:03.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSchedulerImpl: Removed TaskSet 1249.2, whose tasks have all completed, from pool
[2025-05-08T21:13:03.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: ShuffleMapStage 1249 (rdd at GraphFrame.scala:187) finished in 4.109 s
[2025-05-08T21:13:03.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:03.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:13:03.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:03.809+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:03.809+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: Submitting ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:13:03.814+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO MemoryStore: Block broadcast_305 stored as values in memory (estimated size 70.3 KiB, free 416.7 MiB)
[2025-05-08T21:13:03.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO MemoryStore: Block broadcast_305_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 416.7 MiB)
[2025-05-08T21:13:03.835+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Added broadcast_305_piece0 in memory on f2a432e4376a:35283 (size: 28.3 KiB, free: 432.5 MiB)
[2025-05-08T21:13:03.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_299_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:13:03.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO SparkContext: Created broadcast 305 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:03.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:03.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSchedulerImpl: Adding task set 1250.2 with 10 tasks resource profile 0
[2025-05-08T21:13:03.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: Submitting ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:13:03.841+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_299_piece0 on 172.20.0.5:34029 in memory (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T21:13:03.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO MemoryStore: Block broadcast_306 stored as values in memory (estimated size 70.6 KiB, free 416.7 MiB)
[2025-05-08T21:13:03.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Added broadcast_301_piece0 in memory on 172.20.0.5:34029 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:13:03.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO MemoryStore: Block broadcast_306_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 416.6 MiB)
[2025-05-08T21:13:03.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Added broadcast_306_piece0 in memory on f2a432e4376a:35283 (size: 28.5 KiB, free: 432.5 MiB)
[2025-05-08T21:13:03.849+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO SparkContext: Created broadcast 306 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:03.849+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:03.850+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSchedulerImpl: Adding task set 1251.2 with 10 tasks resource profile 0
[2025-05-08T21:13:03.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_298_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.5 MiB)
[2025-05-08T21:13:03.854+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_298_piece0 on 172.20.0.5:34029 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:13:03.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_296_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:13:03.861+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_296_piece0 on 172.20.0.5:34029 in memory (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:13:03.868+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_300_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:13:03.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_300_piece0 on 172.20.0.5:34029 in memory (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:13:03.881+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_297_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:13:03.882+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO BlockManagerInfo: Removed broadcast_297_piece0 on 172.20.0.5:34029 in memory (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:13:03.954+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Starting task 0.0 in stage 1250.2 (TID 2753) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:03.954+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSetManager: Finished task 0.0 in stage 1332.3 (TID 2752) in 146 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:13:03.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO TaskSchedulerImpl: Removed TaskSet 1332.3, whose tasks have all completed, from pool
[2025-05-08T21:13:03.958+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: ShuffleMapStage 1332 (collect at /opt/airflow/spark/build_graph.py:229) finished in 6.448 s
[2025-05-08T21:13:03.960+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:03.962+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1250, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1251, ShuffleMapStage 1333)
[2025-05-08T21:13:03.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:03.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:03 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:04.005+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Added broadcast_305_piece0 in memory on 172.20.0.5:34029 (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.033+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:55838
[2025-05-08T21:13:04.147+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 1.0 in stage 1250.2 (TID 2754) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.147+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 0.0 in stage 1250.2 (TID 2753) in 194 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:04.180+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 2.0 in stage 1250.2 (TID 2755) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.181+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 1.0 in stage 1250.2 (TID 2754) in 34 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:04.217+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 3.0 in stage 1250.2 (TID 2756) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.218+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 2.0 in stage 1250.2 (TID 2755) in 37 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:04.248+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 4.0 in stage 1250.2 (TID 2757) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.249+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 3.0 in stage 1250.2 (TID 2756) in 32 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:04.281+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 5.0 in stage 1250.2 (TID 2758) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 4.0 in stage 1250.2 (TID 2757) in 33 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:04.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 6.0 in stage 1250.2 (TID 2759) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.313+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 5.0 in stage 1250.2 (TID 2758) in 32 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:04.338+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 7.0 in stage 1250.2 (TID 2760) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.338+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 6.0 in stage 1250.2 (TID 2759) in 26 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:04.362+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 8.0 in stage 1250.2 (TID 2761) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.362+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 7.0 in stage 1250.2 (TID 2760) in 25 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:04.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 9.0 in stage 1250.2 (TID 2762) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 8.0 in stage 1250.2 (TID 2761) in 22 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:04.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 0.0 in stage 1251.2 (TID 2763) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 9.0 in stage 1250.2 (TID 2762) in 32 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:04.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSchedulerImpl: Removed TaskSet 1250.2, whose tasks have all completed, from pool
[2025-05-08T21:13:04.417+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: ShuffleMapStage 1250 (rdd at GraphFrame.scala:187) finished in 0.608 s
[2025-05-08T21:13:04.418+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:04.418+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1251, ShuffleMapStage 1333)
[2025-05-08T21:13:04.418+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:04.418+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:04.423+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Added broadcast_306_piece0 in memory on 172.20.0.5:34029 (size: 28.5 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 1.0 in stage 1251.2 (TID 2764) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 0.0 in stage 1251.2 (TID 2763) in 60 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:04.499+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 2.0 in stage 1251.2 (TID 2765) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.499+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 1.0 in stage 1251.2 (TID 2764) in 24 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:04.527+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 3.0 in stage 1251.2 (TID 2766) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.528+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 2.0 in stage 1251.2 (TID 2765) in 29 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:04.549+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 4.0 in stage 1251.2 (TID 2767) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.549+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 3.0 in stage 1251.2 (TID 2766) in 22 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:04.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 5.0 in stage 1251.2 (TID 2768) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 4.0 in stage 1251.2 (TID 2767) in 22 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:04.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 6.0 in stage 1251.2 (TID 2769) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.591+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 5.0 in stage 1251.2 (TID 2768) in 20 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:04.610+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 7.0 in stage 1251.2 (TID 2770) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.610+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 6.0 in stage 1251.2 (TID 2769) in 20 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:04.629+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 8.0 in stage 1251.2 (TID 2771) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.629+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 7.0 in stage 1251.2 (TID 2770) in 20 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:04.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 9.0 in stage 1251.2 (TID 2772) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 8.0 in stage 1251.2 (TID 2771) in 25 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:04.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 0.0 in stage 1333.3 (TID 2773) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 9.0 in stage 1251.2 (TID 2772) in 20 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:04.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSchedulerImpl: Removed TaskSet 1251.2, whose tasks have all completed, from pool
[2025-05-08T21:13:04.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: ShuffleMapStage 1251 (rdd at GraphFrame.scala:187) finished in 0.837 s
[2025-05-08T21:13:04.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:04.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1333)
[2025-05-08T21:13:04.675+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:04.675+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:04.675+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: Submitting ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:13:04.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO MemoryStore: Block broadcast_307 stored as values in memory (estimated size 83.7 KiB, free 416.7 MiB)
[2025-05-08T21:13:04.680+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO MemoryStore: Block broadcast_307_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 416.7 MiB)
[2025-05-08T21:13:04.680+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Added broadcast_307_piece0 in memory on f2a432e4376a:35283 (size: 32.1 KiB, free: 432.5 MiB)
[2025-05-08T21:13:04.680+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO SparkContext: Created broadcast 307 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:04.681+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Added broadcast_302_piece0 in memory on 172.20.0.5:34029 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.681+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: Submitting 20 missing tasks from ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:13:04.681+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSchedulerImpl: Adding task set 1252.2 with 20 tasks resource profile 0
[2025-05-08T21:13:04.726+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 0.0 in stage 1252.2 (TID 2774) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.726+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 0.0 in stage 1333.3 (TID 2773) in 53 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:13:04.726+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSchedulerImpl: Removed TaskSet 1333.3, whose tasks have all completed, from pool
[2025-05-08T21:13:04.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: ShuffleMapStage 1333 (collect at /opt/airflow/spark/build_graph.py:229) finished in 7.213 s
[2025-05-08T21:13:04.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:04.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1252)
[2025-05-08T21:13:04.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:04.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:04.732+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Added broadcast_307_piece0 in memory on 172.20.0.5:34029 (size: 32.1 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.738+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:55838
[2025-05-08T21:13:04.775+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 1.0 in stage 1252.2 (TID 2775) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 0.0 in stage 1252.2 (TID 2774) in 50 ms on 172.20.0.5 (executor 3) (1/20)
[2025-05-08T21:13:04.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 2.0 in stage 1252.2 (TID 2776) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 1.0 in stage 1252.2 (TID 2775) in 14 ms on 172.20.0.5 (executor 3) (2/20)
[2025-05-08T21:13:04.804+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 3.0 in stage 1252.2 (TID 2777) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.805+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 2.0 in stage 1252.2 (TID 2776) in 15 ms on 172.20.0.5 (executor 3) (3/20)
[2025-05-08T21:13:04.818+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 4.0 in stage 1252.2 (TID 2778) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.819+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 3.0 in stage 1252.2 (TID 2777) in 14 ms on 172.20.0.5 (executor 3) (4/20)
[2025-05-08T21:13:04.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 5.0 in stage 1252.2 (TID 2779) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 4.0 in stage 1252.2 (TID 2778) in 13 ms on 172.20.0.5 (executor 3) (5/20)
[2025-05-08T21:13:04.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 6.0 in stage 1252.2 (TID 2780) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 5.0 in stage 1252.2 (TID 2779) in 14 ms on 172.20.0.5 (executor 3) (6/20)
[2025-05-08T21:13:04.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 7.0 in stage 1252.2 (TID 2781) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.859+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 6.0 in stage 1252.2 (TID 2780) in 14 ms on 172.20.0.5 (executor 3) (7/20)
[2025-05-08T21:13:04.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 8.0 in stage 1252.2 (TID 2782) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 7.0 in stage 1252.2 (TID 2781) in 14 ms on 172.20.0.5 (executor 3) (8/20)
[2025-05-08T21:13:04.886+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 9.0 in stage 1252.2 (TID 2783) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.886+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 8.0 in stage 1252.2 (TID 2782) in 15 ms on 172.20.0.5 (executor 3) (9/20)
[2025-05-08T21:13:04.898+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 10.0 in stage 1252.2 (TID 2784) (172.20.0.5, executor 3, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.899+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 9.0 in stage 1252.2 (TID 2783) in 13 ms on 172.20.0.5 (executor 3) (10/20)
[2025-05-08T21:13:04.905+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:55838
[2025-05-08T21:13:04.923+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_305_piece0 on f2a432e4376a:35283 in memory (size: 28.3 KiB, free: 432.6 MiB)
[2025-05-08T21:13:04.927+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_305_piece0 on 172.20.0.5:34029 in memory (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.935+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_302_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:13:04.937+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_302_piece0 on 172.20.0.5:34029 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.945+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_301_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:13:04.947+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_301_piece0 on 172.20.0.5:34029 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.955+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_304_piece0 on f2a432e4376a:35283 in memory (size: 36.3 KiB, free: 432.6 MiB)
[2025-05-08T21:13:04.960+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_304_piece0 on 172.20.0.5:34029 in memory (size: 36.3 KiB, free: 434.3 MiB)
[2025-05-08T21:13:04.960+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 11.0 in stage 1252.2 (TID 2785) (172.20.0.5, executor 3, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.961+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 10.0 in stage 1252.2 (TID 2784) in 63 ms on 172.20.0.5 (executor 3) (11/20)
[2025-05-08T21:13:04.972+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_306_piece0 on f2a432e4376a:35283 in memory (size: 28.5 KiB, free: 432.7 MiB)
[2025-05-08T21:13:04.974+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO BlockManagerInfo: Removed broadcast_306_piece0 on 172.20.0.5:34029 in memory (size: 28.5 KiB, free: 434.4 MiB)
[2025-05-08T21:13:04.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 12.0 in stage 1252.2 (TID 2786) (172.20.0.5, executor 3, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.983+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 11.0 in stage 1252.2 (TID 2785) in 22 ms on 172.20.0.5 (executor 3) (12/20)
[2025-05-08T21:13:04.998+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Starting task 13.0 in stage 1252.2 (TID 2787) (172.20.0.5, executor 3, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:04.999+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:04 INFO TaskSetManager: Finished task 12.0 in stage 1252.2 (TID 2786) in 17 ms on 172.20.0.5 (executor 3) (13/20)
[2025-05-08T21:13:05.019+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 14.0 in stage 1252.2 (TID 2788) (172.20.0.5, executor 3, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.020+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 13.0 in stage 1252.2 (TID 2787) in 23 ms on 172.20.0.5 (executor 3) (14/20)
[2025-05-08T21:13:05.041+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 15.0 in stage 1252.2 (TID 2789) (172.20.0.5, executor 3, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.043+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 14.0 in stage 1252.2 (TID 2788) in 23 ms on 172.20.0.5 (executor 3) (15/20)
[2025-05-08T21:13:05.072+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 16.0 in stage 1252.2 (TID 2790) (172.20.0.5, executor 3, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.073+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 15.0 in stage 1252.2 (TID 2789) in 31 ms on 172.20.0.5 (executor 3) (16/20)
[2025-05-08T21:13:05.090+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 17.0 in stage 1252.2 (TID 2791) (172.20.0.5, executor 3, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.090+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 16.0 in stage 1252.2 (TID 2790) in 19 ms on 172.20.0.5 (executor 3) (17/20)
[2025-05-08T21:13:05.106+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 18.0 in stage 1252.2 (TID 2792) (172.20.0.5, executor 3, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.107+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 17.0 in stage 1252.2 (TID 2791) in 17 ms on 172.20.0.5 (executor 3) (18/20)
[2025-05-08T21:13:05.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 19.0 in stage 1252.2 (TID 2793) (172.20.0.5, executor 3, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 18.0 in stage 1252.2 (TID 2792) in 17 ms on 172.20.0.5 (executor 3) (19/20)
[2025-05-08T21:13:05.141+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 0.0 in stage 1334.3 (TID 2794) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 19.0 in stage 1252.2 (TID 2793) in 19 ms on 172.20.0.5 (executor 3) (20/20)
[2025-05-08T21:13:05.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSchedulerImpl: Removed TaskSet 1252.2, whose tasks have all completed, from pool
[2025-05-08T21:13:05.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: ShuffleMapStage 1252 (rdd at GraphFrame.scala:187) finished in 0.466 s
[2025-05-08T21:13:05.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:05.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342)
[2025-05-08T21:13:05.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:05.143+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:05.143+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:13:05.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added broadcast_303_piece0 in memory on 172.20.0.5:34029 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T21:13:05.150+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_308 stored as values in memory (estimated size 189.5 KiB, free 416.9 MiB)
[2025-05-08T21:13:05.152+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_308_piece0 stored as bytes in memory (estimated size 65.0 KiB, free 416.8 MiB)
[2025-05-08T21:13:05.153+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added broadcast_308_piece0 in memory on f2a432e4376a:35283 (size: 65.0 KiB, free: 432.6 MiB)
[2025-05-08T21:13:05.153+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO SparkContext: Created broadcast 308 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:05.153+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:05.154+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSchedulerImpl: Adding task set 1254.2 with 10 tasks resource profile 0
[2025-05-08T21:13:05.154+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-08T21:13:05.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_309 stored as values in memory (estimated size 232.9 KiB, free 416.6 MiB)
[2025-05-08T21:13:05.163+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_309_piece0 stored as bytes in memory (estimated size 77.4 KiB, free 416.5 MiB)
[2025-05-08T21:13:05.163+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added broadcast_309_piece0 in memory on f2a432e4376a:35283 (size: 77.4 KiB, free: 432.5 MiB)
[2025-05-08T21:13:05.164+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO SparkContext: Created broadcast 309 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:05.164+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:05.164+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSchedulerImpl: Adding task set 1255.2 with 10 tasks resource profile 0
[2025-05-08T21:13:05.164+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:05.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_310 stored as values in memory (estimated size 235.8 KiB, free 416.3 MiB)
[2025-05-08T21:13:05.173+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_310_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 416.2 MiB)
[2025-05-08T21:13:05.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added broadcast_310_piece0 in memory on f2a432e4376a:35283 (size: 77.8 KiB, free: 432.4 MiB)
[2025-05-08T21:13:05.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO SparkContext: Created broadcast 310 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:05.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:05.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSchedulerImpl: Adding task set 1287.2 with 10 tasks resource profile 0
[2025-05-08T21:13:05.217+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 0.0 in stage 1254.2 (TID 2795) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.218+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 0.0 in stage 1334.3 (TID 2794) in 76 ms on 172.20.0.5 (executor 3) (1/1)
[2025-05-08T21:13:05.218+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSchedulerImpl: Removed TaskSet 1334.3, whose tasks have all completed, from pool
[2025-05-08T21:13:05.219+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: ShuffleMapStage 1334 (collect at /opt/airflow/spark/build_graph.py:229) finished in 7.684 s
[2025-05-08T21:13:05.219+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:05.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1254, ShuffleMapStage 1338, ShuffleMapStage 1287, ShuffleMapStage 1255, ResultStage 1342)
[2025-05-08T21:13:05.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:05.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:05.220+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:13:05.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1336.
[2025-05-08T21:13:05.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_311 stored as values in memory (estimated size 109.8 KiB, free 416.1 MiB)
[2025-05-08T21:13:05.257+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MemoryStore: Block broadcast_311_piece0 stored as bytes in memory (estimated size 40.2 KiB, free 416.0 MiB)
[2025-05-08T21:13:05.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added broadcast_311_piece0 in memory on f2a432e4376a:35283 (size: 40.2 KiB, free: 432.4 MiB)
[2025-05-08T21:13:05.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO SparkContext: Created broadcast 311 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:05.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:13:05.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSchedulerImpl: Adding task set 1336.2 with 41 tasks resource profile 0
[2025-05-08T21:13:05.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Removed broadcast_307_piece0 on f2a432e4376a:35283 in memory (size: 32.1 KiB, free: 432.4 MiB)
[2025-05-08T21:13:05.273+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Removed broadcast_307_piece0 on 172.20.0.5:34029 in memory (size: 32.1 KiB, free: 434.4 MiB)
[2025-05-08T21:13:05.273+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added broadcast_308_piece0 in memory on 172.20.0.5:34029 (size: 65.0 KiB, free: 434.3 MiB)
[2025-05-08T21:13:05.565+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:55838
[2025-05-08T21:13:05.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added rdd_169_0 in memory on 172.20.0.5:34029 (size: 8.5 KiB, free: 434.3 MiB)
[2025-05-08T21:13:05.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:34029 (size: 94.3 KiB, free: 434.2 MiB)
[2025-05-08T21:13:05.857+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 1.0 in stage 1254.2 (TID 2796) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 0.0 in stage 1254.2 (TID 2795) in 642 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:05.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added rdd_169_1 in memory on 172.20.0.5:34029 (size: 8.0 KiB, free: 434.2 MiB)
[2025-05-08T21:13:05.916+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 2.0 in stage 1254.2 (TID 2797) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.917+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 1.0 in stage 1254.2 (TID 2796) in 61 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:05.951+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added rdd_169_2 in memory on 172.20.0.5:34029 (size: 7.5 KiB, free: 434.2 MiB)
[2025-05-08T21:13:05.971+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Starting task 3.0 in stage 1254.2 (TID 2798) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:05.972+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO TaskSetManager: Finished task 2.0 in stage 1254.2 (TID 2797) in 56 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:05.994+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:05 INFO BlockManagerInfo: Added rdd_169_3 in memory on 172.20.0.5:34029 (size: 8.1 KiB, free: 434.2 MiB)
[2025-05-08T21:13:06.007+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 4.0 in stage 1254.2 (TID 2799) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.009+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 3.0 in stage 1254.2 (TID 2798) in 36 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:06.026+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added rdd_169_4 in memory on 172.20.0.5:34029 (size: 7.7 KiB, free: 434.2 MiB)
[2025-05-08T21:13:06.040+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 5.0 in stage 1254.2 (TID 2800) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.041+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 4.0 in stage 1254.2 (TID 2799) in 35 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:06.062+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added rdd_169_5 in memory on 172.20.0.5:34029 (size: 7.0 KiB, free: 434.2 MiB)
[2025-05-08T21:13:06.073+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 6.0 in stage 1254.2 (TID 2801) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.074+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 5.0 in stage 1254.2 (TID 2800) in 34 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:06.099+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added rdd_169_6 in memory on 172.20.0.5:34029 (size: 7.3 KiB, free: 434.2 MiB)
[2025-05-08T21:13:06.109+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 7.0 in stage 1254.2 (TID 2802) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.109+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 6.0 in stage 1254.2 (TID 2801) in 36 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:06.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added rdd_169_7 in memory on 172.20.0.5:34029 (size: 8.1 KiB, free: 434.2 MiB)
[2025-05-08T21:13:06.159+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 8.0 in stage 1254.2 (TID 2803) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 7.0 in stage 1254.2 (TID 2802) in 50 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:06.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added rdd_169_8 in memory on 172.20.0.5:34029 (size: 7.6 KiB, free: 434.2 MiB)
[2025-05-08T21:13:06.190+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 9.0 in stage 1254.2 (TID 2804) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.191+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 8.0 in stage 1254.2 (TID 2803) in 34 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:06.210+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added rdd_169_9 in memory on 172.20.0.5:34029 (size: 8.2 KiB, free: 434.2 MiB)
[2025-05-08T21:13:06.222+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 0.0 in stage 1255.2 (TID 2805) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 9.0 in stage 1254.2 (TID 2804) in 33 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:06.225+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSchedulerImpl: Removed TaskSet 1254.2, whose tasks have all completed, from pool
[2025-05-08T21:13:06.228+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO DAGScheduler: ShuffleMapStage 1254 (map at GraphFrame.scala:187) finished in 1.080 s
[2025-05-08T21:13:06.228+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:06.229+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1255, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:06.229+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:06.229+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:06.240+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added broadcast_309_piece0 in memory on 172.20.0.5:34029 (size: 77.4 KiB, free: 434.1 MiB)
[2025-05-08T21:13:06.309+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:34029 (size: 80.3 KiB, free: 434.0 MiB)
[2025-05-08T21:13:06.328+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:34029 (size: 764.6 KiB, free: 433.3 MiB)
[2025-05-08T21:13:06.855+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 1.0 in stage 1255.2 (TID 2806) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.856+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 0.0 in stage 1255.2 (TID 2805) in 633 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:06.942+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Starting task 2.0 in stage 1255.2 (TID 2807) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:06.944+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:06 INFO TaskSetManager: Finished task 1.0 in stage 1255.2 (TID 2806) in 89 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:07.020+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 3.0 in stage 1255.2 (TID 2808) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.021+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 2.0 in stage 1255.2 (TID 2807) in 79 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:07.101+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 4.0 in stage 1255.2 (TID 2809) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.102+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 3.0 in stage 1255.2 (TID 2808) in 81 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:07.167+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 5.0 in stage 1255.2 (TID 2810) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.168+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 4.0 in stage 1255.2 (TID 2809) in 67 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:07.237+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 6.0 in stage 1255.2 (TID 2811) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 5.0 in stage 1255.2 (TID 2810) in 71 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:07.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 7.0 in stage 1255.2 (TID 2812) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.304+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 6.0 in stage 1255.2 (TID 2811) in 66 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:07.372+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 8.0 in stage 1255.2 (TID 2813) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.379+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 7.0 in stage 1255.2 (TID 2812) in 77 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:07.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 9.0 in stage 1255.2 (TID 2814) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.456+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 8.0 in stage 1255.2 (TID 2813) in 85 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:07.511+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 0.0 in stage 1287.2 (TID 2815) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 9.0 in stage 1255.2 (TID 2814) in 57 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:07.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSchedulerImpl: Removed TaskSet 1255.2, whose tasks have all completed, from pool
[2025-05-08T21:13:07.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO DAGScheduler: ShuffleMapStage 1255 (mapPartitions at VertexRDD.scala:356) finished in 2.358 s
[2025-05-08T21:13:07.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:07.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1287, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:07.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:07.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:07.520+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added broadcast_310_piece0 in memory on 172.20.0.5:34029 (size: 77.8 KiB, free: 433.2 MiB)
[2025-05-08T21:13:07.582+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_395_0 in memory on 172.20.0.5:34029 (size: 560.1 KiB, free: 432.6 MiB)
[2025-05-08T21:13:07.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.20.0.5:34029 (size: 560.1 KiB, free: 432.1 MiB)
[2025-05-08T21:13:07.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 1.0 in stage 1287.2 (TID 2816) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.627+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 0.0 in stage 1287.2 (TID 2815) in 116 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:07.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_395_1 in memory on 172.20.0.5:34029 (size: 558.2 KiB, free: 431.5 MiB)
[2025-05-08T21:13:07.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.20.0.5:34029 (size: 558.2 KiB, free: 431.0 MiB)
[2025-05-08T21:13:07.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 2.0 in stage 1287.2 (TID 2817) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 1.0 in stage 1287.2 (TID 2816) in 88 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:07.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_395_2 in memory on 172.20.0.5:34029 (size: 663.8 KiB, free: 430.3 MiB)
[2025-05-08T21:13:07.770+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.20.0.5:34029 (size: 663.8 KiB, free: 429.7 MiB)
[2025-05-08T21:13:07.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 3.0 in stage 1287.2 (TID 2818) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 2.0 in stage 1287.2 (TID 2817) in 77 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:07.819+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_395_3 in memory on 172.20.0.5:34029 (size: 695.0 KiB, free: 429.0 MiB)
[2025-05-08T21:13:07.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.20.0.5:34029 (size: 695.0 KiB, free: 428.3 MiB)
[2025-05-08T21:13:07.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 4.0 in stage 1287.2 (TID 2819) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.848+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 3.0 in stage 1287.2 (TID 2818) in 58 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:07.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_395_4 in memory on 172.20.0.5:34029 (size: 451.0 KiB, free: 427.9 MiB)
[2025-05-08T21:13:07.880+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.20.0.5:34029 (size: 451.0 KiB, free: 427.5 MiB)
[2025-05-08T21:13:07.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 5.0 in stage 1287.2 (TID 2820) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.910+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 4.0 in stage 1287.2 (TID 2819) in 63 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:07.946+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_395_5 in memory on 172.20.0.5:34029 (size: 654.0 KiB, free: 426.8 MiB)
[2025-05-08T21:13:07.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.20.0.5:34029 (size: 654.0 KiB, free: 426.2 MiB)
[2025-05-08T21:13:07.980+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Starting task 6.0 in stage 1287.2 (TID 2821) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:07.981+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:07 INFO TaskSetManager: Finished task 5.0 in stage 1287.2 (TID 2820) in 72 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:08.009+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_395_6 in memory on 172.20.0.5:34029 (size: 548.2 KiB, free: 425.6 MiB)
[2025-05-08T21:13:08.012+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.20.0.5:34029 (size: 548.2 KiB, free: 425.1 MiB)
[2025-05-08T21:13:08.032+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 7.0 in stage 1287.2 (TID 2822) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.033+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 6.0 in stage 1287.2 (TID 2821) in 53 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:08.063+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_395_7 in memory on 172.20.0.5:34029 (size: 557.0 KiB, free: 424.6 MiB)
[2025-05-08T21:13:08.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.20.0.5:34029 (size: 557.0 KiB, free: 424.0 MiB)
[2025-05-08T21:13:08.087+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 8.0 in stage 1287.2 (TID 2823) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.088+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 7.0 in stage 1287.2 (TID 2822) in 56 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:08.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_395_8 in memory on 172.20.0.5:34029 (size: 485.3 KiB, free: 423.5 MiB)
[2025-05-08T21:13:08.115+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.20.0.5:34029 (size: 485.3 KiB, free: 423.1 MiB)
[2025-05-08T21:13:08.142+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 9.0 in stage 1287.2 (TID 2824) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.143+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 8.0 in stage 1287.2 (TID 2823) in 56 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:08.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_395_9 in memory on 172.20.0.5:34029 (size: 694.0 KiB, free: 422.4 MiB)
[2025-05-08T21:13:08.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.20.0.5:34029 (size: 694.0 KiB, free: 421.7 MiB)
[2025-05-08T21:13:08.197+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 1.0 in stage 1336.2 (TID 2825) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 9.0 in stage 1287.2 (TID 2824) in 55 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:08.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSchedulerImpl: Removed TaskSet 1287.2, whose tasks have all completed, from pool
[2025-05-08T21:13:08.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: ShuffleMapStage 1287 (mapPartitions at GraphImpl.scala:208) finished in 3.033 s
[2025-05-08T21:13:08.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:08.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:08.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:08.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:08.199+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: Submitting ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:08.200+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MemoryStore: Block broadcast_312 stored as values in memory (estimated size 10.7 KiB, free 416.2 MiB)
[2025-05-08T21:13:08.201+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MemoryStore: Block broadcast_312_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 416.1 MiB)
[2025-05-08T21:13:08.202+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added broadcast_312_piece0 in memory on f2a432e4376a:35283 (size: 5.3 KiB, free: 432.4 MiB)
[2025-05-08T21:13:08.202+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO SparkContext: Created broadcast 312 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:08.202+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:08.202+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSchedulerImpl: Adding task set 1288.2 with 10 tasks resource profile 0
[2025-05-08T21:13:08.202+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: Submitting ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:08.204+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MemoryStore: Block broadcast_313 stored as values in memory (estimated size 10.1 KiB, free 416.1 MiB)
[2025-05-08T21:13:08.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MemoryStore: Block broadcast_313_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 416.1 MiB)
[2025-05-08T21:13:08.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added broadcast_311_piece0 in memory on 172.20.0.5:34029 (size: 40.2 KiB, free: 421.7 MiB)
[2025-05-08T21:13:08.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added broadcast_313_piece0 in memory on f2a432e4376a:35283 (size: 5.0 KiB, free: 432.4 MiB)
[2025-05-08T21:13:08.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO SparkContext: Created broadcast 313 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:08.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:08.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSchedulerImpl: Adding task set 1289.2 with 10 tasks resource profile 0
[2025-05-08T21:13:08.211+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:13:08.304+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 0.0 in stage 1288.2 (TID 2826) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.311+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 1.0 in stage 1336.2 (TID 2825) in 113 ms on 172.20.0.5 (executor 3) (1/41)
[2025-05-08T21:13:08.315+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added broadcast_312_piece0 in memory on 172.20.0.5:34029 (size: 5.3 KiB, free: 421.7 MiB)
[2025-05-08T21:13:08.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:55838
[2025-05-08T21:13:08.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:55838
[2025-05-08T21:13:08.378+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_0 in memory on 172.20.0.5:34029 (size: 36.3 KiB, free: 421.6 MiB)
[2025-05-08T21:13:08.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_0 in memory on 172.20.0.5:34029 (size: 11.2 KiB, free: 421.6 MiB)
[2025-05-08T21:13:08.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:55838
[2025-05-08T21:13:08.396+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_0 in memory on 172.20.0.5:34029 (size: 11.2 KiB, free: 421.6 MiB)
[2025-05-08T21:13:08.417+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 1.0 in stage 1288.2 (TID 2827) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.417+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 0.0 in stage 1288.2 (TID 2826) in 113 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:08.441+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_1 in memory on 172.20.0.5:34029 (size: 36.7 KiB, free: 421.6 MiB)
[2025-05-08T21:13:08.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_1 in memory on 172.20.0.5:34029 (size: 12.1 KiB, free: 421.6 MiB)
[2025-05-08T21:13:08.451+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_1 in memory on 172.20.0.5:34029 (size: 12.1 KiB, free: 421.6 MiB)
[2025-05-08T21:13:08.459+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 2.0 in stage 1288.2 (TID 2828) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.460+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 1.0 in stage 1288.2 (TID 2827) in 42 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:08.477+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_2 in memory on 172.20.0.5:34029 (size: 34.2 KiB, free: 421.5 MiB)
[2025-05-08T21:13:08.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_2 in memory on 172.20.0.5:34029 (size: 10.9 KiB, free: 421.5 MiB)
[2025-05-08T21:13:08.485+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_2 in memory on 172.20.0.5:34029 (size: 10.9 KiB, free: 421.5 MiB)
[2025-05-08T21:13:08.492+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 3.0 in stage 1288.2 (TID 2829) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.493+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 2.0 in stage 1288.2 (TID 2828) in 33 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:08.511+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_3 in memory on 172.20.0.5:34029 (size: 34.5 KiB, free: 421.5 MiB)
[2025-05-08T21:13:08.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_3 in memory on 172.20.0.5:34029 (size: 10.9 KiB, free: 421.5 MiB)
[2025-05-08T21:13:08.519+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_3 in memory on 172.20.0.5:34029 (size: 10.9 KiB, free: 421.4 MiB)
[2025-05-08T21:13:08.528+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 4.0 in stage 1288.2 (TID 2830) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.529+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 3.0 in stage 1288.2 (TID 2829) in 36 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:08.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_4 in memory on 172.20.0.5:34029 (size: 33.4 KiB, free: 421.4 MiB)
[2025-05-08T21:13:08.549+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_4 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 421.4 MiB)
[2025-05-08T21:13:08.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_4 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 421.4 MiB)
[2025-05-08T21:13:08.561+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 5.0 in stage 1288.2 (TID 2831) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.561+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 4.0 in stage 1288.2 (TID 2830) in 33 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:08.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_5 in memory on 172.20.0.5:34029 (size: 34.7 KiB, free: 421.4 MiB)
[2025-05-08T21:13:08.583+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_5 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 421.3 MiB)
[2025-05-08T21:13:08.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_5 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 421.3 MiB)
[2025-05-08T21:13:08.597+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 6.0 in stage 1288.2 (TID 2832) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.597+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 5.0 in stage 1288.2 (TID 2831) in 37 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:08.615+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_6 in memory on 172.20.0.5:34029 (size: 34.8 KiB, free: 421.3 MiB)
[2025-05-08T21:13:08.618+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_6 in memory on 172.20.0.5:34029 (size: 11.4 KiB, free: 421.3 MiB)
[2025-05-08T21:13:08.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_6 in memory on 172.20.0.5:34029 (size: 11.4 KiB, free: 421.3 MiB)
[2025-05-08T21:13:08.630+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 7.0 in stage 1288.2 (TID 2833) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.631+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 6.0 in stage 1288.2 (TID 2832) in 34 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:08.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_7 in memory on 172.20.0.5:34029 (size: 35.5 KiB, free: 421.2 MiB)
[2025-05-08T21:13:08.649+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_7 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 421.2 MiB)
[2025-05-08T21:13:08.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_7 in memory on 172.20.0.5:34029 (size: 11.6 KiB, free: 421.2 MiB)
[2025-05-08T21:13:08.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 8.0 in stage 1288.2 (TID 2834) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.663+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 7.0 in stage 1288.2 (TID 2833) in 33 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:08.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_8 in memory on 172.20.0.5:34029 (size: 36.5 KiB, free: 421.2 MiB)
[2025-05-08T21:13:08.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_8 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 421.2 MiB)
[2025-05-08T21:13:08.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_8 in memory on 172.20.0.5:34029 (size: 11.7 KiB, free: 421.2 MiB)
[2025-05-08T21:13:08.694+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 9.0 in stage 1288.2 (TID 2835) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 8.0 in stage 1288.2 (TID 2834) in 33 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:08.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_392_9 in memory on 172.20.0.5:34029 (size: 35.4 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.712+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_397_9 in memory on 172.20.0.5:34029 (size: 11.3 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.717+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_600_9 in memory on 172.20.0.5:34029 (size: 11.2 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.724+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 0.0 in stage 1289.2 (TID 2836) (172.20.0.5, executor 3, partition 0, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 9.0 in stage 1288.2 (TID 2835) in 30 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:08.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSchedulerImpl: Removed TaskSet 1288.2, whose tasks have all completed, from pool
[2025-05-08T21:13:08.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: ShuffleMapStage 1288 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.526 s
[2025-05-08T21:13:08.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:08.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:08.726+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:08.726+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:08.733+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added broadcast_313_piece0 in memory on 172.20.0.5:34029 (size: 5.0 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.743+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 1.0 in stage 1289.2 (TID 2837) (172.20.0.5, executor 3, partition 1, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.743+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 0.0 in stage 1289.2 (TID 2836) in 19 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:08.756+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 2.0 in stage 1289.2 (TID 2838) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.756+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 1.0 in stage 1289.2 (TID 2837) in 13 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:08.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 3.0 in stage 1289.2 (TID 2839) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.768+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 2.0 in stage 1289.2 (TID 2838) in 12 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:08.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 4.0 in stage 1289.2 (TID 2840) (172.20.0.5, executor 3, partition 4, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.777+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 3.0 in stage 1289.2 (TID 2839) in 9 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:08.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 5.0 in stage 1289.2 (TID 2841) (172.20.0.5, executor 3, partition 5, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 4.0 in stage 1289.2 (TID 2840) in 13 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:08.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 6.0 in stage 1289.2 (TID 2842) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 5.0 in stage 1289.2 (TID 2841) in 10 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:08.809+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 7.0 in stage 1289.2 (TID 2843) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 6.0 in stage 1289.2 (TID 2842) in 10 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:08.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 8.0 in stage 1289.2 (TID 2844) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 7.0 in stage 1289.2 (TID 2843) in 11 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:08.828+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 9.0 in stage 1289.2 (TID 2845) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.828+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 8.0 in stage 1289.2 (TID 2844) in 8 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:08.836+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 2.0 in stage 1336.2 (TID 2846) (172.20.0.5, executor 3, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 9.0 in stage 1289.2 (TID 2845) in 8 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:08.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSchedulerImpl: Removed TaskSet 1289.2, whose tasks have all completed, from pool
[2025-05-08T21:13:08.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: ShuffleMapStage 1289 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.634 s
[2025-05-08T21:13:08.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:08.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:08.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:08.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:08.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: Submitting ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:08.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:13:08.849+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MemoryStore: Block broadcast_314 stored as values in memory (estimated size 238.4 KiB, free 415.9 MiB)
[2025-05-08T21:13:08.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MemoryStore: Block broadcast_314_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 415.8 MiB)
[2025-05-08T21:13:08.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added broadcast_314_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.4 MiB)
[2025-05-08T21:13:08.852+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO SparkContext: Created broadcast 314 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:08.853+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:08.853+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSchedulerImpl: Adding task set 1290.2 with 10 tasks resource profile 0
[2025-05-08T21:13:08.883+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Starting task 0.0 in stage 1290.2 (TID 2847) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:08.883+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO TaskSetManager: Finished task 2.0 in stage 1336.2 (TID 2846) in 47 ms on 172.20.0.5 (executor 3) (2/41)
[2025-05-08T21:13:08.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added broadcast_314_piece0 in memory on 172.20.0.5:34029 (size: 78.8 KiB, free: 421.0 MiB)
[2025-05-08T21:13:08.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Added rdd_602_0 in memory on 172.20.0.5:34029 (size: 50.5 KiB, free: 421.0 MiB)
[2025-05-08T21:13:08.931+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:08.948+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_310_piece0 on f2a432e4376a:35283 in memory (size: 77.8 KiB, free: 432.4 MiB)
[2025-05-08T21:13:08.952+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_310_piece0 on 172.20.0.5:34029 in memory (size: 77.8 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.958+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_313_piece0 on f2a432e4376a:35283 in memory (size: 5.0 KiB, free: 432.4 MiB)
[2025-05-08T21:13:08.963+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_313_piece0 on 172.20.0.5:34029 in memory (size: 5.0 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.967+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:08.970+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_312_piece0 on f2a432e4376a:35283 in memory (size: 5.3 KiB, free: 432.4 MiB)
[2025-05-08T21:13:08.979+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_312_piece0 on 172.20.0.5:34029 in memory (size: 5.3 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.988+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_309_piece0 on f2a432e4376a:35283 in memory (size: 77.4 KiB, free: 432.5 MiB)
[2025-05-08T21:13:08.993+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_309_piece0 on 172.20.0.5:34029 in memory (size: 77.4 KiB, free: 421.1 MiB)
[2025-05-08T21:13:08.999+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:08 INFO BlockManagerInfo: Removed broadcast_308_piece0 on f2a432e4376a:35283 in memory (size: 65.0 KiB, free: 432.6 MiB)
[2025-05-08T21:13:09.007+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Removed broadcast_308_piece0 on 172.20.0.5:34029 in memory (size: 65.0 KiB, free: 421.2 MiB)
[2025-05-08T21:13:09.014+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Removed broadcast_303_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:13:09.015+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Removed broadcast_303_piece0 on 172.20.0.5:34029 in memory (size: 13.8 KiB, free: 421.2 MiB)
[2025-05-08T21:13:09.016+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 1.0 in stage 1290.2 (TID 2848) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.017+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 0.0 in stage 1290.2 (TID 2847) in 133 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:09.041+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_1 in memory on 172.20.0.5:34029 (size: 51.2 KiB, free: 421.2 MiB)
[2025-05-08T21:13:09.077+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 2.0 in stage 1290.2 (TID 2849) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.077+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 1.0 in stage 1290.2 (TID 2848) in 62 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:09.125+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_2 in memory on 172.20.0.5:34029 (size: 54.2 KiB, free: 421.1 MiB)
[2025-05-08T21:13:09.190+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 3.0 in stage 1290.2 (TID 2850) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 2.0 in stage 1290.2 (TID 2849) in 115 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:09.214+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_3 in memory on 172.20.0.5:34029 (size: 55.4 KiB, free: 421.1 MiB)
[2025-05-08T21:13:09.246+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 4.0 in stage 1290.2 (TID 2851) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.247+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 3.0 in stage 1290.2 (TID 2850) in 58 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:09.261+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_4 in memory on 172.20.0.5:34029 (size: 46.8 KiB, free: 421.0 MiB)
[2025-05-08T21:13:09.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 5.0 in stage 1290.2 (TID 2852) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 4.0 in stage 1290.2 (TID 2851) in 50 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:09.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_5 in memory on 172.20.0.5:34029 (size: 53.5 KiB, free: 421.0 MiB)
[2025-05-08T21:13:09.336+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 6.0 in stage 1290.2 (TID 2853) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.340+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 5.0 in stage 1290.2 (TID 2852) in 44 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:09.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_6 in memory on 172.20.0.5:34029 (size: 50.7 KiB, free: 420.9 MiB)
[2025-05-08T21:13:09.383+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 7.0 in stage 1290.2 (TID 2854) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 6.0 in stage 1290.2 (TID 2853) in 48 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:09.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_7 in memory on 172.20.0.5:34029 (size: 50.4 KiB, free: 420.9 MiB)
[2025-05-08T21:13:09.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 8.0 in stage 1290.2 (TID 2855) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 7.0 in stage 1290.2 (TID 2854) in 50 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:09.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_8 in memory on 172.20.0.5:34029 (size: 48.3 KiB, free: 420.8 MiB)
[2025-05-08T21:13:09.492+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 9.0 in stage 1290.2 (TID 2856) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.493+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 8.0 in stage 1290.2 (TID 2855) in 61 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:09.511+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added rdd_602_9 in memory on 172.20.0.5:34029 (size: 55.5 KiB, free: 420.8 MiB)
[2025-05-08T21:13:09.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 3.0 in stage 1336.2 (TID 2857) (172.20.0.5, executor 3, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.541+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 9.0 in stage 1290.2 (TID 2856) in 49 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:09.541+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSchedulerImpl: Removed TaskSet 1290.2, whose tasks have all completed, from pool
[2025-05-08T21:13:09.542+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: ShuffleMapStage 1290 (mapPartitions at GraphImpl.scala:208) finished in 0.702 s
[2025-05-08T21:13:09.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:09.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:09.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:09.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:09.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: Submitting ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:09.545+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MemoryStore: Block broadcast_315 stored as values in memory (estimated size 12.0 KiB, free 416.7 MiB)
[2025-05-08T21:13:09.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MemoryStore: Block broadcast_315_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 416.7 MiB)
[2025-05-08T21:13:09.547+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added broadcast_315_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.6 MiB)
[2025-05-08T21:13:09.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO SparkContext: Created broadcast 315 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:09.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:09.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSchedulerImpl: Adding task set 1291.2 with 10 tasks resource profile 0
[2025-05-08T21:13:09.552+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:13:09.584+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 0.0 in stage 1291.2 (TID 2858) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.586+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 3.0 in stage 1336.2 (TID 2857) in 46 ms on 172.20.0.5 (executor 3) (3/41)
[2025-05-08T21:13:09.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added broadcast_315_piece0 in memory on 172.20.0.5:34029 (size: 5.7 KiB, free: 420.8 MiB)
[2025-05-08T21:13:09.619+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:09.667+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 1.0 in stage 1291.2 (TID 2859) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.668+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 0.0 in stage 1291.2 (TID 2858) in 82 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:09.691+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 2.0 in stage 1291.2 (TID 2860) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.693+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 1.0 in stage 1291.2 (TID 2859) in 26 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:09.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 3.0 in stage 1291.2 (TID 2861) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 2.0 in stage 1291.2 (TID 2860) in 23 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:09.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 4.0 in stage 1291.2 (TID 2862) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 3.0 in stage 1291.2 (TID 2861) in 17 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:09.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 5.0 in stage 1291.2 (TID 2863) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 4.0 in stage 1291.2 (TID 2862) in 19 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:09.764+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 6.0 in stage 1291.2 (TID 2864) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.765+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 5.0 in stage 1291.2 (TID 2863) in 15 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:09.780+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 7.0 in stage 1291.2 (TID 2865) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.781+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 6.0 in stage 1291.2 (TID 2864) in 16 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:09.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 8.0 in stage 1291.2 (TID 2866) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 7.0 in stage 1291.2 (TID 2865) in 11 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:09.801+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 9.0 in stage 1291.2 (TID 2867) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.801+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 8.0 in stage 1291.2 (TID 2866) in 10 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:09.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 6.0 in stage 1336.2 (TID 2868) (172.20.0.5, executor 3, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 9.0 in stage 1291.2 (TID 2867) in 12 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:09.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSchedulerImpl: Removed TaskSet 1291.2, whose tasks have all completed, from pool
[2025-05-08T21:13:09.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: ShuffleMapStage 1291 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.268 s
[2025-05-08T21:13:09.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:09.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:09.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:09.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:09.816+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: Submitting ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:09.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:13:09.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MemoryStore: Block broadcast_316 stored as values in memory (estimated size 238.8 KiB, free 416.5 MiB)
[2025-05-08T21:13:09.826+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MemoryStore: Block broadcast_316_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 416.4 MiB)
[2025-05-08T21:13:09.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added broadcast_316_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.5 MiB)
[2025-05-08T21:13:09.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO SparkContext: Created broadcast 316 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:09.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:09.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSchedulerImpl: Adding task set 1292.2 with 10 tasks resource profile 0
[2025-05-08T21:13:09.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 0.0 in stage 1292.2 (TID 2869) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 6.0 in stage 1336.2 (TID 2868) in 36 ms on 172.20.0.5 (executor 3) (4/41)
[2025-05-08T21:13:09.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO BlockManagerInfo: Added broadcast_316_piece0 in memory on 172.20.0.5:34029 (size: 78.8 KiB, free: 420.7 MiB)
[2025-05-08T21:13:09.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:09.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:09.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:09.926+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 1.0 in stage 1292.2 (TID 2870) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.927+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 0.0 in stage 1292.2 (TID 2869) in 80 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:09.970+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Starting task 2.0 in stage 1292.2 (TID 2871) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:09.971+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:09 INFO TaskSetManager: Finished task 1.0 in stage 1292.2 (TID 2870) in 46 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:10.002+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 3.0 in stage 1292.2 (TID 2872) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 2.0 in stage 1292.2 (TID 2871) in 33 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:10.035+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 4.0 in stage 1292.2 (TID 2873) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 3.0 in stage 1292.2 (TID 2872) in 34 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:10.068+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 5.0 in stage 1292.2 (TID 2874) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.071+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 4.0 in stage 1292.2 (TID 2873) in 35 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:10.103+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 6.0 in stage 1292.2 (TID 2875) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.104+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 5.0 in stage 1292.2 (TID 2874) in 36 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:10.136+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 7.0 in stage 1292.2 (TID 2876) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.137+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 6.0 in stage 1292.2 (TID 2875) in 35 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:10.201+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 8.0 in stage 1292.2 (TID 2877) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.202+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 7.0 in stage 1292.2 (TID 2876) in 66 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:10.241+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 9.0 in stage 1292.2 (TID 2878) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.242+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 8.0 in stage 1292.2 (TID 2877) in 41 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:10.283+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 7.0 in stage 1336.2 (TID 2879) (172.20.0.5, executor 3, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.284+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 9.0 in stage 1292.2 (TID 2878) in 43 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:10.284+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSchedulerImpl: Removed TaskSet 1292.2, whose tasks have all completed, from pool
[2025-05-08T21:13:10.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: ShuffleMapStage 1292 (mapPartitions at GraphImpl.scala:208) finished in 0.471 s
[2025-05-08T21:13:10.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:10.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:10.286+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:10.286+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:10.286+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: Submitting ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:10.289+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MemoryStore: Block broadcast_317 stored as values in memory (estimated size 12.8 KiB, free 416.4 MiB)
[2025-05-08T21:13:10.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MemoryStore: Block broadcast_317_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 416.4 MiB)
[2025-05-08T21:13:10.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Added broadcast_317_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.5 MiB)
[2025-05-08T21:13:10.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO SparkContext: Created broadcast 317 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:10.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:10.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSchedulerImpl: Adding task set 1293.2 with 10 tasks resource profile 0
[2025-05-08T21:13:10.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:13:10.349+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 0.0 in stage 1293.2 (TID 2880) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.350+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 7.0 in stage 1336.2 (TID 2879) in 66 ms on 172.20.0.5 (executor 3) (5/41)
[2025-05-08T21:13:10.363+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Added broadcast_317_piece0 in memory on 172.20.0.5:34029 (size: 5.9 KiB, free: 420.7 MiB)
[2025-05-08T21:13:10.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:10.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:10.412+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 1.0 in stage 1293.2 (TID 2881) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 0.0 in stage 1293.2 (TID 2880) in 64 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:10.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 2.0 in stage 1293.2 (TID 2882) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 1.0 in stage 1293.2 (TID 2881) in 25 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:10.458+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 3.0 in stage 1293.2 (TID 2883) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.458+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 2.0 in stage 1293.2 (TID 2882) in 23 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:10.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 4.0 in stage 1293.2 (TID 2884) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.480+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 3.0 in stage 1293.2 (TID 2883) in 23 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:10.501+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 5.0 in stage 1293.2 (TID 2885) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.502+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 4.0 in stage 1293.2 (TID 2884) in 22 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:10.525+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 6.0 in stage 1293.2 (TID 2886) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.526+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 5.0 in stage 1293.2 (TID 2885) in 25 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:10.546+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 7.0 in stage 1293.2 (TID 2887) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.546+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 6.0 in stage 1293.2 (TID 2886) in 22 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:10.567+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 8.0 in stage 1293.2 (TID 2888) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.569+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 7.0 in stage 1293.2 (TID 2887) in 23 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:10.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 9.0 in stage 1293.2 (TID 2889) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 8.0 in stage 1293.2 (TID 2888) in 23 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:10.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 8.0 in stage 1336.2 (TID 2890) (172.20.0.5, executor 3, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.610+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 9.0 in stage 1293.2 (TID 2889) in 21 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:10.610+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSchedulerImpl: Removed TaskSet 1293.2, whose tasks have all completed, from pool
[2025-05-08T21:13:10.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: ShuffleMapStage 1293 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.323 s
[2025-05-08T21:13:10.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:10.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:10.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:10.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:10.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: Submitting ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:10.621+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:13:10.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MemoryStore: Block broadcast_318 stored as values in memory (estimated size 239.1 KiB, free 416.2 MiB)
[2025-05-08T21:13:10.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Removed broadcast_315_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.5 MiB)
[2025-05-08T21:13:10.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MemoryStore: Block broadcast_318_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 416.1 MiB)
[2025-05-08T21:13:10.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Added broadcast_318_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.4 MiB)
[2025-05-08T21:13:10.648+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO SparkContext: Created broadcast 318 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:10.648+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:10.649+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSchedulerImpl: Adding task set 1294.2 with 10 tasks resource profile 0
[2025-05-08T21:13:10.665+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Removed broadcast_315_piece0 on 172.20.0.5:34029 in memory (size: 5.7 KiB, free: 420.7 MiB)
[2025-05-08T21:13:10.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 0.0 in stage 1294.2 (TID 2891) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.713+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 8.0 in stage 1336.2 (TID 2890) in 101 ms on 172.20.0.5 (executor 3) (6/41)
[2025-05-08T21:13:10.716+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Removed broadcast_316_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.5 MiB)
[2025-05-08T21:13:10.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Removed broadcast_316_piece0 on 172.20.0.5:34029 in memory (size: 78.8 KiB, free: 420.8 MiB)
[2025-05-08T21:13:10.743+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Added broadcast_318_piece0 in memory on 172.20.0.5:34029 (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T21:13:10.745+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Removed broadcast_314_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.6 MiB)
[2025-05-08T21:13:10.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO BlockManagerInfo: Removed broadcast_314_piece0 on 172.20.0.5:34029 in memory (size: 78.8 KiB, free: 420.8 MiB)
[2025-05-08T21:13:10.802+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:10.811+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:10.814+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:10.817+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:10.853+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 1.0 in stage 1294.2 (TID 2892) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.855+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 0.0 in stage 1294.2 (TID 2891) in 144 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:10.916+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 2.0 in stage 1294.2 (TID 2893) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.917+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 1.0 in stage 1294.2 (TID 2892) in 65 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:10.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Starting task 3.0 in stage 1294.2 (TID 2894) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:10.958+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:10 INFO TaskSetManager: Finished task 2.0 in stage 1294.2 (TID 2893) in 43 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:11.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 4.0 in stage 1294.2 (TID 2895) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.004+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 3.0 in stage 1294.2 (TID 2894) in 46 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:11.047+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 5.0 in stage 1294.2 (TID 2896) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.047+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 4.0 in stage 1294.2 (TID 2895) in 44 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:11.092+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 6.0 in stage 1294.2 (TID 2897) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.092+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 5.0 in stage 1294.2 (TID 2896) in 45 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:11.134+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 7.0 in stage 1294.2 (TID 2898) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.135+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 6.0 in stage 1294.2 (TID 2897) in 44 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:11.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 8.0 in stage 1294.2 (TID 2899) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 7.0 in stage 1294.2 (TID 2898) in 44 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:11.244+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 9.0 in stage 1294.2 (TID 2900) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.244+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 8.0 in stage 1294.2 (TID 2899) in 67 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:11.280+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 9.0 in stage 1336.2 (TID 2901) (172.20.0.5, executor 3, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.280+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 9.0 in stage 1294.2 (TID 2900) in 37 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:11.280+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSchedulerImpl: Removed TaskSet 1294.2, whose tasks have all completed, from pool
[2025-05-08T21:13:11.281+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: ShuffleMapStage 1294 (mapPartitions at GraphImpl.scala:208) finished in 0.669 s
[2025-05-08T21:13:11.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:11.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:11.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:11.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:11.286+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:55838
[2025-05-08T21:13:11.288+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: Submitting ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:11.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MemoryStore: Block broadcast_319 stored as values in memory (estimated size 13.5 KiB, free 416.7 MiB)
[2025-05-08T21:13:11.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 10.0 in stage 1336.2 (TID 2902) (172.20.0.5, executor 3, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 9.0 in stage 1336.2 (TID 2901) in 24 ms on 172.20.0.5 (executor 3) (7/41)
[2025-05-08T21:13:11.309+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MemoryStore: Block broadcast_319_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.7 MiB)
[2025-05-08T21:13:11.310+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO BlockManagerInfo: Added broadcast_319_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.6 MiB)
[2025-05-08T21:13:11.321+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO SparkContext: Created broadcast 319 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:11.321+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:11.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSchedulerImpl: Adding task set 1295.2 with 10 tasks resource profile 0
[2025-05-08T21:13:11.327+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 0.0 in stage 1295.2 (TID 2903) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.327+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 10.0 in stage 1336.2 (TID 2902) in 25 ms on 172.20.0.5 (executor 3) (8/41)
[2025-05-08T21:13:11.336+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO BlockManagerInfo: Added broadcast_319_piece0 in memory on 172.20.0.5:34029 (size: 6.1 KiB, free: 420.7 MiB)
[2025-05-08T21:13:11.355+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:11.380+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:11.403+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:11.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 1.0 in stage 1295.2 (TID 2904) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 0.0 in stage 1295.2 (TID 2903) in 94 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:11.457+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 2.0 in stage 1295.2 (TID 2905) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.458+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 1.0 in stage 1295.2 (TID 2904) in 37 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:11.477+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 3.0 in stage 1295.2 (TID 2906) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.478+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 2.0 in stage 1295.2 (TID 2905) in 20 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:11.500+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 4.0 in stage 1295.2 (TID 2907) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.501+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 3.0 in stage 1295.2 (TID 2906) in 23 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:11.529+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 5.0 in stage 1295.2 (TID 2908) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.529+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 4.0 in stage 1295.2 (TID 2907) in 29 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:11.555+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 6.0 in stage 1295.2 (TID 2909) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 5.0 in stage 1295.2 (TID 2908) in 27 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:11.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 7.0 in stage 1295.2 (TID 2910) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 6.0 in stage 1295.2 (TID 2909) in 26 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:11.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 8.0 in stage 1295.2 (TID 2911) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 7.0 in stage 1295.2 (TID 2910) in 22 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:11.631+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 9.0 in stage 1295.2 (TID 2912) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.631+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 8.0 in stage 1295.2 (TID 2911) in 29 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:11.656+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 11.0 in stage 1336.2 (TID 2913) (172.20.0.5, executor 3, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 9.0 in stage 1295.2 (TID 2912) in 26 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:11.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSchedulerImpl: Removed TaskSet 1295.2, whose tasks have all completed, from pool
[2025-05-08T21:13:11.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: ShuffleMapStage 1295 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.365 s
[2025-05-08T21:13:11.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:11.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:11.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:11.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:11.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: Submitting ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:11.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:11.666+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MemoryStore: Block broadcast_320 stored as values in memory (estimated size 239.4 KiB, free 416.5 MiB)
[2025-05-08T21:13:11.668+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MemoryStore: Block broadcast_320_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.4 MiB)
[2025-05-08T21:13:11.669+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO BlockManagerInfo: Added broadcast_320_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:13:11.669+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO SparkContext: Created broadcast 320 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:11.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:11.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSchedulerImpl: Adding task set 1296.2 with 10 tasks resource profile 0
[2025-05-08T21:13:11.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 0.0 in stage 1296.2 (TID 2914) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.712+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 11.0 in stage 1336.2 (TID 2913) in 55 ms on 172.20.0.5 (executor 3) (9/41)
[2025-05-08T21:13:11.718+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO BlockManagerInfo: Added broadcast_320_piece0 in memory on 172.20.0.5:34029 (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:13:11.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:11.735+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:11.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:11.739+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:11.742+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:55838
[2025-05-08T21:13:11.778+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 1.0 in stage 1296.2 (TID 2915) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.779+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 0.0 in stage 1296.2 (TID 2914) in 68 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:11.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 2.0 in stage 1296.2 (TID 2916) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 1.0 in stage 1296.2 (TID 2915) in 45 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:11.865+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 3.0 in stage 1296.2 (TID 2917) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.866+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 2.0 in stage 1296.2 (TID 2916) in 44 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:11.917+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 4.0 in stage 1296.2 (TID 2918) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.918+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 3.0 in stage 1296.2 (TID 2917) in 54 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:11.974+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Starting task 5.0 in stage 1296.2 (TID 2919) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:11.977+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:11 INFO TaskSetManager: Finished task 4.0 in stage 1296.2 (TID 2918) in 57 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:12.044+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 6.0 in stage 1296.2 (TID 2920) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.045+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 5.0 in stage 1296.2 (TID 2919) in 72 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:12.098+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 7.0 in stage 1296.2 (TID 2921) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.099+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 6.0 in stage 1296.2 (TID 2920) in 56 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:12.135+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 8.0 in stage 1296.2 (TID 2922) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.136+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 7.0 in stage 1296.2 (TID 2921) in 38 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:12.235+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 9.0 in stage 1296.2 (TID 2923) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.235+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 8.0 in stage 1296.2 (TID 2922) in 101 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:12.306+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 12.0 in stage 1336.2 (TID 2924) (172.20.0.5, executor 3, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.306+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 9.0 in stage 1296.2 (TID 2923) in 72 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:12.307+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSchedulerImpl: Removed TaskSet 1296.2, whose tasks have all completed, from pool
[2025-05-08T21:13:12.311+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: ShuffleMapStage 1296 (mapPartitions at GraphImpl.scala:208) finished in 0.649 s
[2025-05-08T21:13:12.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:12.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:12.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:12.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:12.313+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:12.313+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: Submitting ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:12.319+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MemoryStore: Block broadcast_321 stored as values in memory (estimated size 14.2 KiB, free 416.4 MiB)
[2025-05-08T21:13:12.376+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 13.0 in stage 1336.2 (TID 2925) (172.20.0.5, executor 3, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.377+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 12.0 in stage 1336.2 (TID 2924) in 71 ms on 172.20.0.5 (executor 3) (10/41)
[2025-05-08T21:13:12.381+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MemoryStore: Block broadcast_321_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.4 MiB)
[2025-05-08T21:13:12.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Added broadcast_321_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T21:13:12.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO SparkContext: Created broadcast 321 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:12.383+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:12.383+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSchedulerImpl: Adding task set 1297.2 with 10 tasks resource profile 0
[2025-05-08T21:13:12.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Removed broadcast_318_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.6 MiB)
[2025-05-08T21:13:12.408+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Removed broadcast_318_piece0 on 172.20.0.5:34029 in memory (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T21:13:12.423+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Removed broadcast_317_piece0 on 172.20.0.5:34029 in memory (size: 5.9 KiB, free: 420.8 MiB)
[2025-05-08T21:13:12.425+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Removed broadcast_317_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.6 MiB)
[2025-05-08T21:13:12.429+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 0.0 in stage 1297.2 (TID 2926) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 13.0 in stage 1336.2 (TID 2925) in 53 ms on 172.20.0.5 (executor 3) (11/41)
[2025-05-08T21:13:12.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Removed broadcast_319_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.6 MiB)
[2025-05-08T21:13:12.440+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Removed broadcast_319_piece0 on 172.20.0.5:34029 in memory (size: 6.1 KiB, free: 420.8 MiB)
[2025-05-08T21:13:12.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Added broadcast_321_piece0 in memory on 172.20.0.5:34029 (size: 6.1 KiB, free: 420.8 MiB)
[2025-05-08T21:13:12.451+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:12.467+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:12.486+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:12.515+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:55838
[2025-05-08T21:13:12.522+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 1.0 in stage 1297.2 (TID 2927) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.523+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 0.0 in stage 1297.2 (TID 2926) in 94 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:12.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 2.0 in stage 1297.2 (TID 2928) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 1.0 in stage 1297.2 (TID 2927) in 36 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:12.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 3.0 in stage 1297.2 (TID 2929) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 2.0 in stage 1297.2 (TID 2928) in 37 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:12.635+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 4.0 in stage 1297.2 (TID 2930) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.636+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 3.0 in stage 1297.2 (TID 2929) in 42 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:12.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 5.0 in stage 1297.2 (TID 2931) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 4.0 in stage 1297.2 (TID 2930) in 38 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:12.718+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 6.0 in stage 1297.2 (TID 2932) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.718+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 5.0 in stage 1297.2 (TID 2931) in 46 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:12.760+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 7.0 in stage 1297.2 (TID 2933) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.761+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 6.0 in stage 1297.2 (TID 2932) in 43 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:12.802+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 8.0 in stage 1297.2 (TID 2934) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.803+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 7.0 in stage 1297.2 (TID 2933) in 43 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:12.854+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 9.0 in stage 1297.2 (TID 2935) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.854+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 8.0 in stage 1297.2 (TID 2934) in 52 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:12.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 14.0 in stage 1336.2 (TID 2936) (172.20.0.5, executor 3, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 9.0 in stage 1297.2 (TID 2935) in 40 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:12.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSchedulerImpl: Removed TaskSet 1297.2, whose tasks have all completed, from pool
[2025-05-08T21:13:12.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: ShuffleMapStage 1297 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.580 s
[2025-05-08T21:13:12.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:12.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:12.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:12.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:12.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: Submitting ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:12.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:12.907+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MemoryStore: Block broadcast_322 stored as values in memory (estimated size 239.6 KiB, free 416.5 MiB)
[2025-05-08T21:13:12.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MemoryStore: Block broadcast_322_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 416.4 MiB)
[2025-05-08T21:13:12.910+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Added broadcast_322_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.5 MiB)
[2025-05-08T21:13:12.910+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO SparkContext: Created broadcast 322 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:12.911+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:12.911+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSchedulerImpl: Adding task set 1298.2 with 10 tasks resource profile 0
[2025-05-08T21:13:12.938+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Starting task 0.0 in stage 1298.2 (TID 2937) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:12.938+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO TaskSetManager: Finished task 14.0 in stage 1336.2 (TID 2936) in 45 ms on 172.20.0.5 (executor 3) (12/41)
[2025-05-08T21:13:12.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO BlockManagerInfo: Added broadcast_322_piece0 in memory on 172.20.0.5:34029 (size: 79.4 KiB, free: 420.7 MiB)
[2025-05-08T21:13:12.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:12.984+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:12.988+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:12.992+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:12.996+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:55838
[2025-05-08T21:13:12.998+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:55838
[2025-05-08T21:13:13.023+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 1.0 in stage 1298.2 (TID 2938) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.023+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 0.0 in stage 1298.2 (TID 2937) in 89 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:13.050+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 2.0 in stage 1298.2 (TID 2939) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.051+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 1.0 in stage 1298.2 (TID 2938) in 29 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:13.082+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 3.0 in stage 1298.2 (TID 2940) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.083+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 2.0 in stage 1298.2 (TID 2939) in 33 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:13.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 4.0 in stage 1298.2 (TID 2941) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.112+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 3.0 in stage 1298.2 (TID 2940) in 30 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:13.140+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 5.0 in stage 1298.2 (TID 2942) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.141+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 4.0 in stage 1298.2 (TID 2941) in 29 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:13.168+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 6.0 in stage 1298.2 (TID 2943) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.168+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 5.0 in stage 1298.2 (TID 2942) in 28 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:13.195+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 7.0 in stage 1298.2 (TID 2944) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.195+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 6.0 in stage 1298.2 (TID 2943) in 27 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:13.228+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 8.0 in stage 1298.2 (TID 2945) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.229+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 7.0 in stage 1298.2 (TID 2944) in 34 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:13.258+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 9.0 in stage 1298.2 (TID 2946) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.259+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 8.0 in stage 1298.2 (TID 2945) in 31 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:13.291+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 15.0 in stage 1336.2 (TID 2947) (172.20.0.5, executor 3, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 9.0 in stage 1298.2 (TID 2946) in 34 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:13.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSchedulerImpl: Removed TaskSet 1298.2, whose tasks have all completed, from pool
[2025-05-08T21:13:13.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: ShuffleMapStage 1298 (mapPartitions at GraphImpl.scala:208) finished in 0.397 s
[2025-05-08T21:13:13.292+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:13.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:13.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:13:13.293+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:13.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: Submitting ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:13.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MemoryStore: Block broadcast_323 stored as values in memory (estimated size 14.9 KiB, free 416.4 MiB)
[2025-05-08T21:13:13.299+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:13.309+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MemoryStore: Block broadcast_323_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 416.4 MiB)
[2025-05-08T21:13:13.309+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO BlockManagerInfo: Added broadcast_323_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.5 MiB)
[2025-05-08T21:13:13.309+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO SparkContext: Created broadcast 323 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:13.310+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:13.310+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSchedulerImpl: Adding task set 1299.2 with 10 tasks resource profile 0
[2025-05-08T21:13:13.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 0.0 in stage 1299.2 (TID 2948) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.333+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 15.0 in stage 1336.2 (TID 2947) in 39 ms on 172.20.0.5 (executor 3) (13/41)
[2025-05-08T21:13:13.353+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO BlockManagerInfo: Added broadcast_323_piece0 in memory on 172.20.0.5:34029 (size: 6.3 KiB, free: 420.7 MiB)
[2025-05-08T21:13:13.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:13.368+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:13.390+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:13.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:55838
[2025-05-08T21:13:13.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:55838
[2025-05-08T21:13:13.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 1.0 in stage 1299.2 (TID 2949) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 0.0 in stage 1299.2 (TID 2948) in 114 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:13.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 2.0 in stage 1299.2 (TID 2950) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 1.0 in stage 1299.2 (TID 2949) in 70 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:13.573+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 3.0 in stage 1299.2 (TID 2951) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.574+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 2.0 in stage 1299.2 (TID 2950) in 60 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:13.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 4.0 in stage 1299.2 (TID 2952) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 3.0 in stage 1299.2 (TID 2951) in 49 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:13.665+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 5.0 in stage 1299.2 (TID 2953) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.665+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 4.0 in stage 1299.2 (TID 2952) in 43 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:13.719+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 6.0 in stage 1299.2 (TID 2954) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.720+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 5.0 in stage 1299.2 (TID 2953) in 54 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:13.758+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 7.0 in stage 1299.2 (TID 2955) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.758+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 6.0 in stage 1299.2 (TID 2954) in 39 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:13.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 8.0 in stage 1299.2 (TID 2956) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 7.0 in stage 1299.2 (TID 2955) in 41 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:13.844+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 9.0 in stage 1299.2 (TID 2957) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.844+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 8.0 in stage 1299.2 (TID 2956) in 45 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:13.889+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 16.0 in stage 1336.2 (TID 2958) (172.20.0.5, executor 3, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.890+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 9.0 in stage 1299.2 (TID 2957) in 45 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:13.890+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSchedulerImpl: Removed TaskSet 1299.2, whose tasks have all completed, from pool
[2025-05-08T21:13:13.890+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: ShuffleMapStage 1299 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.595 s
[2025-05-08T21:13:13.890+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:13.890+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:13.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:13:13.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:13.892+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: Submitting ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:13.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MemoryStore: Block broadcast_324 stored as values in memory (estimated size 239.9 KiB, free 416.2 MiB)
[2025-05-08T21:13:13.906+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:13.907+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MemoryStore: Block broadcast_324_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 416.1 MiB)
[2025-05-08T21:13:13.908+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO BlockManagerInfo: Added broadcast_324_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.4 MiB)
[2025-05-08T21:13:13.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO SparkContext: Created broadcast 324 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:13.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:13.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSchedulerImpl: Adding task set 1300.2 with 10 tasks resource profile 0
[2025-05-08T21:13:13.949+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Starting task 0.0 in stage 1300.2 (TID 2959) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:13.950+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO TaskSetManager: Finished task 16.0 in stage 1336.2 (TID 2958) in 57 ms on 172.20.0.5 (executor 3) (14/41)
[2025-05-08T21:13:13.978+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO BlockManagerInfo: Added broadcast_324_piece0 in memory on 172.20.0.5:34029 (size: 79.0 KiB, free: 420.6 MiB)
[2025-05-08T21:13:13.999+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:14.021+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:14.024+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:14.028+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:14.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:55838
[2025-05-08T21:13:14.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:55838
[2025-05-08T21:13:14.041+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:55838
[2025-05-08T21:13:14.074+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 1.0 in stage 1300.2 (TID 2960) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.075+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 0.0 in stage 1300.2 (TID 2959) in 130 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:14.117+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 2.0 in stage 1300.2 (TID 2961) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.119+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 1.0 in stage 1300.2 (TID 2960) in 44 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:14.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 3.0 in stage 1300.2 (TID 2962) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.149+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 2.0 in stage 1300.2 (TID 2961) in 32 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:14.179+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 4.0 in stage 1300.2 (TID 2963) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.180+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 3.0 in stage 1300.2 (TID 2962) in 32 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:14.204+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 5.0 in stage 1300.2 (TID 2964) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 4.0 in stage 1300.2 (TID 2963) in 25 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:14.233+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 6.0 in stage 1300.2 (TID 2965) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.234+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 5.0 in stage 1300.2 (TID 2964) in 31 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:14.272+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 7.0 in stage 1300.2 (TID 2966) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.272+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 6.0 in stage 1300.2 (TID 2965) in 39 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:14.325+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 8.0 in stage 1300.2 (TID 2967) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.325+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 7.0 in stage 1300.2 (TID 2966) in 54 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:14.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 9.0 in stage 1300.2 (TID 2968) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 8.0 in stage 1300.2 (TID 2967) in 35 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:14.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 17.0 in stage 1336.2 (TID 2969) (172.20.0.5, executor 3, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 9.0 in stage 1300.2 (TID 2968) in 26 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:14.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSchedulerImpl: Removed TaskSet 1300.2, whose tasks have all completed, from pool
[2025-05-08T21:13:14.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO DAGScheduler: ShuffleMapStage 1300 (mapPartitions at GraphImpl.scala:208) finished in 0.492 s
[2025-05-08T21:13:14.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:14.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:14.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:13:14.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:14.386+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO DAGScheduler: Submitting ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:14.389+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MemoryStore: Block broadcast_325 stored as values in memory (estimated size 15.6 KiB, free 416.1 MiB)
[2025-05-08T21:13:14.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MemoryStore: Block broadcast_325_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 416.1 MiB)
[2025-05-08T21:13:14.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:14.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO BlockManagerInfo: Added broadcast_325_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.4 MiB)
[2025-05-08T21:13:14.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO SparkContext: Created broadcast 325 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:14.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:14.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSchedulerImpl: Adding task set 1301.2 with 10 tasks resource profile 0
[2025-05-08T21:13:14.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 0.0 in stage 1301.2 (TID 2970) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 17.0 in stage 1336.2 (TID 2969) in 36 ms on 172.20.0.5 (executor 3) (15/41)
[2025-05-08T21:13:14.427+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO BlockManagerInfo: Added broadcast_325_piece0 in memory on 172.20.0.5:34029 (size: 6.4 KiB, free: 420.6 MiB)
[2025-05-08T21:13:14.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:14.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:14.462+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:14.473+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:55838
[2025-05-08T21:13:14.487+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:55838
[2025-05-08T21:13:14.528+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:55838
[2025-05-08T21:13:14.534+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 1.0 in stage 1301.2 (TID 2971) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.534+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 0.0 in stage 1301.2 (TID 2970) in 115 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:14.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 2.0 in stage 1301.2 (TID 2972) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 1.0 in stage 1301.2 (TID 2971) in 76 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:14.683+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 3.0 in stage 1301.2 (TID 2973) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 2.0 in stage 1301.2 (TID 2972) in 74 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:14.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 4.0 in stage 1301.2 (TID 2974) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 3.0 in stage 1301.2 (TID 2973) in 86 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:14.833+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 5.0 in stage 1301.2 (TID 2975) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.833+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 4.0 in stage 1301.2 (TID 2974) in 65 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:14.895+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 6.0 in stage 1301.2 (TID 2976) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.895+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 5.0 in stage 1301.2 (TID 2975) in 62 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:14.984+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Starting task 7.0 in stage 1301.2 (TID 2977) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:14.984+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:14 INFO TaskSetManager: Finished task 6.0 in stage 1301.2 (TID 2976) in 90 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:15.045+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 8.0 in stage 1301.2 (TID 2978) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.046+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 7.0 in stage 1301.2 (TID 2977) in 62 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:15.106+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 9.0 in stage 1301.2 (TID 2979) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.107+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 8.0 in stage 1301.2 (TID 2978) in 61 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:15.171+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 18.0 in stage 1336.2 (TID 2980) (172.20.0.5, executor 3, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 9.0 in stage 1301.2 (TID 2979) in 65 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSchedulerImpl: Removed TaskSet 1301.2, whose tasks have all completed, from pool
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: ShuffleMapStage 1301 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.784 s
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:15.172+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: Submitting ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:15.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:15.183+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MemoryStore: Block broadcast_326 stored as values in memory (estimated size 240.2 KiB, free 415.8 MiB)
[2025-05-08T21:13:15.232+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MemoryStore: Block broadcast_326_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 415.8 MiB)
[2025-05-08T21:13:15.234+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 19.0 in stage 1336.2 (TID 2981) (172.20.0.5, executor 3, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.235+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 18.0 in stage 1336.2 (TID 2980) in 63 ms on 172.20.0.5 (executor 3) (16/41)
[2025-05-08T21:13:15.236+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Added broadcast_326_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.3 MiB)
[2025-05-08T21:13:15.236+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO SparkContext: Created broadcast 326 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:15.236+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:15.236+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSchedulerImpl: Adding task set 1302.2 with 10 tasks resource profile 0
[2025-05-08T21:13:15.249+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_324_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.4 MiB)
[2025-05-08T21:13:15.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_324_piece0 on 172.20.0.5:34029 in memory (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T21:13:15.284+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_320_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:13:15.289+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_320_piece0 on 172.20.0.5:34029 in memory (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:13:15.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_322_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.6 MiB)
[2025-05-08T21:13:15.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 0.0 in stage 1302.2 (TID 2982) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_322_piece0 on 172.20.0.5:34029 in memory (size: 79.4 KiB, free: 420.8 MiB)
[2025-05-08T21:13:15.307+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 19.0 in stage 1336.2 (TID 2981) in 69 ms on 172.20.0.5 (executor 3) (17/41)
[2025-05-08T21:13:15.315+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_323_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.6 MiB)
[2025-05-08T21:13:15.318+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_323_piece0 on 172.20.0.5:34029 in memory (size: 6.3 KiB, free: 420.8 MiB)
[2025-05-08T21:13:15.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Added broadcast_326_piece0 in memory on 172.20.0.5:34029 (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:13:15.328+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_321_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.6 MiB)
[2025-05-08T21:13:15.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Removed broadcast_321_piece0 on 172.20.0.5:34029 in memory (size: 6.1 KiB, free: 420.8 MiB)
[2025-05-08T21:13:15.337+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:15.340+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:15.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:15.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:15.345+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:55838
[2025-05-08T21:13:15.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:55838
[2025-05-08T21:13:15.348+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:55838
[2025-05-08T21:13:15.350+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:55838
[2025-05-08T21:13:15.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 1.0 in stage 1302.2 (TID 2983) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 0.0 in stage 1302.2 (TID 2982) in 83 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:15.414+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 2.0 in stage 1302.2 (TID 2984) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.414+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 1.0 in stage 1302.2 (TID 2983) in 32 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:15.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 3.0 in stage 1302.2 (TID 2985) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 2.0 in stage 1302.2 (TID 2984) in 34 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:15.474+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 4.0 in stage 1302.2 (TID 2986) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.474+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 3.0 in stage 1302.2 (TID 2985) in 29 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:15.511+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 5.0 in stage 1302.2 (TID 2987) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.512+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 4.0 in stage 1302.2 (TID 2986) in 38 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:15.544+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 6.0 in stage 1302.2 (TID 2988) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.544+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 5.0 in stage 1302.2 (TID 2987) in 33 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:15.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 7.0 in stage 1302.2 (TID 2989) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 6.0 in stage 1302.2 (TID 2988) in 28 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:15.600+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 8.0 in stage 1302.2 (TID 2990) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 7.0 in stage 1302.2 (TID 2989) in 30 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:15.630+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 9.0 in stage 1302.2 (TID 2991) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.630+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 8.0 in stage 1302.2 (TID 2990) in 30 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:15.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 20.0 in stage 1336.2 (TID 2992) (172.20.0.5, executor 3, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 9.0 in stage 1302.2 (TID 2991) in 28 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:15.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSchedulerImpl: Removed TaskSet 1302.2, whose tasks have all completed, from pool
[2025-05-08T21:13:15.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: ShuffleMapStage 1302 (mapPartitions at GraphImpl.scala:208) finished in 0.485 s
[2025-05-08T21:13:15.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:15.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:15.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:13:15.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:15.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: Submitting ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:15.660+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MemoryStore: Block broadcast_327 stored as values in memory (estimated size 16.4 KiB, free 416.7 MiB)
[2025-05-08T21:13:15.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:55838
[2025-05-08T21:13:15.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MemoryStore: Block broadcast_327_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 416.7 MiB)
[2025-05-08T21:13:15.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Added broadcast_327_piece0 in memory on f2a432e4376a:35283 (size: 6.5 KiB, free: 432.6 MiB)
[2025-05-08T21:13:15.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO SparkContext: Created broadcast 327 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:15.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:15.663+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSchedulerImpl: Adding task set 1303.2 with 10 tasks resource profile 0
[2025-05-08T21:13:15.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 0.0 in stage 1303.2 (TID 2993) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.689+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 20.0 in stage 1336.2 (TID 2992) in 32 ms on 172.20.0.5 (executor 3) (18/41)
[2025-05-08T21:13:15.694+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO BlockManagerInfo: Added broadcast_327_piece0 in memory on 172.20.0.5:34029 (size: 6.5 KiB, free: 420.7 MiB)
[2025-05-08T21:13:15.697+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:15.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:15.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:15.733+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:55838
[2025-05-08T21:13:15.747+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:55838
[2025-05-08T21:13:15.766+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:55838
[2025-05-08T21:13:15.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:55838
[2025-05-08T21:13:15.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 1.0 in stage 1303.2 (TID 2994) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 0.0 in stage 1303.2 (TID 2993) in 158 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:15.970+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Starting task 2.0 in stage 1303.2 (TID 2995) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:15.970+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:15 INFO TaskSetManager: Finished task 1.0 in stage 1303.2 (TID 2994) in 124 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:16.094+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Starting task 3.0 in stage 1303.2 (TID 2996) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:16.094+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Finished task 2.0 in stage 1303.2 (TID 2995) in 124 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:16.243+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Starting task 4.0 in stage 1303.2 (TID 2997) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:16.243+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Finished task 3.0 in stage 1303.2 (TID 2996) in 150 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:16.371+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Starting task 5.0 in stage 1303.2 (TID 2998) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:16.371+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Finished task 4.0 in stage 1303.2 (TID 2997) in 129 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:16.509+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Starting task 6.0 in stage 1303.2 (TID 2999) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:16.510+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Finished task 5.0 in stage 1303.2 (TID 2998) in 139 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:16.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Starting task 7.0 in stage 1303.2 (TID 3000) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:16.647+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Finished task 6.0 in stage 1303.2 (TID 2999) in 137 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:16.766+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Starting task 8.0 in stage 1303.2 (TID 3001) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:16.766+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Finished task 7.0 in stage 1303.2 (TID 3000) in 120 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:16.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Starting task 9.0 in stage 1303.2 (TID 3002) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:16.925+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:16 INFO TaskSetManager: Finished task 8.0 in stage 1303.2 (TID 3001) in 156 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:17.104+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 21.0 in stage 1336.2 (TID 3003) (172.20.0.5, executor 3, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.105+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 9.0 in stage 1303.2 (TID 3002) in 183 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:17.105+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSchedulerImpl: Removed TaskSet 1303.2, whose tasks have all completed, from pool
[2025-05-08T21:13:17.108+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: ShuffleMapStage 1303 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.444 s
[2025-05-08T21:13:17.109+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:17.109+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:17.109+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:13:17.110+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:17.112+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:55838
[2025-05-08T21:13:17.120+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: Submitting ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:17.139+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MemoryStore: Block broadcast_328 stored as values in memory (estimated size 240.5 KiB, free 416.5 MiB)
[2025-05-08T21:13:17.147+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MemoryStore: Block broadcast_328_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.4 MiB)
[2025-05-08T21:13:17.149+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO BlockManagerInfo: Added broadcast_328_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:13:17.160+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO SparkContext: Created broadcast 328 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:17.162+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:17.162+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSchedulerImpl: Adding task set 1304.2 with 10 tasks resource profile 0
[2025-05-08T21:13:17.209+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 0.0 in stage 1304.2 (TID 3004) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.211+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 21.0 in stage 1336.2 (TID 3003) in 109 ms on 172.20.0.5 (executor 3) (19/41)
[2025-05-08T21:13:17.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO BlockManagerInfo: Added broadcast_328_piece0 in memory on 172.20.0.5:34029 (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:13:17.248+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:17.277+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:17.283+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:17.290+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:17.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:55838
[2025-05-08T21:13:17.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:55838
[2025-05-08T21:13:17.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:55838
[2025-05-08T21:13:17.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:55838
[2025-05-08T21:13:17.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:55838
[2025-05-08T21:13:17.352+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 1.0 in stage 1304.2 (TID 3005) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.353+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 0.0 in stage 1304.2 (TID 3004) in 143 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:17.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 2.0 in stage 1304.2 (TID 3006) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.403+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 1.0 in stage 1304.2 (TID 3005) in 51 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:17.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 3.0 in stage 1304.2 (TID 3007) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 2.0 in stage 1304.2 (TID 3006) in 44 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:17.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 4.0 in stage 1304.2 (TID 3008) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.490+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 3.0 in stage 1304.2 (TID 3007) in 46 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:17.534+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 5.0 in stage 1304.2 (TID 3009) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 4.0 in stage 1304.2 (TID 3008) in 47 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:17.617+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 6.0 in stage 1304.2 (TID 3010) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.618+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 5.0 in stage 1304.2 (TID 3009) in 84 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:17.735+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 7.0 in stage 1304.2 (TID 3011) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 6.0 in stage 1304.2 (TID 3010) in 120 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:17.762+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 8.0 in stage 1304.2 (TID 3012) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.762+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 7.0 in stage 1304.2 (TID 3011) in 27 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:17.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 9.0 in stage 1304.2 (TID 3013) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 8.0 in stage 1304.2 (TID 3012) in 29 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:17.821+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 22.0 in stage 1336.2 (TID 3014) (172.20.0.5, executor 3, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.821+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 9.0 in stage 1304.2 (TID 3013) in 32 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:17.821+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSchedulerImpl: Removed TaskSet 1304.2, whose tasks have all completed, from pool
[2025-05-08T21:13:17.822+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: ShuffleMapStage 1304 (mapPartitions at GraphImpl.scala:208) finished in 0.698 s
[2025-05-08T21:13:17.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:17.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:17.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:13:17.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:17.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: Submitting ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:17.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:55838
[2025-05-08T21:13:17.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MemoryStore: Block broadcast_329 stored as values in memory (estimated size 17.1 KiB, free 416.4 MiB)
[2025-05-08T21:13:17.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MemoryStore: Block broadcast_329_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 416.4 MiB)
[2025-05-08T21:13:17.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO BlockManagerInfo: Added broadcast_329_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.5 MiB)
[2025-05-08T21:13:17.841+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO SparkContext: Created broadcast 329 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:17.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:17.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSchedulerImpl: Adding task set 1305.2 with 10 tasks resource profile 0
[2025-05-08T21:13:17.852+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Starting task 0.0 in stage 1305.2 (TID 3015) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:17.854+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO TaskSetManager: Finished task 22.0 in stage 1336.2 (TID 3014) in 32 ms on 172.20.0.5 (executor 3) (20/41)
[2025-05-08T21:13:17.862+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO BlockManagerInfo: Added broadcast_329_piece0 in memory on 172.20.0.5:34029 (size: 6.6 KiB, free: 420.7 MiB)
[2025-05-08T21:13:17.867+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:17.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:17.887+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:17.908+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:55838
[2025-05-08T21:13:17.927+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:55838
[2025-05-08T21:13:17.960+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:55838
[2025-05-08T21:13:18.018+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:55838
[2025-05-08T21:13:18.183+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:55838
[2025-05-08T21:13:18.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:18 INFO TaskSetManager: Starting task 1.0 in stage 1305.2 (TID 3016) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:18.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:18 INFO TaskSetManager: Finished task 0.0 in stage 1305.2 (TID 3015) in 354 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:18.624+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:18 INFO TaskSetManager: Starting task 2.0 in stage 1305.2 (TID 3017) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:18.647+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:18 INFO TaskSetManager: Finished task 1.0 in stage 1305.2 (TID 3016) in 417 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:19.023+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Starting task 3.0 in stage 1305.2 (TID 3018) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:19.024+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Finished task 2.0 in stage 1305.2 (TID 3017) in 409 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:19.311+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Starting task 4.0 in stage 1305.2 (TID 3019) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:19.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Finished task 3.0 in stage 1305.2 (TID 3018) in 288 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:19.567+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Starting task 5.0 in stage 1305.2 (TID 3020) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:19.567+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Finished task 4.0 in stage 1305.2 (TID 3019) in 255 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:19.787+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Starting task 6.0 in stage 1305.2 (TID 3021) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:19.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:19 INFO TaskSetManager: Finished task 5.0 in stage 1305.2 (TID 3020) in 221 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:20.034+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Starting task 7.0 in stage 1305.2 (TID 3022) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:20.034+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Finished task 6.0 in stage 1305.2 (TID 3021) in 247 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:20.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Starting task 8.0 in stage 1305.2 (TID 3023) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:20.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Finished task 7.0 in stage 1305.2 (TID 3022) in 262 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:20.618+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Starting task 9.0 in stage 1305.2 (TID 3024) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:20.619+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Finished task 8.0 in stage 1305.2 (TID 3023) in 324 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:20.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Starting task 23.0 in stage 1336.2 (TID 3025) (172.20.0.5, executor 3, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:20.905+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSetManager: Finished task 9.0 in stage 1305.2 (TID 3024) in 287 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:20.905+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSchedulerImpl: Removed TaskSet 1305.2, whose tasks have all completed, from pool
[2025-05-08T21:13:20.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO DAGScheduler: ShuffleMapStage 1305 (mapPartitions at VertexRDDImpl.scala:247) finished in 3.076 s
[2025-05-08T21:13:20.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:20.911+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:20.911+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:13:20.911+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:20.920+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:55838
[2025-05-08T21:13:20.924+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO DAGScheduler: Submitting ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:20.948+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO MemoryStore: Block broadcast_330 stored as values in memory (estimated size 240.8 KiB, free 416.1 MiB)
[2025-05-08T21:13:20.979+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO MemoryStore: Block broadcast_330_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 416.1 MiB)
[2025-05-08T21:13:20.980+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO BlockManagerInfo: Added broadcast_330_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.4 MiB)
[2025-05-08T21:13:20.991+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO SparkContext: Created broadcast 330 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:20.993+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:20.993+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:20 INFO TaskSchedulerImpl: Adding task set 1306.2 with 10 tasks resource profile 0
[2025-05-08T21:13:21.069+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO TaskSetManager: Starting task 0.0 in stage 1306.2 (TID 3026) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:21.069+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO TaskSetManager: Finished task 23.0 in stage 1336.2 (TID 3025) in 165 ms on 172.20.0.5 (executor 3) (21/41)
[2025-05-08T21:13:21.081+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO BlockManagerInfo: Added broadcast_330_piece0 in memory on 172.20.0.5:34029 (size: 79.4 KiB, free: 420.6 MiB)
[2025-05-08T21:13:21.092+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:21.112+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:21.120+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:21.127+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:21.141+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:55838
[2025-05-08T21:13:21.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:55838
[2025-05-08T21:13:21.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:55838
[2025-05-08T21:13:21.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:55838
[2025-05-08T21:13:21.179+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:55838
[2025-05-08T21:13:21.180+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:55838
[2025-05-08T21:13:21.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO TaskSetManager: Starting task 1.0 in stage 1306.2 (TID 3027) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:21.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:21 INFO TaskSetManager: Finished task 0.0 in stage 1306.2 (TID 3026) in 411 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:22.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:22 INFO TaskSetManager: Starting task 2.0 in stage 1306.2 (TID 3028) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:22.339+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:22 INFO TaskSetManager: Finished task 1.0 in stage 1306.2 (TID 3027) in 725 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:23.150+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:23 INFO TaskSetManager: Starting task 3.0 in stage 1306.2 (TID 3029) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:23.182+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:23 INFO TaskSetManager: Finished task 2.0 in stage 1306.2 (TID 3028) in 975 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:23.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:23 INFO TaskSetManager: Starting task 4.0 in stage 1306.2 (TID 3030) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:23.848+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:23 INFO TaskSetManager: Finished task 3.0 in stage 1306.2 (TID 3029) in 687 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:25.270+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:25 INFO TaskSetManager: Starting task 5.0 in stage 1306.2 (TID 3031) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:25.412+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:25 INFO TaskSetManager: Finished task 4.0 in stage 1306.2 (TID 3030) in 1440 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:29.101+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:29 INFO TaskSetManager: Starting task 6.0 in stage 1306.2 (TID 3032) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:29.181+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:29 INFO TaskSetManager: Finished task 5.0 in stage 1306.2 (TID 3031) in 3816 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:30.222+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:30 INFO TaskSetManager: Starting task 7.0 in stage 1306.2 (TID 3033) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:30.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:30 INFO TaskSetManager: Finished task 6.0 in stage 1306.2 (TID 3032) in 1167 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:31.088+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:31 INFO TaskSetManager: Starting task 8.0 in stage 1306.2 (TID 3034) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:31.100+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:31 INFO TaskSetManager: Finished task 7.0 in stage 1306.2 (TID 3033) in 884 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:31.873+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:31 INFO TaskSetManager: Starting task 9.0 in stage 1306.2 (TID 3035) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:31.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:31 INFO TaskSetManager: Finished task 8.0 in stage 1306.2 (TID 3034) in 794 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:32.212+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSetManager: Starting task 24.0 in stage 1336.2 (TID 3036) (172.20.0.5, executor 3, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:32.213+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSetManager: Finished task 9.0 in stage 1306.2 (TID 3035) in 343 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:32.213+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSchedulerImpl: Removed TaskSet 1306.2, whose tasks have all completed, from pool
[2025-05-08T21:13:32.219+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:55838
[2025-05-08T21:13:32.219+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO DAGScheduler: ShuffleMapStage 1306 (mapPartitions at GraphImpl.scala:208) finished in 11.287 s
[2025-05-08T21:13:32.219+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:32.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:32.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:13:32.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:32.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO DAGScheduler: Submitting ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:32.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1307.
[2025-05-08T21:13:32.234+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MemoryStore: Block broadcast_331 stored as values in memory (estimated size 17.8 KiB, free 416.0 MiB)
[2025-05-08T21:13:32.361+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MemoryStore: Block broadcast_331_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 416.0 MiB)
[2025-05-08T21:13:32.364+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSetManager: Starting task 25.0 in stage 1336.2 (TID 3037) (172.20.0.5, executor 3, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:32.365+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSetManager: Finished task 24.0 in stage 1336.2 (TID 3036) in 153 ms on 172.20.0.5 (executor 3) (22/41)
[2025-05-08T21:13:32.372+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Added broadcast_331_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.4 MiB)
[2025-05-08T21:13:32.375+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_326_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:13:32.383+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO SparkContext: Created broadcast 331 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:32.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:32.385+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSchedulerImpl: Adding task set 1307.2 with 10 tasks resource profile 0
[2025-05-08T21:13:32.399+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_326_piece0 on 172.20.0.5:34029 in memory (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:13:32.414+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_325_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.5 MiB)
[2025-05-08T21:13:32.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_325_piece0 on 172.20.0.5:34029 in memory (size: 6.4 KiB, free: 420.7 MiB)
[2025-05-08T21:13:32.417+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSetManager: Starting task 0.0 in stage 1307.2 (TID 3038) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:32.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO TaskSetManager: Finished task 25.0 in stage 1336.2 (TID 3037) in 57 ms on 172.20.0.5 (executor 3) (23/41)
[2025-05-08T21:13:32.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_328_piece0 on 172.20.0.5:34029 in memory (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:13:32.426+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_328_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.6 MiB)
[2025-05-08T21:13:32.429+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Added broadcast_331_piece0 in memory on 172.20.0.5:34029 (size: 6.6 KiB, free: 420.7 MiB)
[2025-05-08T21:13:32.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_329_piece0 on 172.20.0.5:34029 in memory (size: 6.6 KiB, free: 420.7 MiB)
[2025-05-08T21:13:32.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_329_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.6 MiB)
[2025-05-08T21:13:32.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:32.442+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_327_piece0 on f2a432e4376a:35283 in memory (size: 6.5 KiB, free: 432.6 MiB)
[2025-05-08T21:13:32.452+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO BlockManagerInfo: Removed broadcast_327_piece0 on 172.20.0.5:34029 in memory (size: 6.5 KiB, free: 420.8 MiB)
[2025-05-08T21:13:32.530+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:32.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:32.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:55838
[2025-05-08T21:13:32.697+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:55838
[2025-05-08T21:13:32.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:55838
[2025-05-08T21:13:32.795+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:55838
[2025-05-08T21:13:32.908+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:55838
[2025-05-08T21:13:33.326+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:55838
[2025-05-08T21:13:33.356+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:33 INFO TaskSetManager: Starting task 1.0 in stage 1307.2 (TID 3039) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:33.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:33 INFO TaskSetManager: Finished task 0.0 in stage 1307.2 (TID 3038) in 940 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:34.349+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:34 INFO TaskSetManager: Starting task 2.0 in stage 1307.2 (TID 3040) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:34.373+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:34 INFO TaskSetManager: Finished task 1.0 in stage 1307.2 (TID 3039) in 993 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:34.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:34 INFO TaskSetManager: Starting task 3.0 in stage 1307.2 (TID 3041) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:34.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:34 INFO TaskSetManager: Finished task 2.0 in stage 1307.2 (TID 3040) in 445 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:35.157+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:35 INFO TaskSetManager: Starting task 4.0 in stage 1307.2 (TID 3042) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:35.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:35 INFO TaskSetManager: Finished task 3.0 in stage 1307.2 (TID 3041) in 369 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:35.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:35 INFO TaskSetManager: Starting task 5.0 in stage 1307.2 (TID 3043) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:35.809+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:35 INFO TaskSetManager: Finished task 4.0 in stage 1307.2 (TID 3042) in 645 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:36.173+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:36 INFO TaskSetManager: Starting task 6.0 in stage 1307.2 (TID 3044) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:36.173+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:36 INFO TaskSetManager: Finished task 5.0 in stage 1307.2 (TID 3043) in 374 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:36.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:36 INFO TaskSetManager: Starting task 7.0 in stage 1307.2 (TID 3045) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:36.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:36 INFO TaskSetManager: Finished task 6.0 in stage 1307.2 (TID 3044) in 466 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:37.082+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:37 INFO TaskSetManager: Starting task 8.0 in stage 1307.2 (TID 3046) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:37.087+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:37 INFO TaskSetManager: Finished task 7.0 in stage 1307.2 (TID 3045) in 445 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:37.545+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:37 INFO TaskSetManager: Starting task 9.0 in stage 1307.2 (TID 3047) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:37.545+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:37 INFO TaskSetManager: Finished task 8.0 in stage 1307.2 (TID 3046) in 465 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:38.007+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 26.0 in stage 1336.2 (TID 3048) (172.20.0.5, executor 3, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 9.0 in stage 1307.2 (TID 3047) in 462 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSchedulerImpl: Removed TaskSet 1307.2, whose tasks have all completed, from pool
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: ShuffleMapStage 1307 (mapPartitions at VertexRDDImpl.scala:247) finished in 5.777 s
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:55838
[2025-05-08T21:13:38.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: Submitting ShuffleMapStage 1308 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:13:38.042+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MemoryStore: Block broadcast_332 stored as values in memory (estimated size 241.1 KiB, free 416.5 MiB)
[2025-05-08T21:13:38.062+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MemoryStore: Block broadcast_332_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 416.4 MiB)
[2025-05-08T21:13:38.063+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO BlockManagerInfo: Added broadcast_332_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.5 MiB)
[2025-05-08T21:13:38.063+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 27.0 in stage 1336.2 (TID 3049) (172.20.0.5, executor 3, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.063+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 26.0 in stage 1336.2 (TID 3048) in 58 ms on 172.20.0.5 (executor 3) (24/41)
[2025-05-08T21:13:38.065+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO SparkContext: Created broadcast 332 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:38.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1308 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:38.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSchedulerImpl: Adding task set 1308.1 with 10 tasks resource profile 0
[2025-05-08T21:13:38.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 0.0 in stage 1308.1 (TID 3050) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 27.0 in stage 1336.2 (TID 3049) in 16 ms on 172.20.0.5 (executor 3) (25/41)
[2025-05-08T21:13:38.083+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO BlockManagerInfo: Added broadcast_332_piece0 in memory on 172.20.0.5:34029 (size: 79.6 KiB, free: 420.7 MiB)
[2025-05-08T21:13:38.104+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:55838
[2025-05-08T21:13:38.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:55838
[2025-05-08T21:13:38.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:55838
[2025-05-08T21:13:38.117+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:55838
[2025-05-08T21:13:38.121+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:55838
[2025-05-08T21:13:38.127+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:55838
[2025-05-08T21:13:38.129+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:55838
[2025-05-08T21:13:38.131+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:55838
[2025-05-08T21:13:38.133+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:55838
[2025-05-08T21:13:38.135+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:55838
[2025-05-08T21:13:38.138+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:55838
[2025-05-08T21:13:38.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 1.0 in stage 1308.1 (TID 3051) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 0.0 in stage 1308.1 (TID 3050) in 114 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:38.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 2.0 in stage 1308.1 (TID 3052) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 1.0 in stage 1308.1 (TID 3051) in 29 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:38.246+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 3.0 in stage 1308.1 (TID 3053) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.247+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 2.0 in stage 1308.1 (TID 3052) in 25 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:38.269+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 4.0 in stage 1308.1 (TID 3054) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.270+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 3.0 in stage 1308.1 (TID 3053) in 24 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:38.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 5.0 in stage 1308.1 (TID 3055) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 4.0 in stage 1308.1 (TID 3054) in 27 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:38.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 6.0 in stage 1308.1 (TID 3056) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.323+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 5.0 in stage 1308.1 (TID 3055) in 27 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:38.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 7.0 in stage 1308.1 (TID 3057) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.348+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 6.0 in stage 1308.1 (TID 3056) in 25 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:38.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 8.0 in stage 1308.1 (TID 3058) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 7.0 in stage 1308.1 (TID 3057) in 27 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:38.396+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 9.0 in stage 1308.1 (TID 3059) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 8.0 in stage 1308.1 (TID 3058) in 24 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:13:38.421+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 28.0 in stage 1336.2 (TID 3060) (172.20.0.5, executor 3, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.421+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 9.0 in stage 1308.1 (TID 3059) in 25 ms on 172.20.0.5 (executor 3) (10/10)
[2025-05-08T21:13:38.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSchedulerImpl: Removed TaskSet 1308.1, whose tasks have all completed, from pool
[2025-05-08T21:13:38.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: ShuffleMapStage 1308 (mapPartitions at GraphImpl.scala:208) finished in 0.396 s
[2025-05-08T21:13:38.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:13:38.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:13:38.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:13:38.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: failed: Set()
[2025-05-08T21:13:38.422+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: Submitting ShuffleMapStage 1309 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:13:38.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MemoryStore: Block broadcast_333 stored as values in memory (estimated size 18.5 KiB, free 416.4 MiB)
[2025-05-08T21:13:38.425+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MemoryStore: Block broadcast_333_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 416.4 MiB)
[2025-05-08T21:13:38.425+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO BlockManagerInfo: Added broadcast_333_piece0 in memory on f2a432e4376a:35283 (size: 6.8 KiB, free: 432.5 MiB)
[2025-05-08T21:13:38.425+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO SparkContext: Created broadcast 333 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:13:38.426+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1309 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:13:38.426+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSchedulerImpl: Adding task set 1309.1 with 10 tasks resource profile 0
[2025-05-08T21:13:38.426+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:55838
[2025-05-08T21:13:38.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Starting task 0.0 in stage 1309.1 (TID 3061) (172.20.0.5, executor 3, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:38.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO TaskSetManager: Finished task 28.0 in stage 1336.2 (TID 3060) in 23 ms on 172.20.0.5 (executor 3) (26/41)
[2025-05-08T21:13:38.449+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO BlockManagerInfo: Added broadcast_333_piece0 in memory on 172.20.0.5:34029 (size: 6.8 KiB, free: 420.7 MiB)
[2025-05-08T21:13:38.452+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:55838
[2025-05-08T21:13:38.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:55838
[2025-05-08T21:13:38.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:55838
[2025-05-08T21:13:38.483+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:55838
[2025-05-08T21:13:38.493+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:55838
[2025-05-08T21:13:38.509+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:55838
[2025-05-08T21:13:38.551+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:55838
[2025-05-08T21:13:38.777+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:55838
[2025-05-08T21:13:39.034+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:55838
[2025-05-08T21:13:39.580+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:55838
[2025-05-08T21:13:39.598+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:39 INFO TaskSetManager: Starting task 1.0 in stage 1309.1 (TID 3062) (172.20.0.5, executor 3, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:39.599+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:39 INFO TaskSetManager: Finished task 0.0 in stage 1309.1 (TID 3061) in 1155 ms on 172.20.0.5 (executor 3) (1/10)
[2025-05-08T21:13:40.706+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:40 INFO TaskSetManager: Starting task 2.0 in stage 1309.1 (TID 3063) (172.20.0.5, executor 3, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:40.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:40 INFO TaskSetManager: Finished task 1.0 in stage 1309.1 (TID 3062) in 1108 ms on 172.20.0.5 (executor 3) (2/10)
[2025-05-08T21:13:42.075+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:42 INFO TaskSetManager: Starting task 3.0 in stage 1309.1 (TID 3064) (172.20.0.5, executor 3, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:42.101+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:42 INFO TaskSetManager: Finished task 2.0 in stage 1309.1 (TID 3063) in 1372 ms on 172.20.0.5 (executor 3) (3/10)
[2025-05-08T21:13:43.952+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:43 INFO TaskSetManager: Starting task 4.0 in stage 1309.1 (TID 3065) (172.20.0.5, executor 3, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:43.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:43 INFO TaskSetManager: Finished task 3.0 in stage 1309.1 (TID 3064) in 1880 ms on 172.20.0.5 (executor 3) (4/10)
[2025-05-08T21:13:45.234+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:45 INFO TaskSetManager: Starting task 5.0 in stage 1309.1 (TID 3066) (172.20.0.5, executor 3, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:45.268+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:45 INFO TaskSetManager: Finished task 4.0 in stage 1309.1 (TID 3065) in 1286 ms on 172.20.0.5 (executor 3) (5/10)
[2025-05-08T21:13:46.693+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:46 INFO TaskSetManager: Starting task 6.0 in stage 1309.1 (TID 3067) (172.20.0.5, executor 3, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:46.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:46 INFO TaskSetManager: Finished task 5.0 in stage 1309.1 (TID 3066) in 1461 ms on 172.20.0.5 (executor 3) (6/10)
[2025-05-08T21:13:47.465+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:47 INFO TaskSetManager: Starting task 7.0 in stage 1309.1 (TID 3068) (172.20.0.5, executor 3, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:47.466+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:47 INFO TaskSetManager: Finished task 6.0 in stage 1309.1 (TID 3067) in 773 ms on 172.20.0.5 (executor 3) (7/10)
[2025-05-08T21:13:48.574+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:48 INFO TaskSetManager: Starting task 8.0 in stage 1309.1 (TID 3069) (172.20.0.5, executor 3, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:48.586+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:48 INFO TaskSetManager: Finished task 7.0 in stage 1309.1 (TID 3068) in 1110 ms on 172.20.0.5 (executor 3) (8/10)
[2025-05-08T21:13:49.669+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:49 INFO TaskSetManager: Starting task 9.0 in stage 1309.1 (TID 3070) (172.20.0.5, executor 3, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:13:49.679+0000] {spark_submit.py:571} INFO - 25/05/08 21:13:49 INFO TaskSetManager: Finished task 8.0 in stage 1309.1 (TID 3069) in 1097 ms on 172.20.0.5 (executor 3) (9/10)
[2025-05-08T21:15:38.553+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/3 is now LOST (worker lost)
[2025-05-08T21:15:38.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO StandaloneSchedulerBackend: Executor app-20250508193925-0005/3 removed: worker lost
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO StandaloneSchedulerBackend: Worker worker-20250508061515-172.20.0.5-45383 removed: Not receiving heartbeat for 60 seconds
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 ERROR TaskSchedulerImpl: Lost executor 3 on 172.20.0.5: worker lost
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 19), so marking it as still running.
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 17), so marking it as still running.
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 12), so marking it as still running.
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN TaskSetManager: Lost task 9.0 in stage 1309.1 (TID 3070) (172.20.0.5 executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: worker lost
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO TaskSchedulerImpl: Handle removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 7), so marking it as still running.
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 2), so marking it as still running.
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 14), so marking it as still running.
[2025-05-08T21:15:38.638+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 25), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 27), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 1), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 18), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 23), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 15), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 10), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 3), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 20), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 28), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 8), so marking it as still running.
[2025-05-08T21:15:38.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 24), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 26), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 16), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 21), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 13), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 9), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 11), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 6), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 22), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 1), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 4), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 3), so marking it as still running.
[2025-05-08T21:15:38.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 6), so marking it as still running.
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 0), so marking it as still running.
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 8), so marking it as still running.
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 2), so marking it as still running.
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 5), so marking it as still running.
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Resubmitted ShuffleMapTask(1309, 7), so marking it as still running.
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Executor lost: 3 (epoch 279)
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_3 !
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_1 !
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_4 !
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_5 !
[2025-05-08T21:15:38.641+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_0 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_0 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_3 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_5 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_8 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_9 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_4 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_3 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_9 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_4 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_0 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_9 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_6 !
[2025-05-08T21:15:38.642+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_8 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_6 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_3 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_5 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_7 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_1 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_9 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_6 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_4 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_9 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_8 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_7 !
[2025-05-08T21:15:38.643+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_6 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_1 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_8 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_6 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_1 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_3 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_7 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_1 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_3 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_7 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_2 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_2 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_5 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_2 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_9 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_0 !
[2025-05-08T21:15:38.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_4 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_6 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_1 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_5 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_4 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_0 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_3 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_7 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_0 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_0 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_8 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_2 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_2 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_5 !
[2025-05-08T21:15:38.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_1 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_7 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_9 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_8 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_5 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_2 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_2 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_4 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_7 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_8 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_6 !
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, 172.20.0.5, 34029, None)
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO BlockManagerMaster: Removed 3 successfully in removeExecutor
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 279)
[2025-05-08T21:15:38.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO DAGScheduler: Shuffle files lost for worker worker-20250508061515-172.20.0.5-45383 on host 172.20.0.5
[2025-05-08T21:15:38.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250508193925-0005/4 on worker-20250508061515-172.20.0.5-45383 (172.20.0.5:45383) with 1 core(s)
[2025-05-08T21:15:38.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250508193925-0005/4 on hostPort 172.20.0.5:45383 with 1 core(s), 1024.0 MiB RAM
[2025-05-08T21:15:39.507+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:39 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 3070 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
[2025-05-08T21:15:39.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/4 is now RUNNING
[2025-05-08T21:15:39.535+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:39 WARN CoarseGrainedSchedulerBackend$DriverEndpoint: Ignored task status update (3070 state FAILED) from unknown executor with ID 3
[2025-05-08T21:15:39.432+0000] {job.py:213} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.20.0.2), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 184, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.20.0.2), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-05-08T21:15:43.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:46780) with ID 4,  ResourceProfileId 0
[2025-05-08T21:15:43.226+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:33389 with 434.4 MiB RAM, BlockManagerId(4, 172.20.0.5, 33389, None)
[2025-05-08T21:15:43.402+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:43 INFO TaskSetManager: Starting task 9.1 in stage 1309.1 (TID 3071) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:43.583+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:43 INFO BlockManagerInfo: Added broadcast_333_piece0 in memory on 172.20.0.5:33389 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T21:15:43.995+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:46780
[2025-05-08T21:15:44.071+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSetManager: Starting task 7.1 in stage 1309.1 (TID 3072) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:44.072+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 WARN TaskSetManager: Lost task 9.1 in stage 1309.1 (TID 3071) (172.20.0.5 executor 4): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=9, message=
[2025-05-08T21:15:44.072+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 9
[2025-05-08T21:15:44.072+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:15:44.072+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:15:44.073+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.074+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.075+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.076+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.076+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.076+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.076+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.076+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.076+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.076+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.077+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.078+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.078+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.078+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.078+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.078+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.078+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.078+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.079+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.080+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.081+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.082+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.082+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.082+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.082+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.082+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.082+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.082+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:15:44.083+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:15:44.084+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:15:44.084+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:15:44.084+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:15:44.084+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:15:44.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSetManager: task 9.1 in stage 1309.1 (TID 3071) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:15:44.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Marking ShuffleMapStage 1309 (mapPartitions at VertexRDDImpl.scala:247) as failed due to a fetch failure from ShuffleMapStage 1254 (map at GraphFrame.scala:187)
[2025-05-08T21:15:44.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: ShuffleMapStage 1309 (mapPartitions at VertexRDDImpl.scala:247) failed in 125.649 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 9
[2025-05-08T21:15:44.085+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:15:44.085+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:15:44.085+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.085+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:15:44.085+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:15:44.085+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:15:44.085+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.086+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:15:44.086+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:15:44.086+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:15:44.086+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:15:44.086+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:15:44.086+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:15:44.086+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.087+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.088+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.088+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.088+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.088+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.088+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.088+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.088+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.089+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.089+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.089+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.089+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.089+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.089+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.089+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.090+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.090+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.090+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.090+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.090+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.090+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.090+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.091+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.092+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.093+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:15:44.094+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:15:44.095+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:15:44.095+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:15:44.095+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:15:44.095+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:15:44.095+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:15:44.095+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:15:44.095+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Resubmitting ShuffleMapStage 1254 (map at GraphFrame.scala:187) and ShuffleMapStage 1309 (mapPartitions at VertexRDDImpl.scala:247) due to fetch failure
[2025-05-08T21:15:44.100+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:46780
[2025-05-08T21:15:44.110+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSetManager: Starting task 22.1 in stage 1336.2 (TID 3073) (172.20.0.5, executor 4, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:44.111+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 WARN TaskSetManager: Lost task 7.1 in stage 1309.1 (TID 3072) (172.20.0.5 executor 4): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=7, message=
[2025-05-08T21:15:44.111+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 7
[2025-05-08T21:15:44.111+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:15:44.111+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:15:44.111+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:15:44.112+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.113+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.114+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.115+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.116+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.117+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.118+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.119+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.120+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:15:44.121+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:15:44.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:15:44.122+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:15:44.122+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:15:44.122+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:15:44.122+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:15:44.122+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:15:44.122+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:15:44.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSetManager: task 7.1 in stage 1309.1 (TID 3072) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:15:44.123+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Removed TaskSet 1309.1, whose tasks have all completed, from pool
[2025-05-08T21:15:44.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_311_piece0 in memory on 172.20.0.5:33389 (size: 40.2 KiB, free: 434.4 MiB)
[2025-05-08T21:15:44.273+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T21:15:44.273+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:44.275+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_334 stored as values in memory (estimated size 23.9 KiB, free 416.4 MiB)
[2025-05-08T21:15:44.280+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_334_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.4 MiB)
[2025-05-08T21:15:44.281+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_334_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.5 MiB)
[2025-05-08T21:15:44.281+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 334 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1245.3 with 1 tasks resource profile 0
[2025-05-08T21:15:44.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:44.283+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_335 stored as values in memory (estimated size 22.4 KiB, free 416.3 MiB)
[2025-05-08T21:15:44.284+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_335_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 416.3 MiB)
[2025-05-08T21:15:44.284+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_335_piece0 in memory on f2a432e4376a:35283 (size: 11.1 KiB, free: 432.5 MiB)
[2025-05-08T21:15:44.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 335 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1246.3 with 1 tasks resource profile 0
[2025-05-08T21:15:44.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:44.286+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_336 stored as values in memory (estimated size 22.4 KiB, free 416.3 MiB)
[2025-05-08T21:15:44.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_336_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.3 MiB)
[2025-05-08T21:15:44.300+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_336_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.5 MiB)
[2025-05-08T21:15:44.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 336 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1247.3 with 1 tasks resource profile 0
[2025-05-08T21:15:44.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Removed broadcast_333_piece0 on f2a432e4376a:35283 in memory (size: 6.8 KiB, free: 432.5 MiB)
[2025-05-08T21:15:44.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:44.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_337 stored as values in memory (estimated size 28.8 KiB, free 416.3 MiB)
[2025-05-08T21:15:44.304+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_337_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.3 MiB)
[2025-05-08T21:15:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_337_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.5 MiB)
[2025-05-08T21:15:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 337 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1248.3 with 1 tasks resource profile 0
[2025-05-08T21:15:44.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Removed broadcast_333_piece0 on 172.20.0.5:33389 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-08T21:15:44.327+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Removed broadcast_330_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.5 MiB)
[2025-05-08T21:15:44.331+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Removed broadcast_331_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.5 MiB)
[2025-05-08T21:15:44.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Removed broadcast_332_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.6 MiB)
[2025-05-08T21:15:44.599+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:15:44.603+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSetManager: Starting task 0.0 in stage 1245.3 (TID 3074) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:44.603+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 WARN TaskSetManager: Lost task 22.1 in stage 1336.2 (TID 3073) (172.20.0.5 executor 4): FetchFailed(null, shuffleId=117, mapIndex=-1, mapId=-1, reduceId=1, message=
[2025-05-08T21:15:44.603+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 117 partition 1
[2025-05-08T21:15:44.603+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:15:44.604+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.605+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.606+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.607+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:15:44.608+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSetManager: task 22.1 in stage 1336.2 (TID 3073) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Removed TaskSet 1336.2, whose tasks have all completed, from pool
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Marking ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1333 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T21:15:44.609+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) failed in 159.381 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 117 partition 1
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:15:44.610+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.611+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.612+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.613+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:15:44.614+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:15:44.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:15:44.615+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:15:44.615+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:15:44.615+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:15:44.615+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:15:44.615+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:15:44.615+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Resubmitting ShuffleMapStage 1333 (collect at /opt/airflow/spark/build_graph.py:229) and ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) due to fetch failure
[2025-05-08T21:15:44.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_334_piece0 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:15:44.803+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T21:15:44.804+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:15:44.805+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_338 stored as values in memory (estimated size 22.4 KiB, free 416.9 MiB)
[2025-05-08T21:15:44.806+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_338_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.9 MiB)
[2025-05-08T21:15:44.806+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_338_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:15:44.806+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 338 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.807+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1333 (MapPartitionsRDD[985] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.807+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1333.4 with 1 tasks resource profile 0
[2025-05-08T21:15:44.807+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:15:44.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_339 stored as values in memory (estimated size 23.9 KiB, free 416.9 MiB)
[2025-05-08T21:15:44.809+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_339_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.9 MiB)
[2025-05-08T21:15:44.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_339_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:15:44.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 339 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1331 (MapPartitionsRDD[977] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1331.4 with 1 tasks resource profile 0
[2025-05-08T21:15:44.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:15:44.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_340 stored as values in memory (estimated size 22.4 KiB, free 416.8 MiB)
[2025-05-08T21:15:44.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_340_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.8 MiB)
[2025-05-08T21:15:44.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_340_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:15:44.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 340 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1332 (MapPartitionsRDD[980] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1332.4 with 1 tasks resource profile 0
[2025-05-08T21:15:44.814+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:15:44.815+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_341 stored as values in memory (estimated size 28.8 KiB, free 416.8 MiB)
[2025-05-08T21:15:44.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO MemoryStore: Block broadcast_341_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 416.8 MiB)
[2025-05-08T21:15:44.830+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Added broadcast_341_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:15:44.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Removed broadcast_311_piece0 on f2a432e4376a:35283 in memory (size: 40.2 KiB, free: 432.6 MiB)
[2025-05-08T21:15:44.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO SparkContext: Created broadcast 341 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:44.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1334 (MapPartitionsRDD[991] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:15:44.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO TaskSchedulerImpl: Adding task set 1334.4 with 1 tasks resource profile 0
[2025-05-08T21:15:44.833+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:44 INFO BlockManagerInfo: Removed broadcast_311_piece0 on 172.20.0.5:33389 in memory (size: 40.2 KiB, free: 434.4 MiB)
[2025-05-08T21:15:45.621+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO TaskSetManager: Starting task 0.0 in stage 1246.3 (TID 3075) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:45.621+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO TaskSetManager: Finished task 0.0 in stage 1245.3 (TID 3074) in 1018 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:45.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO TaskSchedulerImpl: Removed TaskSet 1245.3, whose tasks have all completed, from pool
[2025-05-08T21:15:45.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: ShuffleMapStage 1245 (rdd at GraphFrame.scala:187) finished in 1.348 s
[2025-05-08T21:15:45.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:45.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1247, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1246, ShuffleMapStage 1333)
[2025-05-08T21:15:45.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:15:45.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:45.631+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO BlockManagerInfo: Added broadcast_335_piece0 in memory on 172.20.0.5:33389 (size: 11.1 KiB, free: 434.4 MiB)
[2025-05-08T21:15:45.965+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO TaskSetManager: Starting task 0.0 in stage 1247.3 (TID 3076) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:45.965+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO TaskSetManager: Finished task 0.0 in stage 1246.3 (TID 3075) in 345 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:45.965+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO TaskSchedulerImpl: Removed TaskSet 1246.3, whose tasks have all completed, from pool
[2025-05-08T21:15:45.965+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: ShuffleMapStage 1246 (rdd at GraphFrame.scala:187) finished in 1.683 s
[2025-05-08T21:15:45.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:45.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1247, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:15:45.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:15:45.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:45.974+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:45 INFO BlockManagerInfo: Added broadcast_336_piece0 in memory on 172.20.0.5:33389 (size: 11.0 KiB, free: 434.4 MiB)
[2025-05-08T21:15:46.048+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSetManager: Starting task 0.0 in stage 1248.3 (TID 3077) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:46.049+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSetManager: Finished task 0.0 in stage 1247.3 (TID 3076) in 84 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:46.049+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSchedulerImpl: Removed TaskSet 1247.3, whose tasks have all completed, from pool
[2025-05-08T21:15:46.049+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: ShuffleMapStage 1247 (rdd at GraphFrame.scala:187) finished in 1.764 s
[2025-05-08T21:15:46.049+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:46.049+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1331, ShuffleMapStage 1248, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:15:46.050+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:15:46.050+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:46.058+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO BlockManagerInfo: Added broadcast_337_piece0 in memory on 172.20.0.5:33389 (size: 13.8 KiB, free: 434.4 MiB)
[2025-05-08T21:15:46.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSetManager: Starting task 0.0 in stage 1331.4 (TID 3078) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:46.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSetManager: Finished task 0.0 in stage 1248.3 (TID 3077) in 531 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:46.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSchedulerImpl: Removed TaskSet 1248.3, whose tasks have all completed, from pool
[2025-05-08T21:15:46.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: ShuffleMapStage 1248 (rdd at GraphFrame.scala:187) finished in 2.278 s
[2025-05-08T21:15:46.580+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:46.580+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1331, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:15:46.580+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299, ShuffleMapStage 1249)
[2025-05-08T21:15:46.580+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:46.580+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: Submitting ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:46.585+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO MemoryStore: Block broadcast_342 stored as values in memory (estimated size 96.7 KiB, free 416.8 MiB)
[2025-05-08T21:15:46.586+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO MemoryStore: Block broadcast_342_piece0 stored as bytes in memory (estimated size 36.3 KiB, free 416.8 MiB)
[2025-05-08T21:15:46.586+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO BlockManagerInfo: Added broadcast_342_piece0 in memory on f2a432e4376a:35283 (size: 36.3 KiB, free: 432.6 MiB)
[2025-05-08T21:15:46.587+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO SparkContext: Created broadcast 342 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:46.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1249 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:15:46.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSchedulerImpl: Adding task set 1249.3 with 41 tasks resource profile 0
[2025-05-08T21:15:46.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO BlockManagerInfo: Added broadcast_339_piece0 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:15:46.636+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSetManager: Starting task 1.0 in stage 1249.3 (TID 3079) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:46.636+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSetManager: Finished task 0.0 in stage 1331.4 (TID 3078) in 58 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:46.636+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO TaskSchedulerImpl: Removed TaskSet 1331.4, whose tasks have all completed, from pool
[2025-05-08T21:15:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: ShuffleMapStage 1331 (collect at /opt/airflow/spark/build_graph.py:229) finished in 1.829 s
[2025-05-08T21:15:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1332, ShuffleMapStage 1249, ShuffleMapStage 1333)
[2025-05-08T21:15:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:46.637+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:46.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO BlockManagerInfo: Added broadcast_342_piece0 in memory on 172.20.0.5:33389 (size: 36.3 KiB, free: 434.3 MiB)
[2025-05-08T21:15:46.655+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:46780
[2025-05-08T21:15:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:47 INFO TaskSetManager: Starting task 2.0 in stage 1249.3 (TID 3080) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:47.868+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:47 INFO TaskSetManager: Finished task 1.0 in stage 1249.3 (TID 3079) in 1232 ms on 172.20.0.5 (executor 4) (1/41)
[2025-05-08T21:15:47.952+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:47 INFO TaskSetManager: Starting task 3.0 in stage 1249.3 (TID 3081) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:47.953+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:47 INFO TaskSetManager: Finished task 2.0 in stage 1249.3 (TID 3080) in 85 ms on 172.20.0.5 (executor 4) (2/41)
[2025-05-08T21:15:47.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:47 INFO TaskSetManager: Starting task 6.0 in stage 1249.3 (TID 3082) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:47.983+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:47 INFO TaskSetManager: Finished task 3.0 in stage 1249.3 (TID 3081) in 30 ms on 172.20.0.5 (executor 4) (3/41)
[2025-05-08T21:15:48.022+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 7.0 in stage 1249.3 (TID 3083) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.023+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 6.0 in stage 1249.3 (TID 3082) in 40 ms on 172.20.0.5 (executor 4) (4/41)
[2025-05-08T21:15:48.109+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 8.0 in stage 1249.3 (TID 3084) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.110+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 7.0 in stage 1249.3 (TID 3083) in 88 ms on 172.20.0.5 (executor 4) (5/41)
[2025-05-08T21:15:48.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 9.0 in stage 1249.3 (TID 3085) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 8.0 in stage 1249.3 (TID 3084) in 65 ms on 172.20.0.5 (executor 4) (6/41)
[2025-05-08T21:15:48.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 10.0 in stage 1249.3 (TID 3086) (172.20.0.5, executor 4, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.207+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 9.0 in stage 1249.3 (TID 3085) in 32 ms on 172.20.0.5 (executor 4) (7/41)
[2025-05-08T21:15:48.248+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 11.0 in stage 1249.3 (TID 3087) (172.20.0.5, executor 4, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.248+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 10.0 in stage 1249.3 (TID 3086) in 42 ms on 172.20.0.5 (executor 4) (8/41)
[2025-05-08T21:15:48.258+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:46780
[2025-05-08T21:15:48.321+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 12.0 in stage 1249.3 (TID 3088) (172.20.0.5, executor 4, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.321+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 11.0 in stage 1249.3 (TID 3087) in 74 ms on 172.20.0.5 (executor 4) (9/41)
[2025-05-08T21:15:48.381+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 13.0 in stage 1249.3 (TID 3089) (172.20.0.5, executor 4, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.381+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 12.0 in stage 1249.3 (TID 3088) in 60 ms on 172.20.0.5 (executor 4) (10/41)
[2025-05-08T21:15:48.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 14.0 in stage 1249.3 (TID 3090) (172.20.0.5, executor 4, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.444+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 13.0 in stage 1249.3 (TID 3089) in 63 ms on 172.20.0.5 (executor 4) (11/41)
[2025-05-08T21:15:48.507+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 15.0 in stage 1249.3 (TID 3091) (172.20.0.5, executor 4, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.507+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 14.0 in stage 1249.3 (TID 3090) in 64 ms on 172.20.0.5 (executor 4) (12/41)
[2025-05-08T21:15:48.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 16.0 in stage 1249.3 (TID 3092) (172.20.0.5, executor 4, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 15.0 in stage 1249.3 (TID 3091) in 55 ms on 172.20.0.5 (executor 4) (13/41)
[2025-05-08T21:15:48.616+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 17.0 in stage 1249.3 (TID 3093) (172.20.0.5, executor 4, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.617+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 16.0 in stage 1249.3 (TID 3092) in 54 ms on 172.20.0.5 (executor 4) (14/41)
[2025-05-08T21:15:48.671+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 18.0 in stage 1249.3 (TID 3094) (172.20.0.5, executor 4, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 17.0 in stage 1249.3 (TID 3093) in 56 ms on 172.20.0.5 (executor 4) (15/41)
[2025-05-08T21:15:48.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 19.0 in stage 1249.3 (TID 3095) (172.20.0.5, executor 4, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.737+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 18.0 in stage 1249.3 (TID 3094) in 65 ms on 172.20.0.5 (executor 4) (16/41)
[2025-05-08T21:15:48.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 20.0 in stage 1249.3 (TID 3096) (172.20.0.5, executor 4, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.801+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 19.0 in stage 1249.3 (TID 3095) in 65 ms on 172.20.0.5 (executor 4) (17/41)
[2025-05-08T21:15:48.852+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 21.0 in stage 1249.3 (TID 3097) (172.20.0.5, executor 4, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.852+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 20.0 in stage 1249.3 (TID 3096) in 53 ms on 172.20.0.5 (executor 4) (18/41)
[2025-05-08T21:15:48.860+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:46780
[2025-05-08T21:15:48.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 22.0 in stage 1249.3 (TID 3098) (172.20.0.5, executor 4, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.905+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 21.0 in stage 1249.3 (TID 3097) in 53 ms on 172.20.0.5 (executor 4) (19/41)
[2025-05-08T21:15:48.946+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 23.0 in stage 1249.3 (TID 3099) (172.20.0.5, executor 4, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.947+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 22.0 in stage 1249.3 (TID 3098) in 43 ms on 172.20.0.5 (executor 4) (20/41)
[2025-05-08T21:15:48.983+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Starting task 24.0 in stage 1249.3 (TID 3100) (172.20.0.5, executor 4, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:48.984+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:48 INFO TaskSetManager: Finished task 23.0 in stage 1249.3 (TID 3099) in 38 ms on 172.20.0.5 (executor 4) (21/41)
[2025-05-08T21:15:49.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 25.0 in stage 1249.3 (TID 3101) (172.20.0.5, executor 4, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 24.0 in stage 1249.3 (TID 3100) in 47 ms on 172.20.0.5 (executor 4) (22/41)
[2025-05-08T21:15:49.071+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 26.0 in stage 1249.3 (TID 3102) (172.20.0.5, executor 4, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.071+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 25.0 in stage 1249.3 (TID 3101) in 41 ms on 172.20.0.5 (executor 4) (23/41)
[2025-05-08T21:15:49.116+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 27.0 in stage 1249.3 (TID 3103) (172.20.0.5, executor 4, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.117+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 26.0 in stage 1249.3 (TID 3102) in 47 ms on 172.20.0.5 (executor 4) (24/41)
[2025-05-08T21:15:49.154+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 28.0 in stage 1249.3 (TID 3104) (172.20.0.5, executor 4, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.155+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 27.0 in stage 1249.3 (TID 3103) in 38 ms on 172.20.0.5 (executor 4) (25/41)
[2025-05-08T21:15:49.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 29.0 in stage 1249.3 (TID 3105) (172.20.0.5, executor 4, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 28.0 in stage 1249.3 (TID 3104) in 38 ms on 172.20.0.5 (executor 4) (26/41)
[2025-05-08T21:15:49.223+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 30.0 in stage 1249.3 (TID 3106) (172.20.0.5, executor 4, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.224+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 29.0 in stage 1249.3 (TID 3105) in 32 ms on 172.20.0.5 (executor 4) (27/41)
[2025-05-08T21:15:49.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 31.0 in stage 1249.3 (TID 3107) (172.20.0.5, executor 4, partition 31, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.264+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 30.0 in stage 1249.3 (TID 3106) in 41 ms on 172.20.0.5 (executor 4) (28/41)
[2025-05-08T21:15:49.273+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:46780
[2025-05-08T21:15:49.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 32.0 in stage 1249.3 (TID 3108) (172.20.0.5, executor 4, partition 32, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 31.0 in stage 1249.3 (TID 3107) in 58 ms on 172.20.0.5 (executor 4) (29/41)
[2025-05-08T21:15:49.358+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 33.0 in stage 1249.3 (TID 3109) (172.20.0.5, executor 4, partition 33, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 32.0 in stage 1249.3 (TID 3108) in 37 ms on 172.20.0.5 (executor 4) (30/41)
[2025-05-08T21:15:49.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 34.0 in stage 1249.3 (TID 3110) (172.20.0.5, executor 4, partition 34, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 33.0 in stage 1249.3 (TID 3109) in 34 ms on 172.20.0.5 (executor 4) (31/41)
[2025-05-08T21:15:49.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 35.0 in stage 1249.3 (TID 3111) (172.20.0.5, executor 4, partition 35, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 34.0 in stage 1249.3 (TID 3110) in 40 ms on 172.20.0.5 (executor 4) (32/41)
[2025-05-08T21:15:49.464+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 36.0 in stage 1249.3 (TID 3112) (172.20.0.5, executor 4, partition 36, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.464+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 35.0 in stage 1249.3 (TID 3111) in 33 ms on 172.20.0.5 (executor 4) (33/41)
[2025-05-08T21:15:49.497+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 37.0 in stage 1249.3 (TID 3113) (172.20.0.5, executor 4, partition 37, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.498+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 36.0 in stage 1249.3 (TID 3112) in 34 ms on 172.20.0.5 (executor 4) (34/41)
[2025-05-08T21:15:49.527+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 38.0 in stage 1249.3 (TID 3114) (172.20.0.5, executor 4, partition 38, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.528+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 37.0 in stage 1249.3 (TID 3113) in 30 ms on 172.20.0.5 (executor 4) (35/41)
[2025-05-08T21:15:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 39.0 in stage 1249.3 (TID 3115) (172.20.0.5, executor 4, partition 39, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.561+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 38.0 in stage 1249.3 (TID 3114) in 34 ms on 172.20.0.5 (executor 4) (36/41)
[2025-05-08T21:15:49.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 40.0 in stage 1249.3 (TID 3116) (172.20.0.5, executor 4, partition 40, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 39.0 in stage 1249.3 (TID 3115) in 28 ms on 172.20.0.5 (executor 4) (37/41)
[2025-05-08T21:15:49.625+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 0.0 in stage 1249.3 (TID 3117) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.625+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 40.0 in stage 1249.3 (TID 3116) in 37 ms on 172.20.0.5 (executor 4) (38/41)
[2025-05-08T21:15:49.676+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 4.0 in stage 1249.3 (TID 3118) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.676+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 0.0 in stage 1249.3 (TID 3117) in 53 ms on 172.20.0.5 (executor 4) (39/41)
[2025-05-08T21:15:49.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 5.0 in stage 1249.3 (TID 3119) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 4.0 in stage 1249.3 (TID 3118) in 21 ms on 172.20.0.5 (executor 4) (40/41)
[2025-05-08T21:15:49.709+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 0.0 in stage 1332.4 (TID 3120) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 5.0 in stage 1249.3 (TID 3119) in 14 ms on 172.20.0.5 (executor 4) (41/41)
[2025-05-08T21:15:49.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSchedulerImpl: Removed TaskSet 1249.3, whose tasks have all completed, from pool
[2025-05-08T21:15:49.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: ShuffleMapStage 1249 (rdd at GraphFrame.scala:187) finished in 3.128 s
[2025-05-08T21:15:49.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:49.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1332, ShuffleMapStage 1333)
[2025-05-08T21:15:49.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1250, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1251, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:49.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:49.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: Submitting ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:49.713+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO MemoryStore: Block broadcast_343 stored as values in memory (estimated size 70.3 KiB, free 416.7 MiB)
[2025-05-08T21:15:49.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO MemoryStore: Block broadcast_343_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 416.7 MiB)
[2025-05-08T21:15:49.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Added broadcast_343_piece0 in memory on f2a432e4376a:35283 (size: 28.3 KiB, free: 432.5 MiB)
[2025-05-08T21:15:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO SparkContext: Created broadcast 343 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1250 (MapPartitionsRDD[156] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSchedulerImpl: Adding task set 1250.3 with 10 tasks resource profile 0
[2025-05-08T21:15:49.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: Submitting ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:49.717+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Added broadcast_340_piece0 in memory on 172.20.0.5:33389 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:15:49.718+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO MemoryStore: Block broadcast_344 stored as values in memory (estimated size 70.6 KiB, free 416.6 MiB)
[2025-05-08T21:15:49.730+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO MemoryStore: Block broadcast_344_piece0 stored as bytes in memory (estimated size 28.4 KiB, free 416.6 MiB)
[2025-05-08T21:15:49.730+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_336_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.6 MiB)
[2025-05-08T21:15:49.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Added broadcast_344_piece0 in memory on f2a432e4376a:35283 (size: 28.4 KiB, free: 432.5 MiB)
[2025-05-08T21:15:49.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO SparkContext: Created broadcast 344 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:49.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1251 (MapPartitionsRDD[160] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:49.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSchedulerImpl: Adding task set 1251.3 with 10 tasks resource profile 0
[2025-05-08T21:15:49.733+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_336_piece0 on 172.20.0.5:33389 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:15:49.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_335_piece0 on f2a432e4376a:35283 in memory (size: 11.1 KiB, free: 432.5 MiB)
[2025-05-08T21:15:49.738+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_335_piece0 on 172.20.0.5:33389 in memory (size: 11.1 KiB, free: 434.3 MiB)
[2025-05-08T21:15:49.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_339_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:15:49.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_339_piece0 on 172.20.0.5:33389 in memory (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:15:49.768+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_337_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.6 MiB)
[2025-05-08T21:15:49.771+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_337_piece0 on 172.20.0.5:33389 in memory (size: 13.8 KiB, free: 434.3 MiB)
[2025-05-08T21:15:49.786+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_334_piece0 on f2a432e4376a:35283 in memory (size: 11.7 KiB, free: 432.6 MiB)
[2025-05-08T21:15:49.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Removed broadcast_334_piece0 on 172.20.0.5:33389 in memory (size: 11.7 KiB, free: 434.4 MiB)
[2025-05-08T21:15:49.807+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 0.0 in stage 1250.3 (TID 3121) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.809+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 0.0 in stage 1332.4 (TID 3120) in 99 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:49.811+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: ShuffleMapStage 1332 (collect at /opt/airflow/spark/build_graph.py:229) finished in 4.997 s
[2025-05-08T21:15:49.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:49.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1250, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1251, ShuffleMapStage 1333)
[2025-05-08T21:15:49.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:49.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:49.814+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSchedulerImpl: Removed TaskSet 1332.4, whose tasks have all completed, from pool
[2025-05-08T21:15:49.822+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO BlockManagerInfo: Added broadcast_343_piece0 in memory on 172.20.0.5:33389 (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T21:15:49.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:46780
[2025-05-08T21:15:49.931+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 1.0 in stage 1250.3 (TID 3122) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.932+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 0.0 in stage 1250.3 (TID 3121) in 125 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:49.967+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 2.0 in stage 1250.3 (TID 3123) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:49.968+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 1.0 in stage 1250.3 (TID 3122) in 35 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:49.999+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Starting task 3.0 in stage 1250.3 (TID 3124) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.000+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:49 INFO TaskSetManager: Finished task 2.0 in stage 1250.3 (TID 3123) in 33 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:50.031+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 4.0 in stage 1250.3 (TID 3125) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.032+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 3.0 in stage 1250.3 (TID 3124) in 32 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:50.060+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 5.0 in stage 1250.3 (TID 3126) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.060+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 4.0 in stage 1250.3 (TID 3125) in 30 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:50.092+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 6.0 in stage 1250.3 (TID 3127) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.093+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 5.0 in stage 1250.3 (TID 3126) in 32 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:50.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 7.0 in stage 1250.3 (TID 3128) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.114+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 6.0 in stage 1250.3 (TID 3127) in 22 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:50.135+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 8.0 in stage 1250.3 (TID 3129) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.136+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 7.0 in stage 1250.3 (TID 3128) in 22 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:50.163+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 9.0 in stage 1250.3 (TID 3130) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.164+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 8.0 in stage 1250.3 (TID 3129) in 28 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:50.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 0.0 in stage 1251.3 (TID 3131) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 9.0 in stage 1250.3 (TID 3130) in 23 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:50.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Removed TaskSet 1250.3, whose tasks have all completed, from pool
[2025-05-08T21:15:50.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: ShuffleMapStage 1250 (rdd at GraphFrame.scala:187) finished in 0.475 s
[2025-05-08T21:15:50.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:50.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1251, ShuffleMapStage 1333)
[2025-05-08T21:15:50.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:50.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:50.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_344_piece0 in memory on 172.20.0.5:33389 (size: 28.4 KiB, free: 434.3 MiB)
[2025-05-08T21:15:50.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 1.0 in stage 1251.3 (TID 3132) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.239+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 0.0 in stage 1251.3 (TID 3131) in 54 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:50.261+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 2.0 in stage 1251.3 (TID 3133) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.261+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 1.0 in stage 1251.3 (TID 3132) in 23 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:50.279+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 3.0 in stage 1251.3 (TID 3134) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.280+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 2.0 in stage 1251.3 (TID 3133) in 18 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:50.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 4.0 in stage 1251.3 (TID 3135) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 3.0 in stage 1251.3 (TID 3134) in 19 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:50.316+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 5.0 in stage 1251.3 (TID 3136) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.317+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 4.0 in stage 1251.3 (TID 3135) in 19 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:50.337+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 6.0 in stage 1251.3 (TID 3137) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.337+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 5.0 in stage 1251.3 (TID 3136) in 21 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:50.360+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 7.0 in stage 1251.3 (TID 3138) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.360+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 6.0 in stage 1251.3 (TID 3137) in 23 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:50.377+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 8.0 in stage 1251.3 (TID 3139) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.378+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 7.0 in stage 1251.3 (TID 3138) in 18 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:50.396+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 9.0 in stage 1251.3 (TID 3140) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.396+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 8.0 in stage 1251.3 (TID 3139) in 19 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:50.412+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 0.0 in stage 1333.4 (TID 3141) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 9.0 in stage 1251.3 (TID 3140) in 17 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:50.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Removed TaskSet 1251.3, whose tasks have all completed, from pool
[2025-05-08T21:15:50.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: ShuffleMapStage 1251 (rdd at GraphFrame.scala:187) finished in 0.697 s
[2025-05-08T21:15:50.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:50.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1333)
[2025-05-08T21:15:50.414+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1252, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:50.414+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:50.414+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:50.417+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_345 stored as values in memory (estimated size 83.7 KiB, free 416.7 MiB)
[2025-05-08T21:15:50.419+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_345_piece0 stored as bytes in memory (estimated size 32.1 KiB, free 416.7 MiB)
[2025-05-08T21:15:50.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_338_piece0 in memory on 172.20.0.5:33389 (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:15:50.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_345_piece0 in memory on f2a432e4376a:35283 (size: 32.1 KiB, free: 432.5 MiB)
[2025-05-08T21:15:50.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO SparkContext: Created broadcast 345 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:50.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting 20 missing tasks from ShuffleMapStage 1252 (MapPartitionsRDD[165] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:15:50.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Adding task set 1252.3 with 20 tasks resource profile 0
[2025-05-08T21:15:50.459+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 0.0 in stage 1252.3 (TID 3142) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.459+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 0.0 in stage 1333.4 (TID 3141) in 47 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:50.459+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Removed TaskSet 1333.4, whose tasks have all completed, from pool
[2025-05-08T21:15:50.460+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: ShuffleMapStage 1333 (collect at /opt/airflow/spark/build_graph.py:229) finished in 5.656 s
[2025-05-08T21:15:50.460+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:50.460+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1252)
[2025-05-08T21:15:50.461+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:50.461+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:50.465+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_345_piece0 in memory on 172.20.0.5:33389 (size: 32.1 KiB, free: 434.3 MiB)
[2025-05-08T21:15:50.471+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:46780
[2025-05-08T21:15:50.509+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 1.0 in stage 1252.3 (TID 3143) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.510+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 0.0 in stage 1252.3 (TID 3142) in 52 ms on 172.20.0.5 (executor 4) (1/20)
[2025-05-08T21:15:50.527+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 2.0 in stage 1252.3 (TID 3144) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.527+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 1.0 in stage 1252.3 (TID 3143) in 18 ms on 172.20.0.5 (executor 4) (2/20)
[2025-05-08T21:15:50.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 3.0 in stage 1252.3 (TID 3145) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.544+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 2.0 in stage 1252.3 (TID 3144) in 16 ms on 172.20.0.5 (executor 4) (3/20)
[2025-05-08T21:15:50.559+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 4.0 in stage 1252.3 (TID 3146) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.559+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 3.0 in stage 1252.3 (TID 3145) in 16 ms on 172.20.0.5 (executor 4) (4/20)
[2025-05-08T21:15:50.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 5.0 in stage 1252.3 (TID 3147) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 4.0 in stage 1252.3 (TID 3146) in 17 ms on 172.20.0.5 (executor 4) (5/20)
[2025-05-08T21:15:50.593+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 6.0 in stage 1252.3 (TID 3148) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 5.0 in stage 1252.3 (TID 3147) in 17 ms on 172.20.0.5 (executor 4) (6/20)
[2025-05-08T21:15:50.605+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 7.0 in stage 1252.3 (TID 3149) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.606+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 6.0 in stage 1252.3 (TID 3148) in 12 ms on 172.20.0.5 (executor 4) (7/20)
[2025-05-08T21:15:50.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 8.0 in stage 1252.3 (TID 3150) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 7.0 in stage 1252.3 (TID 3149) in 17 ms on 172.20.0.5 (executor 4) (8/20)
[2025-05-08T21:15:50.634+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 9.0 in stage 1252.3 (TID 3151) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.635+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 8.0 in stage 1252.3 (TID 3150) in 12 ms on 172.20.0.5 (executor 4) (9/20)
[2025-05-08T21:15:50.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 10.0 in stage 1252.3 (TID 3152) (172.20.0.5, executor 4, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.647+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 9.0 in stage 1252.3 (TID 3151) in 12 ms on 172.20.0.5 (executor 4) (10/20)
[2025-05-08T21:15:50.652+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:46780
[2025-05-08T21:15:50.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 11.0 in stage 1252.3 (TID 3153) (172.20.0.5, executor 4, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 10.0 in stage 1252.3 (TID 3152) in 32 ms on 172.20.0.5 (executor 4) (11/20)
[2025-05-08T21:15:50.695+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 12.0 in stage 1252.3 (TID 3154) (172.20.0.5, executor 4, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.696+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 11.0 in stage 1252.3 (TID 3153) in 17 ms on 172.20.0.5 (executor 4) (12/20)
[2025-05-08T21:15:50.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 13.0 in stage 1252.3 (TID 3155) (172.20.0.5, executor 4, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 12.0 in stage 1252.3 (TID 3154) in 19 ms on 172.20.0.5 (executor 4) (13/20)
[2025-05-08T21:15:50.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 14.0 in stage 1252.3 (TID 3156) (172.20.0.5, executor 4, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.727+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 13.0 in stage 1252.3 (TID 3155) in 14 ms on 172.20.0.5 (executor 4) (14/20)
[2025-05-08T21:15:50.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 15.0 in stage 1252.3 (TID 3157) (172.20.0.5, executor 4, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 14.0 in stage 1252.3 (TID 3156) in 14 ms on 172.20.0.5 (executor 4) (15/20)
[2025-05-08T21:15:50.760+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 16.0 in stage 1252.3 (TID 3158) (172.20.0.5, executor 4, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.760+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 15.0 in stage 1252.3 (TID 3157) in 20 ms on 172.20.0.5 (executor 4) (16/20)
[2025-05-08T21:15:50.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 17.0 in stage 1252.3 (TID 3159) (172.20.0.5, executor 4, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 16.0 in stage 1252.3 (TID 3158) in 16 ms on 172.20.0.5 (executor 4) (17/20)
[2025-05-08T21:15:50.787+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 18.0 in stage 1252.3 (TID 3160) (172.20.0.5, executor 4, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 17.0 in stage 1252.3 (TID 3159) in 12 ms on 172.20.0.5 (executor 4) (18/20)
[2025-05-08T21:15:50.799+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 19.0 in stage 1252.3 (TID 3161) (172.20.0.5, executor 4, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 18.0 in stage 1252.3 (TID 3160) in 12 ms on 172.20.0.5 (executor 4) (19/20)
[2025-05-08T21:15:50.811+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 0.0 in stage 1334.4 (TID 3162) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.811+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 19.0 in stage 1252.3 (TID 3161) in 13 ms on 172.20.0.5 (executor 4) (20/20)
[2025-05-08T21:15:50.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Removed TaskSet 1252.3, whose tasks have all completed, from pool
[2025-05-08T21:15:50.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: ShuffleMapStage 1252 (rdd at GraphFrame.scala:187) finished in 0.398 s
[2025-05-08T21:15:50.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:50.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1334, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342)
[2025-05-08T21:15:50.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1287, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1254, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1255, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:50.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:50.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:15:50.817+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_341_piece0 in memory on 172.20.0.5:33389 (size: 13.8 KiB, free: 434.2 MiB)
[2025-05-08T21:15:50.818+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_346 stored as values in memory (estimated size 189.5 KiB, free 416.5 MiB)
[2025-05-08T21:15:50.819+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_346_piece0 stored as bytes in memory (estimated size 65.0 KiB, free 416.4 MiB)
[2025-05-08T21:15:50.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_346_piece0 in memory on f2a432e4376a:35283 (size: 65.0 KiB, free: 432.5 MiB)
[2025-05-08T21:15:50.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO SparkContext: Created broadcast 346 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:50.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1254 (MapPartitionsRDD[177] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:50.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Adding task set 1254.3 with 10 tasks resource profile 0
[2025-05-08T21:15:50.820+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-08T21:15:50.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_347 stored as values in memory (estimated size 232.9 KiB, free 416.2 MiB)
[2025-05-08T21:15:50.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_347_piece0 stored as bytes in memory (estimated size 77.5 KiB, free 416.1 MiB)
[2025-05-08T21:15:50.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_347_piece0 in memory on f2a432e4376a:35283 (size: 77.5 KiB, free: 432.4 MiB)
[2025-05-08T21:15:50.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO SparkContext: Created broadcast 347 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:50.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1255 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[389] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:50.833+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Adding task set 1255.3 with 10 tasks resource profile 0
[2025-05-08T21:15:50.833+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:50.843+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_348 stored as values in memory (estimated size 235.8 KiB, free 415.9 MiB)
[2025-05-08T21:15:50.868+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_348_piece0 stored as bytes in memory (estimated size 77.8 KiB, free 415.8 MiB)
[2025-05-08T21:15:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_348_piece0 in memory on f2a432e4376a:35283 (size: 77.8 KiB, free: 432.3 MiB)
[2025-05-08T21:15:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO SparkContext: Created broadcast 348 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1287 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[596] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:50.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Adding task set 1287.3 with 10 tasks resource profile 0
[2025-05-08T21:15:50.870+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_340_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.3 MiB)
[2025-05-08T21:15:50.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_340_piece0 on 172.20.0.5:33389 in memory (size: 11.0 KiB, free: 434.3 MiB)
[2025-05-08T21:15:50.889+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Starting task 0.0 in stage 1254.3 (TID 3163) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:50.890+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSetManager: Finished task 0.0 in stage 1334.4 (TID 3162) in 78 ms on 172.20.0.5 (executor 4) (1/1)
[2025-05-08T21:15:50.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Removed TaskSet 1334.4, whose tasks have all completed, from pool
[2025-05-08T21:15:50.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: ShuffleMapStage 1334 (collect at /opt/airflow/spark/build_graph.py:229) finished in 6.076 s
[2025-05-08T21:15:50.892+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:50.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1254, ShuffleMapStage 1338, ShuffleMapStage 1287, ShuffleMapStage 1255, ResultStage 1342)
[2025-05-08T21:15:50.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1336, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:50.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:50.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229), which has no missing parents
[2025-05-08T21:15:50.894+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1336.
[2025-05-08T21:15:50.895+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_343_piece0 on f2a432e4376a:35283 in memory (size: 28.3 KiB, free: 432.4 MiB)
[2025-05-08T21:15:50.896+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_349 stored as values in memory (estimated size 109.8 KiB, free 415.8 MiB)
[2025-05-08T21:15:50.898+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO MemoryStore: Block broadcast_349_piece0 stored as bytes in memory (estimated size 40.2 KiB, free 415.8 MiB)
[2025-05-08T21:15:50.898+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_343_piece0 on 172.20.0.5:33389 in memory (size: 28.3 KiB, free: 434.3 MiB)
[2025-05-08T21:15:50.899+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_349_piece0 in memory on f2a432e4376a:35283 (size: 40.2 KiB, free: 432.3 MiB)
[2025-05-08T21:15:50.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO SparkContext: Created broadcast 349 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:50.900+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO DAGScheduler: Submitting 41 missing tasks from ShuffleMapStage 1336 (MapPartitionsRDD[1086] at collect at /opt/airflow/spark/build_graph.py:229) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-05-08T21:15:50.901+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO TaskSchedulerImpl: Adding task set 1336.3 with 41 tasks resource profile 0
[2025-05-08T21:15:50.903+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_338_piece0 on f2a432e4376a:35283 in memory (size: 11.0 KiB, free: 432.3 MiB)
[2025-05-08T21:15:50.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Added broadcast_346_piece0 in memory on 172.20.0.5:33389 (size: 65.0 KiB, free: 434.2 MiB)
[2025-05-08T21:15:50.907+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_338_piece0 on 172.20.0.5:33389 in memory (size: 11.0 KiB, free: 434.2 MiB)
[2025-05-08T21:15:50.912+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_344_piece0 on f2a432e4376a:35283 in memory (size: 28.4 KiB, free: 432.4 MiB)
[2025-05-08T21:15:50.916+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_344_piece0 on 172.20.0.5:33389 in memory (size: 28.4 KiB, free: 434.3 MiB)
[2025-05-08T21:15:50.920+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_342_piece0 on f2a432e4376a:35283 in memory (size: 36.3 KiB, free: 432.4 MiB)
[2025-05-08T21:15:50.921+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:50 INFO BlockManagerInfo: Removed broadcast_342_piece0 on 172.20.0.5:33389 in memory (size: 36.3 KiB, free: 434.3 MiB)
[2025-05-08T21:15:51.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:46780
[2025-05-08T21:15:51.239+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_0 in memory on 172.20.0.5:33389 (size: 8.5 KiB, free: 434.3 MiB)
[2025-05-08T21:15:51.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:33389 (size: 94.3 KiB, free: 434.2 MiB)
[2025-05-08T21:15:51.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 1.0 in stage 1254.3 (TID 3164) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 0.0 in stage 1254.3 (TID 3163) in 508 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:51.426+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_1 in memory on 172.20.0.5:33389 (size: 8.0 KiB, free: 434.2 MiB)
[2025-05-08T21:15:51.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 2.0 in stage 1254.3 (TID 3165) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 1.0 in stage 1254.3 (TID 3164) in 51 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:51.471+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_2 in memory on 172.20.0.5:33389 (size: 7.5 KiB, free: 434.2 MiB)
[2025-05-08T21:15:51.487+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 3.0 in stage 1254.3 (TID 3166) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.487+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 2.0 in stage 1254.3 (TID 3165) in 41 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:51.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_3 in memory on 172.20.0.5:33389 (size: 8.1 KiB, free: 434.2 MiB)
[2025-05-08T21:15:51.525+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 4.0 in stage 1254.3 (TID 3167) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.526+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 3.0 in stage 1254.3 (TID 3166) in 40 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:51.546+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_4 in memory on 172.20.0.5:33389 (size: 7.7 KiB, free: 434.2 MiB)
[2025-05-08T21:15:51.557+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 5.0 in stage 1254.3 (TID 3168) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.558+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 4.0 in stage 1254.3 (TID 3167) in 32 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:51.582+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_5 in memory on 172.20.0.5:33389 (size: 7.0 KiB, free: 434.2 MiB)
[2025-05-08T21:15:51.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 6.0 in stage 1254.3 (TID 3169) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 5.0 in stage 1254.3 (TID 3168) in 38 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:51.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_6 in memory on 172.20.0.5:33389 (size: 7.3 KiB, free: 434.1 MiB)
[2025-05-08T21:15:51.634+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 7.0 in stage 1254.3 (TID 3170) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.635+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 6.0 in stage 1254.3 (TID 3169) in 41 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:51.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_7 in memory on 172.20.0.5:33389 (size: 8.1 KiB, free: 434.1 MiB)
[2025-05-08T21:15:51.666+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 8.0 in stage 1254.3 (TID 3171) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.666+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 7.0 in stage 1254.3 (TID 3170) in 32 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:51.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_8 in memory on 172.20.0.5:33389 (size: 7.6 KiB, free: 434.1 MiB)
[2025-05-08T21:15:51.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 9.0 in stage 1254.3 (TID 3172) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.699+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 8.0 in stage 1254.3 (TID 3171) in 34 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:51.721+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added rdd_169_9 in memory on 172.20.0.5:33389 (size: 8.2 KiB, free: 434.1 MiB)
[2025-05-08T21:15:51.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Starting task 0.0 in stage 1255.3 (TID 3173) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:51.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSetManager: Finished task 9.0 in stage 1254.3 (TID 3172) in 33 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:51.731+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO TaskSchedulerImpl: Removed TaskSet 1254.3, whose tasks have all completed, from pool
[2025-05-08T21:15:51.732+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO DAGScheduler: ShuffleMapStage 1254 (map at GraphFrame.scala:187) finished in 0.919 s
[2025-05-08T21:15:51.732+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:51.732+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1287, ShuffleMapStage 1338, ShuffleMapStage 1255, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:51.733+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:51.733+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:51.739+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added broadcast_347_piece0 in memory on 172.20.0.5:33389 (size: 77.5 KiB, free: 434.0 MiB)
[2025-05-08T21:15:51.782+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:33389 (size: 80.3 KiB, free: 434.0 MiB)
[2025-05-08T21:15:51.802+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:51 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:33389 (size: 764.6 KiB, free: 433.2 MiB)
[2025-05-08T21:15:52.189+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 1.0 in stage 1255.3 (TID 3174) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.189+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 0.0 in stage 1255.3 (TID 3173) in 459 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:52.254+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 2.0 in stage 1255.3 (TID 3175) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.254+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 1.0 in stage 1255.3 (TID 3174) in 65 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:52.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 3.0 in stage 1255.3 (TID 3176) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 2.0 in stage 1255.3 (TID 3175) in 47 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:52.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 4.0 in stage 1255.3 (TID 3177) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.347+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 3.0 in stage 1255.3 (TID 3176) in 47 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:52.403+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 5.0 in stage 1255.3 (TID 3178) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.404+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 4.0 in stage 1255.3 (TID 3177) in 57 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:52.461+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 6.0 in stage 1255.3 (TID 3179) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.461+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 5.0 in stage 1255.3 (TID 3178) in 59 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:52.516+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 7.0 in stage 1255.3 (TID 3180) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.516+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 6.0 in stage 1255.3 (TID 3179) in 55 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:52.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 8.0 in stage 1255.3 (TID 3181) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.551+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 7.0 in stage 1255.3 (TID 3180) in 36 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:52.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 9.0 in stage 1255.3 (TID 3182) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.589+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 8.0 in stage 1255.3 (TID 3181) in 39 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:52.623+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 0.0 in stage 1287.3 (TID 3183) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.624+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 9.0 in stage 1255.3 (TID 3182) in 36 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:52.625+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSchedulerImpl: Removed TaskSet 1255.3, whose tasks have all completed, from pool
[2025-05-08T21:15:52.625+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO DAGScheduler: ShuffleMapStage 1255 (mapPartitions at VertexRDD.scala:356) finished in 1.804 s
[2025-05-08T21:15:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1287, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:52.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:52.630+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added broadcast_348_piece0 in memory on 172.20.0.5:33389 (size: 77.8 KiB, free: 433.1 MiB)
[2025-05-08T21:15:52.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_395_0 in memory on 172.20.0.5:33389 (size: 560.1 KiB, free: 432.6 MiB)
[2025-05-08T21:15:52.679+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_399_0 in memory on 172.20.0.5:33389 (size: 560.1 KiB, free: 432.1 MiB)
[2025-05-08T21:15:52.718+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 1.0 in stage 1287.3 (TID 3184) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.719+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 0.0 in stage 1287.3 (TID 3183) in 96 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:52.760+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_395_1 in memory on 172.20.0.5:33389 (size: 558.2 KiB, free: 431.5 MiB)
[2025-05-08T21:15:52.772+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_399_1 in memory on 172.20.0.5:33389 (size: 558.2 KiB, free: 431.0 MiB)
[2025-05-08T21:15:52.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 2.0 in stage 1287.3 (TID 3185) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.801+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 1.0 in stage 1287.3 (TID 3184) in 83 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:52.839+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_395_2 in memory on 172.20.0.5:33389 (size: 663.8 KiB, free: 430.3 MiB)
[2025-05-08T21:15:52.848+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_399_2 in memory on 172.20.0.5:33389 (size: 663.8 KiB, free: 429.7 MiB)
[2025-05-08T21:15:52.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 3.0 in stage 1287.3 (TID 3186) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 2.0 in stage 1287.3 (TID 3185) in 76 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:52.913+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_395_3 in memory on 172.20.0.5:33389 (size: 695.0 KiB, free: 429.0 MiB)
[2025-05-08T21:15:52.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_399_3 in memory on 172.20.0.5:33389 (size: 695.0 KiB, free: 428.3 MiB)
[2025-05-08T21:15:52.948+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Starting task 4.0 in stage 1287.3 (TID 3187) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:52.949+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO TaskSetManager: Finished task 3.0 in stage 1287.3 (TID 3186) in 74 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:52.979+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_395_4 in memory on 172.20.0.5:33389 (size: 451.0 KiB, free: 427.9 MiB)
[2025-05-08T21:15:52.986+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:52 INFO BlockManagerInfo: Added rdd_399_4 in memory on 172.20.0.5:33389 (size: 451.0 KiB, free: 427.4 MiB)
[2025-05-08T21:15:53.011+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 5.0 in stage 1287.3 (TID 3188) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.012+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 4.0 in stage 1287.3 (TID 3187) in 64 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:53.047+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_395_5 in memory on 172.20.0.5:33389 (size: 654.0 KiB, free: 426.8 MiB)
[2025-05-08T21:15:53.051+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_399_5 in memory on 172.20.0.5:33389 (size: 654.0 KiB, free: 426.2 MiB)
[2025-05-08T21:15:53.072+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 6.0 in stage 1287.3 (TID 3189) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.072+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 5.0 in stage 1287.3 (TID 3188) in 61 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:53.094+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_395_6 in memory on 172.20.0.5:33389 (size: 548.2 KiB, free: 425.6 MiB)
[2025-05-08T21:15:53.098+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_399_6 in memory on 172.20.0.5:33389 (size: 548.2 KiB, free: 425.1 MiB)
[2025-05-08T21:15:53.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 7.0 in stage 1287.3 (TID 3190) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.125+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 6.0 in stage 1287.3 (TID 3189) in 54 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:53.155+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_395_7 in memory on 172.20.0.5:33389 (size: 557.0 KiB, free: 424.5 MiB)
[2025-05-08T21:15:53.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_399_7 in memory on 172.20.0.5:33389 (size: 557.0 KiB, free: 424.0 MiB)
[2025-05-08T21:15:53.185+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 8.0 in stage 1287.3 (TID 3191) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 7.0 in stage 1287.3 (TID 3190) in 61 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:53.214+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_395_8 in memory on 172.20.0.5:33389 (size: 485.3 KiB, free: 423.5 MiB)
[2025-05-08T21:15:53.217+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_399_8 in memory on 172.20.0.5:33389 (size: 485.3 KiB, free: 423.0 MiB)
[2025-05-08T21:15:53.234+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 9.0 in stage 1287.3 (TID 3192) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.235+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 8.0 in stage 1287.3 (TID 3191) in 51 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:53.265+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_395_9 in memory on 172.20.0.5:33389 (size: 694.0 KiB, free: 422.4 MiB)
[2025-05-08T21:15:53.268+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_399_9 in memory on 172.20.0.5:33389 (size: 694.0 KiB, free: 421.7 MiB)
[2025-05-08T21:15:53.294+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 1.0 in stage 1336.3 (TID 3193) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 9.0 in stage 1287.3 (TID 3192) in 61 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSchedulerImpl: Removed TaskSet 1287.3, whose tasks have all completed, from pool
[2025-05-08T21:15:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: ShuffleMapStage 1287 (mapPartitions at GraphImpl.scala:208) finished in 2.461 s
[2025-05-08T21:15:53.295+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:53.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:53.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1289, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1288, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:53.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:53.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: Submitting ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:53.298+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MemoryStore: Block broadcast_350 stored as values in memory (estimated size 10.7 KiB, free 416.0 MiB)
[2025-05-08T21:15:53.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added broadcast_349_piece0 in memory on 172.20.0.5:33389 (size: 40.2 KiB, free: 421.6 MiB)
[2025-05-08T21:15:53.301+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MemoryStore: Block broadcast_350_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 416.0 MiB)
[2025-05-08T21:15:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added broadcast_350_piece0 in memory on f2a432e4376a:35283 (size: 5.3 KiB, free: 432.4 MiB)
[2025-05-08T21:15:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO SparkContext: Created broadcast 350 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1288 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[614] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:53.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSchedulerImpl: Adding task set 1288.3 with 10 tasks resource profile 0
[2025-05-08T21:15:53.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: Submitting ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:53.304+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MemoryStore: Block broadcast_351 stored as values in memory (estimated size 10.1 KiB, free 416.0 MiB)
[2025-05-08T21:15:53.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MemoryStore: Block broadcast_351_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 416.0 MiB)
[2025-05-08T21:15:53.305+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added broadcast_351_piece0 in memory on f2a432e4376a:35283 (size: 5.0 KiB, free: 432.4 MiB)
[2025-05-08T21:15:53.306+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO SparkContext: Created broadcast 351 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:53.306+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1289 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[604] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:53.306+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSchedulerImpl: Adding task set 1289.3 with 10 tasks resource profile 0
[2025-05-08T21:15:53.309+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:53.387+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 0.0 in stage 1288.3 (TID 3194) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 1.0 in stage 1336.3 (TID 3193) in 93 ms on 172.20.0.5 (executor 4) (1/41)
[2025-05-08T21:15:53.395+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added broadcast_350_piece0 in memory on 172.20.0.5:33389 (size: 5.3 KiB, free: 421.6 MiB)
[2025-05-08T21:15:53.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:46780
[2025-05-08T21:15:53.404+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:46780
[2025-05-08T21:15:53.442+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_0 in memory on 172.20.0.5:33389 (size: 36.3 KiB, free: 421.6 MiB)
[2025-05-08T21:15:53.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_0 in memory on 172.20.0.5:33389 (size: 11.2 KiB, free: 421.6 MiB)
[2025-05-08T21:15:53.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 72 to 172.20.0.5:46780
[2025-05-08T21:15:53.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_0 in memory on 172.20.0.5:33389 (size: 11.2 KiB, free: 421.6 MiB)
[2025-05-08T21:15:53.474+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 1.0 in stage 1288.3 (TID 3195) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.474+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 0.0 in stage 1288.3 (TID 3194) in 87 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:53.495+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_1 in memory on 172.20.0.5:33389 (size: 36.7 KiB, free: 421.6 MiB)
[2025-05-08T21:15:53.497+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_1 in memory on 172.20.0.5:33389 (size: 12.1 KiB, free: 421.5 MiB)
[2025-05-08T21:15:53.503+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_1 in memory on 172.20.0.5:33389 (size: 12.1 KiB, free: 421.5 MiB)
[2025-05-08T21:15:53.510+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 2.0 in stage 1288.3 (TID 3196) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.510+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 1.0 in stage 1288.3 (TID 3195) in 36 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:53.524+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_2 in memory on 172.20.0.5:33389 (size: 34.2 KiB, free: 421.5 MiB)
[2025-05-08T21:15:53.527+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_2 in memory on 172.20.0.5:33389 (size: 10.9 KiB, free: 421.5 MiB)
[2025-05-08T21:15:53.532+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_2 in memory on 172.20.0.5:33389 (size: 10.9 KiB, free: 421.5 MiB)
[2025-05-08T21:15:53.538+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 3.0 in stage 1288.3 (TID 3197) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 2.0 in stage 1288.3 (TID 3196) in 28 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:53.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_3 in memory on 172.20.0.5:33389 (size: 34.5 KiB, free: 421.4 MiB)
[2025-05-08T21:15:53.559+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_3 in memory on 172.20.0.5:33389 (size: 10.9 KiB, free: 421.4 MiB)
[2025-05-08T21:15:53.563+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_3 in memory on 172.20.0.5:33389 (size: 10.9 KiB, free: 421.4 MiB)
[2025-05-08T21:15:53.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 4.0 in stage 1288.3 (TID 3198) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 3.0 in stage 1288.3 (TID 3197) in 32 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:53.588+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_4 in memory on 172.20.0.5:33389 (size: 33.4 KiB, free: 421.4 MiB)
[2025-05-08T21:15:53.591+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_4 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 421.4 MiB)
[2025-05-08T21:15:53.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_4 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 421.4 MiB)
[2025-05-08T21:15:53.601+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 5.0 in stage 1288.3 (TID 3199) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.601+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 4.0 in stage 1288.3 (TID 3198) in 31 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:53.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_5 in memory on 172.20.0.5:33389 (size: 34.7 KiB, free: 421.3 MiB)
[2025-05-08T21:15:53.615+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_5 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 421.3 MiB)
[2025-05-08T21:15:53.620+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_5 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 421.3 MiB)
[2025-05-08T21:15:53.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 6.0 in stage 1288.3 (TID 3200) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.627+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 5.0 in stage 1288.3 (TID 3199) in 26 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:53.644+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_6 in memory on 172.20.0.5:33389 (size: 34.8 KiB, free: 421.3 MiB)
[2025-05-08T21:15:53.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_6 in memory on 172.20.0.5:33389 (size: 11.4 KiB, free: 421.3 MiB)
[2025-05-08T21:15:53.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_6 in memory on 172.20.0.5:33389 (size: 11.4 KiB, free: 421.2 MiB)
[2025-05-08T21:15:53.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 7.0 in stage 1288.3 (TID 3201) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.658+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 6.0 in stage 1288.3 (TID 3200) in 32 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:53.675+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_7 in memory on 172.20.0.5:33389 (size: 35.5 KiB, free: 421.2 MiB)
[2025-05-08T21:15:53.677+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_7 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 421.2 MiB)
[2025-05-08T21:15:53.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_7 in memory on 172.20.0.5:33389 (size: 11.6 KiB, free: 421.2 MiB)
[2025-05-08T21:15:53.690+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 8.0 in stage 1288.3 (TID 3202) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.691+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 7.0 in stage 1288.3 (TID 3201) in 33 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:53.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_8 in memory on 172.20.0.5:33389 (size: 36.5 KiB, free: 421.2 MiB)
[2025-05-08T21:15:53.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_8 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_8 in memory on 172.20.0.5:33389 (size: 11.7 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.722+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 9.0 in stage 1288.3 (TID 3203) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.722+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 8.0 in stage 1288.3 (TID 3202) in 33 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:53.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_392_9 in memory on 172.20.0.5:33389 (size: 35.4 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.742+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_397_9 in memory on 172.20.0.5:33389 (size: 11.3 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.746+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added rdd_600_9 in memory on 172.20.0.5:33389 (size: 11.2 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.753+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 0.0 in stage 1289.3 (TID 3204) (172.20.0.5, executor 4, partition 0, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.753+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 9.0 in stage 1288.3 (TID 3203) in 31 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSchedulerImpl: Removed TaskSet 1288.3, whose tasks have all completed, from pool
[2025-05-08T21:15:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: ShuffleMapStage 1288 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.456 s
[2025-05-08T21:15:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: running: Set(ShuffleMapStage 1289, ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:53.759+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added broadcast_351_piece0 in memory on 172.20.0.5:33389 (size: 5.0 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 1.0 in stage 1289.3 (TID 3205) (172.20.0.5, executor 4, partition 1, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.768+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 0.0 in stage 1289.3 (TID 3204) in 14 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:53.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 2.0 in stage 1289.3 (TID 3206) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.777+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 1.0 in stage 1289.3 (TID 3205) in 9 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:53.786+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 3.0 in stage 1289.3 (TID 3207) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.786+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 2.0 in stage 1289.3 (TID 3206) in 10 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:53.794+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 4.0 in stage 1289.3 (TID 3208) (172.20.0.5, executor 4, partition 4, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.795+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 3.0 in stage 1289.3 (TID 3207) in 9 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:53.802+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 5.0 in stage 1289.3 (TID 3209) (172.20.0.5, executor 4, partition 5, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.803+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 4.0 in stage 1289.3 (TID 3208) in 8 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:53.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 6.0 in stage 1289.3 (TID 3210) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.812+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 5.0 in stage 1289.3 (TID 3209) in 10 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:53.821+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 7.0 in stage 1289.3 (TID 3211) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.822+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 6.0 in stage 1289.3 (TID 3210) in 9 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:53.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 8.0 in stage 1289.3 (TID 3212) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 7.0 in stage 1289.3 (TID 3211) in 10 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:53.840+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 9.0 in stage 1289.3 (TID 3213) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.840+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 8.0 in stage 1289.3 (TID 3212) in 10 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:53.849+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 2.0 in stage 1336.3 (TID 3214) (172.20.0.5, executor 4, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.849+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 9.0 in stage 1289.3 (TID 3213) in 9 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:53.850+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSchedulerImpl: Removed TaskSet 1289.3, whose tasks have all completed, from pool
[2025-05-08T21:15:53.850+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: ShuffleMapStage 1289 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.546 s
[2025-05-08T21:15:53.850+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:53.850+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:53.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1290, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:53.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:53.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: Submitting ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:53.857+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MemoryStore: Block broadcast_352 stored as values in memory (estimated size 238.4 KiB, free 415.8 MiB)
[2025-05-08T21:15:53.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:53.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO MemoryStore: Block broadcast_352_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 415.7 MiB)
[2025-05-08T21:15:53.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added broadcast_352_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.3 MiB)
[2025-05-08T21:15:53.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO SparkContext: Created broadcast 352 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:53.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_341_piece0 on f2a432e4376a:35283 in memory (size: 13.8 KiB, free: 432.3 MiB)
[2025-05-08T21:15:53.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1290 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[618] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:53.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSchedulerImpl: Adding task set 1290.3 with 10 tasks resource profile 0
[2025-05-08T21:15:53.883+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_341_piece0 on 172.20.0.5:33389 in memory (size: 13.8 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.918+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_350_piece0 on f2a432e4376a:35283 in memory (size: 5.3 KiB, free: 432.3 MiB)
[2025-05-08T21:15:53.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_350_piece0 on 172.20.0.5:33389 in memory (size: 5.3 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Starting task 0.0 in stage 1290.3 (TID 3215) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:53.930+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO TaskSetManager: Finished task 2.0 in stage 1336.3 (TID 3214) in 81 ms on 172.20.0.5 (executor 4) (2/41)
[2025-05-08T21:15:53.938+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_345_piece0 on f2a432e4376a:35283 in memory (size: 32.1 KiB, free: 432.4 MiB)
[2025-05-08T21:15:53.944+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_345_piece0 on 172.20.0.5:33389 in memory (size: 32.1 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.945+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Added broadcast_352_piece0 in memory on 172.20.0.5:33389 (size: 78.8 KiB, free: 421.0 MiB)
[2025-05-08T21:15:53.959+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_346_piece0 on f2a432e4376a:35283 in memory (size: 65.0 KiB, free: 432.4 MiB)
[2025-05-08T21:15:53.977+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_346_piece0 on 172.20.0.5:33389 in memory (size: 65.0 KiB, free: 421.1 MiB)
[2025-05-08T21:15:53.996+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:53 INFO BlockManagerInfo: Removed broadcast_347_piece0 on f2a432e4376a:35283 in memory (size: 77.5 KiB, free: 432.5 MiB)
[2025-05-08T21:15:54.004+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_0 in memory on 172.20.0.5:33389 (size: 50.5 KiB, free: 421.1 MiB)
[2025-05-08T21:15:54.009+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Removed broadcast_347_piece0 on 172.20.0.5:33389 in memory (size: 77.5 KiB, free: 421.1 MiB)
[2025-05-08T21:15:54.010+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:54.036+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:54.039+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Removed broadcast_348_piece0 on f2a432e4376a:35283 in memory (size: 77.8 KiB, free: 432.6 MiB)
[2025-05-08T21:15:54.043+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Removed broadcast_348_piece0 on 172.20.0.5:33389 in memory (size: 77.8 KiB, free: 421.2 MiB)
[2025-05-08T21:15:54.071+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 1.0 in stage 1290.3 (TID 3216) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.072+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 0.0 in stage 1290.3 (TID 3215) in 143 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:54.090+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_1 in memory on 172.20.0.5:33389 (size: 51.2 KiB, free: 421.2 MiB)
[2025-05-08T21:15:54.122+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 2.0 in stage 1290.3 (TID 3217) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.122+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 1.0 in stage 1290.3 (TID 3216) in 51 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:54.134+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_2 in memory on 172.20.0.5:33389 (size: 54.2 KiB, free: 421.1 MiB)
[2025-05-08T21:15:54.152+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 3.0 in stage 1290.3 (TID 3218) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.153+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 2.0 in stage 1290.3 (TID 3217) in 32 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:54.165+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_3 in memory on 172.20.0.5:33389 (size: 55.4 KiB, free: 421.1 MiB)
[2025-05-08T21:15:54.185+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 4.0 in stage 1290.3 (TID 3219) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.186+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 3.0 in stage 1290.3 (TID 3218) in 34 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:54.201+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_4 in memory on 172.20.0.5:33389 (size: 46.8 KiB, free: 421.0 MiB)
[2025-05-08T21:15:54.226+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 5.0 in stage 1290.3 (TID 3220) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.227+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 4.0 in stage 1290.3 (TID 3219) in 43 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:54.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_5 in memory on 172.20.0.5:33389 (size: 53.5 KiB, free: 421.0 MiB)
[2025-05-08T21:15:54.270+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 6.0 in stage 1290.3 (TID 3221) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.271+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 5.0 in stage 1290.3 (TID 3220) in 45 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:54.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_6 in memory on 172.20.0.5:33389 (size: 50.7 KiB, free: 420.9 MiB)
[2025-05-08T21:15:54.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 7.0 in stage 1290.3 (TID 3222) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.302+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 6.0 in stage 1290.3 (TID 3221) in 32 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:54.313+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_7 in memory on 172.20.0.5:33389 (size: 50.4 KiB, free: 420.9 MiB)
[2025-05-08T21:15:54.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 8.0 in stage 1290.3 (TID 3223) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.331+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 7.0 in stage 1290.3 (TID 3222) in 30 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:54.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_8 in memory on 172.20.0.5:33389 (size: 48.3 KiB, free: 420.8 MiB)
[2025-05-08T21:15:54.366+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 9.0 in stage 1290.3 (TID 3224) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.366+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 8.0 in stage 1290.3 (TID 3223) in 36 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:54.378+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added rdd_602_9 in memory on 172.20.0.5:33389 (size: 55.5 KiB, free: 420.8 MiB)
[2025-05-08T21:15:54.396+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 3.0 in stage 1336.3 (TID 3225) (172.20.0.5, executor 4, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 9.0 in stage 1290.3 (TID 3224) in 30 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSchedulerImpl: Removed TaskSet 1290.3, whose tasks have all completed, from pool
[2025-05-08T21:15:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: ShuffleMapStage 1290 (mapPartitions at GraphImpl.scala:208) finished in 0.546 s
[2025-05-08T21:15:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:54.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1291, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:54.398+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:54.398+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: Submitting ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:54.399+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MemoryStore: Block broadcast_353 stored as values in memory (estimated size 12.0 KiB, free 416.7 MiB)
[2025-05-08T21:15:54.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MemoryStore: Block broadcast_353_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 416.7 MiB)
[2025-05-08T21:15:54.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added broadcast_353_piece0 in memory on f2a432e4376a:35283 (size: 5.7 KiB, free: 432.6 MiB)
[2025-05-08T21:15:54.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO SparkContext: Created broadcast 353 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:54.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1291 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[626] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:54.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSchedulerImpl: Adding task set 1291.3 with 10 tasks resource profile 0
[2025-05-08T21:15:54.404+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:54.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 0.0 in stage 1291.3 (TID 3226) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 3.0 in stage 1336.3 (TID 3225) in 24 ms on 172.20.0.5 (executor 4) (3/41)
[2025-05-08T21:15:54.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added broadcast_353_piece0 in memory on 172.20.0.5:33389 (size: 5.7 KiB, free: 420.8 MiB)
[2025-05-08T21:15:54.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:54.449+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 1.0 in stage 1291.3 (TID 3227) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.450+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 0.0 in stage 1291.3 (TID 3226) in 29 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:54.471+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 2.0 in stage 1291.3 (TID 3228) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.472+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 1.0 in stage 1291.3 (TID 3227) in 23 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:54.486+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 3.0 in stage 1291.3 (TID 3229) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.486+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 2.0 in stage 1291.3 (TID 3228) in 15 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:54.500+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 4.0 in stage 1291.3 (TID 3230) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.500+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 3.0 in stage 1291.3 (TID 3229) in 14 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:54.510+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 5.0 in stage 1291.3 (TID 3231) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.510+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 4.0 in stage 1291.3 (TID 3230) in 10 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:54.521+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 6.0 in stage 1291.3 (TID 3232) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.521+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 5.0 in stage 1291.3 (TID 3231) in 12 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:54.531+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 7.0 in stage 1291.3 (TID 3233) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.531+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 6.0 in stage 1291.3 (TID 3232) in 11 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:54.541+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 8.0 in stage 1291.3 (TID 3234) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.541+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 7.0 in stage 1291.3 (TID 3233) in 10 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:54.552+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 9.0 in stage 1291.3 (TID 3235) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.552+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 8.0 in stage 1291.3 (TID 3234) in 12 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:54.561+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 6.0 in stage 1336.3 (TID 3236) (172.20.0.5, executor 4, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 9.0 in stage 1291.3 (TID 3235) in 10 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:54.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSchedulerImpl: Removed TaskSet 1291.3, whose tasks have all completed, from pool
[2025-05-08T21:15:54.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: ShuffleMapStage 1291 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.163 s
[2025-05-08T21:15:54.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:54.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:54.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1292, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:54.562+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:54.563+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: Submitting ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:54.569+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:54.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MemoryStore: Block broadcast_354 stored as values in memory (estimated size 238.8 KiB, free 416.5 MiB)
[2025-05-08T21:15:54.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MemoryStore: Block broadcast_354_piece0 stored as bytes in memory (estimated size 78.8 KiB, free 416.4 MiB)
[2025-05-08T21:15:54.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added broadcast_354_piece0 in memory on f2a432e4376a:35283 (size: 78.8 KiB, free: 432.5 MiB)
[2025-05-08T21:15:54.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO SparkContext: Created broadcast 354 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:54.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1292 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[630] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:54.572+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSchedulerImpl: Adding task set 1292.3 with 10 tasks resource profile 0
[2025-05-08T21:15:54.591+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 0.0 in stage 1292.3 (TID 3237) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.591+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 6.0 in stage 1336.3 (TID 3236) in 30 ms on 172.20.0.5 (executor 4) (4/41)
[2025-05-08T21:15:54.597+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added broadcast_354_piece0 in memory on 172.20.0.5:33389 (size: 78.8 KiB, free: 420.7 MiB)
[2025-05-08T21:15:54.607+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:54.611+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:54.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:15:54.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 1.0 in stage 1292.3 (TID 3238) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.646+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 0.0 in stage 1292.3 (TID 3237) in 56 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:54.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 2.0 in stage 1292.3 (TID 3239) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 1.0 in stage 1292.3 (TID 3238) in 28 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:54.702+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 3.0 in stage 1292.3 (TID 3240) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.703+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 2.0 in stage 1292.3 (TID 3239) in 30 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:54.741+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 4.0 in stage 1292.3 (TID 3241) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.741+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 3.0 in stage 1292.3 (TID 3240) in 38 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:54.768+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 5.0 in stage 1292.3 (TID 3242) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 4.0 in stage 1292.3 (TID 3241) in 30 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:54.809+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 6.0 in stage 1292.3 (TID 3243) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.810+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 5.0 in stage 1292.3 (TID 3242) in 42 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:54.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 7.0 in stage 1292.3 (TID 3244) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.847+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 6.0 in stage 1292.3 (TID 3243) in 38 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:54.884+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 8.0 in stage 1292.3 (TID 3245) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.885+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 7.0 in stage 1292.3 (TID 3244) in 38 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:54.921+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 9.0 in stage 1292.3 (TID 3246) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 8.0 in stage 1292.3 (TID 3245) in 38 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:54.953+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Starting task 7.0 in stage 1336.3 (TID 3247) (172.20.0.5, executor 4, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:54.953+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSetManager: Finished task 9.0 in stage 1292.3 (TID 3246) in 32 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:54.953+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSchedulerImpl: Removed TaskSet 1292.3, whose tasks have all completed, from pool
[2025-05-08T21:15:54.956+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: ShuffleMapStage 1292 (mapPartitions at GraphImpl.scala:208) finished in 0.390 s
[2025-05-08T21:15:54.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:54.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:54.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1293, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:54.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:54.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: Submitting ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:54.963+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MemoryStore: Block broadcast_355 stored as values in memory (estimated size 12.8 KiB, free 416.4 MiB)
[2025-05-08T21:15:54.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MemoryStore: Block broadcast_355_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 416.4 MiB)
[2025-05-08T21:15:54.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO BlockManagerInfo: Added broadcast_355_piece0 in memory on f2a432e4376a:35283 (size: 5.9 KiB, free: 432.5 MiB)
[2025-05-08T21:15:54.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO SparkContext: Created broadcast 355 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:54.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1293 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[638] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:54.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO TaskSchedulerImpl: Adding task set 1293.3 with 10 tasks resource profile 0
[2025-05-08T21:15:54.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:55.007+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 0.0 in stage 1293.3 (TID 3248) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.007+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 7.0 in stage 1336.3 (TID 3247) in 55 ms on 172.20.0.5 (executor 4) (5/41)
[2025-05-08T21:15:55.017+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Added broadcast_355_piece0 in memory on 172.20.0.5:33389 (size: 5.9 KiB, free: 420.7 MiB)
[2025-05-08T21:15:55.032+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:55.041+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:15:55.050+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 1.0 in stage 1293.3 (TID 3249) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.050+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 0.0 in stage 1293.3 (TID 3248) in 43 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:55.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 2.0 in stage 1293.3 (TID 3250) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 1.0 in stage 1293.3 (TID 3249) in 16 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:55.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 3.0 in stage 1293.3 (TID 3251) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.085+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 2.0 in stage 1293.3 (TID 3250) in 19 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:55.099+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 4.0 in stage 1293.3 (TID 3252) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.099+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 3.0 in stage 1293.3 (TID 3251) in 15 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:55.112+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 5.0 in stage 1293.3 (TID 3253) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.113+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 4.0 in stage 1293.3 (TID 3252) in 13 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:55.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 6.0 in stage 1293.3 (TID 3254) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.130+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 5.0 in stage 1293.3 (TID 3253) in 18 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:55.149+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 7.0 in stage 1293.3 (TID 3255) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.150+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 6.0 in stage 1293.3 (TID 3254) in 19 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:55.168+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 8.0 in stage 1293.3 (TID 3256) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.169+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 7.0 in stage 1293.3 (TID 3255) in 19 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:55.187+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 9.0 in stage 1293.3 (TID 3257) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.188+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 8.0 in stage 1293.3 (TID 3256) in 19 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:55.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 8.0 in stage 1336.3 (TID 3258) (172.20.0.5, executor 4, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 9.0 in stage 1293.3 (TID 3257) in 18 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:55.205+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSchedulerImpl: Removed TaskSet 1293.3, whose tasks have all completed, from pool
[2025-05-08T21:15:55.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: ShuffleMapStage 1293 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.247 s
[2025-05-08T21:15:55.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:55.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:55.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1294, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:55.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:55.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:55.213+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:55.215+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MemoryStore: Block broadcast_356 stored as values in memory (estimated size 239.1 KiB, free 416.2 MiB)
[2025-05-08T21:15:55.229+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_353_piece0 on f2a432e4376a:35283 in memory (size: 5.7 KiB, free: 432.5 MiB)
[2025-05-08T21:15:55.229+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MemoryStore: Block broadcast_356_piece0 stored as bytes in memory (estimated size 79.0 KiB, free 416.1 MiB)
[2025-05-08T21:15:55.232+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Added broadcast_356_piece0 in memory on f2a432e4376a:35283 (size: 79.0 KiB, free: 432.4 MiB)
[2025-05-08T21:15:55.235+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO SparkContext: Created broadcast 356 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:55.236+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1294 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[642] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:55.236+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSchedulerImpl: Adding task set 1294.3 with 10 tasks resource profile 0
[2025-05-08T21:15:55.244+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_353_piece0 on 172.20.0.5:33389 in memory (size: 5.7 KiB, free: 420.7 MiB)
[2025-05-08T21:15:55.257+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 0.0 in stage 1294.3 (TID 3259) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.258+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 8.0 in stage 1336.3 (TID 3258) in 51 ms on 172.20.0.5 (executor 4) (6/41)
[2025-05-08T21:15:55.260+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_352_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.5 MiB)
[2025-05-08T21:15:55.266+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_352_piece0 on 172.20.0.5:33389 in memory (size: 78.8 KiB, free: 420.7 MiB)
[2025-05-08T21:15:55.274+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Added broadcast_356_piece0 in memory on 172.20.0.5:33389 (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T21:15:55.279+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_351_piece0 on f2a432e4376a:35283 in memory (size: 5.0 KiB, free: 432.5 MiB)
[2025-05-08T21:15:55.297+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_351_piece0 on 172.20.0.5:33389 in memory (size: 5.0 KiB, free: 420.7 MiB)
[2025-05-08T21:15:55.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:55.314+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_354_piece0 on f2a432e4376a:35283 in memory (size: 78.8 KiB, free: 432.6 MiB)
[2025-05-08T21:15:55.314+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Removed broadcast_354_piece0 on 172.20.0.5:33389 in memory (size: 78.8 KiB, free: 420.8 MiB)
[2025-05-08T21:15:55.317+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:55.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:15:55.324+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:15:55.350+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 1.0 in stage 1294.3 (TID 3260) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.351+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 0.0 in stage 1294.3 (TID 3259) in 94 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:55.397+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 2.0 in stage 1294.3 (TID 3261) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.399+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 1.0 in stage 1294.3 (TID 3260) in 48 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:55.438+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 3.0 in stage 1294.3 (TID 3262) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.438+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 2.0 in stage 1294.3 (TID 3261) in 42 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:55.469+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 4.0 in stage 1294.3 (TID 3263) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.469+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 3.0 in stage 1294.3 (TID 3262) in 32 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:55.497+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 5.0 in stage 1294.3 (TID 3264) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.498+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 4.0 in stage 1294.3 (TID 3263) in 30 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:55.525+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 6.0 in stage 1294.3 (TID 3265) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.525+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 5.0 in stage 1294.3 (TID 3264) in 28 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:55.550+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 7.0 in stage 1294.3 (TID 3266) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.551+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 6.0 in stage 1294.3 (TID 3265) in 27 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:55.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 8.0 in stage 1294.3 (TID 3267) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.581+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 7.0 in stage 1294.3 (TID 3266) in 31 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:55.614+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 9.0 in stage 1294.3 (TID 3268) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.614+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 8.0 in stage 1294.3 (TID 3267) in 34 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:55.650+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 9.0 in stage 1336.3 (TID 3269) (172.20.0.5, executor 4, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.650+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 9.0 in stage 1294.3 (TID 3268) in 37 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:55.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSchedulerImpl: Removed TaskSet 1294.3, whose tasks have all completed, from pool
[2025-05-08T21:15:55.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: ShuffleMapStage 1294 (mapPartitions at GraphImpl.scala:208) finished in 0.445 s
[2025-05-08T21:15:55.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:55.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:55.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1295, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:55.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:55.651+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:55.653+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MemoryStore: Block broadcast_357 stored as values in memory (estimated size 13.5 KiB, free 416.7 MiB)
[2025-05-08T21:15:55.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MemoryStore: Block broadcast_357_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.7 MiB)
[2025-05-08T21:15:55.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Added broadcast_357_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.6 MiB)
[2025-05-08T21:15:55.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO SparkContext: Created broadcast 357 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:55.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1295 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[650] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:55.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSchedulerImpl: Adding task set 1295.3 with 10 tasks resource profile 0
[2025-05-08T21:15:55.656+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:55.667+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 0.0 in stage 1295.3 (TID 3270) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.667+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 9.0 in stage 1336.3 (TID 3269) in 17 ms on 172.20.0.5 (executor 4) (7/41)
[2025-05-08T21:15:55.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Added broadcast_357_piece0 in memory on 172.20.0.5:33389 (size: 6.1 KiB, free: 420.7 MiB)
[2025-05-08T21:15:55.675+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:55.680+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:15:55.688+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:15:55.694+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 1.0 in stage 1295.3 (TID 3271) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.695+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 0.0 in stage 1295.3 (TID 3270) in 27 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:55.726+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 2.0 in stage 1295.3 (TID 3272) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.726+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 1.0 in stage 1295.3 (TID 3271) in 32 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:55.751+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 3.0 in stage 1295.3 (TID 3273) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.751+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 2.0 in stage 1295.3 (TID 3272) in 25 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:55.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 4.0 in stage 1295.3 (TID 3274) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 3.0 in stage 1295.3 (TID 3273) in 25 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:55.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 5.0 in stage 1295.3 (TID 3275) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.801+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 4.0 in stage 1295.3 (TID 3274) in 24 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:55.822+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 6.0 in stage 1295.3 (TID 3276) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.822+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 5.0 in stage 1295.3 (TID 3275) in 22 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:55.841+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 7.0 in stage 1295.3 (TID 3277) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.842+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 6.0 in stage 1295.3 (TID 3276) in 20 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:55.864+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 8.0 in stage 1295.3 (TID 3278) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.864+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 7.0 in stage 1295.3 (TID 3277) in 23 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:55.880+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 9.0 in stage 1295.3 (TID 3279) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.880+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 8.0 in stage 1295.3 (TID 3278) in 16 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:55.896+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 10.0 in stage 1336.3 (TID 3280) (172.20.0.5, executor 4, partition 10, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.896+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 9.0 in stage 1295.3 (TID 3279) in 16 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:55.897+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSchedulerImpl: Removed TaskSet 1295.3, whose tasks have all completed, from pool
[2025-05-08T21:15:55.897+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: ShuffleMapStage 1295 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.244 s
[2025-05-08T21:15:55.897+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:55.897+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:55.897+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1296, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:55.897+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:55.897+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:55.901+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 115 to 172.20.0.5:46780
[2025-05-08T21:15:55.906+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MemoryStore: Block broadcast_358 stored as values in memory (estimated size 239.4 KiB, free 416.5 MiB)
[2025-05-08T21:15:55.908+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MemoryStore: Block broadcast_358_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 416.4 MiB)
[2025-05-08T21:15:55.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Added broadcast_358_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.5 MiB)
[2025-05-08T21:15:55.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO SparkContext: Created broadcast 358 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:55.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1296 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[654] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:55.909+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSchedulerImpl: Adding task set 1296.3 with 10 tasks resource profile 0
[2025-05-08T21:15:55.916+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 0.0 in stage 1296.3 (TID 3281) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.917+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 10.0 in stage 1336.3 (TID 3280) in 20 ms on 172.20.0.5 (executor 4) (8/41)
[2025-05-08T21:15:55.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO BlockManagerInfo: Added broadcast_358_piece0 in memory on 172.20.0.5:33389 (size: 79.2 KiB, free: 420.7 MiB)
[2025-05-08T21:15:55.931+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:55.933+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:55.935+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:15:55.936+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:15:55.938+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:15:55.962+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 1.0 in stage 1296.3 (TID 3282) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.962+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 0.0 in stage 1296.3 (TID 3281) in 46 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:55.986+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Starting task 2.0 in stage 1296.3 (TID 3283) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:55.987+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:55 INFO TaskSetManager: Finished task 1.0 in stage 1296.3 (TID 3282) in 26 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:56.010+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 3.0 in stage 1296.3 (TID 3284) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.010+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 2.0 in stage 1296.3 (TID 3283) in 24 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:56.038+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 4.0 in stage 1296.3 (TID 3285) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.039+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 3.0 in stage 1296.3 (TID 3284) in 29 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:56.063+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 5.0 in stage 1296.3 (TID 3286) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.064+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 4.0 in stage 1296.3 (TID 3285) in 25 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:56.089+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 6.0 in stage 1296.3 (TID 3287) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.089+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 5.0 in stage 1296.3 (TID 3286) in 27 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:56.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 7.0 in stage 1296.3 (TID 3288) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 6.0 in stage 1296.3 (TID 3287) in 36 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:56.146+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 8.0 in stage 1296.3 (TID 3289) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.147+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 7.0 in stage 1296.3 (TID 3288) in 23 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:56.170+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 9.0 in stage 1296.3 (TID 3290) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.170+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 8.0 in stage 1296.3 (TID 3289) in 24 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:56.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 11.0 in stage 1336.3 (TID 3291) (172.20.0.5, executor 4, partition 11, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 9.0 in stage 1296.3 (TID 3290) in 23 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:56.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSchedulerImpl: Removed TaskSet 1296.3, whose tasks have all completed, from pool
[2025-05-08T21:15:56.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: ShuffleMapStage 1296 (mapPartitions at GraphImpl.scala:208) finished in 0.294 s
[2025-05-08T21:15:56.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:56.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:56.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1297, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:56.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:56.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: Submitting ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:56.195+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MemoryStore: Block broadcast_359 stored as values in memory (estimated size 14.2 KiB, free 416.4 MiB)
[2025-05-08T21:15:56.196+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MemoryStore: Block broadcast_359_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 416.4 MiB)
[2025-05-08T21:15:56.196+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Added broadcast_359_piece0 in memory on f2a432e4376a:35283 (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T21:15:56.196+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO SparkContext: Created broadcast 359 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:56.196+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1297 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[662] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:56.196+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSchedulerImpl: Adding task set 1297.3 with 10 tasks resource profile 0
[2025-05-08T21:15:56.197+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:56.232+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 0.0 in stage 1297.3 (TID 3292) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.233+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 11.0 in stage 1336.3 (TID 3291) in 41 ms on 172.20.0.5 (executor 4) (9/41)
[2025-05-08T21:15:56.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Added broadcast_359_piece0 in memory on 172.20.0.5:33389 (size: 6.1 KiB, free: 420.7 MiB)
[2025-05-08T21:15:56.242+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:56.247+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:15:56.254+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:15:56.282+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:15:56.287+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 1.0 in stage 1297.3 (TID 3293) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.288+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 0.0 in stage 1297.3 (TID 3292) in 55 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:56.311+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 2.0 in stage 1297.3 (TID 3294) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.312+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 1.0 in stage 1297.3 (TID 3293) in 24 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:56.334+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 3.0 in stage 1297.3 (TID 3295) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.334+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 2.0 in stage 1297.3 (TID 3294) in 23 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:56.356+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 4.0 in stage 1297.3 (TID 3296) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.356+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 3.0 in stage 1297.3 (TID 3295) in 22 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:56.381+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 5.0 in stage 1297.3 (TID 3297) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 4.0 in stage 1297.3 (TID 3296) in 25 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:56.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 6.0 in stage 1297.3 (TID 3298) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.416+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 5.0 in stage 1297.3 (TID 3297) in 34 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:56.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 7.0 in stage 1297.3 (TID 3299) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 6.0 in stage 1297.3 (TID 3298) in 31 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:56.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 8.0 in stage 1297.3 (TID 3300) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 7.0 in stage 1297.3 (TID 3299) in 30 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:56.498+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 9.0 in stage 1297.3 (TID 3301) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.498+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 8.0 in stage 1297.3 (TID 3300) in 23 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:56.518+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 12.0 in stage 1336.3 (TID 3302) (172.20.0.5, executor 4, partition 12, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.519+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 9.0 in stage 1297.3 (TID 3301) in 20 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:56.519+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSchedulerImpl: Removed TaskSet 1297.3, whose tasks have all completed, from pool
[2025-05-08T21:15:56.519+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: ShuffleMapStage 1297 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.325 s
[2025-05-08T21:15:56.519+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:56.519+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:56.520+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1298, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:56.520+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:56.520+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: Submitting ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:56.525+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:56.528+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MemoryStore: Block broadcast_360 stored as values in memory (estimated size 239.6 KiB, free 416.1 MiB)
[2025-05-08T21:15:56.533+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MemoryStore: Block broadcast_360_piece0 stored as bytes in memory (estimated size 79.3 KiB, free 416.1 MiB)
[2025-05-08T21:15:56.533+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Added broadcast_360_piece0 in memory on f2a432e4376a:35283 (size: 79.3 KiB, free: 432.4 MiB)
[2025-05-08T21:15:56.533+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO SparkContext: Created broadcast 360 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:56.534+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1298 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[666] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:56.534+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSchedulerImpl: Adding task set 1298.3 with 10 tasks resource profile 0
[2025-05-08T21:15:56.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 0.0 in stage 1298.3 (TID 3303) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 12.0 in stage 1336.3 (TID 3302) in 25 ms on 172.20.0.5 (executor 4) (10/41)
[2025-05-08T21:15:56.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Added broadcast_360_piece0 in memory on 172.20.0.5:33389 (size: 79.3 KiB, free: 420.6 MiB)
[2025-05-08T21:15:56.561+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:56.563+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:56.565+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:15:56.567+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:15:56.569+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:15:56.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:15:56.597+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 1.0 in stage 1298.3 (TID 3304) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.597+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 0.0 in stage 1298.3 (TID 3303) in 55 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:56.621+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 2.0 in stage 1298.3 (TID 3305) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.622+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 1.0 in stage 1298.3 (TID 3304) in 24 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:56.648+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 3.0 in stage 1298.3 (TID 3306) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.649+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 2.0 in stage 1298.3 (TID 3305) in 28 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:56.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 4.0 in stage 1298.3 (TID 3307) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.670+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 3.0 in stage 1298.3 (TID 3306) in 22 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:56.702+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 5.0 in stage 1298.3 (TID 3308) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.702+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 4.0 in stage 1298.3 (TID 3307) in 32 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:56.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 6.0 in stage 1298.3 (TID 3309) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.725+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 5.0 in stage 1298.3 (TID 3308) in 24 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:56.747+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 7.0 in stage 1298.3 (TID 3310) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.747+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 6.0 in stage 1298.3 (TID 3309) in 22 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:56.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 8.0 in stage 1298.3 (TID 3311) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 7.0 in stage 1298.3 (TID 3310) in 29 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:56.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 9.0 in stage 1298.3 (TID 3312) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.800+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 8.0 in stage 1298.3 (TID 3311) in 24 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:56.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 13.0 in stage 1336.3 (TID 3313) (172.20.0.5, executor 4, partition 13, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 9.0 in stage 1298.3 (TID 3312) in 23 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:56.823+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSchedulerImpl: Removed TaskSet 1298.3, whose tasks have all completed, from pool
[2025-05-08T21:15:56.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: ShuffleMapStage 1298 (mapPartitions at GraphImpl.scala:208) finished in 0.304 s
[2025-05-08T21:15:56.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:56.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:56.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328, ShuffleMapStage 1299)
[2025-05-08T21:15:56.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:56.825+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: Submitting ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:56.826+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MemoryStore: Block broadcast_361 stored as values in memory (estimated size 14.9 KiB, free 416.1 MiB)
[2025-05-08T21:15:56.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:56.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MemoryStore: Block broadcast_361_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 416.1 MiB)
[2025-05-08T21:15:56.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Added broadcast_361_piece0 in memory on f2a432e4376a:35283 (size: 6.3 KiB, free: 432.4 MiB)
[2025-05-08T21:15:56.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_356_piece0 on f2a432e4376a:35283 in memory (size: 79.0 KiB, free: 432.5 MiB)
[2025-05-08T21:15:56.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO SparkContext: Created broadcast 361 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:56.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1299 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[674] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:56.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSchedulerImpl: Adding task set 1299.3 with 10 tasks resource profile 0
[2025-05-08T21:15:56.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_356_piece0 on 172.20.0.5:33389 in memory (size: 79.0 KiB, free: 420.7 MiB)
[2025-05-08T21:15:56.858+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_355_piece0 on f2a432e4376a:35283 in memory (size: 5.9 KiB, free: 432.5 MiB)
[2025-05-08T21:15:56.863+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_355_piece0 on 172.20.0.5:33389 in memory (size: 5.9 KiB, free: 420.7 MiB)
[2025-05-08T21:15:56.865+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 0.0 in stage 1299.3 (TID 3314) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.865+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 13.0 in stage 1336.3 (TID 3313) in 42 ms on 172.20.0.5 (executor 4) (11/41)
[2025-05-08T21:15:56.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_359_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T21:15:56.869+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_359_piece0 on 172.20.0.5:33389 in memory (size: 6.1 KiB, free: 420.7 MiB)
[2025-05-08T21:15:56.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Added broadcast_361_piece0 in memory on 172.20.0.5:33389 (size: 6.3 KiB, free: 420.7 MiB)
[2025-05-08T21:15:56.873+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_357_piece0 on f2a432e4376a:35283 in memory (size: 6.1 KiB, free: 432.5 MiB)
[2025-05-08T21:15:56.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_357_piece0 on 172.20.0.5:33389 in memory (size: 6.1 KiB, free: 420.7 MiB)
[2025-05-08T21:15:56.877+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:56.881+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_358_piece0 on 172.20.0.5:33389 in memory (size: 79.2 KiB, free: 420.8 MiB)
[2025-05-08T21:15:56.883+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO BlockManagerInfo: Removed broadcast_358_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.6 MiB)
[2025-05-08T21:15:56.885+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:15:56.893+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:15:56.910+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:15:56.945+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:15:56.953+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Starting task 1.0 in stage 1299.3 (TID 3315) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:56.955+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:56 INFO TaskSetManager: Finished task 0.0 in stage 1299.3 (TID 3314) in 92 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:57.025+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 2.0 in stage 1299.3 (TID 3316) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.026+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 1.0 in stage 1299.3 (TID 3315) in 73 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:57.079+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 3.0 in stage 1299.3 (TID 3317) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.080+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 2.0 in stage 1299.3 (TID 3316) in 54 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:57.115+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 4.0 in stage 1299.3 (TID 3318) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.115+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 3.0 in stage 1299.3 (TID 3317) in 36 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:57.152+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 5.0 in stage 1299.3 (TID 3319) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.152+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 4.0 in stage 1299.3 (TID 3318) in 37 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:57.198+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 6.0 in stage 1299.3 (TID 3320) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.199+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 5.0 in stage 1299.3 (TID 3319) in 48 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:57.257+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 7.0 in stage 1299.3 (TID 3321) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.257+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 6.0 in stage 1299.3 (TID 3320) in 59 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:57.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 8.0 in stage 1299.3 (TID 3322) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.296+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 7.0 in stage 1299.3 (TID 3321) in 39 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:57.350+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 9.0 in stage 1299.3 (TID 3323) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.351+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 8.0 in stage 1299.3 (TID 3322) in 55 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:57.387+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 14.0 in stage 1336.3 (TID 3324) (172.20.0.5, executor 4, partition 14, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 9.0 in stage 1299.3 (TID 3323) in 37 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSchedulerImpl: Removed TaskSet 1299.3, whose tasks have all completed, from pool
[2025-05-08T21:15:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: ShuffleMapStage 1299 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.562 s
[2025-05-08T21:15:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1300, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:15:57.388+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:57.389+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: Submitting ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:57.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:57.399+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MemoryStore: Block broadcast_362 stored as values in memory (estimated size 239.9 KiB, free 416.5 MiB)
[2025-05-08T21:15:57.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MemoryStore: Block broadcast_362_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.4 MiB)
[2025-05-08T21:15:57.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO BlockManagerInfo: Added broadcast_362_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:15:57.401+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO SparkContext: Created broadcast 362 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:57.402+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1300 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[678] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:57.402+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSchedulerImpl: Adding task set 1300.3 with 10 tasks resource profile 0
[2025-05-08T21:15:57.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 0.0 in stage 1300.3 (TID 3325) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 14.0 in stage 1336.3 (TID 3324) in 33 ms on 172.20.0.5 (executor 4) (12/41)
[2025-05-08T21:15:57.428+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO BlockManagerInfo: Added broadcast_362_piece0 in memory on 172.20.0.5:33389 (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:15:57.442+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:57.455+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:57.456+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:15:57.458+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:15:57.460+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:15:57.461+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:15:57.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:46780
[2025-05-08T21:15:57.487+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 1.0 in stage 1300.3 (TID 3326) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.487+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 0.0 in stage 1300.3 (TID 3325) in 68 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:57.513+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 2.0 in stage 1300.3 (TID 3327) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 1.0 in stage 1300.3 (TID 3326) in 28 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:57.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 3.0 in stage 1300.3 (TID 3328) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.539+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 2.0 in stage 1300.3 (TID 3327) in 26 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:57.570+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 4.0 in stage 1300.3 (TID 3329) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.571+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 3.0 in stage 1300.3 (TID 3328) in 33 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:57.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 5.0 in stage 1300.3 (TID 3330) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.602+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 4.0 in stage 1300.3 (TID 3329) in 32 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:57.629+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 6.0 in stage 1300.3 (TID 3331) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.630+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 5.0 in stage 1300.3 (TID 3330) in 28 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:57.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 7.0 in stage 1300.3 (TID 3332) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.662+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 6.0 in stage 1300.3 (TID 3331) in 33 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:57.690+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 8.0 in stage 1300.3 (TID 3333) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.691+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 7.0 in stage 1300.3 (TID 3332) in 30 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:57.722+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 9.0 in stage 1300.3 (TID 3334) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.723+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 8.0 in stage 1300.3 (TID 3333) in 33 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:57.747+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 15.0 in stage 1336.3 (TID 3335) (172.20.0.5, executor 4, partition 15, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.747+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 9.0 in stage 1300.3 (TID 3334) in 25 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:57.747+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSchedulerImpl: Removed TaskSet 1300.3, whose tasks have all completed, from pool
[2025-05-08T21:15:57.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: ShuffleMapStage 1300 (mapPartitions at GraphImpl.scala:208) finished in 0.359 s
[2025-05-08T21:15:57.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:57.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:57.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1301, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:15:57.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:57.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: Submitting ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:57.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MemoryStore: Block broadcast_363 stored as values in memory (estimated size 15.6 KiB, free 416.4 MiB)
[2025-05-08T21:15:57.751+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MemoryStore: Block broadcast_363_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 416.4 MiB)
[2025-05-08T21:15:57.751+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO BlockManagerInfo: Added broadcast_363_piece0 in memory on f2a432e4376a:35283 (size: 6.4 KiB, free: 432.5 MiB)
[2025-05-08T21:15:57.752+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO SparkContext: Created broadcast 363 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:57.752+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1301 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[686] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:57.752+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSchedulerImpl: Adding task set 1301.3 with 10 tasks resource profile 0
[2025-05-08T21:15:57.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:57.775+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 0.0 in stage 1301.3 (TID 3336) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 15.0 in stage 1336.3 (TID 3335) in 28 ms on 172.20.0.5 (executor 4) (13/41)
[2025-05-08T21:15:57.782+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO BlockManagerInfo: Added broadcast_363_piece0 in memory on 172.20.0.5:33389 (size: 6.4 KiB, free: 420.7 MiB)
[2025-05-08T21:15:57.786+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:57.792+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:15:57.797+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:15:57.815+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:15:57.831+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:15:57.867+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:46780
[2025-05-08T21:15:57.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 1.0 in stage 1301.3 (TID 3337) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.872+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 0.0 in stage 1301.3 (TID 3336) in 98 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:57.939+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 2.0 in stage 1301.3 (TID 3338) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.939+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 1.0 in stage 1301.3 (TID 3337) in 67 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:57.998+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Starting task 3.0 in stage 1301.3 (TID 3339) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:57.999+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:57 INFO TaskSetManager: Finished task 2.0 in stage 1301.3 (TID 3338) in 59 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:58.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 4.0 in stage 1301.3 (TID 3340) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.084+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 3.0 in stage 1301.3 (TID 3339) in 86 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:58.138+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 5.0 in stage 1301.3 (TID 3341) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.138+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 4.0 in stage 1301.3 (TID 3340) in 54 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:58.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 6.0 in stage 1301.3 (TID 3342) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.194+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 5.0 in stage 1301.3 (TID 3341) in 55 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:58.257+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 7.0 in stage 1301.3 (TID 3343) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.258+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 6.0 in stage 1301.3 (TID 3342) in 64 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:58.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 8.0 in stage 1301.3 (TID 3344) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 7.0 in stage 1301.3 (TID 3343) in 63 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:58.371+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 9.0 in stage 1301.3 (TID 3345) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.372+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 8.0 in stage 1301.3 (TID 3344) in 52 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:58.423+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 16.0 in stage 1336.3 (TID 3346) (172.20.0.5, executor 4, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 9.0 in stage 1301.3 (TID 3345) in 52 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSchedulerImpl: Removed TaskSet 1301.3, whose tasks have all completed, from pool
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: ShuffleMapStage 1301 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.675 s
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1302, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:58.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: Submitting ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:58.428+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:58.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MemoryStore: Block broadcast_364 stored as values in memory (estimated size 240.2 KiB, free 416.2 MiB)
[2025-05-08T21:15:58.431+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MemoryStore: Block broadcast_364_piece0 stored as bytes in memory (estimated size 79.2 KiB, free 416.1 MiB)
[2025-05-08T21:15:58.431+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Added broadcast_364_piece0 in memory on f2a432e4376a:35283 (size: 79.2 KiB, free: 432.4 MiB)
[2025-05-08T21:15:58.431+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO SparkContext: Created broadcast 364 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:58.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1302 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[690] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:58.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSchedulerImpl: Adding task set 1302.3 with 10 tasks resource profile 0
[2025-05-08T21:15:58.448+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 0.0 in stage 1302.3 (TID 3347) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.449+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 16.0 in stage 1336.3 (TID 3346) in 26 ms on 172.20.0.5 (executor 4) (14/41)
[2025-05-08T21:15:58.454+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Added broadcast_364_piece0 in memory on 172.20.0.5:33389 (size: 79.2 KiB, free: 420.6 MiB)
[2025-05-08T21:15:58.465+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:58.475+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:58.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:15:58.477+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:15:58.478+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:15:58.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:15:58.481+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:46780
[2025-05-08T21:15:58.482+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:46780
[2025-05-08T21:15:58.496+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 1.0 in stage 1302.3 (TID 3348) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.496+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 0.0 in stage 1302.3 (TID 3347) in 48 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:58.516+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 2.0 in stage 1302.3 (TID 3349) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.516+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 1.0 in stage 1302.3 (TID 3348) in 21 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:58.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 3.0 in stage 1302.3 (TID 3350) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.536+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 2.0 in stage 1302.3 (TID 3349) in 20 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:58.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 4.0 in stage 1302.3 (TID 3351) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.556+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 3.0 in stage 1302.3 (TID 3350) in 20 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:58.576+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 5.0 in stage 1302.3 (TID 3352) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.577+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 4.0 in stage 1302.3 (TID 3351) in 21 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:58.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 6.0 in stage 1302.3 (TID 3353) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 5.0 in stage 1302.3 (TID 3352) in 19 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:58.613+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 7.0 in stage 1302.3 (TID 3354) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.614+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 6.0 in stage 1302.3 (TID 3353) in 19 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:58.631+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 8.0 in stage 1302.3 (TID 3355) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.632+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 7.0 in stage 1302.3 (TID 3354) in 19 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:58.653+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 9.0 in stage 1302.3 (TID 3356) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.654+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 8.0 in stage 1302.3 (TID 3355) in 23 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:58.681+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 17.0 in stage 1336.3 (TID 3357) (172.20.0.5, executor 4, partition 17, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 9.0 in stage 1302.3 (TID 3356) in 29 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:58.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSchedulerImpl: Removed TaskSet 1302.3, whose tasks have all completed, from pool
[2025-05-08T21:15:58.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: ShuffleMapStage 1302 (mapPartitions at GraphImpl.scala:208) finished in 0.258 s
[2025-05-08T21:15:58.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:58.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:58.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1303, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:15:58.682+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:58.683+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: Submitting ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:58.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MemoryStore: Block broadcast_365 stored as values in memory (estimated size 16.4 KiB, free 416.1 MiB)
[2025-05-08T21:15:58.686+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:58.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MemoryStore: Block broadcast_365_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 416.1 MiB)
[2025-05-08T21:15:58.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Added broadcast_365_piece0 in memory on f2a432e4376a:35283 (size: 6.5 KiB, free: 432.4 MiB)
[2025-05-08T21:15:58.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO SparkContext: Created broadcast 365 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:58.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1303 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[698] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:58.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSchedulerImpl: Adding task set 1303.3 with 10 tasks resource profile 0
[2025-05-08T21:15:58.703+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 0.0 in stage 1303.3 (TID 3358) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.704+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 17.0 in stage 1336.3 (TID 3357) in 22 ms on 172.20.0.5 (executor 4) (15/41)
[2025-05-08T21:15:58.707+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Added broadcast_365_piece0 in memory on 172.20.0.5:33389 (size: 6.5 KiB, free: 420.6 MiB)
[2025-05-08T21:15:58.710+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:58.713+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:15:58.716+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:15:58.730+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:15:58.738+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:15:58.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:46780
[2025-05-08T21:15:58.811+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:46780
[2025-05-08T21:15:58.824+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_360_piece0 on f2a432e4376a:35283 in memory (size: 79.3 KiB, free: 432.5 MiB)
[2025-05-08T21:15:58.825+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_360_piece0 on 172.20.0.5:33389 in memory (size: 79.3 KiB, free: 420.7 MiB)
[2025-05-08T21:15:58.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_361_piece0 on f2a432e4376a:35283 in memory (size: 6.3 KiB, free: 432.5 MiB)
[2025-05-08T21:15:58.828+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_361_piece0 on 172.20.0.5:33389 in memory (size: 6.3 KiB, free: 420.7 MiB)
[2025-05-08T21:15:58.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 1.0 in stage 1303.3 (TID 3359) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 0.0 in stage 1303.3 (TID 3358) in 126 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:58.830+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_363_piece0 on f2a432e4376a:35283 in memory (size: 6.4 KiB, free: 432.5 MiB)
[2025-05-08T21:15:58.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_363_piece0 on 172.20.0.5:33389 in memory (size: 6.4 KiB, free: 420.7 MiB)
[2025-05-08T21:15:58.834+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_364_piece0 on f2a432e4376a:35283 in memory (size: 79.2 KiB, free: 432.6 MiB)
[2025-05-08T21:15:58.835+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_364_piece0 on 172.20.0.5:33389 in memory (size: 79.2 KiB, free: 420.8 MiB)
[2025-05-08T21:15:58.837+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_362_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.7 MiB)
[2025-05-08T21:15:58.838+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO BlockManagerInfo: Removed broadcast_362_piece0 on 172.20.0.5:33389 in memory (size: 79.1 KiB, free: 420.8 MiB)
[2025-05-08T21:15:58.957+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Starting task 2.0 in stage 1303.3 (TID 3360) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:58.958+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:58 INFO TaskSetManager: Finished task 1.0 in stage 1303.3 (TID 3359) in 129 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:59.054+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 3.0 in stage 1303.3 (TID 3361) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.055+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 2.0 in stage 1303.3 (TID 3360) in 97 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:59.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 4.0 in stage 1303.3 (TID 3362) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.158+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 3.0 in stage 1303.3 (TID 3361) in 104 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:59.255+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 5.0 in stage 1303.3 (TID 3363) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.256+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 4.0 in stage 1303.3 (TID 3362) in 97 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:59.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 6.0 in stage 1303.3 (TID 3364) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 5.0 in stage 1303.3 (TID 3363) in 86 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:59.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 7.0 in stage 1303.3 (TID 3365) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 6.0 in stage 1303.3 (TID 3364) in 92 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:59.514+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 8.0 in stage 1303.3 (TID 3366) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.515+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 7.0 in stage 1303.3 (TID 3365) in 81 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:59.600+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 9.0 in stage 1303.3 (TID 3367) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.600+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 8.0 in stage 1303.3 (TID 3366) in 86 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:59.683+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 18.0 in stage 1336.3 (TID 3368) (172.20.0.5, executor 4, partition 18, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.683+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 9.0 in stage 1303.3 (TID 3367) in 84 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:59.683+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSchedulerImpl: Removed TaskSet 1303.3, whose tasks have all completed, from pool
[2025-05-08T21:15:59.683+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: ShuffleMapStage 1303 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.000 s
[2025-05-08T21:15:59.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:59.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:59.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1304, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:15:59.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:59.684+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: Submitting ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:15:59.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:59.691+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MemoryStore: Block broadcast_366 stored as values in memory (estimated size 240.5 KiB, free 416.8 MiB)
[2025-05-08T21:15:59.692+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MemoryStore: Block broadcast_366_piece0 stored as bytes in memory (estimated size 79.1 KiB, free 416.7 MiB)
[2025-05-08T21:15:59.692+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO BlockManagerInfo: Added broadcast_366_piece0 in memory on f2a432e4376a:35283 (size: 79.1 KiB, free: 432.6 MiB)
[2025-05-08T21:15:59.692+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO SparkContext: Created broadcast 366 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:59.693+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1304 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[702] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:59.693+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSchedulerImpl: Adding task set 1304.3 with 10 tasks resource profile 0
[2025-05-08T21:15:59.703+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 0.0 in stage 1304.3 (TID 3369) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.703+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 18.0 in stage 1336.3 (TID 3368) in 20 ms on 172.20.0.5 (executor 4) (16/41)
[2025-05-08T21:15:59.706+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO BlockManagerInfo: Added broadcast_366_piece0 in memory on 172.20.0.5:33389 (size: 79.1 KiB, free: 420.8 MiB)
[2025-05-08T21:15:59.715+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:15:59.730+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:15:59.732+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:15:59.733+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:15:59.734+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:15:59.735+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:15:59.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:46780
[2025-05-08T21:15:59.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:46780
[2025-05-08T21:15:59.737+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:46780
[2025-05-08T21:15:59.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 1.0 in stage 1304.3 (TID 3370) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 0.0 in stage 1304.3 (TID 3369) in 52 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:15:59.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 2.0 in stage 1304.3 (TID 3371) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 1.0 in stage 1304.3 (TID 3370) in 19 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:15:59.792+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 3.0 in stage 1304.3 (TID 3372) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.793+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 2.0 in stage 1304.3 (TID 3371) in 19 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:15:59.813+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 4.0 in stage 1304.3 (TID 3373) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.814+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 3.0 in stage 1304.3 (TID 3372) in 22 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:15:59.832+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 5.0 in stage 1304.3 (TID 3374) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.833+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 4.0 in stage 1304.3 (TID 3373) in 19 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:15:59.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 6.0 in stage 1304.3 (TID 3375) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.851+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 5.0 in stage 1304.3 (TID 3374) in 19 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:15:59.870+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 7.0 in stage 1304.3 (TID 3376) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.871+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 6.0 in stage 1304.3 (TID 3375) in 19 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:15:59.892+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 8.0 in stage 1304.3 (TID 3377) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.892+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 7.0 in stage 1304.3 (TID 3376) in 22 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:15:59.912+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 9.0 in stage 1304.3 (TID 3378) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.912+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 8.0 in stage 1304.3 (TID 3377) in 21 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:15:59.940+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 19.0 in stage 1336.3 (TID 3379) (172.20.0.5, executor 4, partition 19, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.940+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 9.0 in stage 1304.3 (TID 3378) in 28 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:15:59.940+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSchedulerImpl: Removed TaskSet 1304.3, whose tasks have all completed, from pool
[2025-05-08T21:15:59.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: ShuffleMapStage 1304 (mapPartitions at GraphImpl.scala:208) finished in 0.256 s
[2025-05-08T21:15:59.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:15:59.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:15:59.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1305, ShuffleMapStage 1328)
[2025-05-08T21:15:59.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: failed: Set()
[2025-05-08T21:15:59.941+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: Submitting ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:15:59.943+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MemoryStore: Block broadcast_367 stored as values in memory (estimated size 17.1 KiB, free 416.7 MiB)
[2025-05-08T21:15:59.944+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MemoryStore: Block broadcast_367_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 416.7 MiB)
[2025-05-08T21:15:59.944+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO BlockManagerInfo: Added broadcast_367_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.6 MiB)
[2025-05-08T21:15:59.944+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO SparkContext: Created broadcast 367 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:15:59.944+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1305 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[710] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:15:59.945+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSchedulerImpl: Adding task set 1305.3 with 10 tasks resource profile 0
[2025-05-08T21:15:59.945+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:15:59.960+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Starting task 0.0 in stage 1305.3 (TID 3380) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:15:59.961+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO TaskSetManager: Finished task 19.0 in stage 1336.3 (TID 3379) in 21 ms on 172.20.0.5 (executor 4) (17/41)
[2025-05-08T21:15:59.965+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO BlockManagerInfo: Added broadcast_367_piece0 in memory on 172.20.0.5:33389 (size: 6.6 KiB, free: 420.7 MiB)
[2025-05-08T21:15:59.967+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:15:59.970+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:15:59.973+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:15:59.985+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:15:59.994+0000] {spark_submit.py:571} INFO - 25/05/08 21:15:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:16:00.010+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:46780
[2025-05-08T21:16:00.039+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:46780
[2025-05-08T21:16:00.156+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:46780
[2025-05-08T21:16:00.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Starting task 1.0 in stage 1305.3 (TID 3381) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:00.162+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Finished task 0.0 in stage 1305.3 (TID 3380) in 201 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:00.379+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Starting task 2.0 in stage 1305.3 (TID 3382) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:00.379+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Finished task 1.0 in stage 1305.3 (TID 3381) in 218 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:00.578+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Starting task 3.0 in stage 1305.3 (TID 3383) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:00.579+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Finished task 2.0 in stage 1305.3 (TID 3382) in 199 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:00.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Starting task 4.0 in stage 1305.3 (TID 3384) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:00.751+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Finished task 3.0 in stage 1305.3 (TID 3383) in 172 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:00.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Starting task 5.0 in stage 1305.3 (TID 3385) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:00.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:00 INFO TaskSetManager: Finished task 4.0 in stage 1305.3 (TID 3384) in 179 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:01.095+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 6.0 in stage 1305.3 (TID 3386) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.096+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 5.0 in stage 1305.3 (TID 3385) in 167 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:01.262+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 7.0 in stage 1305.3 (TID 3387) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.263+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 6.0 in stage 1305.3 (TID 3386) in 167 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:01.423+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 8.0 in stage 1305.3 (TID 3388) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.423+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 7.0 in stage 1305.3 (TID 3387) in 161 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:01.565+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 9.0 in stage 1305.3 (TID 3389) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.565+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 8.0 in stage 1305.3 (TID 3388) in 142 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:01.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 20.0 in stage 1336.3 (TID 3390) (172.20.0.5, executor 4, partition 20, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 9.0 in stage 1305.3 (TID 3389) in 175 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:01.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSchedulerImpl: Removed TaskSet 1305.3, whose tasks have all completed, from pool
[2025-05-08T21:16:01.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO DAGScheduler: ShuffleMapStage 1305 (mapPartitions at VertexRDDImpl.scala:247) finished in 1.798 s
[2025-05-08T21:16:01.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:01.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:01.740+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1306, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:01.741+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:01.741+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO DAGScheduler: Submitting ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:16:01.745+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:46780
[2025-05-08T21:16:01.745+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MemoryStore: Block broadcast_368 stored as values in memory (estimated size 240.8 KiB, free 416.5 MiB)
[2025-05-08T21:16:01.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MemoryStore: Block broadcast_368_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 416.4 MiB)
[2025-05-08T21:16:01.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO BlockManagerInfo: Added broadcast_368_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.5 MiB)
[2025-05-08T21:16:01.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO SparkContext: Created broadcast 368 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:01.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1306 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[714] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:01.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSchedulerImpl: Adding task set 1306.3 with 10 tasks resource profile 0
[2025-05-08T21:16:01.764+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 0.0 in stage 1306.3 (TID 3391) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.765+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 20.0 in stage 1336.3 (TID 3390) in 25 ms on 172.20.0.5 (executor 4) (18/41)
[2025-05-08T21:16:01.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO BlockManagerInfo: Added broadcast_368_piece0 in memory on 172.20.0.5:33389 (size: 79.4 KiB, free: 420.7 MiB)
[2025-05-08T21:16:01.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:16:01.778+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:16:01.787+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:16:01.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:16:01.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:16:01.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:16:01.791+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:46780
[2025-05-08T21:16:01.792+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:46780
[2025-05-08T21:16:01.793+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:46780
[2025-05-08T21:16:01.794+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:46780
[2025-05-08T21:16:01.806+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 1.0 in stage 1306.3 (TID 3392) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.806+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 0.0 in stage 1306.3 (TID 3391) in 42 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:01.826+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 2.0 in stage 1306.3 (TID 3393) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 1.0 in stage 1306.3 (TID 3392) in 20 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:01.856+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 3.0 in stage 1306.3 (TID 3394) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.857+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 2.0 in stage 1306.3 (TID 3393) in 31 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:01.875+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 4.0 in stage 1306.3 (TID 3395) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.876+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 3.0 in stage 1306.3 (TID 3394) in 20 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:01.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 5.0 in stage 1306.3 (TID 3396) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.904+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 4.0 in stage 1306.3 (TID 3395) in 29 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:01.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 6.0 in stage 1306.3 (TID 3397) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.922+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 5.0 in stage 1306.3 (TID 3396) in 19 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:01.945+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 7.0 in stage 1306.3 (TID 3398) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.946+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 6.0 in stage 1306.3 (TID 3397) in 24 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:01.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 8.0 in stage 1306.3 (TID 3399) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.964+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 7.0 in stage 1306.3 (TID 3398) in 19 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:01.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Starting task 9.0 in stage 1306.3 (TID 3400) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:01.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:01 INFO TaskSetManager: Finished task 8.0 in stage 1306.3 (TID 3399) in 18 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:02.000+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Starting task 21.0 in stage 1336.3 (TID 3401) (172.20.0.5, executor 4, partition 21, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:02.000+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Finished task 9.0 in stage 1306.3 (TID 3400) in 18 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:02.000+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSchedulerImpl: Removed TaskSet 1306.3, whose tasks have all completed, from pool
[2025-05-08T21:16:02.000+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO DAGScheduler: ShuffleMapStage 1306 (mapPartitions at GraphImpl.scala:208) finished in 0.259 s
[2025-05-08T21:16:02.001+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:02.001+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:02.001+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1307, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:02.001+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:02.001+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO DAGScheduler: Submitting ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:16:02.002+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MemoryStore: Block broadcast_369 stored as values in memory (estimated size 17.8 KiB, free 416.4 MiB)
[2025-05-08T21:16:02.002+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MemoryStore: Block broadcast_369_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 416.4 MiB)
[2025-05-08T21:16:02.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO BlockManagerInfo: Added broadcast_369_piece0 in memory on f2a432e4376a:35283 (size: 6.6 KiB, free: 432.5 MiB)
[2025-05-08T21:16:02.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO SparkContext: Created broadcast 369 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:02.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1307 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[722] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:02.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSchedulerImpl: Adding task set 1307.3 with 10 tasks resource profile 0
[2025-05-08T21:16:02.004+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:16:02.029+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Starting task 0.0 in stage 1307.3 (TID 3402) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:02.030+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Finished task 21.0 in stage 1336.3 (TID 3401) in 29 ms on 172.20.0.5 (executor 4) (19/41)
[2025-05-08T21:16:02.033+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO BlockManagerInfo: Added broadcast_369_piece0 in memory on 172.20.0.5:33389 (size: 6.6 KiB, free: 420.7 MiB)
[2025-05-08T21:16:02.035+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:16:02.039+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:16:02.042+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:16:02.048+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:16:02.066+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:16:02.081+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:46780
[2025-05-08T21:16:02.104+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:46780
[2025-05-08T21:16:02.149+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:46780
[2025-05-08T21:16:02.359+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:46780
[2025-05-08T21:16:02.363+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Starting task 1.0 in stage 1307.3 (TID 3403) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:02.363+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Finished task 0.0 in stage 1307.3 (TID 3402) in 334 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:02.734+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Starting task 2.0 in stage 1307.3 (TID 3404) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:02.737+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:02 INFO TaskSetManager: Finished task 1.0 in stage 1307.3 (TID 3403) in 371 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:03.040+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Starting task 3.0 in stage 1307.3 (TID 3405) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:03.040+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Finished task 2.0 in stage 1307.3 (TID 3404) in 305 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:03.343+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Starting task 4.0 in stage 1307.3 (TID 3406) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:03.343+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Finished task 3.0 in stage 1307.3 (TID 3405) in 303 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:03.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Starting task 5.0 in stage 1307.3 (TID 3407) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:03.626+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Finished task 4.0 in stage 1307.3 (TID 3406) in 284 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:03.951+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Starting task 6.0 in stage 1307.3 (TID 3408) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:03.952+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:03 INFO TaskSetManager: Finished task 5.0 in stage 1307.3 (TID 3407) in 325 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:04.267+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:04 INFO TaskSetManager: Starting task 7.0 in stage 1307.3 (TID 3409) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:04.267+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:04 INFO TaskSetManager: Finished task 6.0 in stage 1307.3 (TID 3408) in 316 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:04.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:04 INFO TaskSetManager: Starting task 8.0 in stage 1307.3 (TID 3410) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:04.596+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:04 INFO TaskSetManager: Finished task 7.0 in stage 1307.3 (TID 3409) in 329 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:04.881+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:04 INFO TaskSetManager: Starting task 9.0 in stage 1307.3 (TID 3411) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:04.881+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:04 INFO TaskSetManager: Finished task 8.0 in stage 1307.3 (TID 3410) in 286 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:05.144+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 22.0 in stage 1336.3 (TID 3412) (172.20.0.5, executor 4, partition 22, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.144+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 9.0 in stage 1307.3 (TID 3411) in 263 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:05.145+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSchedulerImpl: Removed TaskSet 1307.3, whose tasks have all completed, from pool
[2025-05-08T21:16:05.147+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:16:05.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: ShuffleMapStage 1307 (mapPartitions at VertexRDDImpl.scala:247) finished in 3.143 s
[2025-05-08T21:16:05.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:05.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:05.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1308, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:05.149+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:05.149+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 1308 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:16:05.163+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 23.0 in stage 1336.3 (TID 3413) (172.20.0.5, executor 4, partition 23, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.163+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 22.0 in stage 1336.3 (TID 3412) in 19 ms on 172.20.0.5 (executor 4) (20/41)
[2025-05-08T21:16:05.166+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MemoryStore: Block broadcast_370 stored as values in memory (estimated size 241.1 KiB, free 416.1 MiB)
[2025-05-08T21:16:05.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 24.0 in stage 1336.3 (TID 3414) (172.20.0.5, executor 4, partition 24, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 23.0 in stage 1336.3 (TID 3413) in 12 ms on 172.20.0.5 (executor 4) (21/41)
[2025-05-08T21:16:05.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MemoryStore: Block broadcast_370_piece0 stored as bytes in memory (estimated size 79.6 KiB, free 416.1 MiB)
[2025-05-08T21:16:05.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Added broadcast_370_piece0 in memory on f2a432e4376a:35283 (size: 79.6 KiB, free: 432.4 MiB)
[2025-05-08T21:16:05.179+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO SparkContext: Created broadcast 370 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:05.180+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1308 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[726] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:05.180+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSchedulerImpl: Adding task set 1308.2 with 10 tasks resource profile 0
[2025-05-08T21:16:05.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 0.0 in stage 1308.2 (TID 3415) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.193+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 24.0 in stage 1336.3 (TID 3414) in 18 ms on 172.20.0.5 (executor 4) (22/41)
[2025-05-08T21:16:05.197+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Added broadcast_370_piece0 in memory on 172.20.0.5:33389 (size: 79.6 KiB, free: 420.6 MiB)
[2025-05-08T21:16:05.203+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:16:05.212+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:16:05.216+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:16:05.223+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:16:05.226+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:16:05.230+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:16:05.232+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:46780
[2025-05-08T21:16:05.234+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:46780
[2025-05-08T21:16:05.237+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:46780
[2025-05-08T21:16:05.237+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:46780
[2025-05-08T21:16:05.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:46780
[2025-05-08T21:16:05.267+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 1.0 in stage 1308.2 (TID 3416) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.268+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 0.0 in stage 1308.2 (TID 3415) in 76 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:05.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 2.0 in stage 1308.2 (TID 3417) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.285+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 1.0 in stage 1308.2 (TID 3416) in 18 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:05.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 3.0 in stage 1308.2 (TID 3418) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.303+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 2.0 in stage 1308.2 (TID 3417) in 18 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:05.321+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 4.0 in stage 1308.2 (TID 3419) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 3.0 in stage 1308.2 (TID 3418) in 19 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:05.339+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 5.0 in stage 1308.2 (TID 3420) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.339+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 4.0 in stage 1308.2 (TID 3419) in 18 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:05.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 6.0 in stage 1308.2 (TID 3421) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.357+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 5.0 in stage 1308.2 (TID 3420) in 18 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:05.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 7.0 in stage 1308.2 (TID 3422) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.374+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 6.0 in stage 1308.2 (TID 3421) in 18 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:05.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 8.0 in stage 1308.2 (TID 3423) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.400+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 7.0 in stage 1308.2 (TID 3422) in 26 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:05.428+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 9.0 in stage 1308.2 (TID 3424) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.429+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 8.0 in stage 1308.2 (TID 3423) in 30 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:05.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 25.0 in stage 1336.3 (TID 3425) (172.20.0.5, executor 4, partition 25, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.446+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 9.0 in stage 1308.2 (TID 3424) in 18 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSchedulerImpl: Removed TaskSet 1308.2, whose tasks have all completed, from pool
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: ShuffleMapStage 1308 (mapPartitions at GraphImpl.scala:208) finished in 0.291 s
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1309, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 1309 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:16:05.447+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 1309.
[2025-05-08T21:16:05.449+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MemoryStore: Block broadcast_371 stored as values in memory (estimated size 18.5 KiB, free 416.0 MiB)
[2025-05-08T21:16:05.462+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:16:05.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MemoryStore: Block broadcast_371_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 416.0 MiB)
[2025-05-08T21:16:05.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Added broadcast_371_piece0 in memory on f2a432e4376a:35283 (size: 6.8 KiB, free: 432.4 MiB)
[2025-05-08T21:16:05.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_365_piece0 on f2a432e4376a:35283 in memory (size: 6.5 KiB, free: 432.4 MiB)
[2025-05-08T21:16:05.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO SparkContext: Created broadcast 371 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:05.463+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1309 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[734] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:05.464+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSchedulerImpl: Adding task set 1309.2 with 10 tasks resource profile 0
[2025-05-08T21:16:05.465+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_365_piece0 on 172.20.0.5:33389 in memory (size: 6.5 KiB, free: 420.6 MiB)
[2025-05-08T21:16:05.466+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_369_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.4 MiB)
[2025-05-08T21:16:05.470+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_369_piece0 on 172.20.0.5:33389 in memory (size: 6.6 KiB, free: 420.6 MiB)
[2025-05-08T21:16:05.476+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_366_piece0 on f2a432e4376a:35283 in memory (size: 79.1 KiB, free: 432.5 MiB)
[2025-05-08T21:16:05.477+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Starting task 0.0 in stage 1309.2 (TID 3426) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:05.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO TaskSetManager: Finished task 25.0 in stage 1336.3 (TID 3425) in 32 ms on 172.20.0.5 (executor 4) (23/41)
[2025-05-08T21:16:05.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_366_piece0 on 172.20.0.5:33389 in memory (size: 79.1 KiB, free: 420.7 MiB)
[2025-05-08T21:16:05.482+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_367_piece0 on f2a432e4376a:35283 in memory (size: 6.6 KiB, free: 432.5 MiB)
[2025-05-08T21:16:05.483+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_367_piece0 on 172.20.0.5:33389 in memory (size: 6.6 KiB, free: 420.7 MiB)
[2025-05-08T21:16:05.484+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Added broadcast_371_piece0 in memory on 172.20.0.5:33389 (size: 6.8 KiB, free: 420.7 MiB)
[2025-05-08T21:16:05.485+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_368_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.6 MiB)
[2025-05-08T21:16:05.487+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:16:05.489+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO BlockManagerInfo: Removed broadcast_368_piece0 on 172.20.0.5:33389 in memory (size: 79.4 KiB, free: 420.8 MiB)
[2025-05-08T21:16:05.492+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:16:05.499+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:16:05.506+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:16:05.528+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:16:05.546+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:46780
[2025-05-08T21:16:05.590+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:46780
[2025-05-08T21:16:05.645+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:46780
[2025-05-08T21:16:05.741+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:46780
[2025-05-08T21:16:06.128+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:46780
[2025-05-08T21:16:06.132+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:06 INFO TaskSetManager: Starting task 1.0 in stage 1309.2 (TID 3427) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:06.133+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:06 INFO TaskSetManager: Finished task 0.0 in stage 1309.2 (TID 3426) in 655 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:06.685+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:06 INFO TaskSetManager: Starting task 2.0 in stage 1309.2 (TID 3428) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:06.685+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:06 INFO TaskSetManager: Finished task 1.0 in stage 1309.2 (TID 3427) in 553 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:07.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:07 INFO TaskSetManager: Starting task 3.0 in stage 1309.2 (TID 3429) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:07.206+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:07 INFO TaskSetManager: Finished task 2.0 in stage 1309.2 (TID 3428) in 521 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:07.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:07 INFO TaskSetManager: Starting task 4.0 in stage 1309.2 (TID 3430) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:07.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:07 INFO TaskSetManager: Finished task 3.0 in stage 1309.2 (TID 3429) in 505 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:08.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:08 INFO TaskSetManager: Starting task 5.0 in stage 1309.2 (TID 3431) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:08.238+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:08 INFO TaskSetManager: Finished task 4.0 in stage 1309.2 (TID 3430) in 527 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:08.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:08 INFO TaskSetManager: Starting task 6.0 in stage 1309.2 (TID 3432) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:08.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:08 INFO TaskSetManager: Finished task 5.0 in stage 1309.2 (TID 3431) in 529 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:09.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:09 INFO TaskSetManager: Starting task 7.0 in stage 1309.2 (TID 3433) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:09.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:09 INFO TaskSetManager: Finished task 6.0 in stage 1309.2 (TID 3432) in 676 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:10.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:10 INFO TaskSetManager: Starting task 8.0 in stage 1309.2 (TID 3434) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:10.003+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:10 INFO TaskSetManager: Finished task 7.0 in stage 1309.2 (TID 3433) in 561 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:10.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:10 INFO TaskSetManager: Starting task 9.0 in stage 1309.2 (TID 3435) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:10.657+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:10 INFO TaskSetManager: Finished task 8.0 in stage 1309.2 (TID 3434) in 653 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:11.327+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 26.0 in stage 1336.3 (TID 3436) (172.20.0.5, executor 4, partition 26, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.328+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 9.0 in stage 1309.2 (TID 3435) in 671 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:11.328+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSchedulerImpl: Removed TaskSet 1309.2, whose tasks have all completed, from pool
[2025-05-08T21:16:11.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: ShuffleMapStage 1309 (mapPartitions at VertexRDDImpl.scala:247) finished in 5.880 s
[2025-05-08T21:16:11.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:11.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:11.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1310, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:11.330+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:11.331+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: Submitting ShuffleMapStage 1310 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[738] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:16:11.333+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:16:11.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MemoryStore: Block broadcast_372 stored as values in memory (estimated size 241.4 KiB, free 416.5 MiB)
[2025-05-08T21:16:11.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MemoryStore: Block broadcast_372_piece0 stored as bytes in memory (estimated size 79.7 KiB, free 416.4 MiB)
[2025-05-08T21:16:11.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO BlockManagerInfo: Added broadcast_372_piece0 in memory on f2a432e4376a:35283 (size: 79.7 KiB, free: 432.5 MiB)
[2025-05-08T21:16:11.344+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO SparkContext: Created broadcast 372 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:11.345+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1310 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[738] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:11.345+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSchedulerImpl: Adding task set 1310.1 with 10 tasks resource profile 0
[2025-05-08T21:16:11.350+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 0.0 in stage 1310.1 (TID 3437) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.350+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 26.0 in stage 1336.3 (TID 3436) in 23 ms on 172.20.0.5 (executor 4) (24/41)
[2025-05-08T21:16:11.353+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO BlockManagerInfo: Added broadcast_372_piece0 in memory on 172.20.0.5:33389 (size: 79.7 KiB, free: 420.7 MiB)
[2025-05-08T21:16:11.361+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:16:11.365+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:16:11.375+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:16:11.377+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:16:11.380+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:16:11.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:16:11.384+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:46780
[2025-05-08T21:16:11.387+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:46780
[2025-05-08T21:16:11.390+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:46780
[2025-05-08T21:16:11.391+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:46780
[2025-05-08T21:16:11.392+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:46780
[2025-05-08T21:16:11.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:46780
[2025-05-08T21:16:11.414+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 1.0 in stage 1310.1 (TID 3438) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.415+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 0.0 in stage 1310.1 (TID 3437) in 66 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:11.442+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 2.0 in stage 1310.1 (TID 3439) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.443+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 1.0 in stage 1310.1 (TID 3438) in 29 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:11.468+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 3.0 in stage 1310.1 (TID 3440) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.468+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 2.0 in stage 1310.1 (TID 3439) in 26 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:11.488+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 4.0 in stage 1310.1 (TID 3441) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.488+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 3.0 in stage 1310.1 (TID 3440) in 20 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:11.515+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 5.0 in stage 1310.1 (TID 3442) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.516+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 4.0 in stage 1310.1 (TID 3441) in 28 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:11.543+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 6.0 in stage 1310.1 (TID 3443) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.544+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 5.0 in stage 1310.1 (TID 3442) in 28 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:11.574+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 7.0 in stage 1310.1 (TID 3444) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.575+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 6.0 in stage 1310.1 (TID 3443) in 32 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:11.617+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 8.0 in stage 1310.1 (TID 3445) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.618+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 7.0 in stage 1310.1 (TID 3444) in 43 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:11.639+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 9.0 in stage 1310.1 (TID 3446) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5235 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.640+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 8.0 in stage 1310.1 (TID 3445) in 22 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:11.671+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 27.0 in stage 1336.3 (TID 3447) (172.20.0.5, executor 4, partition 27, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 9.0 in stage 1310.1 (TID 3446) in 33 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:11.672+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSchedulerImpl: Removed TaskSet 1310.1, whose tasks have all completed, from pool
[2025-05-08T21:16:11.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: ShuffleMapStage 1310 (mapPartitions at GraphImpl.scala:208) finished in 0.339 s
[2025-05-08T21:16:11.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:11.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:11.673+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1311, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:11.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:11.674+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: Submitting ShuffleMapStage 1311 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[746] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:16:11.675+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MemoryStore: Block broadcast_373 stored as values in memory (estimated size 19.2 KiB, free 416.4 MiB)
[2025-05-08T21:16:11.676+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MemoryStore: Block broadcast_373_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 416.4 MiB)
[2025-05-08T21:16:11.677+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO BlockManagerInfo: Added broadcast_373_piece0 in memory on f2a432e4376a:35283 (size: 7.0 KiB, free: 432.5 MiB)
[2025-05-08T21:16:11.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO SparkContext: Created broadcast 373 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:11.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1311 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[746] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:11.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSchedulerImpl: Adding task set 1311.1 with 10 tasks resource profile 0
[2025-05-08T21:16:11.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:16:11.695+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Starting task 0.0 in stage 1311.1 (TID 3448) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:11.695+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO TaskSetManager: Finished task 27.0 in stage 1336.3 (TID 3447) in 24 ms on 172.20.0.5 (executor 4) (25/41)
[2025-05-08T21:16:11.702+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO BlockManagerInfo: Added broadcast_373_piece0 in memory on 172.20.0.5:33389 (size: 7.0 KiB, free: 420.7 MiB)
[2025-05-08T21:16:11.705+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:16:11.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:16:11.729+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:16:11.738+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:16:11.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:16:11.778+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:46780
[2025-05-08T21:16:11.829+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:46780
[2025-05-08T21:16:11.891+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:46780
[2025-05-08T21:16:12.033+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:46780
[2025-05-08T21:16:12.265+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:46780
[2025-05-08T21:16:13.179+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:46780
[2025-05-08T21:16:13.185+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:13 INFO TaskSetManager: Starting task 1.0 in stage 1311.1 (TID 3449) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:13.185+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:13 INFO TaskSetManager: Finished task 0.0 in stage 1311.1 (TID 3448) in 1491 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:14.398+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:14 INFO TaskSetManager: Starting task 2.0 in stage 1311.1 (TID 3450) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:14.398+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:14 INFO TaskSetManager: Finished task 1.0 in stage 1311.1 (TID 3449) in 1213 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:15.438+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:15 INFO TaskSetManager: Starting task 3.0 in stage 1311.1 (TID 3451) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:15.438+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:15 INFO TaskSetManager: Finished task 2.0 in stage 1311.1 (TID 3450) in 1040 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:16.594+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:16 INFO TaskSetManager: Starting task 4.0 in stage 1311.1 (TID 3452) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:16.595+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:16 INFO TaskSetManager: Finished task 3.0 in stage 1311.1 (TID 3451) in 1156 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:17.803+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:17 INFO TaskSetManager: Starting task 5.0 in stage 1311.1 (TID 3453) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:17.804+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:17 INFO TaskSetManager: Finished task 4.0 in stage 1311.1 (TID 3452) in 1209 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:18.974+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:18 INFO TaskSetManager: Starting task 6.0 in stage 1311.1 (TID 3454) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:18.974+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:18 INFO TaskSetManager: Finished task 5.0 in stage 1311.1 (TID 3453) in 1171 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:20.125+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:20 INFO TaskSetManager: Starting task 7.0 in stage 1311.1 (TID 3455) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:20.126+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:20 INFO TaskSetManager: Finished task 6.0 in stage 1311.1 (TID 3454) in 1151 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:21.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:21 INFO TaskSetManager: Starting task 8.0 in stage 1311.1 (TID 3456) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:21.394+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:21 INFO TaskSetManager: Finished task 7.0 in stage 1311.1 (TID 3455) in 1269 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:22.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:22 INFO TaskSetManager: Starting task 9.0 in stage 1311.1 (TID 3457) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5444 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:22.548+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:22 INFO TaskSetManager: Finished task 8.0 in stage 1311.1 (TID 3456) in 1155 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:23.660+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 28.0 in stage 1336.3 (TID 3458) (172.20.0.5, executor 4, partition 28, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 9.0 in stage 1311.1 (TID 3457) in 1112 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSchedulerImpl: Removed TaskSet 1311.1, whose tasks have all completed, from pool
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: ShuffleMapStage 1311 (mapPartitions at VertexRDDImpl.scala:247) finished in 11.987 s
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1312, ShuffleMapStage 1314, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:23.661+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: Submitting ShuffleMapStage 1312 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[750] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-08T21:16:23.664+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:16:23.671+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MemoryStore: Block broadcast_374 stored as values in memory (estimated size 241.7 KiB, free 416.1 MiB)
[2025-05-08T21:16:23.677+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 29.0 in stage 1336.3 (TID 3459) (172.20.0.5, executor 4, partition 29, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.677+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MemoryStore: Block broadcast_374_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 416.1 MiB)
[2025-05-08T21:16:23.677+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 28.0 in stage 1336.3 (TID 3458) in 19 ms on 172.20.0.5 (executor 4) (26/41)
[2025-05-08T21:16:23.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO BlockManagerInfo: Added broadcast_374_piece0 in memory on f2a432e4376a:35283 (size: 79.4 KiB, free: 432.4 MiB)
[2025-05-08T21:16:23.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO SparkContext: Created broadcast 374 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:23.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1312 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[750] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:23.678+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSchedulerImpl: Adding task set 1312.1 with 10 tasks resource profile 0
[2025-05-08T21:16:23.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 0.0 in stage 1312.1 (TID 3460) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.687+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 29.0 in stage 1336.3 (TID 3459) in 11 ms on 172.20.0.5 (executor 4) (27/41)
[2025-05-08T21:16:23.690+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO BlockManagerInfo: Added broadcast_374_piece0 in memory on 172.20.0.5:33389 (size: 79.4 KiB, free: 420.6 MiB)
[2025-05-08T21:16:23.703+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 71 to 172.20.0.5:46780
[2025-05-08T21:16:23.706+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 73 to 172.20.0.5:46780
[2025-05-08T21:16:23.708+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 74 to 172.20.0.5:46780
[2025-05-08T21:16:23.709+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 76 to 172.20.0.5:46780
[2025-05-08T21:16:23.711+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 78 to 172.20.0.5:46780
[2025-05-08T21:16:23.712+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 80 to 172.20.0.5:46780
[2025-05-08T21:16:23.714+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 82 to 172.20.0.5:46780
[2025-05-08T21:16:23.716+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 84 to 172.20.0.5:46780
[2025-05-08T21:16:23.717+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 86 to 172.20.0.5:46780
[2025-05-08T21:16:23.719+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 88 to 172.20.0.5:46780
[2025-05-08T21:16:23.720+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 90 to 172.20.0.5:46780
[2025-05-08T21:16:23.722+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 92 to 172.20.0.5:46780
[2025-05-08T21:16:23.724+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 94 to 172.20.0.5:46780
[2025-05-08T21:16:23.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 1.0 in stage 1312.1 (TID 3461) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 0.0 in stage 1312.1 (TID 3460) in 62 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:23.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 2.0 in stage 1312.1 (TID 3462) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 1.0 in stage 1312.1 (TID 3461) in 20 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:23.785+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 3.0 in stage 1312.1 (TID 3463) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.786+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 2.0 in stage 1312.1 (TID 3462) in 20 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:23.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 4.0 in stage 1312.1 (TID 3464) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.808+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 3.0 in stage 1312.1 (TID 3463) in 23 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:16:23.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 5.0 in stage 1312.1 (TID 3465) (172.20.0.5, executor 4, partition 5, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.827+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 4.0 in stage 1312.1 (TID 3464) in 19 ms on 172.20.0.5 (executor 4) (5/10)
[2025-05-08T21:16:23.845+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 6.0 in stage 1312.1 (TID 3466) (172.20.0.5, executor 4, partition 6, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.846+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 5.0 in stage 1312.1 (TID 3465) in 19 ms on 172.20.0.5 (executor 4) (6/10)
[2025-05-08T21:16:23.863+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 7.0 in stage 1312.1 (TID 3467) (172.20.0.5, executor 4, partition 7, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.864+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 6.0 in stage 1312.1 (TID 3466) in 18 ms on 172.20.0.5 (executor 4) (7/10)
[2025-05-08T21:16:23.884+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 8.0 in stage 1312.1 (TID 3468) (172.20.0.5, executor 4, partition 8, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.885+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 7.0 in stage 1312.1 (TID 3467) in 22 ms on 172.20.0.5 (executor 4) (8/10)
[2025-05-08T21:16:23.907+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 9.0 in stage 1312.1 (TID 3469) (172.20.0.5, executor 4, partition 9, PROCESS_LOCAL, 5276 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.907+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 8.0 in stage 1312.1 (TID 3468) in 23 ms on 172.20.0.5 (executor 4) (9/10)
[2025-05-08T21:16:23.928+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 30.0 in stage 1336.3 (TID 3470) (172.20.0.5, executor 4, partition 30, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 9.0 in stage 1312.1 (TID 3469) in 23 ms on 172.20.0.5 (executor 4) (10/10)
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSchedulerImpl: Removed TaskSet 1312.1, whose tasks have all completed, from pool
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: ShuffleMapStage 1312 (mapPartitions at GraphImpl.scala:208) finished in 0.268 s
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: looking for newly runnable stages
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: running: Set(ResultStage 1340, ShuffleMapStage 1337, ShuffleMapStage 1344, ShuffleMapStage 1338, ResultStage 1342, ShuffleMapStage 1336)
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1322, ShuffleMapStage 1324, ShuffleMapStage 1316, ShuffleMapStage 1318, ShuffleMapStage 1320, ShuffleMapStage 1314, ShuffleMapStage 1325, ShuffleMapStage 1327, ShuffleMapStage 1329, ShuffleMapStage 1321, ShuffleMapStage 1323, ShuffleMapStage 1317, ShuffleMapStage 1319, ShuffleMapStage 1313, ShuffleMapStage 1315, ShuffleMapStage 1326, ShuffleMapStage 1328)
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: failed: Set()
[2025-05-08T21:16:23.929+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: Submitting ShuffleMapStage 1313 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[758] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-08T21:16:23.931+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MemoryStore: Block broadcast_375 stored as values in memory (estimated size 19.9 KiB, free 416.1 MiB)
[2025-05-08T21:16:23.933+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 117 to 172.20.0.5:46780
[2025-05-08T21:16:23.934+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MemoryStore: Block broadcast_375_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 416.0 MiB)
[2025-05-08T21:16:23.934+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO BlockManagerInfo: Added broadcast_375_piece0 in memory on f2a432e4376a:35283 (size: 7.1 KiB, free: 432.4 MiB)
[2025-05-08T21:16:23.934+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO SparkContext: Created broadcast 375 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:16:23.935+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1313 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[758] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-08T21:16:23.935+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSchedulerImpl: Adding task set 1313.1 with 10 tasks resource profile 0
[2025-05-08T21:16:23.948+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Starting task 0.0 in stage 1313.1 (TID 3471) (172.20.0.5, executor 4, partition 0, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:23.948+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO TaskSetManager: Finished task 30.0 in stage 1336.3 (TID 3470) in 20 ms on 172.20.0.5 (executor 4) (28/41)
[2025-05-08T21:16:23.952+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO BlockManagerInfo: Added broadcast_375_piece0 in memory on 172.20.0.5:33389 (size: 7.1 KiB, free: 420.6 MiB)
[2025-05-08T21:16:23.954+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 75 to 172.20.0.5:46780
[2025-05-08T21:16:23.958+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 77 to 172.20.0.5:46780
[2025-05-08T21:16:23.961+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 79 to 172.20.0.5:46780
[2025-05-08T21:16:23.966+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 81 to 172.20.0.5:46780
[2025-05-08T21:16:23.982+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 83 to 172.20.0.5:46780
[2025-05-08T21:16:23.997+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 85 to 172.20.0.5:46780
[2025-05-08T21:16:24.024+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 87 to 172.20.0.5:46780
[2025-05-08T21:16:24.077+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 89 to 172.20.0.5:46780
[2025-05-08T21:16:24.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 91 to 172.20.0.5:46780
[2025-05-08T21:16:24.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 93 to 172.20.0.5:46780
[2025-05-08T21:16:24.771+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 95 to 172.20.0.5:46780
[2025-05-08T21:16:26.320+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 97 to 172.20.0.5:46780
[2025-05-08T21:16:26.324+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:26 INFO TaskSetManager: Starting task 1.0 in stage 1313.1 (TID 3472) (172.20.0.5, executor 4, partition 1, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:26.324+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:26 INFO TaskSetManager: Finished task 0.0 in stage 1313.1 (TID 3471) in 2377 ms on 172.20.0.5 (executor 4) (1/10)
[2025-05-08T21:16:28.772+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:28 INFO TaskSetManager: Starting task 2.0 in stage 1313.1 (TID 3473) (172.20.0.5, executor 4, partition 2, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:28.772+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:28 INFO TaskSetManager: Finished task 1.0 in stage 1313.1 (TID 3472) in 2449 ms on 172.20.0.5 (executor 4) (2/10)
[2025-05-08T21:16:31.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:31 INFO TaskSetManager: Starting task 3.0 in stage 1313.1 (TID 3474) (172.20.0.5, executor 4, partition 3, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:31.124+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:31 INFO TaskSetManager: Finished task 2.0 in stage 1313.1 (TID 3473) in 2352 ms on 172.20.0.5 (executor 4) (3/10)
[2025-05-08T21:16:34.983+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:34 INFO TaskSetManager: Starting task 4.0 in stage 1313.1 (TID 3475) (172.20.0.5, executor 4, partition 4, PROCESS_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T21:16:34.990+0000] {spark_submit.py:571} INFO - 25/05/08 21:16:34 INFO TaskSetManager: Finished task 3.0 in stage 1313.1 (TID 3474) in 3861 ms on 172.20.0.5 (executor 4) (4/10)
[2025-05-08T21:21:43.507+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:43 WARN HeartbeatReceiver: Removing executor 4 with no recent heartbeats: 244994 ms exceeds timeout 120000 ms
[2025-05-08T21:21:43.565+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:43 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 4
[2025-05-08T21:21:43.565+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:43 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is 4
[2025-05-08T21:21:43.639+0000] {job.py:213} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.20.0.2), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 209, in heartbeat
    heartbeat_callback(session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/local_task_job_runner.py", line 243, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 811, in refresh_from_db
    ti = qry.one_or_none()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.20.0.2), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-05-08T21:21:45.113+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/4 is now LOST (worker lost)
[2025-05-08T21:21:45.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO StandaloneSchedulerBackend: Executor app-20250508193925-0005/4 removed: worker lost
[2025-05-08T21:21:45.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:21:45.174+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO StandaloneSchedulerBackend: Worker worker-20250508061515-172.20.0.5-45383 removed: Not receiving heartbeat for 60 seconds
[2025-05-08T21:21:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250508193925-0005/5 on worker-20250508061515-172.20.0.5-45383 (172.20.0.5:45383) with 1 core(s)
[2025-05-08T21:21:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 ERROR TaskSchedulerImpl: Lost executor 4 on 172.20.0.5: worker lost
[2025-05-08T21:21:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 13), so marking it as still running.
[2025-05-08T21:21:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 22), so marking it as still running.
[2025-05-08T21:21:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 10), so marking it as still running.
[2025-05-08T21:21:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 19), so marking it as still running.
[2025-05-08T21:21:45.175+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 1), so marking it as still running.
[2025-05-08T21:21:45.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN TaskSetManager: Lost task 4.0 in stage 1313.1 (TID 3475) (172.20.0.5 executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: worker lost
[2025-05-08T21:21:45.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 7), so marking it as still running.
[2025-05-08T21:21:45.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 27), so marking it as still running.
[2025-05-08T21:21:45.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 2), so marking it as still running.
[2025-05-08T21:21:45.176+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 29), so marking it as still running.
[2025-05-08T21:21:45.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 24), so marking it as still running.
[2025-05-08T21:21:45.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 11), so marking it as still running.
[2025-05-08T21:21:45.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 20), so marking it as still running.
[2025-05-08T21:21:45.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 17), so marking it as still running.
[2025-05-08T21:21:45.177+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 8), so marking it as still running.
[2025-05-08T21:21:45.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 14), so marking it as still running.
[2025-05-08T21:21:45.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 3), so marking it as still running.
[2025-05-08T21:21:45.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 25), so marking it as still running.
[2025-05-08T21:21:45.178+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 30), so marking it as still running.
[2025-05-08T21:21:45.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 21), so marking it as still running.
[2025-05-08T21:21:45.424+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 18), so marking it as still running.
[2025-05-08T21:21:45.425+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 28), so marking it as still running.
[2025-05-08T21:21:45.425+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 23), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 15), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 12), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 9), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 6), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 26), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1336, 16), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1313, 0), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1313, 3), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1313, 2), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Resubmitted ShuffleMapTask(1313, 1), so marking it as still running.
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250508193925-0005/5 on hostPort 172.20.0.5:45383 with 1 core(s), 1024.0 MiB RAM
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO TaskSchedulerImpl: Handle removed worker worker-20250508061515-172.20.0.5-45383: Not receiving heartbeat for 60 seconds
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Executor lost: 4 (epoch 321)
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO BlockManagerMaster: Removal of executor 4 requested
[2025-05-08T21:21:45.430+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 4
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 ERROR Inbox: Ignoring error
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at scala.Predef$.assert(Predef.scala:223)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:587)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
[2025-05-08T21:21:45.431+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_3 !
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_1 !
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_4 !
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_5 !
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_0 !
[2025-05-08T21:21:45.432+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_0 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_3 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_5 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_8 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_9 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_4 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_3 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_9 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_4 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_0 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_9 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_6 !
[2025-05-08T21:21:45.433+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_8 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_6 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_3 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_5 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_7 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_1 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_9 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_6 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_4 !
[2025-05-08T21:21:45.434+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_9 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_8 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_7 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_6 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_1 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_8 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_6 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_1 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_3 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_7 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_1 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_3 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_7 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_2 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_2 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_5 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_2 !
[2025-05-08T21:21:45.435+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_9 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_0 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_4 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_6 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_1 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_5 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_4 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_0 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_3 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_7 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_0 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_0 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_392_8 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_602_2 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_2 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_5 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_1 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_7 !
[2025-05-08T21:21:45.436+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_9 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_395_8 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_5 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_2 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_399_2 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_4 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_169_7 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_397_8 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_600_6 !
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, 172.20.0.5, 33389, None)
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO BlockManagerMaster: Removed 4 successfully in removeExecutor
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 321)
[2025-05-08T21:21:45.437+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:45 INFO DAGScheduler: Shuffle files lost for worker worker-20250508061515-172.20.0.5-45383 on host 172.20.0.5
[2025-05-08T21:21:47.221+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250508193925-0005/5 is now RUNNING
[2025-05-08T21:21:52.155+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:45470) with ID 5,  ResourceProfileId 0
[2025-05-08T21:21:52.306+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:52 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:32971 with 434.4 MiB RAM, BlockManagerId(5, 172.20.0.5, 32971, None)
[2025-05-08T21:21:52.479+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:52 INFO TaskSetManager: Starting task 4.1 in stage 1313.1 (TID 3476) (172.20.0.5, executor 5, partition 4, NODE_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T21:21:52.680+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:52 INFO BlockManagerInfo: Added broadcast_375_piece0 in memory on 172.20.0.5:32971 (size: 7.1 KiB, free: 434.4 MiB)
[2025-05-08T21:21:53.086+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:45470
[2025-05-08T21:21:53.133+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSetManager: Starting task 1.1 in stage 1313.1 (TID 3477) (172.20.0.5, executor 5, partition 1, NODE_LOCAL, 5517 bytes) taskResourceAssignments Map()
[2025-05-08T21:21:53.133+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 WARN TaskSetManager: Lost task 4.1 in stage 1313.1 (TID 3476) (172.20.0.5 executor 5): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=4, message=
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 4
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.134+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.135+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.136+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.138+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.139+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.140+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.141+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.142+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.143+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.144+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.145+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:53.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:53.146+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:53.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:53.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:53.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:53.147+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:53.147+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:53.147+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:53.147+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:53.148+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:53.148+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:21:53.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSetManager: task 4.1 in stage 1313.1 (TID 3476) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:21:53.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Marking ShuffleMapStage 1313 (mapPartitions at VertexRDDImpl.scala:247) as failed due to a fetch failure from ShuffleMapStage 1254 (map at GraphFrame.scala:187)
[2025-05-08T21:21:53.148+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1313 (mapPartitions at VertexRDDImpl.scala:247) failed in 329.203 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 4
[2025-05-08T21:21:53.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:53.148+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:53.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.149+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:53.149+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:53.149+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:53.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:53.149+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.150+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.151+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.152+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.153+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.154+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.155+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.156+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.157+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.157+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.157+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.157+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.157+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.157+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.157+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.158+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:53.159+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:53.160+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:53.161+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:53.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Resubmitting ShuffleMapStage 1254 (map at GraphFrame.scala:187) and ShuffleMapStage 1313 (mapPartitions at VertexRDDImpl.scala:247) due to fetch failure
[2025-05-08T21:21:53.161+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:45470
[2025-05-08T21:21:53.173+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSetManager: Starting task 16.1 in stage 1336.3 (TID 3478) (172.20.0.5, executor 5, partition 16, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-08T21:21:53.173+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 WARN TaskSetManager: Lost task 1.1 in stage 1313.1 (TID 3477) (172.20.0.5 executor 5): FetchFailed(null, shuffleId=37, mapIndex=-1, mapId=-1, reduceId=1, message=
[2025-05-08T21:21:53.173+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 37 partition 1
[2025-05-08T21:21:53.173+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:53.174+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.175+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.176+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.177+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-08T21:21:53.178+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.179+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.180+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.181+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.182+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.183+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:53.184+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:53.185+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:53.185+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:53.185+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:53.185+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:53.185+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:21:53.185+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSetManager: task 1.1 in stage 1313.1 (TID 3477) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:21:53.185+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1313.1, whose tasks have all completed, from pool
[2025-05-08T21:21:53.192+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Added broadcast_349_piece0 in memory on 172.20.0.5:32971 (size: 40.2 KiB, free: 434.4 MiB)
[2025-05-08T21:21:53.334+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Resubmitting failed stages
[2025-05-08T21:21:53.335+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:21:53.336+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_376 stored as values in memory (estimated size 23.9 KiB, free 416.0 MiB)
[2025-05-08T21:21:53.339+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_376_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 416.0 MiB)
[2025-05-08T21:21:53.339+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Added broadcast_376_piece0 in memory on f2a432e4376a:35283 (size: 11.7 KiB, free: 432.4 MiB)
[2025-05-08T21:21:53.340+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO SparkContext: Created broadcast 376 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:21:53.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1245 (MapPartitionsRDD[121] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:21:53.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Adding task set 1245.4 with 1 tasks resource profile 0
[2025-05-08T21:21:53.341+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:21:53.342+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_377 stored as values in memory (estimated size 22.4 KiB, free 416.0 MiB)
[2025-05-08T21:21:53.363+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_377_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 416.0 MiB)
[2025-05-08T21:21:53.368+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Added broadcast_377_piece0 in memory on f2a432e4376a:35283 (size: 11.1 KiB, free: 432.4 MiB)
[2025-05-08T21:21:53.369+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO SparkContext: Created broadcast 377 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:21:53.370+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1246 (MapPartitionsRDD[129] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:21:53.370+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Adding task set 1246.4 with 1 tasks resource profile 0
[2025-05-08T21:21:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:21:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_378 stored as values in memory (estimated size 22.4 KiB, free 416.0 MiB)
[2025-05-08T21:21:53.371+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Removed broadcast_371_piece0 on f2a432e4376a:35283 in memory (size: 6.8 KiB, free: 432.4 MiB)
[2025-05-08T21:21:53.373+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_378_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 416.0 MiB)
[2025-05-08T21:21:53.376+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Added broadcast_378_piece0 in memory on f2a432e4376a:35283 (size: 11.0 KiB, free: 432.4 MiB)
[2025-05-08T21:21:53.376+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO SparkContext: Created broadcast 378 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:21:53.376+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1247 (MapPartitionsRDD[137] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:21:53.377+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Adding task set 1247.4 with 1 tasks resource profile 0
[2025-05-08T21:21:53.377+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-08T21:21:53.377+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_379 stored as values in memory (estimated size 28.8 KiB, free 415.9 MiB)
[2025-05-08T21:21:53.379+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MemoryStore: Block broadcast_379_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 415.9 MiB)
[2025-05-08T21:21:53.380+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Added broadcast_379_piece0 in memory on f2a432e4376a:35283 (size: 13.8 KiB, free: 432.4 MiB)
[2025-05-08T21:21:53.381+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO SparkContext: Created broadcast 379 from broadcast at DAGScheduler.scala:1474
[2025-05-08T21:21:53.382+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1248 (MapPartitionsRDD[145] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-08T21:21:53.383+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Adding task set 1248.4 with 1 tasks resource profile 0
[2025-05-08T21:21:53.393+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Removed broadcast_372_piece0 on f2a432e4376a:35283 in memory (size: 79.7 KiB, free: 432.5 MiB)
[2025-05-08T21:21:53.398+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Removed broadcast_370_piece0 on f2a432e4376a:35283 in memory (size: 79.6 KiB, free: 432.5 MiB)
[2025-05-08T21:21:53.404+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Removed broadcast_375_piece0 on f2a432e4376a:35283 in memory (size: 7.1 KiB, free: 432.5 MiB)
[2025-05-08T21:21:53.413+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Removed broadcast_375_piece0 on 172.20.0.5:32971 in memory (size: 7.1 KiB, free: 434.4 MiB)
[2025-05-08T21:21:53.420+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Removed broadcast_373_piece0 on f2a432e4376a:35283 in memory (size: 7.0 KiB, free: 432.5 MiB)
[2025-05-08T21:21:53.426+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Removed broadcast_374_piece0 on f2a432e4376a:35283 in memory (size: 79.4 KiB, free: 432.6 MiB)
[2025-05-08T21:21:53.723+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 116 to 172.20.0.5:45470
[2025-05-08T21:21:53.728+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSetManager: Starting task 0.0 in stage 1245.4 (TID 3479) (172.20.0.5, executor 5, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-08T21:21:53.729+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 WARN TaskSetManager: Lost task 16.1 in stage 1336.3 (TID 3478) (172.20.0.5 executor 5): FetchFailed(null, shuffleId=116, mapIndex=-1, mapId=-1, reduceId=5, message=
[2025-05-08T21:21:53.729+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 116 partition 5
[2025-05-08T21:21:53.729+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:53.729+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:53.729+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.729+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:53.730+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:53.731+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:53.731+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:21:53.731+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.731+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.731+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.731+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.731+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.732+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.732+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.732+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.732+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.732+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.732+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.732+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.733+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.733+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.733+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:21:53.733+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.733+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.733+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.733+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:53.734+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:53.735+0000] {spark_submit.py:571} INFO - )
[2025-05-08T21:21:53.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSetManager: task 16.1 in stage 1336.3 (TID 3478) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-08T21:21:53.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1336.3, whose tasks have all completed, from pool
[2025-05-08T21:21:53.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Marking ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) as failed due to a fetch failure from ShuffleMapStage 1332 (collect at /opt/airflow/spark/build_graph.py:229)
[2025-05-08T21:21:53.736+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) failed in 362.836 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 116 partition 5
[2025-05-08T21:21:53.736+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:53.736+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:53.736+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:53.737+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.738+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.739+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.740+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.741+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.741+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.741+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:53.741+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:53.741+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:53.741+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:53.741+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:53.742+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:53.742+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:53.742+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:53.742+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:53.742+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:53.742+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:53.748+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 82
[2025-05-08T21:21:53.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1344
[2025-05-08T21:21:53.749+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1344: Stage cancelled
[2025-05-08T21:21:53.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job group 747eff66-33fb-411b-9aed-c25983042c04
[2025-05-08T21:21:53.750+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 82
[2025-05-08T21:21:53.751+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 74
[2025-05-08T21:21:53.751+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 78
[2025-05-08T21:21:53.752+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 82
[2025-05-08T21:21:53.752+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 79
[2025-05-08T21:21:53.753+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 79
[2025-05-08T21:21:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 82
[2025-05-08T21:21:53.754+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 78
[2025-05-08T21:21:53.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 79
[2025-05-08T21:21:53.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 79
[2025-05-08T21:21:53.755+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 79
[2025-05-08T21:21:53.756+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 79
[2025-05-08T21:21:53.756+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 82
[2025-05-08T21:21:53.757+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 79
[2025-05-08T21:21:53.757+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job 82
[2025-05-08T21:21:53.758+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: Asked to cancel job group 4fea40b2-067f-43ca-bb22-ca0af7e683f3
[2025-05-08T21:21:53.758+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1344.0, whose tasks have all completed, from pool
[2025-05-08T21:21:53.759+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1344 was cancelled
[2025-05-08T21:21:53.759+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1344 (collect at /opt/airflow/spark/build_graph.py:229) failed in 2253.192 s due to Job 82 cancelled
[2025-05-08T21:21:53.760+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO BlockManagerInfo: Added broadcast_376_piece0 in memory on 172.20.0.5:32971 (size: 11.7 KiB, free: 434.3 MiB)
[2025-05-08T21:21:53.762+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1340
[2025-05-08T21:21:53.765+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1340: Stage cancelled
[2025-05-08T21:21:53.765+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1340.0, whose tasks have all completed, from pool
[2025-05-08T21:21:53.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1340 was cancelled
[2025-05-08T21:21:53.767+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ResultStage 1340 (collect at /opt/airflow/spark/build_graph.py:229) failed in 5700.901 s due to Job 80 cancelled part of cancelled job group 747eff66-33fb-411b-9aed-c25983042c04
[2025-05-08T21:21:53.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1337
[2025-05-08T21:21:53.769+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1337: Stage cancelled
[2025-05-08T21:21:53.771+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1337.0, whose tasks have all completed, from pool
[2025-05-08T21:21:53.771+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1337 was cancelled
[2025-05-08T21:21:53.772+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1337 (collect at /opt/airflow/spark/build_graph.py:229) failed in 5900.901 s due to Job 78 cancelled
[2025-05-08T21:21:53.772+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1338
[2025-05-08T21:21:53.773+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1338: Stage cancelled
[2025-05-08T21:21:53.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1338.0, whose tasks have all completed, from pool
[2025-05-08T21:21:53.774+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1338 was cancelled
[2025-05-08T21:21:53.775+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1338 (collect at /opt/airflow/spark/build_graph.py:229) failed in 5900.604 s due to Job 79 cancelled
[2025-05-08T21:21:53.775+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1245
[2025-05-08T21:21:53.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1245: Stage cancelled
[2025-05-08T21:21:53.776+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1245 was cancelled
[2025-05-08T21:21:53.781+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1245 (rdd at GraphFrame.scala:187) failed in 0.437 s due to Job 81 cancelled part of cancelled job group 4fea40b2-067f-43ca-bb22-ca0af7e683f3
[2025-05-08T21:21:53.782+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1246
[2025-05-08T21:21:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1246: Stage cancelled
[2025-05-08T21:21:53.783+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1246.4, whose tasks have all completed, from pool
[2025-05-08T21:21:53.784+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1246 was cancelled
[2025-05-08T21:21:53.784+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1246 (rdd at GraphFrame.scala:187) failed in 0.431 s due to Job 81 cancelled part of cancelled job group 4fea40b2-067f-43ca-bb22-ca0af7e683f3
[2025-05-08T21:21:53.785+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1342
[2025-05-08T21:21:53.785+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1342: Stage cancelled
[2025-05-08T21:21:53.786+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1342.0, whose tasks have all completed, from pool
[2025-05-08T21:21:53.787+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1342 was cancelled
[2025-05-08T21:21:53.788+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ResultStage 1342 (collect at /opt/airflow/spark/build_graph.py:229) failed in 5699.614 s due to Job 81 cancelled part of cancelled job group 4fea40b2-067f-43ca-bb22-ca0af7e683f3
[2025-05-08T21:21:53.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1247
[2025-05-08T21:21:53.789+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1247: Stage cancelled
[2025-05-08T21:21:53.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1247.4, whose tasks have all completed, from pool
[2025-05-08T21:21:53.790+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1247 was cancelled
[2025-05-08T21:21:53.792+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1247 (rdd at GraphFrame.scala:187) failed in 0.406 s due to Job 81 cancelled part of cancelled job group 4fea40b2-067f-43ca-bb22-ca0af7e683f3
[2025-05-08T21:21:53.793+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Cancelling stage 1248
[2025-05-08T21:21:53.793+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 1248: Stage cancelled
[2025-05-08T21:21:53.794+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Removed TaskSet 1248.4, whose tasks have all completed, from pool
[2025-05-08T21:21:53.794+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO TaskSchedulerImpl: Stage 1248 was cancelled
[2025-05-08T21:21:53.794+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:53 INFO DAGScheduler: ShuffleMapStage 1248 (rdd at GraphFrame.scala:187) failed in 0.399 s due to Job 81 cancelled part of cancelled job group 4fea40b2-067f-43ca-bb22-ca0af7e683f3
[2025-05-08T21:21:53.971+0000] {spark_submit.py:571} INFO - 2025-05-08 21:21:53,896 [ERROR] Ошибка при обработке транзакционного графа: An error occurred while calling o364.collectToPython.
[2025-05-08T21:21:53.972+0000] {spark_submit.py:571} INFO - : org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) has failed the maximum allowable number of times: 4. Most recent failure reason:
[2025-05-08T21:21:53.972+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 116 partition 5
[2025-05-08T21:21:53.972+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:53.972+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:53.972+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.972+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:53.972+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:53.973+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:53.973+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.973+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:53.973+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:53.973+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:53.973+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:53.973+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.974+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.975+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.976+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:21:53.976+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.976+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.976+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.976+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.976+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.976+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:53.977+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:53.978+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:53.978+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:53.978+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:53.978+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:53.978+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:53.978+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
[2025-05-08T21:21:53.978+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)
[2025-05-08T21:21:53.979+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)
[2025-05-08T21:21:53.979+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[2025-05-08T21:21:53.979+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[2025-05-08T21:21:53.979+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[2025-05-08T21:21:53.979+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)
[2025-05-08T21:21:53.979+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1839)
[2025-05-08T21:21:53.979+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2635)
[2025-05-08T21:21:53.980+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
[2025-05-08T21:21:53.980+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
[2025-05-08T21:21:53.980+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
[2025-05-08T21:21:53.980+0000] {spark_submit.py:571} INFO - Traceback (most recent call last):
[2025-05-08T21:21:53.980+0000] {spark_submit.py:571} INFO - File "/opt/airflow/spark/build_graph.py", line 229, in main
[2025-05-08T21:21:53.980+0000] {spark_submit.py:571} INFO - top_node_ids = top_nodes.select("id").collect()
[2025-05-08T21:21:53.980+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 693, in collect
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - sock_info = self._jdf.collectToPython()
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - return_value = get_return_value(
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - return f(*a, **kw)
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py", line 326, in get_return_value
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - raise Py4JJavaError(
[2025-05-08T21:21:53.981+0000] {spark_submit.py:571} INFO - py4j.protocol.Py4JJavaError: An error occurred while calling o364.collectToPython.
[2025-05-08T21:21:53.982+0000] {spark_submit.py:571} INFO - : org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) has failed the maximum allowable number of times: 4. Most recent failure reason:
[2025-05-08T21:21:53.982+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 116 partition 5
[2025-05-08T21:21:53.982+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:53.982+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:53.982+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.982+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:53.982+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:53.983+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.984+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.985+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:53.986+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:53.987+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:53.987+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:53.987+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:53.987+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:53.987+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:53.987+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:53.987+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:53.988+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:53.988+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:53.988+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:53.988+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:53.988+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
[2025-05-08T21:21:53.988+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)
[2025-05-08T21:21:53.989+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)
[2025-05-08T21:21:53.989+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[2025-05-08T21:21:53.989+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[2025-05-08T21:21:53.989+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[2025-05-08T21:21:53.989+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)
[2025-05-08T21:21:53.989+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1839)
[2025-05-08T21:21:53.989+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2635)
[2025-05-08T21:21:53.990+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
[2025-05-08T21:21:53.990+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
[2025-05-08T21:21:53.990+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
[2025-05-08T21:21:53.990+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:54.014+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO SparkUI: Stopped Spark web UI at http://f2a432e4376a:4040
[2025-05-08T21:21:54.018+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-05-08T21:21:54.018+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
[2025-05-08T21:21:54.038+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-08T21:21:54.115+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO MemoryStore: MemoryStore cleared
[2025-05-08T21:21:54.115+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO BlockManager: BlockManager stopped
[2025-05-08T21:21:54.118+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-08T21:21:54.121+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-08T21:21:54.129+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:54 INFO SparkContext: Successfully stopped SparkContext
[2025-05-08T21:21:54.641+0000] {spark_submit.py:571} INFO - 2025-05-08 21:21:54,641 [INFO] SparkSession остановлена
[2025-05-08T21:21:54.646+0000] {spark_submit.py:571} INFO - Traceback (most recent call last):
[2025-05-08T21:21:54.646+0000] {spark_submit.py:571} INFO - File "/opt/airflow/spark/build_graph.py", line 315, in <module>
[2025-05-08T21:21:54.650+0000] {spark_submit.py:571} INFO - main()
[2025-05-08T21:21:54.650+0000] {spark_submit.py:571} INFO - File "/opt/airflow/spark/build_graph.py", line 229, in main
[2025-05-08T21:21:54.650+0000] {spark_submit.py:571} INFO - top_node_ids = top_nodes.select("id").collect()
[2025-05-08T21:21:54.650+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 693, in collect
[2025-05-08T21:21:54.651+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
[2025-05-08T21:21:54.652+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
[2025-05-08T21:21:54.652+0000] {spark_submit.py:571} INFO - File "/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py", line 326, in get_return_value
[2025-05-08T21:21:54.652+0000] {spark_submit.py:571} INFO - py4j.protocol.Py4JJavaError: An error occurred while calling o364.collectToPython.
[2025-05-08T21:21:54.652+0000] {spark_submit.py:571} INFO - : org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1336 (collect at /opt/airflow/spark/build_graph.py:229) has failed the maximum allowable number of times: 4. Most recent failure reason:
[2025-05-08T21:21:54.652+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 116 partition 5
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.653+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-08T21:21:54.654+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1839)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2635)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
[2025-05-08T21:21:54.655+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
[2025-05-08T21:21:54.656+0000] {spark_submit.py:571} INFO - 
[2025-05-08T21:21:55.322+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:55 INFO ShutdownHookManager: Shutdown hook called
[2025-05-08T21:21:55.323+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-b365f90a-d489-4d1d-b661-04514a948913/pyspark-4d564a5e-9ed9-42df-b03e-4a94c0c55f45
[2025-05-08T21:21:55.325+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-11b82628-f280-4ea5-b32d-9305b2a06d51
[2025-05-08T21:21:55.327+0000] {spark_submit.py:571} INFO - 25/05/08 21:21:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-b365f90a-d489-4d1d-b661-04514a948913
[2025-05-08T21:21:55.587+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 174, in execute
    self._hook.submit(self.application)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 502, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******. Error code is: 1.
[2025-05-08T21:21:55.610+0000] {taskinstance.py:1345} INFO - Marking task as FAILED. dag_id=graph_analysis, task_id=build_graph, execution_date=20250508T193913, start_date=20250508T193921, end_date=20250508T212155
[2025-05-08T21:21:55.710+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 356 for task build_graph (Cannot execute: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******. Error code is: 1.; 13016)
[2025-05-08T21:21:55.727+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2025-05-08T21:21:55.778+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
