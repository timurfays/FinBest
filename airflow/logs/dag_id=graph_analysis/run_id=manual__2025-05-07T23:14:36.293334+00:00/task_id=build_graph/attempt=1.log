[2025-05-07T23:14:45.029+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T23:14:36.293334+00:00 [queued]>
[2025-05-07T23:14:45.034+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: graph_analysis.build_graph manual__2025-05-07T23:14:36.293334+00:00 [queued]>
[2025-05-07T23:14:45.034+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 2
[2025-05-07T23:14:45.044+0000] {taskinstance.py:1327} INFO - Executing <Task(SparkSubmitOperator): build_graph> on 2025-05-07 23:14:36.293334+00:00
[2025-05-07T23:14:45.048+0000] {standard_task_runner.py:57} INFO - Started process 13052 to run task
[2025-05-07T23:14:45.050+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'graph_analysis', 'build_graph', 'manual__2025-05-07T23:14:36.293334+00:00', '--job-id', '293', '--raw', '--subdir', 'DAGS_FOLDER/graph_analysis.py', '--cfg-path', '/tmp/tmphum_kubs']
[2025-05-07T23:14:45.051+0000] {standard_task_runner.py:85} INFO - Job 293: Subtask build_graph
[2025-05-07T23:14:45.064+0000] {logging_mixin.py:150} WARNING - /home/airflow/.local/lib/python3.8/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-05-07T23:14:45.091+0000] {task_command.py:410} INFO - Running <TaskInstance: graph_analysis.build_graph manual__2025-05-07T23:14:36.293334+00:00 [running]> on host 3530b0b864fd
[2025-05-07T23:14:45.157+0000] {taskinstance.py:1545} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='finbest' AIRFLOW_CTX_DAG_ID='graph_analysis' AIRFLOW_CTX_TASK_ID='build_graph' AIRFLOW_CTX_EXECUTION_DATE='2025-05-07T23:14:36.293334+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-07T23:14:36.293334+00:00'
[2025-05-07T23:14:45.165+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2025-05-07T23:14:45.165+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.driver.maxResultSize=512m --conf spark.sql.shuffle.partitions=10 --packages org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark --verbose /opt/airflow/spark/build_graph.py --jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ******
[2025-05-07T23:14:45.183+0000] {spark_submit.py:571} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2025-05-07T23:14:46.206+0000] {spark_submit.py:571} INFO - Using properties file: null
[2025-05-07T23:14:46.279+0000] {spark_submit.py:571} INFO - WARNING: An illegal reflective access operation has occurred
[2025-05-07T23:14:46.279+0000] {spark_submit.py:571} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2025-05-07T23:14:46.280+0000] {spark_submit.py:571} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2025-05-07T23:14:46.280+0000] {spark_submit.py:571} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-05-07T23:14:46.280+0000] {spark_submit.py:571} INFO - WARNING: All illegal access operations will be denied in a future release
[2025-05-07T23:14:46.314+0000] {spark_submit.py:571} INFO - Parsed arguments:
[2025-05-07T23:14:46.314+0000] {spark_submit.py:571} INFO - master                  spark://spark-master:7077
[2025-05-07T23:14:46.314+0000] {spark_submit.py:571} INFO - deployMode              null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - executorMemory          1g
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - executorCores           1
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - totalExecutorCores      null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - propertiesFile          null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - driverMemory            1g
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - driverCores             null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - driverExtraClassPath    null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - driverExtraLibraryPath  null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - driverExtraJavaOptions  null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - supervise               false
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - queue                   null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - numExecutors            null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - files                   null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - pyFiles                 null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - archives                null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - mainClass               null
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - primaryResource         file:/opt/airflow/spark/build_graph.py
[2025-05-07T23:14:46.315+0000] {spark_submit.py:571} INFO - name                    arrow-spark
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - childArgs               [--jdbc jdbc:postgresql://postgres:5432/finbest --user finbest --password ***]
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - jars                    null
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - packages                org.postgresql:postgresql:42.6.0,graphframes:graphframes:0.8.2-spark3.2-s_2.12
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - packagesExclusions      null
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - repositories            null
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - verbose                 true
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - Spark properties used, including those specified through
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - --conf and those from the properties file null:
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:14:46.316+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:14:46.420+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-07T23:14:46.500+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-05-07T23:14:46.500+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-05-07T23:14:46.505+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql added as a dependency
[2025-05-07T23:14:46.506+0000] {spark_submit.py:571} INFO - graphframes#graphframes added as a dependency
[2025-05-07T23:14:46.506+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-3c708d30-0bca-4d3f-beb6-3e7bb27d5eb2;1.0
[2025-05-07T23:14:46.506+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T23:14:46.607+0000] {spark_submit.py:571} INFO - found org.postgresql#postgresql;42.6.0 in central
[2025-05-07T23:14:46.630+0000] {spark_submit.py:571} INFO - found org.checkerframework#checker-qual;3.31.0 in central
[2025-05-07T23:14:46.651+0000] {spark_submit.py:571} INFO - found graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages
[2025-05-07T23:14:46.668+0000] {spark_submit.py:571} INFO - found org.slf4j#slf4j-api;1.7.16 in central
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 173ms :: artifacts dl 6ms
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - graphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - org.checkerframework#checker-qual;3.31.0 from central in [default]
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - org.postgresql#postgresql;42.6.0 from central in [default]
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - org.slf4j#slf4j-api;1.7.16 from central in [default]
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T23:14:46.686+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-05-07T23:14:46.687+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-07T23:14:46.687+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T23:14:46.687+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-05-07T23:14:46.687+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-05-07T23:14:46.692+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-3c708d30-0bca-4d3f-beb6-3e7bb27d5eb2
[2025-05-07T23:14:46.692+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-05-07T23:14:46.697+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/6ms)
[2025-05-07T23:14:46.897+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-07T23:14:47.092+0000] {spark_submit.py:571} INFO - Main class:
[2025-05-07T23:14:47.093+0000] {spark_submit.py:571} INFO - org.apache.spark.deploy.PythonRunner
[2025-05-07T23:14:47.093+0000] {spark_submit.py:571} INFO - Arguments:
[2025-05-07T23:14:47.093+0000] {spark_submit.py:571} INFO - file:/opt/airflow/spark/build_graph.py
[2025-05-07T23:14:47.093+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T23:14:47.093+0000] {spark_submit.py:571} INFO - --jdbc
[2025-05-07T23:14:47.093+0000] {spark_submit.py:571} INFO - jdbc:postgresql://postgres:5432/finbest
[2025-05-07T23:14:47.093+0000] {spark_submit.py:571} INFO - --user
[2025-05-07T23:14:47.094+0000] {spark_submit.py:571} INFO - finbest
[2025-05-07T23:14:47.094+0000] {spark_submit.py:571} INFO - --password
[2025-05-07T23:14:47.094+0000] {spark_submit.py:571} INFO - ***
[2025-05-07T23:14:47.095+0000] {spark_submit.py:571} INFO - Spark config:
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.driver.maxResultSize,512m)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.app.name,arrow-spark)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.driver.memory,1g)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.submit.pyFiles,/home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,/home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,/home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,/home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.files,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.submit.deployMode,client)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.master,spark://spark-master:7077)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.executor.memory,1g)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.executor.cores,1)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.repl.local.jars,file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar,file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar,file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar,file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - (spark.sql.shuffle.partitions,10)
[2025-05-07T23:14:47.096+0000] {spark_submit.py:571} INFO - Classpath elements:
[2025-05-07T23:14:47.097+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T23:14:47.097+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T23:14:47.097+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T23:14:47.097+0000] {spark_submit.py:571} INFO - file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T23:14:47.097+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:14:47.097+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:14:48.592+0000] {spark_submit.py:571} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2025-05-07T23:14:48.597+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SparkContext: Running Spark version 3.2.4
[2025-05-07T23:14:48.613+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO ResourceUtils: ==============================================================
[2025-05-07T23:14:48.613+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-07T23:14:48.613+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO ResourceUtils: ==============================================================
[2025-05-07T23:14:48.614+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SparkContext: Submitted application: FinBestGraphAnalysis
[2025-05-07T23:14:48.632+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-07T23:14:48.644+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-05-07T23:14:48.645+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-07T23:14:48.695+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SecurityManager: Changing view acls to: airflow
[2025-05-07T23:14:48.695+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SecurityManager: Changing modify acls to: airflow
[2025-05-07T23:14:48.695+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SecurityManager: Changing view acls groups to:
[2025-05-07T23:14:48.695+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SecurityManager: Changing modify acls groups to:
[2025-05-07T23:14:48.696+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(airflow); groups with view permissions: Set(); users  with modify permissions: Set(airflow); groups with modify permissions: Set()
[2025-05-07T23:14:48.931+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO Utils: Successfully started service 'sparkDriver' on port 45999.
[2025-05-07T23:14:48.955+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SparkEnv: Registering MapOutputTracker
[2025-05-07T23:14:48.983+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-07T23:14:48.999+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-07T23:14:49.000+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-07T23:14:49.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-07T23:14:49.031+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eacb8362-c4e3-49ff-956a-61ac067fa1f3
[2025-05-07T23:14:49.051+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-07T23:14:49.071+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-07T23:14:49.249+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-07T23:14:49.294+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://3530b0b864fd:4040
[2025-05-07T23:14:49.304+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://3530b0b864fd:45999/jars/org.postgresql_postgresql-42.6.0.jar with timestamp 1746659688590
[2025-05-07T23:14:49.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://3530b0b864fd:45999/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746659688590
[2025-05-07T23:14:49.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://3530b0b864fd:45999/jars/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746659688590
[2025-05-07T23:14:49.307+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://3530b0b864fd:45999/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746659688590
[2025-05-07T23:14:49.307+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar at spark://3530b0b864fd:45999/files/org.postgresql_postgresql-42.6.0.jar with timestamp 1746659688590
[2025-05-07T23:14:49.308+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO Utils: Copying /home/airflow/.ivy2/jars/org.postgresql_postgresql-42.6.0.jar to /tmp/spark-dc1459ef-c206-4ef2-a28e-3e1547da29b4/userFiles-87ee4934-a04d-4c3e-9d3a-31cd9d13f4d5/org.postgresql_postgresql-42.6.0.jar
[2025-05-07T23:14:49.318+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar at spark://3530b0b864fd:45999/files/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar with timestamp 1746659688590
[2025-05-07T23:14:49.318+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO Utils: Copying /home/airflow/.ivy2/jars/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar to /tmp/spark-dc1459ef-c206-4ef2-a28e-3e1547da29b4/userFiles-87ee4934-a04d-4c3e-9d3a-31cd9d13f4d5/graphframes_graphframes-0.8.2-spark3.2-s_2.12.jar
[2025-05-07T23:14:49.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar at spark://3530b0b864fd:45999/files/org.checkerframework_checker-qual-3.31.0.jar with timestamp 1746659688590
[2025-05-07T23:14:49.324+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO Utils: Copying /home/airflow/.ivy2/jars/org.checkerframework_checker-qual-3.31.0.jar to /tmp/spark-dc1459ef-c206-4ef2-a28e-3e1547da29b4/userFiles-87ee4934-a04d-4c3e-9d3a-31cd9d13f4d5/org.checkerframework_checker-qual-3.31.0.jar
[2025-05-07T23:14:49.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://3530b0b864fd:45999/files/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1746659688590
[2025-05-07T23:14:49.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO Utils: Copying /home/airflow/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-dc1459ef-c206-4ef2-a28e-3e1547da29b4/userFiles-87ee4934-a04d-4c3e-9d3a-31cd9d13f4d5/org.slf4j_slf4j-api-1.7.16.jar
[2025-05-07T23:14:49.471+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-05-07T23:14:49.506+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO TransportClientFactory: Successfully created connection to spark-master/172.20.0.2:7077 after 22 ms (0 ms spent in bootstraps)
[2025-05-07T23:14:49.853+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250507231449-0007
[2025-05-07T23:14:49.859+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41807.
[2025-05-07T23:14:49.860+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO NettyBlockTransferService: Server created on 3530b0b864fd:41807
[2025-05-07T23:14:49.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-07T23:14:49.866+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3530b0b864fd, 41807, None)
[2025-05-07T23:14:49.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO BlockManagerMasterEndpoint: Registering block manager 3530b0b864fd:41807 with 434.4 MiB RAM, BlockManagerId(driver, 3530b0b864fd, 41807, None)
[2025-05-07T23:14:49.870+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3530b0b864fd, 41807, None)
[2025-05-07T23:14:49.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3530b0b864fd, 41807, None)
[2025-05-07T23:14:49.882+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507231449-0007/0 on worker-20250507121535-172.20.0.5-41865 (172.20.0.5:41865) with 1 core(s)
[2025-05-07T23:14:49.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507231449-0007/0 on hostPort 172.20.0.5:41865 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T23:14:50.012+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:50 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-05-07T23:14:50.150+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-07T23:14:50.151+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:50 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-05-07T23:14:50.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:50 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507231449-0007/0 is now RUNNING
[2025-05-07T23:14:50.833+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:50,833 [INFO] SparkSession создана
[2025-05-07T23:14:50.833+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:50,833 [INFO] Загружаем клиентов и транзакции
[2025-05-07T23:14:53.064+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:34280) with ID 0,  ResourceProfileId 0
[2025-05-07T23:14:53.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:40511 with 434.4 MiB RAM, BlockManagerId(0, 172.20.0.5, 40511, None)
[2025-05-07T23:14:53.814+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO CodeGenerator: Code generated in 111.080216 ms
[2025-05-07T23:14:53.860+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO DAGScheduler: Registering RDD 2 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-05-07T23:14:53.864+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T23:14:53.864+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T23:14:53.864+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:53.865+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:53.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T23:14:53.986+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T23:14:54.017+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.4 MiB)
[2025-05-07T23:14:54.020+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3530b0b864fd:41807 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:54.024+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:54.037+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:54.039+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-07T23:14:54.067+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:54.286+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.20.0.5:40511 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.252+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1193 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:14:55.254+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-07T23:14:55.262+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.385 s
[2025-05-07T23:14:55.262+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:14:55.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: running: Set()
[2025-05-07T23:14:55.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:14:55.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: failed: Set()
[2025-05-07T23:14:55.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO CodeGenerator: Code generated in 8.007562 ms
[2025-05-07T23:14:55.339+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T23:14:55.342+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T23:14:55.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T23:14:55.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-05-07T23:14:55.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:55.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T23:14:55.352+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-07T23:14:55.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-07T23:14:55.354+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3530b0b864fd:41807 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.354+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:55.357+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:55.358+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-07T23:14:55.363+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:55.386+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.20.0.5:40511 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.454+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.20.0.5:34280
[2025-05-07T23:14:55.548+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 186 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:14:55.548+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-07T23:14:55.549+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.200 s
[2025-05-07T23:14:55.550+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:14:55.551+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-07T23:14:55.552+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.212852 s
[2025-05-07T23:14:55.604+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Registering RDD 8 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-05-07T23:14:55.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T23:14:55.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T23:14:55.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:55.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:55.607+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T23:14:55.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.9 KiB, free 434.4 MiB)
[2025-05-07T23:14:55.620+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.3 MiB)
[2025-05-07T23:14:55.621+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3530b0b864fd:41807 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.625+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:55.625+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:55.626+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-05-07T23:14:55.626+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:55.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 3530b0b864fd:41807 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.664+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.20.0.5:40511 (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.665+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.20.0.5:40511 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.678+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 3530b0b864fd:41807 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.680+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.20.0.5:40511 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.703+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 77 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:14:55.703+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-07T23:14:55.704+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.096 s
[2025-05-07T23:14:55.704+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:14:55.704+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: running: Set()
[2025-05-07T23:14:55.705+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:14:55.705+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: failed: Set()
[2025-05-07T23:14:55.730+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-05-07T23:14:55.731+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-05-07T23:14:55.732+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
[2025-05-07T23:14:55.732+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-07T23:14:55.732+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:55.733+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-05-07T23:14:55.734+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-05-07T23:14:55.745+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
[2025-05-07T23:14:55.746+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3530b0b864fd:41807 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:55.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 3530b0b864fd:41807 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:55.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-07T23:14:55.749+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:55.753+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.20.0.5:40511 in memory (size: 6.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.20.0.5:40511 (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:55.784+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.20.0.5:34280
[2025-05-07T23:14:55.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 47 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:14:55.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-07T23:14:55.797+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.063 s
[2025-05-07T23:14:55.797+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:14:55.797+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-07T23:14:55.798+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:55 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.066855 s
[2025-05-07T23:14:55.799+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:55,799 [INFO] Загружено 4652 транзакций и 1200 клиентов
[2025-05-07T23:14:55.948+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:55,948 [INFO] Создаем вершины двудольного графа
[2025-05-07T23:14:56.294+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:56,293 [INFO] Создаем ATM-хабы
[2025-05-07T23:14:56.380+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 3530b0b864fd:41807 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:56.382+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.20.0.5:40511 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2025-05-07T23:14:56.510+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:56,510 [INFO] Объединяем ребра двудольного графа
[2025-05-07T23:14:56.620+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:56,620 [INFO] Создаем P2P-слой
[2025-05-07T23:14:56.670+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:56,670 [INFO] Создаем проекцию клиент-клиент
[2025-05-07T23:14:57.311+0000] {spark_submit.py:571} INFO - 2025-05-07 23:14:57,311 [INFO] Вычисляем метрики графа
[2025-05-07T23:14:57.671+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO CodeGenerator: Code generated in 17.94651 ms
[2025-05-07T23:14:57.676+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: Registering RDD 15 (rdd at GraphFrame.scala:187) as input to shuffle 2
[2025-05-07T23:14:57.676+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: Got map stage job 4 (rdd at GraphFrame.scala:187) with 1 output partitions
[2025-05-07T23:14:57.677+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (rdd at GraphFrame.scala:187)
[2025-05-07T23:14:57.677+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:57.677+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:57.677+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T23:14:57.691+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
[2025-05-07T23:14:57.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.4 MiB)
[2025-05-07T23:14:57.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3530b0b864fd:41807 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T23:14:57.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:57.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[15] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:57.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-05-07T23:14:57.702+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:57.719+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.20.0.5:40511 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T23:14:57.966+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 263 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:14:57.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-07T23:14:57.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: ShuffleMapStage 6 (rdd at GraphFrame.scala:187) finished in 0.287 s
[2025-05-07T23:14:57.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:14:57.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: running: Set()
[2025-05-07T23:14:57.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:14:57.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO DAGScheduler: failed: Set()
[2025-05-07T23:14:57.997+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:57 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:14:58.024+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:14:58.025+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T23:14:58.026+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:14:58.026+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-07T23:14:58.026+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:58.026+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:14:58.029+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.2 KiB, free 434.4 MiB)
[2025-05-07T23:14:58.037+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 434.4 MiB)
[2025-05-07T23:14:58.038+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:58.038+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 3530b0b864fd:41807 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T23:14:58.041+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:58.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:58.043+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-07T23:14:58.044+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:58.045+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.20.0.5:40511 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-07T23:14:58.062+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.20.0.5:40511 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:58.073+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.20.0.5:34280
[2025-05-07T23:14:58.087+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 44 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:14:58.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-07T23:14:58.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.059 s
[2025-05-07T23:14:58.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:14:58.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-07T23:14:58.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.063893 s
[2025-05-07T23:14:58.113+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 8.013841 ms
[2025-05-07T23:14:58.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 3530b0b864fd:41807 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:58.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.20.0.5:40511 in memory (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:58.137+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.1 MiB, free 432.3 MiB)
[2025-05-07T23:14:58.144+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 28.8 KiB, free 432.3 MiB)
[2025-05-07T23:14:58.145+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3530b0b864fd:41807 (size: 28.8 KiB, free: 434.4 MiB)
[2025-05-07T23:14:58.145+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:14:58.182+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 11.360408 ms
[2025-05-07T23:14:58.186+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:58.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:58.222+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 26.808869 ms
[2025-05-07T23:14:58.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 5.095885 ms
[2025-05-07T23:14:58.268+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#995 - id.nullCount#994) > 0)
[2025-05-07T23:14:58.789+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 4.998345 ms
[2025-05-07T23:14:58.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 4.959584 ms
[2025-05-07T23:14:58.803+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 4.997834 ms
[2025-05-07T23:14:58.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 8.684833 ms
[2025-05-07T23:14:58.827+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:58 INFO CodeGenerator: Code generated in 4.931019 ms
[2025-05-07T23:14:59.036+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 9.231781 ms
[2025-05-07T23:14:59.054+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 9.360603 ms
[2025-05-07T23:14:59.071+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 9.428018 ms
[2025-05-07T23:14:59.085+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 8.274726 ms
[2025-05-07T23:14:59.100+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 9.194806 ms
[2025-05-07T23:14:59.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 23.411929 ms
[2025-05-07T23:14:59.167+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 60 (collect at GraphFrame.scala:574) as input to shuffle 4
[2025-05-07T23:14:59.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 6 (collect at GraphFrame.scala:574) with 6 output partitions
[2025-05-07T23:14:59.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.169+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.179+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 11.25299 ms
[2025-05-07T23:14:59.185+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:59.186+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 36.4 KiB, free 432.3 MiB)
[2025-05-07T23:14:59.194+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 432.3 MiB)
[2025-05-07T23:14:59.195+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3530b0b864fd:41807 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T23:14:59.195+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.196+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[60] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T23:14:59.196+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 9.0 with 6 tasks resource profile 0
[2025-05-07T23:14:59.197+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 62 (collect at GraphFrame.scala:574) as input to shuffle 5
[2025-05-07T23:14:59.197+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 7 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:14:59.198+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.198+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.198+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.200+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.201+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:59.206+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 12.6 KiB, free 432.3 MiB)
[2025-05-07T23:14:59.209+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 432.2 MiB)
[2025-05-07T23:14:59.211+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 3530b0b864fd:41807 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T23:14:59.214+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.218+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[62] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:59.218+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-05-07T23:14:59.218+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 22.280836 ms
[2025-05-07T23:14:59.228+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.20.0.5:40511 (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T23:14:59.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:59.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 64 (collect at GraphFrame.scala:574) as input to shuffle 6
[2025-05-07T23:14:59.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 8 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:14:59.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.252+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.261+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 27.3 KiB, free 432.2 MiB)
[2025-05-07T23:14:59.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.2 MiB)
[2025-05-07T23:14:59.264+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 3530b0b864fd:41807 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T23:14:59.266+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.267+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[64] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:59.267+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-05-07T23:14:59.269+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 35.341578 ms
[2025-05-07T23:14:59.284+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:59.284+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 66 (collect at GraphFrame.scala:574) as input to shuffle 7
[2025-05-07T23:14:59.285+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 9 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:14:59.285+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.285+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.286+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.300+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 28.5 KiB, free 432.2 MiB)
[2025-05-07T23:14:59.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 432.2 MiB)
[2025-05-07T23:14:59.331+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 3530b0b864fd:41807 (size: 13.5 KiB, free: 434.3 MiB)
[2025-05-07T23:14:59.332+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 40.067133 ms
[2025-05-07T23:14:59.332+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.333+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[66] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:59.333+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-05-07T23:14:59.336+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:59.340+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 68 (collect at GraphFrame.scala:574) as input to shuffle 8
[2025-05-07T23:14:59.346+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 10 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:14:59.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T23:14:59.356+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.1 MiB)
[2025-05-07T23:14:59.357+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 3530b0b864fd:41807 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T23:14:59.361+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.362+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:59.362+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-05-07T23:14:59.371+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 7) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:59.375+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 178 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T23:14:59.378+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 34.902962 ms
[2025-05-07T23:14:59.391+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:59.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 70 (collect at GraphFrame.scala:574) as input to shuffle 9
[2025-05-07T23:14:59.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 11 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:14:59.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.398+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.432+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 27.4 KiB, free 432.1 MiB)
[2025-05-07T23:14:59.433+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.1 MiB)
[2025-05-07T23:14:59.436+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 3530b0b864fd:41807 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T23:14:59.446+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.447+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[70] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:59.447+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2025-05-07T23:14:59.465+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 42.500949 ms
[2025-05-07T23:14:59.468+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 8) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:59.471+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 7) in 101 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T23:14:59.490+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:14:59.491+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 72 (collect at GraphFrame.scala:574) as input to shuffle 10
[2025-05-07T23:14:59.492+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 12 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:14:59.492+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.493+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.493+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.496+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.509+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 28.5 KiB, free 432.1 MiB)
[2025-05-07T23:14:59.564+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 432.0 MiB)
[2025-05-07T23:14:59.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 3530b0b864fd:41807 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T23:14:59.581+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.582+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[72] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:59.588+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-05-07T23:14:59.594+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 9) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:59.600+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 8) in 130 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T23:14:59.623+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO CodeGenerator: Code generated in 117.171012 ms
[2025-05-07T23:14:59.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Registering RDD 74 (collect at GraphFrame.scala:574) as input to shuffle 11
[2025-05-07T23:14:59.643+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Got map stage job 13 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:14:59.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (collect at GraphFrame.scala:574)
[2025-05-07T23:14:59.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:14:59.651+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:14:59.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:14:59.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 432.0 MiB)
[2025-05-07T23:14:59.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 432.0 MiB)
[2025-05-07T23:14:59.704+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 3530b0b864fd:41807 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T23:14:59.707+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:14:59.708+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[74] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:14:59.708+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-05-07T23:14:59.721+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 10) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:59.723+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 9) in 130 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T23:14:59.813+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 11) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:14:59.816+0000] {spark_submit.py:571} INFO - 25/05/07 23:14:59 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 10) in 95 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T23:15:00.398+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:00.398+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 11) in 590 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T23:15:00.399+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-05-07T23:15:00.400+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: ShuffleMapStage 9 (collect at GraphFrame.scala:574) finished in 1.230 s
[2025-05-07T23:15:00.401+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:00.401+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 10, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T23:15:00.401+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:00.401+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:00.415+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.20.0.5:40511 (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T23:15:00.428+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:15:00.430+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:15:00.478+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:00.482+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 79 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:00.483+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-05-07T23:15:00.491+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: ShuffleMapStage 10 (collect at GraphFrame.scala:574) finished in 1.283 s
[2025-05-07T23:15:00.494+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:00.495+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 14, ShuffleMapStage 11)
[2025-05-07T23:15:00.496+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:00.497+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:00.508+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:15:00.510+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T23:15:00.511+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:15:00.511+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-05-07T23:15:00.512+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:15:00.516+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:15:00.518+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:15:00.523+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T23:15:00.538+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.20.0.5:40511 (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T23:15:00.543+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T23:15:00.554+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T23:15:00.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:15:00.562+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.20.0.5:40511 in memory (size: 11.2 KiB, free: 434.4 MiB)
[2025-05-07T23:15:00.568+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 3530b0b864fd:41807 in memory (size: 11.2 KiB, free: 434.3 MiB)
[2025-05-07T23:15:00.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[77] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:15:00.570+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-05-07T23:15:00.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 3530b0b864fd:41807 in memory (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T23:15:00.618+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.20.0.5:40511 in memory (size: 6.7 KiB, free: 434.4 MiB)
[2025-05-07T23:15:00.715+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:15:00.717+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T23:15:00.718+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:15:00.719+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-05-07T23:15:00.719+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:15:00.734+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:15:00.736+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.2 KiB, free 432.0 MiB)
[2025-05-07T23:15:00.772+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 432.0 MiB)
[2025-05-07T23:15:00.777+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T23:15:00.778+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:15:00.778+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:15:00.778+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-05-07T23:15:00.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:00.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 398 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:00.874+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-05-07T23:15:00.881+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: ShuffleMapStage 11 (collect at GraphFrame.scala:574) finished in 1.624 s
[2025-05-07T23:15:00.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:00.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T23:15:00.884+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:00.884+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:00.901+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.20.0.5:40511 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T23:15:00.989+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:00.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 118 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:00.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-05-07T23:15:00.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: ShuffleMapStage 12 (collect at GraphFrame.scala:574) finished in 1.703 s
[2025-05-07T23:15:00.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:00.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ShuffleMapStage 13, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T23:15:00.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:00.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:00 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:01.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.20.0.5:40511 (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.058+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.059+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 70 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:01.059+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-05-07T23:15:01.060+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: ShuffleMapStage 13 (collect at GraphFrame.scala:574) finished in 1.714 s
[2025-05-07T23:15:01.060+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:01.060+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18, ShuffleMapStage 14)
[2025-05-07T23:15:01.060+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:01.061+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:01.077+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.20.0.5:40511 (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.127+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.127+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 69 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:01.127+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-05-07T23:15:01.128+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: ShuffleMapStage 14 (collect at GraphFrame.scala:574) finished in 1.716 s
[2025-05-07T23:15:01.128+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:01.129+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: running: Set(ShuffleMapStage 15, ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T23:15:01.129+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:01.129+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:01.145+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.20.0.5:40511 (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.192+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.193+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 67 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:01.193+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-05-07T23:15:01.193+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: ShuffleMapStage 15 (collect at GraphFrame.scala:574) finished in 1.697 s
[2025-05-07T23:15:01.194+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:01.194+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: running: Set(ShuffleMapStage 16, ResultStage 20, ResultStage 18)
[2025-05-07T23:15:01.194+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:01.194+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:01.211+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.20.0.5:40511 (size: 14.9 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.288+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.290+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 97 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:01.290+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-05-07T23:15:01.290+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: ShuffleMapStage 16 (collect at GraphFrame.scala:574) finished in 1.641 s
[2025-05-07T23:15:01.291+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:01.291+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: running: Set(ResultStage 20, ResultStage 18)
[2025-05-07T23:15:01.291+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:01.291+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:01.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO ShufflePartitionsUtil: For shuffle(6, 7, 8, 9, 10, 11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:15:01.310+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.20.0.5:40511 (size: 3.8 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.317+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.20.0.5:34280
[2025-05-07T23:15:01.331+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 3530b0b864fd:41807 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.350+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.20.0.5:40511 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.379+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.20.0.5:40511 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.382+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 3530b0b864fd:41807 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.405+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.408+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 120 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:01.409+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-05-07T23:15:01.410+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 3530b0b864fd:41807 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.411+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.892 s
[2025-05-07T23:15:01.411+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:15:01.411+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-05-07T23:15:01.412+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.905354 s
[2025-05-07T23:15:01.412+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 9.388034 ms
[2025-05-07T23:15:01.414+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:01.416+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.20.0.5:40511 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.430+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.20.0.5:40511 (size: 3.8 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.431+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 3530b0b864fd:41807 in memory (size: 13.0 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.433+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.20.0.5:40511 in memory (size: 13.0 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.434+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 17.112498 ms
[2025-05-07T23:15:01.438+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:34280
[2025-05-07T23:15:01.442+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 12.866866 ms
[2025-05-07T23:15:01.448+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 3530b0b864fd:41807 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.451+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 46 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:01.451+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-05-07T23:15:01.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.20.0.5:40511 in memory (size: 14.9 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.454+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.719 s
[2025-05-07T23:15:01.457+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:01.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:15:01.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2025-05-07T23:15:01.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.743328 s
[2025-05-07T23:15:01.465+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 3530b0b864fd:41807 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.467+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.20.0.5:40511 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 2.1 MiB, free 430.2 MiB)
[2025-05-07T23:15:01.471+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 430.2 MiB)
[2025-05-07T23:15:01.472+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 3530b0b864fd:41807 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T23:15:01.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:15:01.481+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 19.439005 ms
[2025-05-07T23:15:01.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:01.502+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 8.732132 ms
[2025-05-07T23:15:01.510+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:01.519+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 MiB, free 425.2 MiB)
[2025-05-07T23:15:01.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 8.957669 ms
[2025-05-07T23:15:01.528+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:01.541+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 10.338352 ms
[2025-05-07T23:15:01.547+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:01.548+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 424.7 MiB)
[2025-05-07T23:15:01.548+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 3530b0b864fd:41807 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-07T23:15:01.549+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO SparkContext: Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:15:01.562+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO CodeGenerator: Code generated in 13.585773 ms
[2025-05-07T23:15:01.579+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:15:01.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Got job 16 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T23:15:01.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Final stage: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:15:01.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24, ShuffleMapStage 21, ShuffleMapStage 25, ShuffleMapStage 22, ShuffleMapStage 26, ShuffleMapStage 23)
[2025-05-07T23:15:01.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:15:01.581+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[105] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:15:01.585+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 91.7 KiB, free 424.6 MiB)
[2025-05-07T23:15:01.586+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 424.6 MiB)
[2025-05-07T23:15:01.586+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 3530b0b864fd:41807 (size: 30.3 KiB, free: 433.8 MiB)
[2025-05-07T23:15:01.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:15:01.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 27 (MapPartitionsRDD[105] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T23:15:01.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Adding task set 27.0 with 6 tasks resource profile 0
[2025-05-07T23:15:01.589+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 21) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.599+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.20.0.5:40511 (size: 30.3 KiB, free: 434.4 MiB)
[2025-05-07T23:15:01.617+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.20.0.5:34280
[2025-05-07T23:15:01.640+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 22) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.641+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 21) in 52 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T23:15:01.651+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.20.0.5:34280
[2025-05-07T23:15:01.684+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 23) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.686+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 22) in 46 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T23:15:01.702+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.20.0.5:34280
[2025-05-07T23:15:01.724+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 24) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.727+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 23) in 43 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T23:15:01.740+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.20.0.5:34280
[2025-05-07T23:15:01.761+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 25) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.762+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 24) in 38 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T23:15:01.774+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.20.0.5:34280
[2025-05-07T23:15:01.816+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 26) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:01.820+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 25) in 58 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T23:15:01.835+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.20.0.5:34280
[2025-05-07T23:15:01.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 26) in 79 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T23:15:01.895+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-05-07T23:15:01.896+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: ResultStage 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.312 s
[2025-05-07T23:15:01.896+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:15:01.896+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-05-07T23:15:01.896+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO DAGScheduler: Job 16 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.317016 s
[2025-05-07T23:15:01.912+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.3 MiB, free 422.3 MiB)
[2025-05-07T23:15:01.916+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 422.2 MiB)
[2025-05-07T23:15:01.917+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 3530b0b864fd:41807 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T23:15:01.918+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:01 INFO SparkContext: Created broadcast 20 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:15:02.018+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO CodeGenerator: Code generated in 41.181893 ms
[2025-05-07T23:15:02.020+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:02.083+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO CodeGenerator: Code generated in 35.842401 ms
[2025-05-07T23:15:02.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO CodeGenerator: Code generated in 11.713358 ms
[2025-05-07T23:15:02.186+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO DAGScheduler: Registering RDD 112 (collect at GraphFrame.scala:574) as input to shuffle 12
[2025-05-07T23:15:02.186+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO DAGScheduler: Got map stage job 17 (collect at GraphFrame.scala:574) with 11 output partitions
[2025-05-07T23:15:02.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO DAGScheduler: Final stage: ShuffleMapStage 29 (collect at GraphFrame.scala:574)
[2025-05-07T23:15:02.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2025-05-07T23:15:02.188+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:15:02.190+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:15:02.199+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 141.0 KiB, free 422.1 MiB)
[2025-05-07T23:15:02.230+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 49.8 KiB, free 422.0 MiB)
[2025-05-07T23:15:02.233+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 3530b0b864fd:41807 (size: 49.8 KiB, free: 433.7 MiB)
[2025-05-07T23:15:02.234+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:15:02.235+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[112] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T23:15:02.235+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSchedulerImpl: Adding task set 29.0 with 11 tasks resource profile 0
[2025-05-07T23:15:02.236+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 27) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.293+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.20.0.5:40511 (size: 49.8 KiB, free: 434.3 MiB)
[2025-05-07T23:15:02.381+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.20.0.5:34280
[2025-05-07T23:15:02.442+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.20.0.5:40511 (size: 502.1 KiB, free: 433.8 MiB)
[2025-05-07T23:15:02.474+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.20.0.5:40511 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T23:15:02.511+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.20.0.5:40511 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T23:15:02.638+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 28) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.639+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 27) in 403 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T23:15:02.689+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 29) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.691+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 28) in 53 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T23:15:02.729+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 3.0 in stage 29.0 (TID 30) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.729+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 29) in 40 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T23:15:02.791+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 4.0 in stage 29.0 (TID 31) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.791+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Finished task 3.0 in stage 29.0 (TID 30) in 63 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T23:15:02.857+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 5.0 in stage 29.0 (TID 32) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.860+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Finished task 4.0 in stage 29.0 (TID 31) in 70 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T23:15:02.913+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 6.0 in stage 29.0 (TID 33) (172.20.0.5, executor 0, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.914+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Finished task 5.0 in stage 29.0 (TID 32) in 57 ms on 172.20.0.5 (executor 0) (6/11)
[2025-05-07T23:15:02.962+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Starting task 7.0 in stage 29.0 (TID 34) (172.20.0.5, executor 0, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:02.964+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:02 INFO TaskSetManager: Finished task 6.0 in stage 29.0 (TID 33) in 51 ms on 172.20.0.5 (executor 0) (7/11)
[2025-05-07T23:15:03.018+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Starting task 8.0 in stage 29.0 (TID 35) (172.20.0.5, executor 0, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:03.019+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Finished task 7.0 in stage 29.0 (TID 34) in 56 ms on 172.20.0.5 (executor 0) (8/11)
[2025-05-07T23:15:03.061+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Starting task 9.0 in stage 29.0 (TID 36) (172.20.0.5, executor 0, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:03.062+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Finished task 8.0 in stage 29.0 (TID 35) in 44 ms on 172.20.0.5 (executor 0) (9/11)
[2025-05-07T23:15:03.095+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Starting task 10.0 in stage 29.0 (TID 37) (172.20.0.5, executor 0, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:03.095+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Finished task 9.0 in stage 29.0 (TID 36) in 35 ms on 172.20.0.5 (executor 0) (10/11)
[2025-05-07T23:15:03.274+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Finished task 10.0 in stage 29.0 (TID 37) in 180 ms on 172.20.0.5 (executor 0) (11/11)
[2025-05-07T23:15:03.274+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-05-07T23:15:03.275+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: ShuffleMapStage 29 (collect at GraphFrame.scala:574) finished in 1.084 s
[2025-05-07T23:15:03.276+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:03.276+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: running: Set()
[2025-05-07T23:15:03.276+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:03.276+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:03.280+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:15:03.302+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:03.348+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO CodeGenerator: Code generated in 35.781542 ms
[2025-05-07T23:15:03.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Registering RDD 115 (collect at GraphFrame.scala:574) as input to shuffle 13
[2025-05-07T23:15:03.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Got map stage job 18 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:15:03.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (collect at GraphFrame.scala:574)
[2025-05-07T23:15:03.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-05-07T23:15:03.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:15:03.372+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[115] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:15:03.378+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 129.7 KiB, free 421.9 MiB)
[2025-05-07T23:15:03.383+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 44.4 KiB, free 421.9 MiB)
[2025-05-07T23:15:03.383+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 3530b0b864fd:41807 (size: 44.4 KiB, free: 433.6 MiB)
[2025-05-07T23:15:03.385+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:15:03.385+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[115] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:15:03.385+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-05-07T23:15:03.385+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 38) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:03.407+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.20.0.5:40511 (size: 44.4 KiB, free: 433.6 MiB)
[2025-05-07T23:15:03.451+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.20.0.5:34280
[2025-05-07T23:15:03.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 38) in 180 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:03.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-05-07T23:15:03.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: ShuffleMapStage 32 (collect at GraphFrame.scala:574) finished in 0.195 s
[2025-05-07T23:15:03.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:15:03.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: running: Set()
[2025-05-07T23:15:03.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:15:03.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: failed: Set()
[2025-05-07T23:15:03.575+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:15:03.607+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:15:03.651+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO CodeGenerator: Code generated in 37.771704 ms
[2025-05-07T23:15:03.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO SparkContext: Starting job: collect at GraphFrame.scala:574
[2025-05-07T23:15:03.698+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Got job 19 (collect at GraphFrame.scala:574) with 1 output partitions
[2025-05-07T23:15:03.698+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Final stage: ResultStage 36 (collect at GraphFrame.scala:574)
[2025-05-07T23:15:03.698+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-05-07T23:15:03.698+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:15:03.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[118] at collect at GraphFrame.scala:574), which has no missing parents
[2025-05-07T23:15:03.710+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 122.6 KiB, free 421.8 MiB)
[2025-05-07T23:15:03.774+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 41.9 KiB, free 421.7 MiB)
[2025-05-07T23:15:03.777+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 3530b0b864fd:41807 (size: 41.9 KiB, free: 433.6 MiB)
[2025-05-07T23:15:03.777+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:15:03.780+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[118] at collect at GraphFrame.scala:574) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:15:03.780+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-05-07T23:15:03.781+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:15:03.829+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.20.0.5:40511 (size: 41.9 KiB, free: 433.6 MiB)
[2025-05-07T23:15:03.843+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.20.0.5:34280
[2025-05-07T23:15:03.943+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 161 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:15:03.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-05-07T23:15:03.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: ResultStage 36 (collect at GraphFrame.scala:574) finished in 0.243 s
[2025-05-07T23:15:03.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:15:03.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-05-07T23:15:03.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:03 INFO DAGScheduler: Job 19 finished: collect at GraphFrame.scala:574, took 0.260064 s
[2025-05-07T23:15:04.023+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 3530b0b864fd:41807 in memory (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T23:15:06.457+0000] {spark_submit.py:571} INFO - 25/05/07 23:15:06 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.20.0.5:40511 in memory (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T23:16:03.661+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 3530b0b864fd:41807 in memory (size: 49.8 KiB, free: 433.6 MiB)
[2025-05-07T23:16:03.848+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.20.0.5:40511 in memory (size: 49.8 KiB, free: 433.7 MiB)
[2025-05-07T23:16:03.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.20.0.5:40511 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T23:16:03.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 3530b0b864fd:41807 in memory (size: 30.3 KiB, free: 433.7 MiB)
[2025-05-07T23:16:03.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 3530b0b864fd:41807 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T23:16:03.895+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.20.0.5:40511 in memory (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T23:16:03.919+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.20.0.5:40511 in memory (size: 41.9 KiB, free: 433.7 MiB)
[2025-05-07T23:16:03.921+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 3530b0b864fd:41807 in memory (size: 41.9 KiB, free: 433.7 MiB)
[2025-05-07T23:16:03.942+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 3530b0b864fd:41807 in memory (size: 44.4 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.020+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.20.0.5:40511 in memory (size: 44.4 KiB, free: 433.8 MiB)
[2025-05-07T23:16:04.020+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO DAGScheduler: Registering RDD 149 (rdd at GraphFrame.scala:188) as input to shuffle 14
[2025-05-07T23:16:04.020+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO DAGScheduler: Got map stage job 20 (rdd at GraphFrame.scala:188) with 6 output partitions
[2025-05-07T23:16:04.021+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.021+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.021+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.021+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.021+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:03 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 36.4 KiB, free 422.3 MiB)
[2025-05-07T23:16:04.063+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:04.110+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 422.3 MiB)
[2025-05-07T23:16:04.118+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 3530b0b864fd:41807 (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.119+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.119+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[149] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T23:16:04.119+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 37.0 with 6 tasks resource profile 0
[2025-05-07T23:16:04.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Registering RDD 151 (rdd at GraphFrame.scala:188) as input to shuffle 15
[2025-05-07T23:16:04.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got map stage job 21 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T23:16:04.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.131+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.135+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 12.6 KiB, free 422.3 MiB)
[2025-05-07T23:16:04.143+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:04.165+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 422.3 MiB)
[2025-05-07T23:16:04.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 3530b0b864fd:41807 (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.172+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:04.177+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.178+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.178+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.207+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Registering RDD 153 (rdd at GraphFrame.scala:188) as input to shuffle 16
[2025-05-07T23:16:04.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got map stage job 22 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T23:16:04.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.216+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:04.217+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.20.0.5:40511 (size: 11.2 KiB, free: 433.8 MiB)
[2025-05-07T23:16:04.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 27.3 KiB, free 422.3 MiB)
[2025-05-07T23:16:04.228+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:04.236+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.3 MiB)
[2025-05-07T23:16:04.238+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:04.239+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 3530b0b864fd:41807 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.239+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[153] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.241+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Registering RDD 155 (rdd at GraphFrame.scala:188) as input to shuffle 17
[2025-05-07T23:16:04.241+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got map stage job 23 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T23:16:04.241+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.242+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.242+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.242+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.250+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T23:16:04.254+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-07T23:16:04.256+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 3530b0b864fd:41807 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.257+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.258+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[155] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.258+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.259+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Registering RDD 157 (rdd at GraphFrame.scala:188) as input to shuffle 18
[2025-05-07T23:16:04.260+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got map stage job 24 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T23:16:04.260+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.260+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.260+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.262+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.266+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 28.5 KiB, free 422.2 MiB)
[2025-05-07T23:16:04.273+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 422.2 MiB)
[2025-05-07T23:16:04.275+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 3530b0b864fd:41807 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.276+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[157] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Registering RDD 159 (rdd at GraphFrame.scala:188) as input to shuffle 19
[2025-05-07T23:16:04.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got map stage job 25 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T23:16:04.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.279+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.282+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 27.4 KiB, free 422.2 MiB)
[2025-05-07T23:16:04.290+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 422.1 MiB)
[2025-05-07T23:16:04.291+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 3530b0b864fd:41807 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.297+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.298+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[159] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.298+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.299+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Registering RDD 161 (rdd at GraphFrame.scala:188) as input to shuffle 20
[2025-05-07T23:16:04.299+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got map stage job 26 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T23:16:04.299+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.303+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.304+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.307+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.307+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 28.5 KiB, free 422.1 MiB)
[2025-05-07T23:16:04.311+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 422.1 MiB)
[2025-05-07T23:16:04.312+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 3530b0b864fd:41807 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.314+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.317+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[161] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.317+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.317+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Registering RDD 163 (rdd at GraphFrame.scala:188) as input to shuffle 21
[2025-05-07T23:16:04.318+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got map stage job 27 (rdd at GraphFrame.scala:188) with 1 output partitions
[2025-05-07T23:16:04.318+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ShuffleMapStage 44 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:04.319+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:16:04.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[163] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:04.322+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 31.7 KiB, free 422.1 MiB)
[2025-05-07T23:16:04.324+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 422.1 MiB)
[2025-05-07T23:16:04.328+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 3530b0b864fd:41807 (size: 14.9 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.330+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.330+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[163] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.330+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.331+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 41) (172.20.0.5, executor 0, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.334+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 215 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T23:16:04.409+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 42) (172.20.0.5, executor 0, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.410+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 41) in 81 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T23:16:04.470+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 43) (172.20.0.5, executor 0, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.472+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 42) in 61 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T23:16:04.540+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 44) (172.20.0.5, executor 0, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.541+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 43) in 72 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T23:16:04.623+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 45) (172.20.0.5, executor 0, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.630+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 44) in 89 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T23:16:04.734+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 46) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.736+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 45) in 115 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T23:16:04.737+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: ShuffleMapStage 37 (rdd at GraphFrame.scala:188) finished in 0.742 s
[2025-05-07T23:16:04.737+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:04.737+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: running: Set(ShuffleMapStage 38, ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T23:16:04.738+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:04.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:04.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-05-07T23:16:04.757+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.20.0.5:40511 (size: 6.7 KiB, free: 433.8 MiB)
[2025-05-07T23:16:04.781+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:16:04.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:16:04.794+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 47) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.795+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 46) in 60 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:04.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-05-07T23:16:04.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: ShuffleMapStage 38 (rdd at GraphFrame.scala:188) finished in 0.661 s
[2025-05-07T23:16:04.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:04.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ShuffleMapStage 39, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T23:16:04.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:04.796+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:04.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:16:04.807+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T23:16:04.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:16:04.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-05-07T23:16:04.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.809+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[166] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:16:04.812+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.2 KiB, free 422.1 MiB)
[2025-05-07T23:16:04.812+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.9 KiB, free 422.1 MiB)
[2025-05-07T23:16:04.815+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 3530b0b864fd:41807 (size: 3.9 KiB, free: 433.6 MiB)
[2025-05-07T23:16:04.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.822+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[166] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.822+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.822+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.20.0.5:40511 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.856+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:16:04.857+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:16:04.858+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:16:04.866+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 48) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.870+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 47) in 76 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:04.871+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-05-07T23:16:04.871+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: ShuffleMapStage 39 (rdd at GraphFrame.scala:188) finished in 0.654 s
[2025-05-07T23:16:04.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:04.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: running: Set(ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 40, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T23:16:04.875+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:04.877+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:04.877+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:16:04.877+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T23:16:04.878+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Final stage: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:16:04.878+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-05-07T23:16:04.878+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:04.879+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[170] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:16:04.879+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.2 KiB, free 422.0 MiB)
[2025-05-07T23:16:04.882+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 422.0 MiB)
[2025-05-07T23:16:04.888+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T23:16:04.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:04.896+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[170] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:16:04.897+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-05-07T23:16:04.903+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.20.0.5:40511 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.931+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 49) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.932+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 48) in 66 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:04.932+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-05-07T23:16:04.933+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: ShuffleMapStage 40 (rdd at GraphFrame.scala:188) finished in 0.690 s
[2025-05-07T23:16:04.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:04.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 41)
[2025-05-07T23:16:04.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:04.935+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:04.950+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.20.0.5:40511 (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T23:16:04.991+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 50) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:04.992+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 49) in 62 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:04.993+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:04 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-05-07T23:16:05.003+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: ShuffleMapStage 41 (rdd at GraphFrame.scala:188) finished in 0.735 s
[2025-05-07T23:16:05.004+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:05.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T23:16:05.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:05.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:05.025+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.20.0.5:40511 (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.063+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 51) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.063+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 50) in 73 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:05.064+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: ShuffleMapStage 42 (rdd at GraphFrame.scala:188) finished in 0.784 s
[2025-05-07T23:16:05.064+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:05.064+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 43, ShuffleMapStage 44)
[2025-05-07T23:16:05.064+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:05.064+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:05.064+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-05-07T23:16:05.078+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.20.0.5:40511 (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.132+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 52) (172.20.0.5, executor 0, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.133+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 51) in 70 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:05.133+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-05-07T23:16:05.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: ShuffleMapStage 43 (rdd at GraphFrame.scala:188) finished in 0.833 s
[2025-05-07T23:16:05.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:05.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46, ShuffleMapStage 44)
[2025-05-07T23:16:05.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:05.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:05.151+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.20.0.5:40511 (size: 14.9 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.198+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 53) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.199+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 52) in 69 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:05.199+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-05-07T23:16:05.200+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: ShuffleMapStage 44 (rdd at GraphFrame.scala:188) finished in 0.881 s
[2025-05-07T23:16:05.200+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:16:05.200+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: running: Set(ResultStage 48, ResultStage 46)
[2025-05-07T23:16:05.201+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:16:05.201+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: failed: Set()
[2025-05-07T23:16:05.217+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.20.0.5:40511 (size: 3.9 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.223+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.20.0.5:34280
[2025-05-07T23:16:05.223+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO ShufflePartitionsUtil: For shuffle(16, 17, 18, 19, 20, 21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:16:05.265+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 14.159027 ms
[2025-05-07T23:16:05.265+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:05.275+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.276+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 53) in 78 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:05.278+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-05-07T23:16:05.279+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.467 s
[2025-05-07T23:16:05.279+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:16:05.279+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2025-05-07T23:16:05.280+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 10.768841 ms
[2025-05-07T23:16:05.280+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.471602 s
[2025-05-07T23:16:05.290+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:05.294+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.20.0.5:40511 (size: 3.8 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.301+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:34280
[2025-05-07T23:16:05.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 12.031183 ms
[2025-05-07T23:16:05.311+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 5.0 MiB, free 417.0 MiB)
[2025-05-07T23:16:05.311+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:05.341+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:05.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 3530b0b864fd:41807 in memory (size: 3.9 KiB, free: 433.6 MiB)
[2025-05-07T23:16:05.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 54) in 70 ms on 172.20.0.5 (executor 0) (1/1)
[2025-05-07T23:16:05.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-05-07T23:16:05.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: ResultStage 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.467 s
[2025-05-07T23:16:05.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:16:05.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-05-07T23:16:05.347+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.472422 s
[2025-05-07T23:16:05.352+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 2.1 MiB, free 415.0 MiB)
[2025-05-07T23:16:05.354+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 20.6 KiB, free 415.0 MiB)
[2025-05-07T23:16:05.356+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 11.955631 ms
[2025-05-07T23:16:05.357+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 3530b0b864fd:41807 (size: 20.6 KiB, free: 433.6 MiB)
[2025-05-07T23:16:05.360+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO SparkContext: Created broadcast 35 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:16:05.365+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.20.0.5:40511 in memory (size: 3.9 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 414.5 MiB)
[2025-05-07T23:16:05.371+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 3530b0b864fd:41807 (size: 502.1 KiB, free: 433.1 MiB)
[2025-05-07T23:16:05.372+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:16:05.381+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:05.388+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 3530b0b864fd:41807 in memory (size: 6.7 KiB, free: 433.1 MiB)
[2025-05-07T23:16:05.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.20.0.5:40511 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.396+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 14.867399 ms
[2025-05-07T23:16:05.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 3530b0b864fd:41807 in memory (size: 14.9 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.428+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:05.431+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.20.0.5:40511 in memory (size: 14.9 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.443+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 3530b0b864fd:41807 in memory (size: 11.2 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.444+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 13.668477 ms
[2025-05-07T23:16:05.446+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.20.0.5:40511 in memory (size: 11.2 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.455+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 3530b0b864fd:41807 in memory (size: 13.4 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.20.0.5:40511 in memory (size: 13.4 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.464+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 3530b0b864fd:41807 in memory (size: 13.0 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.466+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.20.0.5:40511 in memory (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.467+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:16:05.468+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 6 output partitions
[2025-05-07T23:16:05.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:16:05.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 49, ShuffleMapStage 53, ShuffleMapStage 50, ShuffleMapStage 54)
[2025-05-07T23:16:05.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:05.471+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[193] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:16:05.475+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 3530b0b864fd:41807 in memory (size: 13.0 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.477+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 91.7 KiB, free 414.6 MiB)
[2025-05-07T23:16:05.479+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.20.0.5:40511 in memory (size: 13.0 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.480+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 414.6 MiB)
[2025-05-07T23:16:05.480+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 3530b0b864fd:41807 (size: 30.2 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.481+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:05.482+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Submitting 6 missing tasks from ResultStage 55 (MapPartitionsRDD[193] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T23:16:05.482+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Adding task set 55.0 with 6 tasks resource profile 0
[2025-05-07T23:16:05.483+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.487+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 3530b0b864fd:41807 in memory (size: 13.5 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.492+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.20.0.5:40511 in memory (size: 13.5 KiB, free: 433.8 MiB)
[2025-05-07T23:16:05.497+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 3530b0b864fd:41807 in memory (size: 13.5 KiB, free: 433.2 MiB)
[2025-05-07T23:16:05.498+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.20.0.5:40511 (size: 30.2 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.498+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.20.0.5:40511 in memory (size: 13.5 KiB, free: 433.7 MiB)
[2025-05-07T23:16:05.503+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.20.0.5:34280
[2025-05-07T23:16:05.533+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 56) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.533+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 50 ms on 172.20.0.5 (executor 0) (1/6)
[2025-05-07T23:16:05.548+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.20.0.5:34280
[2025-05-07T23:16:05.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 57) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.578+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 56) in 45 ms on 172.20.0.5 (executor 0) (2/6)
[2025-05-07T23:16:05.586+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.20.0.5:34280
[2025-05-07T23:16:05.598+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 58) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.599+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 57) in 22 ms on 172.20.0.5 (executor 0) (3/6)
[2025-05-07T23:16:05.608+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.20.0.5:34280
[2025-05-07T23:16:05.632+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 4.0 in stage 55.0 (TID 59) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 58) in 35 ms on 172.20.0.5 (executor 0) (4/6)
[2025-05-07T23:16:05.643+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.20.0.5:34280
[2025-05-07T23:16:05.664+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 5.0 in stage 55.0 (TID 60) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4566 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.665+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 4.0 in stage 55.0 (TID 59) in 32 ms on 172.20.0.5 (executor 0) (5/6)
[2025-05-07T23:16:05.675+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.20.0.5:34280
[2025-05-07T23:16:05.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Finished task 5.0 in stage 55.0 (TID 60) in 37 ms on 172.20.0.5 (executor 0) (6/6)
[2025-05-07T23:16:05.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-05-07T23:16:05.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.228 s
[2025-05-07T23:16:05.702+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:16:05.703+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-05-07T23:16:05.703+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.234855 s
[2025-05-07T23:16:05.721+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 2.3 MiB, free 412.4 MiB)
[2025-05-07T23:16:05.725+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 114.2 KiB, free 412.3 MiB)
[2025-05-07T23:16:05.726+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 3530b0b864fd:41807 (size: 114.2 KiB, free: 433.1 MiB)
[2025-05-07T23:16:05.726+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO SparkContext: Created broadcast 37 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:16:05.756+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:16:05.865+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 82.257983 ms
[2025-05-07T23:16:05.912+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO CodeGenerator: Code generated in 6.851933 ms
[2025-05-07T23:16:05.932+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Registering RDD 200 (rdd at GraphFrame.scala:188) as input to shuffle 22
[2025-05-07T23:16:05.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Got map stage job 31 (rdd at GraphFrame.scala:188) with 11 output partitions
[2025-05-07T23:16:05.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Final stage: ShuffleMapStage 57 (rdd at GraphFrame.scala:188)
[2025-05-07T23:16:05.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-05-07T23:16:05.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:16:05.936+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[200] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:16:05.951+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 129.6 KiB, free 412.2 MiB)
[2025-05-07T23:16:05.954+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 45.0 KiB, free 412.1 MiB)
[2025-05-07T23:16:05.955+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 3530b0b864fd:41807 (size: 45.0 KiB, free: 433.1 MiB)
[2025-05-07T23:16:05.955+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:16:05.955+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[200] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T23:16:05.955+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSchedulerImpl: Adding task set 57.0 with 11 tasks resource profile 0
[2025-05-07T23:16:05.957+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 61) (172.20.0.5, executor 0, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:05.993+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:05 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.20.0.5:40511 (size: 45.0 KiB, free: 433.7 MiB)
[2025-05-07T23:16:06.019+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:34280
[2025-05-07T23:16:06.082+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:06 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.20.0.5:40511 (size: 502.1 KiB, free: 433.2 MiB)
[2025-05-07T23:16:06.115+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:06 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.20.0.5:40511 (size: 114.2 KiB, free: 433.1 MiB)
[2025-05-07T23:16:06.388+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:06 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:40511 (size: 20.6 KiB, free: 433.1 MiB)
[2025-05-07T23:16:06.472+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:06 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 62) (172.20.0.5, executor 0, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:08.703+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:06 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 61) in 516 ms on 172.20.0.5 (executor 0) (1/11)
[2025-05-07T23:16:21.381+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:21 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 63) (172.20.0.5, executor 0, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:21.418+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:21 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 62) in 14927 ms on 172.20.0.5 (executor 0) (2/11)
[2025-05-07T23:16:21.449+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:21 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 64) (172.20.0.5, executor 0, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:21.450+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:21 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 63) in 70 ms on 172.20.0.5 (executor 0) (3/11)
[2025-05-07T23:16:21.481+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:21 INFO TaskSetManager: Starting task 4.0 in stage 57.0 (TID 65) (172.20.0.5, executor 0, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:16:21.482+0000] {spark_submit.py:571} INFO - 25/05/07 23:16:21 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 64) in 33 ms on 172.20.0.5 (executor 0) (4/11)
[2025-05-07T23:18:48.416+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO TaskSetManager: Starting task 5.0 in stage 57.0 (TID 66) (172.20.0.5, executor 0, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:48.435+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO TaskSetManager: Finished task 4.0 in stage 57.0 (TID 65) in 146954 ms on 172.20.0.5 (executor 0) (5/11)
[2025-05-07T23:18:48.508+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 WARN HeartbeatReceiver: Removing executor 0 with no recent heartbeats: 146969 ms exceeds timeout 120000 ms
[2025-05-07T23:18:48.547+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507231449-0007/0 is now LOST (worker lost)
[2025-05-07T23:18:48.554+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO StandaloneSchedulerBackend: Executor app-20250507231449-0007/0 removed: worker lost
[2025-05-07T23:18:48.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T23:18:48.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO StandaloneSchedulerBackend: Worker worker-20250507121535-172.20.0.5-41865 removed: Not receiving heartbeat for 60 seconds
[2025-05-07T23:18:48.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 0
[2025-05-07T23:18:48.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 ERROR TaskSchedulerImpl: Lost executor 0 on 172.20.0.5: worker lost
[2025-05-07T23:18:48.937+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 WARN TaskSetManager: Lost task 5.0 in stage 57.0 (TID 66) (172.20.0.5 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: worker lost
[2025-05-07T23:18:49.022+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:48 INFO DAGScheduler: Resubmitted ShuffleMapTask(57, 1), so marking it as still running.
[2025-05-07T23:18:49.023+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO DAGScheduler: Resubmitted ShuffleMapTask(57, 4), so marking it as still running.
[2025-05-07T23:18:49.023+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO DAGScheduler: Resubmitted ShuffleMapTask(57, 3), so marking it as still running.
[2025-05-07T23:18:49.023+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO DAGScheduler: Resubmitted ShuffleMapTask(57, 0), so marking it as still running.
[2025-05-07T23:18:49.023+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO DAGScheduler: Resubmitted ShuffleMapTask(57, 2), so marking it as still running.
[2025-05-07T23:18:49.035+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 WARN StandaloneSchedulerBackend: Executor to kill 0 does not exist!
[2025-05-07T23:18:49.036+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is
[2025-05-07T23:18:49.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO DAGScheduler: Executor lost: 0 (epoch 21)
[2025-05-07T23:18:49.047+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO TaskSchedulerImpl: Handle removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T23:18:49.071+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2025-05-07T23:18:49.079+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.20.0.5, 40511, None)
[2025-05-07T23:18:49.085+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO BlockManagerMaster: Removed 0 successfully in removeExecutor
[2025-05-07T23:18:49.085+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 21)
[2025-05-07T23:18:49.089+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 ERROR TaskSchedulerImpl: Ignoring update with state RUNNING for TID 66 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
[2025-05-07T23:18:49.092+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO BlockManagerMaster: Removal of executor 0 requested
[2025-05-07T23:18:49.093+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO DAGScheduler: Shuffle files lost for worker worker-20250507121535-172.20.0.5-41865 on host 172.20.0.5
[2025-05-07T23:18:49.093+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 0
[2025-05-07T23:18:49.093+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 ERROR TaskSchedulerImpl: Ignoring update with state FINISHED for TID 66 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
[2025-05-07T23:18:49.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 WARN CoarseGrainedSchedulerBackend$DriverEndpoint: Ignored task status update (66 state FINISHED) from unknown executor with ID 0
[2025-05-07T23:18:49.121+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO BlockManagerMasterEndpoint: BlockManager (BlockManagerId(0, 172.20.0.5, 40511, None)) re-registration is rejected since the executor (0) has been lost
[2025-05-07T23:18:49.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2025-05-07T23:18:49.714+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507231449-0007/1 on worker-20250507121535-172.20.0.5-41865 (172.20.0.5:41865) with 1 core(s)
[2025-05-07T23:18:49.718+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507231449-0007/1 on hostPort 172.20.0.5:41865 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T23:18:50.189+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:50 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507231449-0007/1 is now RUNNING
[2025-05-07T23:18:53.155+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:51174) with ID 1,  ResourceProfileId 0
[2025-05-07T23:18:53.324+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:42805 with 434.4 MiB RAM, BlockManagerId(1, 172.20.0.5, 42805, None)
[2025-05-07T23:18:53.489+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:53 INFO TaskSetManager: Starting task 5.1 in stage 57.0 (TID 67) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:53.688+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:53 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.20.0.5:42805 (size: 45.0 KiB, free: 434.4 MiB)
[2025-05-07T23:18:54.385+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:51174
[2025-05-07T23:18:54.438+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO TaskSetManager: Starting task 2.1 in stage 57.0 (TID 68) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:54.442+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 WARN TaskSetManager: Lost task 5.1 in stage 57.0 (TID 67) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=15, mapIndex=-1, mapId=-1, reduceId=5, message=
[2025-05-07T23:18:54.444+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 15 partition 5
[2025-05-07T23:18:54.444+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:18:54.444+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:18:54.444+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:18:54.444+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:18:54.446+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:18:54.446+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:18:54.447+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:18:54.447+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:18:54.447+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:18:54.447+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:18:54.447+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:18:54.447+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:18:54.447+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.448+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:18:54.449+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - )
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO TaskSetManager: task 5.1 in stage 57.0 (TID 67) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO DAGScheduler: Marking ShuffleMapStage 57 (rdd at GraphFrame.scala:188) as failed due to a fetch failure from ShuffleMapStage 56 (rdd at GraphFrame.scala:188)
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO DAGScheduler: ShuffleMapStage 57 (rdd at GraphFrame.scala:188) failed in 168.507 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 15 partition 5
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:18:54.450+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:18:54.451+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.452+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:18:54.453+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:18:54.454+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:18:54.454+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:18:54.454+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:18:54.454+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:18:54.454+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:18:54.454+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:18:54.454+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO DAGScheduler: Resubmitting ShuffleMapStage 56 (rdd at GraphFrame.scala:188) and ShuffleMapStage 57 (rdd at GraphFrame.scala:188) due to fetch failure
[2025-05-07T23:18:54.460+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:51174
[2025-05-07T23:18:54.465+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 WARN TaskSetManager: Lost task 2.1 in stage 57.0 (TID 68) (172.20.0.5 executor 1): FetchFailed(null, shuffleId=15, mapIndex=-1, mapId=-1, reduceId=2, message=
[2025-05-07T23:18:54.465+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 15 partition 2
[2025-05-07T23:18:54.465+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:18:54.465+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:18:54.466+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:106)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.467+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:18:54.468+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:18:54.469+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:18:54.469+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:18:54.469+0000] {spark_submit.py:571} INFO - )
[2025-05-07T23:18:54.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO TaskSetManager: task 2.1 in stage 57.0 (TID 68) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T23:18:54.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-05-07T23:18:54.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO DAGScheduler: Resubmitting failed stages
[2025-05-07T23:18:54.652+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:18:54.654+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.6 KiB, free 412.1 MiB)
[2025-05-07T23:18:54.671+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 412.1 MiB)
[2025-05-07T23:18:54.672+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 3530b0b864fd:41807 (size: 6.8 KiB, free: 433.0 MiB)
[2025-05-07T23:18:54.672+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:54.673+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 3530b0b864fd:41807 in memory (size: 30.2 KiB, free: 433.1 MiB)
[2025-05-07T23:18:54.673+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[151] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:18:54.673+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO TaskSchedulerImpl: Adding task set 56.1 with 1 tasks resource profile 0
[2025-05-07T23:18:54.674+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO TaskSetManager: Starting task 0.0 in stage 56.1 (TID 69) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:54.689+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.20.0.5:42805 (size: 6.8 KiB, free: 434.3 MiB)
[2025-05-07T23:18:54.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 3530b0b864fd:41807 in memory (size: 45.0 KiB, free: 433.1 MiB)
[2025-05-07T23:18:54.702+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.20.0.5:42805 in memory (size: 45.0 KiB, free: 434.4 MiB)
[2025-05-07T23:18:54.722+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:54 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 3530b0b864fd:41807 in memory (size: 3.8 KiB, free: 433.1 MiB)
[2025-05-07T23:18:55.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Finished task 0.0 in stage 56.1 (TID 69) in 632 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T23:18:55.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSchedulerImpl: Removed TaskSet 56.1, whose tasks have all completed, from pool
[2025-05-07T23:18:55.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO DAGScheduler: ShuffleMapStage 56 (rdd at GraphFrame.scala:188) finished in 0.653 s
[2025-05-07T23:18:55.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:18:55.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO DAGScheduler: running: Set()
[2025-05-07T23:18:55.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 57)
[2025-05-07T23:18:55.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO DAGScheduler: failed: Set()
[2025-05-07T23:18:55.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[200] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:18:55.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 57.
[2025-05-07T23:18:55.312+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 129.6 KiB, free 412.3 MiB)
[2025-05-07T23:18:55.313+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 45.0 KiB, free 412.3 MiB)
[2025-05-07T23:18:55.314+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 3530b0b864fd:41807 (size: 45.0 KiB, free: 433.1 MiB)
[2025-05-07T23:18:55.314+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:55.314+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[200] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
[2025-05-07T23:18:55.314+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSchedulerImpl: Adding task set 57.1 with 11 tasks resource profile 0
[2025-05-07T23:18:55.315+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Starting task 0.0 in stage 57.1 (TID 70) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:55.324+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.20.0.5:42805 (size: 45.0 KiB, free: 434.3 MiB)
[2025-05-07T23:18:55.336+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.20.0.5:51174
[2025-05-07T23:18:55.487+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.20.0.5:42805 (size: 502.1 KiB, free: 433.9 MiB)
[2025-05-07T23:18:55.566+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.20.0.5:42805 (size: 114.2 KiB, free: 433.7 MiB)
[2025-05-07T23:18:55.598+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:42805 (size: 20.6 KiB, free: 433.7 MiB)
[2025-05-07T23:18:55.723+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Starting task 1.0 in stage 57.1 (TID 71) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:55.724+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Finished task 0.0 in stage 57.1 (TID 70) in 408 ms on 172.20.0.5 (executor 1) (1/11)
[2025-05-07T23:18:55.782+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Starting task 2.0 in stage 57.1 (TID 72) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:55.782+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Finished task 1.0 in stage 57.1 (TID 71) in 59 ms on 172.20.0.5 (executor 1) (2/11)
[2025-05-07T23:18:55.830+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Starting task 3.0 in stage 57.1 (TID 73) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:55.830+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Finished task 2.0 in stage 57.1 (TID 72) in 49 ms on 172.20.0.5 (executor 1) (3/11)
[2025-05-07T23:18:55.879+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Starting task 4.0 in stage 57.1 (TID 74) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:55.882+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Finished task 3.0 in stage 57.1 (TID 73) in 51 ms on 172.20.0.5 (executor 1) (4/11)
[2025-05-07T23:18:55.931+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Starting task 5.0 in stage 57.1 (TID 75) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:55.932+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Finished task 4.0 in stage 57.1 (TID 74) in 55 ms on 172.20.0.5 (executor 1) (5/11)
[2025-05-07T23:18:55.978+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Starting task 6.0 in stage 57.1 (TID 76) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:55.983+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:55 INFO TaskSetManager: Finished task 5.0 in stage 57.1 (TID 75) in 48 ms on 172.20.0.5 (executor 1) (6/11)
[2025-05-07T23:18:56.049+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Starting task 7.0 in stage 57.1 (TID 77) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:56.050+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Finished task 6.0 in stage 57.1 (TID 76) in 73 ms on 172.20.0.5 (executor 1) (7/11)
[2025-05-07T23:18:56.098+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Starting task 8.0 in stage 57.1 (TID 78) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:56.099+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Finished task 7.0 in stage 57.1 (TID 77) in 48 ms on 172.20.0.5 (executor 1) (8/11)
[2025-05-07T23:18:56.164+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Starting task 9.0 in stage 57.1 (TID 79) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4555 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:56.165+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Finished task 8.0 in stage 57.1 (TID 78) in 69 ms on 172.20.0.5 (executor 1) (9/11)
[2025-05-07T23:18:56.203+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Starting task 10.0 in stage 57.1 (TID 80) (172.20.0.5, executor 1, partition 10, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:56.205+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Finished task 9.0 in stage 57.1 (TID 79) in 41 ms on 172.20.0.5 (executor 1) (10/11)
[2025-05-07T23:18:56.521+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Finished task 10.0 in stage 57.1 (TID 80) in 318 ms on 172.20.0.5 (executor 1) (11/11)
[2025-05-07T23:18:56.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSchedulerImpl: Removed TaskSet 57.1, whose tasks have all completed, from pool
[2025-05-07T23:18:56.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: ShuffleMapStage 57 (rdd at GraphFrame.scala:188) finished in 1.214 s
[2025-05-07T23:18:56.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:18:56.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: running: Set()
[2025-05-07T23:18:56.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:18:56.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: failed: Set()
[2025-05-07T23:18:56.532+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:18:56.558+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO CodeGenerator: Code generated in 13.41469 ms
[2025-05-07T23:18:56.576+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:18:56.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Got job 32 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T23:18:56.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Final stage: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:18:56.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-05-07T23:18:56.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:18:56.579+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[204] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:18:56.582+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 116.0 KiB, free 412.1 MiB)
[2025-05-07T23:18:56.584+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 412.1 MiB)
[2025-05-07T23:18:56.584+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 3530b0b864fd:41807 (size: 39.3 KiB, free: 433.0 MiB)
[2025-05-07T23:18:56.585+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:56.585+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[204] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:18:56.585+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-05-07T23:18:56.586+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 81) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:56.597+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.20.0.5:42805 (size: 39.3 KiB, free: 433.7 MiB)
[2025-05-07T23:18:56.652+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.20.0.5:51174
[2025-05-07T23:18:56.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 81) in 179 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T23:18:56.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-05-07T23:18:56.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: ResultStage 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.187 s
[2025-05-07T23:18:56.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:18:56.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
[2025-05-07T23:18:56.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Job 32 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.189765 s
[2025-05-07T23:18:56.769+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 2.0 MiB, free 410.1 MiB)
[2025-05-07T23:18:56.772+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 96.0 KiB, free 410.0 MiB)
[2025-05-07T23:18:56.772+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 3530b0b864fd:41807 (size: 96.0 KiB, free: 432.9 MiB)
[2025-05-07T23:18:56.772+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO SparkContext: Created broadcast 42 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:18:56.794+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO CodeGenerator: Code generated in 7.966614 ms
[2025-05-07T23:18:56.795+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1543 - id.nullCount#1542) > 0)
[2025-05-07T23:18:56.800+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Registering RDD 19 (rdd at GraphFrame.scala:187) as input to shuffle 3
[2025-05-07T23:18:56.800+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Registering RDD 209 (rdd at GraphFrame.scala:188) as input to shuffle 23
[2025-05-07T23:18:56.801+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Got map stage job 33 (rdd at GraphFrame.scala:188) with 10 output partitions
[2025-05-07T23:18:56.801+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (rdd at GraphFrame.scala:188)
[2025-05-07T23:18:56.801+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 61)
[2025-05-07T23:18:56.802+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 61)
[2025-05-07T23:18:56.803+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Submitting ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T23:18:56.804+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 12.6 KiB, free 410.0 MiB)
[2025-05-07T23:18:56.805+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 410.0 MiB)
[2025-05-07T23:18:56.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 3530b0b864fd:41807 (size: 6.7 KiB, free: 432.9 MiB)
[2025-05-07T23:18:56.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:56.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:18:56.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
[2025-05-07T23:18:56.807+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 82) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:56.819+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.20.0.5:42805 (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T23:18:56.866+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 82) in 59 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T23:18:56.866+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-05-07T23:18:56.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: ShuffleMapStage 61 (rdd at GraphFrame.scala:187) finished in 0.063 s
[2025-05-07T23:18:56.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:18:56.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: running: Set()
[2025-05-07T23:18:56.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 62)
[2025-05-07T23:18:56.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: failed: Set()
[2025-05-07T23:18:56.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[209] at rdd at GraphFrame.scala:188), which has no missing parents
[2025-05-07T23:18:56.882+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 51.0 KiB, free 409.9 MiB)
[2025-05-07T23:18:56.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 21.7 KiB, free 409.9 MiB)
[2025-05-07T23:18:56.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 3530b0b864fd:41807 (size: 21.7 KiB, free: 432.9 MiB)
[2025-05-07T23:18:56.884+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:56.884+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[209] at rdd at GraphFrame.scala:188) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:18:56.884+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSchedulerImpl: Adding task set 62.0 with 10 tasks resource profile 0
[2025-05-07T23:18:56.885+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 83) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:56.895+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.20.0.5:42805 (size: 21.7 KiB, free: 433.7 MiB)
[2025-05-07T23:18:56.968+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:51174
[2025-05-07T23:18:57.063+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:42805 (size: 2.0 KiB, free: 433.7 MiB)
[2025-05-07T23:18:57.131+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.20.0.5:42805 (size: 96.0 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.150+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 84) (172.20.0.5, executor 1, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.151+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 83) in 265 ms on 172.20.0.5 (executor 1) (1/10)
[2025-05-07T23:18:57.182+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:42805 (size: 2.5 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.203+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 2.0 in stage 62.0 (TID 85) (172.20.0.5, executor 1, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.204+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 84) in 54 ms on 172.20.0.5 (executor 1) (2/10)
[2025-05-07T23:18:57.225+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:42805 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.237+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 3.0 in stage 62.0 (TID 86) (172.20.0.5, executor 1, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.237+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 2.0 in stage 62.0 (TID 85) in 34 ms on 172.20.0.5 (executor 1) (3/10)
[2025-05-07T23:18:57.265+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:42805 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.280+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 4.0 in stage 62.0 (TID 87) (172.20.0.5, executor 1, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.281+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 3.0 in stage 62.0 (TID 86) in 44 ms on 172.20.0.5 (executor 1) (4/10)
[2025-05-07T23:18:57.307+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:42805 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.326+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 5.0 in stage 62.0 (TID 88) (172.20.0.5, executor 1, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.328+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 4.0 in stage 62.0 (TID 87) in 45 ms on 172.20.0.5 (executor 1) (5/10)
[2025-05-07T23:18:57.359+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:42805 (size: 2.0 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.376+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 6.0 in stage 62.0 (TID 89) (172.20.0.5, executor 1, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.377+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 5.0 in stage 62.0 (TID 88) in 52 ms on 172.20.0.5 (executor 1) (6/10)
[2025-05-07T23:18:57.406+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:42805 (size: 2.1 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.423+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 7.0 in stage 62.0 (TID 90) (172.20.0.5, executor 1, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.423+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 6.0 in stage 62.0 (TID 89) in 48 ms on 172.20.0.5 (executor 1) (7/10)
[2025-05-07T23:18:57.445+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:42805 (size: 2.3 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.455+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 8.0 in stage 62.0 (TID 91) (172.20.0.5, executor 1, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.455+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 7.0 in stage 62.0 (TID 90) in 33 ms on 172.20.0.5 (executor 1) (8/10)
[2025-05-07T23:18:57.476+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:42805 (size: 2.4 KiB, free: 433.5 MiB)
[2025-05-07T23:18:57.490+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 9.0 in stage 62.0 (TID 92) (172.20.0.5, executor 1, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.490+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 8.0 in stage 62.0 (TID 91) in 35 ms on 172.20.0.5 (executor 1) (9/10)
[2025-05-07T23:18:57.513+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:42805 (size: 2.3 KiB, free: 433.5 MiB)
[2025-05-07T23:18:57.526+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 9.0 in stage 62.0 (TID 92) in 37 ms on 172.20.0.5 (executor 1) (10/10)
[2025-05-07T23:18:57.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-05-07T23:18:57.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: ShuffleMapStage 62 (rdd at GraphFrame.scala:188) finished in 0.658 s
[2025-05-07T23:18:57.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:18:57.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: running: Set()
[2025-05-07T23:18:57.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:18:57.528+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: failed: Set()
[2025-05-07T23:18:57.536+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:18:57.544+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:18:57.545+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Got job 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-05-07T23:18:57.545+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Final stage: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-05-07T23:18:57.545+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
[2025-05-07T23:18:57.545+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:18:57.546+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[211] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-05-07T23:18:57.548+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 7.2 KiB, free 409.9 MiB)
[2025-05-07T23:18:57.566+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 409.9 MiB)
[2025-05-07T23:18:57.568+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 432.9 MiB)
[2025-05-07T23:18:57.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 3530b0b864fd:41807 in memory (size: 21.7 KiB, free: 432.9 MiB)
[2025-05-07T23:18:57.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:57.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[211] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:18:57.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
[2025-05-07T23:18:57.570+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 93) (172.20.0.5, executor 1, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.573+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.20.0.5:42805 in memory (size: 21.7 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.586+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 3530b0b864fd:41807 in memory (size: 45.0 KiB, free: 433.0 MiB)
[2025-05-07T23:18:57.590+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.20.0.5:42805 in memory (size: 45.0 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.593+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.20.0.5:42805 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 3530b0b864fd:41807 in memory (size: 39.3 KiB, free: 433.0 MiB)
[2025-05-07T23:18:57.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.20.0.5:51174
[2025-05-07T23:18:57.606+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.20.0.5:42805 in memory (size: 39.3 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.617+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 3530b0b864fd:41807 in memory (size: 6.7 KiB, free: 433.0 MiB)
[2025-05-07T23:18:57.618+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.20.0.5:42805 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T23:18:57.641+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 93) in 69 ms on 172.20.0.5 (executor 1) (1/1)
[2025-05-07T23:18:57.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool
[2025-05-07T23:18:57.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: ResultStage 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.093 s
[2025-05-07T23:18:57.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:18:57.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
[2025-05-07T23:18:57.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Job 34 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.097222 s
[2025-05-07T23:18:57.648+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 3530b0b864fd:41807 in memory (size: 20.6 KiB, free: 433.0 MiB)
[2025-05-07T23:18:57.653+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 2.0 MiB, free 410.3 MiB)
[2025-05-07T23:18:57.655+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 98.0 KiB, free 410.2 MiB)
[2025-05-07T23:18:57.656+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 3530b0b864fd:41807 (size: 98.0 KiB, free: 432.9 MiB)
[2025-05-07T23:18:57.656+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-05-07T23:18:57.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 3530b0b864fd:41807 in memory (size: 502.1 KiB, free: 433.4 MiB)
[2025-05-07T23:18:57.666+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 3530b0b864fd:41807 in memory (size: 114.2 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.683+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 3530b0b864fd:41807 in memory (size: 6.8 KiB, free: 433.6 MiB)
[2025-05-07T23:18:57.684+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.20.0.5:42805 in memory (size: 6.8 KiB, free: 433.7 MiB)
[2025-05-07T23:18:57.685+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO CodeGenerator: Code generated in 13.513036 ms
[2025-05-07T23:18:57.686+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#1553 - id.nullCount#1552) > 0)
[2025-05-07T23:18:57.809+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T23:18:57.811+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Registering RDD 224 (mapPartitions at VertexRDD.scala:356) as input to shuffle 28
[2025-05-07T23:18:57.812+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Registering RDD 31 (map at GraphFrame.scala:187) as input to shuffle 25
[2025-05-07T23:18:57.812+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Registering RDD 250 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 26
[2025-05-07T23:18:57.812+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Registering RDD 246 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 24
[2025-05-07T23:18:57.813+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Registering RDD 254 (mapPartitions at GraphImpl.scala:208) as input to shuffle 27
[2025-05-07T23:18:57.813+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Got job 35 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T23:18:57.813+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Final stage: ResultStage 72 (fold at VertexRDDImpl.scala:90)
[2025-05-07T23:18:57.813+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T23:18:57.814+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68)
[2025-05-07T23:18:57.817+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Submitting ShuffleMapStage 67 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[224] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-07T23:18:57.874+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 158.2 KiB, free 418.0 MiB)
[2025-05-07T23:18:57.879+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 55.7 KiB, free 417.9 MiB)
[2025-05-07T23:18:57.879+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 3530b0b864fd:41807 (size: 55.7 KiB, free: 433.5 MiB)
[2025-05-07T23:18:57.879+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:57.880+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 67 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[224] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:18:57.880+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSchedulerImpl: Adding task set 67.0 with 10 tasks resource profile 0
[2025-05-07T23:18:57.882+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-07T23:18:57.882+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 94) (172.20.0.5, executor 1, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:18:57.896+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 59.1 KiB, free 417.8 MiB)
[2025-05-07T23:18:57.899+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 417.8 MiB)
[2025-05-07T23:18:57.899+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 3530b0b864fd:41807 (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T23:18:57.899+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:18:57.903+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:18:57.904+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO TaskSchedulerImpl: Adding task set 68.0 with 10 tasks resource profile 0
[2025-05-07T23:18:57.904+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:57 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.20.0.5:42805 (size: 55.7 KiB, free: 433.6 MiB)
[2025-05-07T23:18:58.170+0000] {spark_submit.py:571} INFO - 25/05/07 23:18:58 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:42805 (size: 98.0 KiB, free: 433.5 MiB)
[2025-05-07T23:24:38.514+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(1,WrappedArray((94,67,0,Vector(AccumulableInfo(2544,Some(internal.metrics.jvmGCTime),Some(56),None,true,true,None), AccumulableInfo(2548,Some(internal.metrics.peakExecutionMemory),Some(33652736),None,true,true,None), AccumulableInfo(2560,Some(internal.metrics.input.bytesRead),Some(2072),None,true,true,None)))),Map((67,0) -> org.apache.spark.executor.ExecutorMetrics@365533f4)) by listener AppStatusListener took 3.312109778s.
[2025-05-07T23:24:38.520+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507231449-0007/1 is now LOST (worker lost)
[2025-05-07T23:24:38.520+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneSchedulerBackend: Executor app-20250507231449-0007/1 removed: worker lost
[2025-05-07T23:24:38.520+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneAppClient$ClientEndpoint: Master removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T23:24:38.520+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneSchedulerBackend: Worker worker-20250507121535-172.20.0.5-41865 removed: Not receiving heartbeat for 60 seconds
[2025-05-07T23:24:38.597+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 ERROR TaskSchedulerImpl: Lost executor 1 on 172.20.0.5: worker lost
[2025-05-07T23:24:38.598+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN TaskSetManager: Lost task 0.0 in stage 67.0 (TID 94) (172.20.0.5 executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: worker lost
[2025-05-07T23:24:38.598+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO TaskSchedulerImpl: Handle removed worker worker-20250507121535-172.20.0.5-41865: Not receiving heartbeat for 60 seconds
[2025-05-07T23:24:38.600+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN HeartbeatReceiver: Removing executor 1 with no recent heartbeats: 218769 ms exceeds timeout 120000 ms
[2025-05-07T23:24:38.600+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO DAGScheduler: Executor lost: 1 (epoch 27)
[2025-05-07T23:24:38.600+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
[2025-05-07T23:24:38.622+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneSchedulerBackend: Requesting to kill executor(s) 1
[2025-05-07T23:24:38.623+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN StandaloneSchedulerBackend: Executor to kill 1 does not exist!
[2025-05-07T23:24:38.623+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneSchedulerBackend: Actual list of executor(s) to be killed is
[2025-05-07T23:24:38.623+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO BlockManagerMaster: Removal of executor 1 requested
[2025-05-07T23:24:38.623+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 1
[2025-05-07T23:24:38.629+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_1 !
[2025-05-07T23:24:38.630+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_5 !
[2025-05-07T23:24:38.630+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_7 !
[2025-05-07T23:24:38.631+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_6 !
[2025-05-07T23:24:38.631+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_9 !
[2025-05-07T23:24:38.631+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_0 !
[2025-05-07T23:24:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_3 !
[2025-05-07T23:24:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_4 !
[2025-05-07T23:24:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_8 !
[2025-05-07T23:24:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_23_2 !
[2025-05-07T23:24:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.20.0.5, 42805, None)
[2025-05-07T23:24:38.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
[2025-05-07T23:24:38.634+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
[2025-05-07T23:24:38.634+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO DAGScheduler: Shuffle files lost for host: 172.20.0.5 (epoch 27)
[2025-05-07T23:24:38.634+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO DAGScheduler: Shuffle files lost for worker worker-20250507121535-172.20.0.5-41865 on host 172.20.0.5
[2025-05-07T23:24:38.634+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO BlockManagerMasterEndpoint: BlockManager (BlockManagerId(1, 172.20.0.5, 42805, None)) re-registration is rejected since the executor (1) has been lost
[2025-05-07T23:24:38.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250507231449-0007/2 on worker-20250507121535-172.20.0.5-41865 (172.20.0.5:41865) with 1 core(s)
[2025-05-07T23:24:38.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250507231449-0007/2 on hostPort 172.20.0.5:41865 with 1 core(s), 1024.0 MiB RAM
[2025-05-07T23:24:39.550+0000] {spark_submit.py:571} INFO - 25/05/07 23:24:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250507231449-0007/2 is now RUNNING
[2025-05-07T23:25:45.333+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.5:47382) with ID 2,  ResourceProfileId 0
[2025-05-07T23:25:45.494+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.20.0.5:40779 with 434.4 MiB RAM, BlockManagerId(2, 172.20.0.5, 40779, None)
[2025-05-07T23:25:45.680+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:45 INFO TaskSetManager: Starting task 0.1 in stage 67.0 (TID 95) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:45.891+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:45 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.20.0.5:40779 (size: 55.7 KiB, free: 434.3 MiB)
[2025-05-07T23:25:46.818+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:47382
[2025-05-07T23:25:46.860+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 96) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:46.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 WARN TaskSetManager: Lost task 0.1 in stage 67.0 (TID 95) (172.20.0.5 executor 2): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-07T23:25:46.861+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 0
[2025-05-07T23:25:46.861+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:25:46.861+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:25:46.861+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.861+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:25:46.861+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:25:46.862+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.863+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.864+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.865+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.866+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:25:46.867+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - )
[2025-05-07T23:25:46.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSetManager: task 0.1 in stage 67.0 (TID 95) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO DAGScheduler: Marking ShuffleMapStage 67 (mapPartitions at VertexRDD.scala:356) as failed due to a fetch failure from ShuffleMapStage 66 (rdd at GraphFrame.scala:187)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO DAGScheduler: ShuffleMapStage 67 (mapPartitions at VertexRDD.scala:356) failed in 409.043 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 0
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.869+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.870+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-07T23:25:46.871+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.872+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.873+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.874+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:25:46.875+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:25:46.876+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:25:46.876+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:25:46.876+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:25:46.876+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:25:46.876+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:25:46.876+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:25:46.876+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO DAGScheduler: Resubmitting ShuffleMapStage 66 (rdd at GraphFrame.scala:187) and ShuffleMapStage 67 (mapPartitions at VertexRDD.scala:356) due to fetch failure
[2025-05-07T23:25:46.888+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:47382
[2025-05-07T23:25:46.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 97) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:46.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 WARN TaskSetManager: Lost task 1.0 in stage 67.0 (TID 96) (172.20.0.5 executor 2): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=1, message=
[2025-05-07T23:25:46.894+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 1
[2025-05-07T23:25:46.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:25:46.894+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:25:46.895+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.896+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-07T23:25:46.897+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.898+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.899+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.900+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:25:46.901+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:25:46.902+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:25:46.902+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:25:46.902+0000] {spark_submit.py:571} INFO - )
[2025-05-07T23:25:46.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSetManager: task 1.0 in stage 67.0 (TID 96) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T23:25:46.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-05-07T23:25:46.906+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.20.0.5:40779 (size: 26.0 KiB, free: 434.3 MiB)
[2025-05-07T23:25:46.918+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:47382
[2025-05-07T23:25:46.924+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 98) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:46.924+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 WARN TaskSetManager: Lost task 0.0 in stage 68.0 (TID 97) (172.20.0.5 executor 2): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=0, message=
[2025-05-07T23:25:46.924+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 0
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:25:46.925+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.926+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-07T23:25:46.927+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.928+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.929+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:25:46.930+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - )
[2025-05-07T23:25:46.931+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSetManager: task 0.0 in stage 68.0 (TID 97) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO DAGScheduler: Marking ShuffleMapStage 68 (map at GraphFrame.scala:187) as failed due to a fetch failure from ShuffleMapStage 66 (rdd at GraphFrame.scala:187)
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO DAGScheduler: ShuffleMapStage 68 (map at GraphFrame.scala:187) failed in 409.041 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 0
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:25:46.932+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.933+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.934+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.935+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.936+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:25:46.937+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:25:46.938+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO DAGScheduler: Resubmitting ShuffleMapStage 66 (rdd at GraphFrame.scala:187) and ShuffleMapStage 68 (map at GraphFrame.scala:187) due to fetch failure
[2025-05-07T23:25:46.941+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:47382
[2025-05-07T23:25:46.947+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 WARN TaskSetManager: Lost task 1.0 in stage 68.0 (TID 98) (172.20.0.5 executor 2): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=1, message=
[2025-05-07T23:25:46.947+0000] {spark_submit.py:571} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 1
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1623)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1570)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach(Iterator.scala:943)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1569)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1234)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1196)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)
[2025-05-07T23:25:46.948+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:386)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1496)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1423)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1487)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1310)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)
[2025-05-07T23:25:46.949+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:335)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.950+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.$anonfun$compute$1(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:158)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:52)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.Task.run(Task.scala:131)
[2025-05-07T23:25:46.951+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - at java.base/java.lang.Thread.run(Thread.java:829)
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - 
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - )
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSetManager: task 1.0 in stage 68.0 (TID 98) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded).
[2025-05-07T23:25:46.952+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:46 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-05-07T23:25:47.063+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: Resubmitting failed stages
[2025-05-07T23:25:47.063+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187), which has no missing parents
[2025-05-07T23:25:47.066+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 12.6 KiB, free 417.8 MiB)
[2025-05-07T23:25:47.069+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.8 MiB)
[2025-05-07T23:25:47.069+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 3530b0b864fd:41807 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:47.070+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:47.071+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[19] at rdd at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:25:47.071+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
[2025-05-07T23:25:47.072+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 99) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:47.090+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.20.0.5:40779 (size: 6.7 KiB, free: 434.3 MiB)
[2025-05-07T23:25:47.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 99) in 590 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:25:47.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-05-07T23:25:47.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: ShuffleMapStage 66 (rdd at GraphFrame.scala:187) finished in 0.598 s
[2025-05-07T23:25:47.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:47.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:47.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 67, ShuffleMapStage 71, ShuffleMapStage 68, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T23:25:47.663+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:47.663+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 67 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[224] at mapPartitions at VertexRDD.scala:356), which has no missing parents
[2025-05-07T23:25:47.663+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 67.
[2025-05-07T23:25:47.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 158.2 KiB, free 417.6 MiB)
[2025-05-07T23:25:47.684+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 55.7 KiB, free 417.6 MiB)
[2025-05-07T23:25:47.685+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 3530b0b864fd:41807 (size: 55.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:47.686+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:47.686+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 67 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[224] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:47.686+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO TaskSchedulerImpl: Adding task set 67.1 with 10 tasks resource profile 0
[2025-05-07T23:25:47.687+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 3530b0b864fd:41807 in memory (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T23:25:47.688+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO TaskSetManager: Starting task 0.0 in stage 67.1 (TID 100) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:47.689+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[31] at map at GraphFrame.scala:187), which has no missing parents
[2025-05-07T23:25:47.689+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO OutputCommitCoordinator: Reusing state from previous attempt of stage 68.
[2025-05-07T23:25:47.693+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 59.1 KiB, free 417.5 MiB)
[2025-05-07T23:25:47.695+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 417.5 MiB)
[2025-05-07T23:25:47.696+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 3530b0b864fd:41807 (size: 26.0 KiB, free: 433.4 MiB)
[2025-05-07T23:25:47.696+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:47.697+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[31] at map at GraphFrame.scala:187) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:47.697+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO TaskSchedulerImpl: Adding task set 68.1 with 10 tasks resource profile 0
[2025-05-07T23:25:47.707+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.20.0.5:40779 (size: 55.7 KiB, free: 434.3 MiB)
[2025-05-07T23:25:47.710+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 3530b0b864fd:41807 in memory (size: 55.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:47.718+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.20.0.5:40779 in memory (size: 55.7 KiB, free: 434.3 MiB)
[2025-05-07T23:25:47.759+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 3530b0b864fd:41807 in memory (size: 26.0 KiB, free: 433.5 MiB)
[2025-05-07T23:25:47.761+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.20.0.5:47382
[2025-05-07T23:25:47.761+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:47 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.20.0.5:40779 in memory (size: 26.0 KiB, free: 434.3 MiB)
[2025-05-07T23:25:48.007+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:48 INFO BlockManagerInfo: Added rdd_23_0 in memory on 172.20.0.5:40779 (size: 2.0 KiB, free: 434.3 MiB)
[2025-05-07T23:25:48.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:48 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.20.0.5:40779 (size: 20.6 KiB, free: 434.3 MiB)
[2025-05-07T23:25:48.108+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:48 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.20.0.5:40779 (size: 98.0 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.077+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 1.0 in stage 67.1 (TID 101) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.078+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 0.0 in stage 67.1 (TID 100) in 1389 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:49.143+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_1 in memory on 172.20.0.5:40779 (size: 2.5 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.172+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 2.0 in stage 67.1 (TID 102) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.173+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 1.0 in stage 67.1 (TID 101) in 97 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:49.213+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.230+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 3.0 in stage 67.1 (TID 103) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.230+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 2.0 in stage 67.1 (TID 102) in 58 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:49.267+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_3 in memory on 172.20.0.5:40779 (size: 2.3 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.282+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 4.0 in stage 67.1 (TID 104) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.282+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 3.0 in stage 67.1 (TID 103) in 52 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:49.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_4 in memory on 172.20.0.5:40779 (size: 2.1 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.346+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 5.0 in stage 67.1 (TID 105) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.346+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 4.0 in stage 67.1 (TID 104) in 65 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:49.374+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_5 in memory on 172.20.0.5:40779 (size: 2.0 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.385+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 6.0 in stage 67.1 (TID 106) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.386+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 5.0 in stage 67.1 (TID 105) in 40 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:49.413+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_6 in memory on 172.20.0.5:40779 (size: 2.1 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.424+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 7.0 in stage 67.1 (TID 107) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 6.0 in stage 67.1 (TID 106) in 39 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:49.461+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_7 in memory on 172.20.0.5:40779 (size: 2.3 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.476+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 8.0 in stage 67.1 (TID 108) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.477+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 7.0 in stage 67.1 (TID 107) in 52 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:49.503+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_8 in memory on 172.20.0.5:40779 (size: 2.4 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.526+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 9.0 in stage 67.1 (TID 109) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 8.0 in stage 67.1 (TID 108) in 50 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:49.556+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added rdd_23_9 in memory on 172.20.0.5:40779 (size: 2.3 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.566+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 0.0 in stage 68.1 (TID 110) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 9.0 in stage 67.1 (TID 109) in 41 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:49.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSchedulerImpl: Removed TaskSet 67.1, whose tasks have all completed, from pool
[2025-05-07T23:25:49.590+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: ShuffleMapStage 67 (mapPartitions at VertexRDD.scala:356) finished in 1.902 s
[2025-05-07T23:25:49.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:49.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: running: Set(ShuffleMapStage 68)
[2025-05-07T23:25:49.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T23:25:49.592+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:49.592+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.20.0.5:40779 (size: 26.0 KiB, free: 434.2 MiB)
[2025-05-07T23:25:49.620+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.20.0.5:40779 (size: 28.8 KiB, free: 434.1 MiB)
[2025-05-07T23:25:49.667+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 1.0 in stage 68.1 (TID 111) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.668+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 0.0 in stage 68.1 (TID 110) in 101 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:49.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 2.0 in stage 68.1 (TID 112) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 1.0 in stage 68.1 (TID 111) in 32 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:49.725+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 3.0 in stage 68.1 (TID 113) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.726+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 2.0 in stage 68.1 (TID 112) in 26 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:49.753+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 4.0 in stage 68.1 (TID 114) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.754+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 3.0 in stage 68.1 (TID 113) in 29 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:49.790+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 5.0 in stage 68.1 (TID 115) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.790+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 4.0 in stage 68.1 (TID 114) in 38 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:49.816+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 6.0 in stage 68.1 (TID 116) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.816+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 5.0 in stage 68.1 (TID 115) in 27 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:49.839+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 7.0 in stage 68.1 (TID 117) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.840+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 6.0 in stage 68.1 (TID 116) in 24 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:49.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 8.0 in stage 68.1 (TID 118) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.862+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 7.0 in stage 68.1 (TID 117) in 23 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:49.885+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 9.0 in stage 68.1 (TID 119) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.886+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 8.0 in stage 68.1 (TID 118) in 24 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:49.901+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Finished task 9.0 in stage 68.1 (TID 119) in 16 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:49.901+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSchedulerImpl: Removed TaskSet 68.1, whose tasks have all completed, from pool
[2025-05-07T23:25:49.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: ShuffleMapStage 68 (map at GraphFrame.scala:187) finished in 2.211 s
[2025-05-07T23:25:49.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:49.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:49.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 70, ShuffleMapStage 71, ResultStage 72, ShuffleMapStage 69)
[2025-05-07T23:25:49.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:49.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: Submitting ShuffleMapStage 70 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[246] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:49.919+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 10.3 KiB, free 417.8 MiB)
[2025-05-07T23:25:49.922+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.8 MiB)
[2025-05-07T23:25:49.922+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 3530b0b864fd:41807 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T23:25:49.923+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:49.924+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 70 (ReplicatedVertexView.updateVertices - shippedVerts false false (broadcast) MapPartitionsRDD[246] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:49.924+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSchedulerImpl: Adding task set 70.0 with 10 tasks resource profile 0
[2025-05-07T23:25:49.925+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: Submitting ShuffleMapStage 69 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[250] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:49.927+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 9.9 KiB, free 417.8 MiB)
[2025-05-07T23:25:49.927+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 120) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:49.928+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 417.8 MiB)
[2025-05-07T23:25:49.928+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 3530b0b864fd:41807 (size: 4.9 KiB, free: 433.5 MiB)
[2025-05-07T23:25:49.928+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:49.929+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 69 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[250] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:49.929+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO TaskSchedulerImpl: Adding task set 69.0 with 10 tasks resource profile 0
[2025-05-07T23:25:49.939+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.20.0.5:40779 (size: 5.0 KiB, free: 434.1 MiB)
[2025-05-07T23:25:49.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.20.0.5:47382
[2025-05-07T23:25:49.994+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.20.0.5:47382
[2025-05-07T23:25:50.195+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_0 in memory on 172.20.0.5:40779 (size: 18.6 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.199+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_0 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.202+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.206+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.223+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 121) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.223+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 120) in 299 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:50.232+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.20.0.5:40779 (size: 4.9 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.244+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 122) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.244+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 121) in 22 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:50.272+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_1 in memory on 172.20.0.5:40779 (size: 18.6 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.275+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_1 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.280+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 123) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 122) in 44 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:50.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_2 in memory on 172.20.0.5:40779 (size: 18.5 KiB, free: 434.1 MiB)
[2025-05-07T23:25:50.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_2 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.330+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.335+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 124) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 123) in 58 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:50.366+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_3 in memory on 172.20.0.5:40779 (size: 18.2 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.369+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_3 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.371+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.373+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.381+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 4.0 in stage 69.0 (TID 125) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.382+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 124) in 38 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:50.405+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_4 in memory on 172.20.0.5:40779 (size: 18.8 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.408+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_4 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.411+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.413+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.421+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 5.0 in stage 69.0 (TID 126) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.421+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 4.0 in stage 69.0 (TID 125) in 40 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:50.445+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_5 in memory on 172.20.0.5:40779 (size: 18.5 KiB, free: 434.0 MiB)
[2025-05-07T23:25:50.448+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_5 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.450+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.453+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.461+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 6.0 in stage 69.0 (TID 127) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.462+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 5.0 in stage 69.0 (TID 126) in 42 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:50.482+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_6 in memory on 172.20.0.5:40779 (size: 18.4 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.485+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_6 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.491+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.498+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 7.0 in stage 69.0 (TID 128) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.499+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 6.0 in stage 69.0 (TID 127) in 37 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:50.519+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_7 in memory on 172.20.0.5:40779 (size: 18.4 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_7 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.525+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.528+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.535+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 8.0 in stage 69.0 (TID 129) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.535+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 7.0 in stage 69.0 (TID 128) in 37 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:50.551+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_8 in memory on 172.20.0.5:40779 (size: 18.0 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.554+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_8 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.9 MiB)
[2025-05-07T23:25:50.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:50.559+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:50.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 9.0 in stage 69.0 (TID 130) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 8.0 in stage 69.0 (TID 129) in 33 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:50.586+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_227_9 in memory on 172.20.0.5:40779 (size: 18.0 KiB, free: 433.8 MiB)
[2025-05-07T23:25:50.589+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_232_9 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:50.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_238_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:50.594+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_242_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:50.600+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 131) (172.20.0.5, executor 2, partition 1, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 9.0 in stage 69.0 (TID 130) in 33 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:50.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-05-07T23:25:50.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: ShuffleMapStage 69 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.675 s
[2025-05-07T23:25:50.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:50.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: running: Set(ShuffleMapStage 70)
[2025-05-07T23:25:50.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T23:25:50.602+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:50.609+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 2.0 in stage 70.0 (TID 132) (172.20.0.5, executor 2, partition 2, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 131) in 9 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:50.617+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 3.0 in stage 70.0 (TID 133) (172.20.0.5, executor 2, partition 3, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.618+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 2.0 in stage 70.0 (TID 132) in 8 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:50.626+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 4.0 in stage 70.0 (TID 134) (172.20.0.5, executor 2, partition 4, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.626+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 3.0 in stage 70.0 (TID 133) in 9 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:50.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 5.0 in stage 70.0 (TID 135) (172.20.0.5, executor 2, partition 5, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 4.0 in stage 70.0 (TID 134) in 9 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:50.643+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 6.0 in stage 70.0 (TID 136) (172.20.0.5, executor 2, partition 6, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.644+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 5.0 in stage 70.0 (TID 135) in 10 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:50.653+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 7.0 in stage 70.0 (TID 137) (172.20.0.5, executor 2, partition 7, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.653+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 6.0 in stage 70.0 (TID 136) in 10 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:50.661+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 8.0 in stage 70.0 (TID 138) (172.20.0.5, executor 2, partition 8, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 7.0 in stage 70.0 (TID 137) in 8 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:50.673+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 9.0 in stage 70.0 (TID 139) (172.20.0.5, executor 2, partition 9, NODE_LOCAL, 4568 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.674+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 8.0 in stage 70.0 (TID 138) in 12 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:50.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 9.0 in stage 70.0 (TID 139) in 8 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:50.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-05-07T23:25:50.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: ShuffleMapStage 70 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.778 s
[2025-05-07T23:25:50.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:50.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:50.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: waiting: Set(ShuffleMapStage 71, ResultStage 72)
[2025-05-07T23:25:50.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:50.683+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: Submitting ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[254] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:50.690+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 162.8 KiB, free 417.6 MiB)
[2025-05-07T23:25:50.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.6 MiB)
[2025-05-07T23:25:50.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 3530b0b864fd:41807 (size: 57.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:50.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:50.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 71 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[254] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:50.693+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSchedulerImpl: Adding task set 71.0 with 10 tasks resource profile 0
[2025-05-07T23:25:50.693+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 140) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.20.0.5:40779 (size: 57.7 KiB, free: 433.8 MiB)
[2025-05-07T23:25:50.729+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_230_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.731+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_234_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.733+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_240_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.734+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.20.0.5:47382
[2025-05-07T23:25:50.740+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_248_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.741+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.20.0.5:47382
[2025-05-07T23:25:50.751+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 141) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.752+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 140) in 58 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:50.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_230_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.779+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_234_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.781+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_240_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.786+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_248_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.792+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 142) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.793+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 141) in 41 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:50.820+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_230_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.824+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_234_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.826+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_240_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.833+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_248_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.841+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 143) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.841+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 142) in 50 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:50.859+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_230_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_234_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.863+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_240_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_248_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 4.0 in stage 71.0 (TID 144) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.874+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 143) in 33 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:50.892+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_230_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.895+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_234_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.897+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_240_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_248_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.907+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 5.0 in stage 71.0 (TID 145) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.907+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 4.0 in stage 71.0 (TID 144) in 34 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:50.923+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_230_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.925+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_234_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.927+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_240_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.931+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_248_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.937+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 6.0 in stage 71.0 (TID 146) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.937+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 5.0 in stage 71.0 (TID 145) in 30 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:50.956+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_230_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.958+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_234_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.959+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_240_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.964+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO BlockManagerInfo: Added rdd_248_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:50.974+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Starting task 7.0 in stage 71.0 (TID 147) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:50.975+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:50 INFO TaskSetManager: Finished task 6.0 in stage 71.0 (TID 146) in 38 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:51.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_230_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.008+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_234_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.011+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_240_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.017+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_248_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.026+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 8.0 in stage 71.0 (TID 148) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.026+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 7.0 in stage 71.0 (TID 147) in 52 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:51.049+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_230_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.050+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_234_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.052+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_240_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.056+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_248_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.061+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 9.0 in stage 71.0 (TID 149) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.061+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 8.0 in stage 71.0 (TID 148) in 36 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:51.076+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_230_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.078+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_234_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.080+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_240_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.083+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_248_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 9.0 in stage 71.0 (TID 149) in 27 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: ShuffleMapStage 71 (mapPartitions at GraphImpl.scala:208) finished in 0.404 s
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: waiting: Set(ResultStage 72)
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:51.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[258] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T23:25:51.090+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 11.2 KiB, free 417.6 MiB)
[2025-05-07T23:25:51.090+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.6 MiB)
[2025-05-07T23:25:51.091+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 3530b0b864fd:41807 (size: 5.3 KiB, free: 433.4 MiB)
[2025-05-07T23:25:51.091+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:51.091+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 72 (MapPartitionsRDD[258] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:51.091+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Adding task set 72.0 with 10 tasks resource profile 0
[2025-05-07T23:25:51.092+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 150) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.101+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.20.0.5:40779 (size: 5.3 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.143+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.20.0.5:47382
[2025-05-07T23:25:51.147+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_0 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.149+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 151) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.149+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 150) in 57 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:51.154+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_1 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.157+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 152) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.157+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 151) in 8 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:51.164+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_2 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.166+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 153) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.166+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 152) in 10 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:51.172+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_3 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.174+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 4.0 in stage 72.0 (TID 154) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.174+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 153) in 8 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:51.179+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_4 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.182+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 5.0 in stage 72.0 (TID 155) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.182+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 4.0 in stage 72.0 (TID 154) in 8 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:51.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_5 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.189+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 6.0 in stage 72.0 (TID 156) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.190+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 5.0 in stage 72.0 (TID 155) in 8 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:51.195+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_6 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.197+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 7.0 in stage 72.0 (TID 157) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.197+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 6.0 in stage 72.0 (TID 156) in 8 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:51.202+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_7 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.205+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 8.0 in stage 72.0 (TID 158) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.205+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 7.0 in stage 72.0 (TID 157) in 9 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:51.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_8 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.212+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 9.0 in stage 72.0 (TID 159) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4588 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.213+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 8.0 in stage 72.0 (TID 158) in 8 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:51.218+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_256_9 in memory on 172.20.0.5:40779 (size: 4.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 9.0 in stage 72.0 (TID 159) in 8 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:51.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-05-07T23:25:51.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: ResultStage 72 (fold at VertexRDDImpl.scala:90) finished in 0.131 s
[2025-05-07T23:25:51.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:51.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-05-07T23:25:51.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Job 35 finished: fold at VertexRDDImpl.scala:90, took 413.411182 s
[2025-05-07T23:25:51.222+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO ZippedPartitionsRDD2: Removing RDD 256 from persistence list
[2025-05-07T23:25:51.226+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManager: Removing RDD 256
[2025-05-07T23:25:51.451+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:51.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Registering RDD 261 (mapPartitions at GraphImpl.scala:208) as input to shuffle 30
[2025-05-07T23:25:51.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Registering RDD 269 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 29
[2025-05-07T23:25:51.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Registering RDD 279 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 31
[2025-05-07T23:25:51.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Registering RDD 283 (mapPartitions at GraphImpl.scala:208) as input to shuffle 33
[2025-05-07T23:25:51.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Registering RDD 291 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 32
[2025-05-07T23:25:51.453+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Got job 36 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:51.453+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Final stage: ResultStage 81 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:51.453+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78, ShuffleMapStage 73, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T23:25:51.453+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T23:25:51.454+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[261] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:51.458+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 161.0 KiB, free 417.4 MiB)
[2025-05-07T23:25:51.477+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 56.7 KiB, free 417.3 MiB)
[2025-05-07T23:25:51.478+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 3530b0b864fd:41807 (size: 56.7 KiB, free: 433.3 MiB)
[2025-05-07T23:25:51.478+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 3530b0b864fd:41807 in memory (size: 5.0 KiB, free: 433.4 MiB)
[2025-05-07T23:25:51.478+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:51.478+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 75 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[261] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:51.478+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Adding task set 75.0 with 10 tasks resource profile 0
[2025-05-07T23:25:51.479+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 160) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.481+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.20.0.5:40779 in memory (size: 5.0 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.484+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 3530b0b864fd:41807 in memory (size: 5.3 KiB, free: 433.4 MiB)
[2025-05-07T23:25:51.486+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.20.0.5:40779 in memory (size: 5.3 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.487+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.20.0.5:40779 (size: 56.7 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.494+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.20.0.5:40779 in memory (size: 26.0 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.496+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 3530b0b864fd:41807 in memory (size: 26.0 KiB, free: 433.4 MiB)
[2025-05-07T23:25:51.507+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 3530b0b864fd:41807 in memory (size: 4.9 KiB, free: 433.4 MiB)
[2025-05-07T23:25:51.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.20.0.5:40779 in memory (size: 4.9 KiB, free: 433.6 MiB)
[2025-05-07T23:25:51.529+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 161) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.531+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 160) in 52 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:51.547+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 162) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.548+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManager: Removing RDD 256
[2025-05-07T23:25:51.549+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 161) in 20 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:51.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.20.0.5:40779 in memory (size: 6.7 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.558+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 3530b0b864fd:41807 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:51.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 163) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 162) in 31 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:51.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 3530b0b864fd:41807 in memory (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:51.582+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.20.0.5:40779 in memory (size: 57.7 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.586+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 3530b0b864fd:41807 in memory (size: 55.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:51.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.20.0.5:40779 in memory (size: 55.7 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 4.0 in stage 75.0 (TID 164) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.588+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 163) in 12 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:51.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManager: Removing RDD 248
[2025-05-07T23:25:51.599+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 5.0 in stage 75.0 (TID 165) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.599+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 4.0 in stage 75.0 (TID 164) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:51.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 6.0 in stage 75.0 (TID 166) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 5.0 in stage 75.0 (TID 165) in 12 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:51.620+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 7.0 in stage 75.0 (TID 167) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.621+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 6.0 in stage 75.0 (TID 166) in 10 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:51.629+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 8.0 in stage 75.0 (TID 168) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.630+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 7.0 in stage 75.0 (TID 167) in 10 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:51.638+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 9.0 in stage 75.0 (TID 169) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.639+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 8.0 in stage 75.0 (TID 168) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:51.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 9.0 in stage 75.0 (TID 169) in 9 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:51.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-05-07T23:25:51.648+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: ShuffleMapStage 75 (mapPartitions at GraphImpl.scala:208) finished in 0.193 s
[2025-05-07T23:25:51.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:51.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:51.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 78, ShuffleMapStage 79, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-05-07T23:25:51.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:51.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[279] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:51.655+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 10.7 KiB, free 417.9 MiB)
[2025-05-07T23:25:51.656+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 417.9 MiB)
[2025-05-07T23:25:51.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 3530b0b864fd:41807 (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T23:25:51.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:51.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 78 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[279] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:51.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Adding task set 78.0 with 10 tasks resource profile 0
[2025-05-07T23:25:51.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[269] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:51.659+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 170) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.660+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 10.1 KiB, free 417.9 MiB)
[2025-05-07T23:25:51.661+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 417.9 MiB)
[2025-05-07T23:25:51.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 3530b0b864fd:41807 (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T23:25:51.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:51.662+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 77 (ReplicatedVertexView.upgrade(true, false) - shippedVerts true false (broadcast) MapPartitionsRDD[269] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:51.663+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSchedulerImpl: Adding task set 77.0 with 10 tasks resource profile 0
[2025-05-07T23:25:51.666+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.20.0.5:40779 (size: 5.3 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.693+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.20.0.5:47382
[2025-05-07T23:25:51.714+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_265_0 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.733+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_275_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.763+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 171) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.764+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 170) in 105 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:51.777+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.20.0.5:40779 (size: 5.0 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.785+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 172) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.785+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 171) in 25 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:51.828+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_265_1 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.834+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 173) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.834+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 172) in 49 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:51.850+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_265_2 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 174) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 173) in 28 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:51.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_265_3 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.8 MiB)
[2025-05-07T23:25:51.881+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 4.0 in stage 77.0 (TID 175) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.881+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 174) in 21 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:51.890+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_265_4 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.895+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 5.0 in stage 77.0 (TID 176) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.895+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 4.0 in stage 77.0 (TID 175) in 15 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:51.904+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_265_5 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.910+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 6.0 in stage 77.0 (TID 177) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.911+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 5.0 in stage 77.0 (TID 176) in 17 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:51.938+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO BlockManagerInfo: Added rdd_265_6 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:51.946+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Starting task 7.0 in stage 77.0 (TID 178) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:51.947+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:51 INFO TaskSetManager: Finished task 6.0 in stage 77.0 (TID 177) in 37 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:52.030+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_265_7 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.054+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 8.0 in stage 77.0 (TID 179) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.054+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 7.0 in stage 77.0 (TID 178) in 108 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:52.066+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_265_8 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.073+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 9.0 in stage 77.0 (TID 180) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.073+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 8.0 in stage 77.0 (TID 179) in 20 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:52.081+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_265_9 in memory on 172.20.0.5:40779 (size: 4.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.086+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 181) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.086+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 9.0 in stage 77.0 (TID 180) in 13 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:52.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-05-07T23:25:52.088+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: ShuffleMapStage 77 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.427 s
[2025-05-07T23:25:52.089+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:52.089+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: running: Set(ShuffleMapStage 78)
[2025-05-07T23:25:52.089+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T23:25:52.089+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:52.104+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.110+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 182) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.110+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 181) in 24 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:52.133+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.139+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 183) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.139+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 182) in 29 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:52.144+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.156+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 4.0 in stage 78.0 (TID 184) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.156+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 183) in 17 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:52.161+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.165+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 5.0 in stage 78.0 (TID 185) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.166+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 4.0 in stage 78.0 (TID 184) in 9 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:52.170+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.174+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 6.0 in stage 78.0 (TID 186) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.174+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 5.0 in stage 78.0 (TID 185) in 9 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:52.178+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.182+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 7.0 in stage 78.0 (TID 187) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.182+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 6.0 in stage 78.0 (TID 186) in 8 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:52.186+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.190+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 8.0 in stage 78.0 (TID 188) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.190+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 7.0 in stage 78.0 (TID 187) in 7 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:52.194+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.199+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 9.0 in stage 78.0 (TID 189) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4609 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.200+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 8.0 in stage 78.0 (TID 188) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:52.204+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_275_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:25:52.211+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Finished task 9.0 in stage 78.0 (TID 189) in 12 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:52.212+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-05-07T23:25:52.212+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: ShuffleMapStage 78 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.562 s
[2025-05-07T23:25:52.212+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:52.212+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:52.212+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-05-07T23:25:52.212+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:52.213+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: Submitting ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[283] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:52.299+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 163.7 KiB, free 417.7 MiB)
[2025-05-07T23:25:52.373+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T23:25:52.376+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 3530b0b864fd:41807 (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T23:25:52.412+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:52.430+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 79 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[283] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:52.431+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSchedulerImpl: Adding task set 79.0 with 10 tasks resource profile 0
[2025-05-07T23:25:52.438+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 190) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:52.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.20.0.5:40779 (size: 58.0 KiB, free: 433.6 MiB)
[2025-05-07T23:25:52.963+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO BlockManagerInfo: Added rdd_267_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.002+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.20.0.5:47382
[2025-05-07T23:25:53.164+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.177+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:47382
[2025-05-07T23:25:53.255+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 191) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.260+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 190) in 827 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:53.291+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.294+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.297+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 2.0 in stage 79.0 (TID 192) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.298+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 191) in 63 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:53.438+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.455+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 3.0 in stage 79.0 (TID 193) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.489+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 2.0 in stage 79.0 (TID 192) in 192 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:53.542+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.558+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.562+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 4.0 in stage 79.0 (TID 194) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 3.0 in stage 79.0 (TID 193) in 110 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:53.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.818+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.818+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 5.0 in stage 79.0 (TID 195) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.818+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 4.0 in stage 79.0 (TID 194) in 256 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:53.830+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.834+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.842+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 6.0 in stage 79.0 (TID 196) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.843+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 5.0 in stage 79.0 (TID 195) in 28 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:53.852+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.856+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 7.0 in stage 79.0 (TID 197) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 6.0 in stage 79.0 (TID 196) in 19 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:53.870+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.877+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 8.0 in stage 79.0 (TID 198) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.877+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 7.0 in stage 79.0 (TID 197) in 17 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:53.886+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.889+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 9.0 in stage 79.0 (TID 199) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4825 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 8.0 in stage 79.0 (TID 198) in 17 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:53.904+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_267_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.908+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_277_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.913+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 9.0 in stage 79.0 (TID 199) in 20 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:53.914+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-05-07T23:25:53.917+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO DAGScheduler: ShuffleMapStage 79 (mapPartitions at GraphImpl.scala:208) finished in 1.693 s
[2025-05-07T23:25:53.917+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:53.917+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:53.917+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO DAGScheduler: waiting: Set(ResultStage 81, ShuffleMapStage 80)
[2025-05-07T23:25:53.917+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:53.918+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[291] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:53.923+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 12.0 KiB, free 417.7 MiB)
[2025-05-07T23:25:53.942+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 417.6 MiB)
[2025-05-07T23:25:53.942+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 3530b0b864fd:41807 (size: 5.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:53.943+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:53.945+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 80 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[291] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:53.945+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSchedulerImpl: Adding task set 80.0 with 10 tasks resource profile 0
[2025-05-07T23:25:53.946+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 200) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.952+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.20.0.5:40779 (size: 5.7 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.961+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.20.0.5:47382
[2025-05-07T23:25:53.990+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO BlockManagerInfo: Added rdd_287_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:53.995+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 201) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:53.995+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:53 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 200) in 50 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:54.003+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.007+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 202) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.007+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 201) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:54.014+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.018+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 203) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.019+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 202) in 12 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:54.026+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.032+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 4.0 in stage 80.0 (TID 204) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.032+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 203) in 14 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:54.039+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.043+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 5.0 in stage 80.0 (TID 205) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.044+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 4.0 in stage 80.0 (TID 204) in 13 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:54.053+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.057+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 6.0 in stage 80.0 (TID 206) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.058+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 5.0 in stage 80.0 (TID 205) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:54.067+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.074+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 7.0 in stage 80.0 (TID 207) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.075+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 6.0 in stage 80.0 (TID 206) in 18 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:54.084+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.090+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 8.0 in stage 80.0 (TID 208) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.090+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 7.0 in stage 80.0 (TID 207) in 16 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:54.099+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.105+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 9.0 in stage 80.0 (TID 209) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4714 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.106+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 8.0 in stage 80.0 (TID 208) in 17 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:54.115+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_287_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.121+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 9.0 in stage 80.0 (TID 209) in 16 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:54.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool
[2025-05-07T23:25:54.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: ShuffleMapStage 80 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.203 s
[2025-05-07T23:25:54.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:54.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:54.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: waiting: Set(ResultStage 81)
[2025-05-07T23:25:54.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:54.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting ResultStage 81 (EdgeRDDImpl[294] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:54.128+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 163.5 KiB, free 417.5 MiB)
[2025-05-07T23:25:54.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 57.7 KiB, free 417.4 MiB)
[2025-05-07T23:25:54.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 3530b0b864fd:41807 (size: 57.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.134+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:54.135+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 81 (EdgeRDDImpl[294] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:54.135+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Adding task set 81.0 with 10 tasks resource profile 0
[2025-05-07T23:25:54.135+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 210) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.147+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.20.0.5:40779 (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.167+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.20.0.5:47382
[2025-05-07T23:25:54.172+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.20.0.5:47382
[2025-05-07T23:25:54.179+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.183+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 211) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.193+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.194+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 210) in 58 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:54.196+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 212) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.196+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 211) in 14 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:54.205+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 213) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 212) in 13 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:54.218+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 4.0 in stage 81.0 (TID 214) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 213) in 13 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:54.230+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.233+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 5.0 in stage 81.0 (TID 215) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.233+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 4.0 in stage 81.0 (TID 214) in 13 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:54.243+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.246+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 6.0 in stage 81.0 (TID 216) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.246+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 5.0 in stage 81.0 (TID 215) in 13 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:54.256+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.259+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 7.0 in stage 81.0 (TID 217) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.259+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 6.0 in stage 81.0 (TID 216) in 14 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:54.281+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.283+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 8.0 in stage 81.0 (TID 218) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.284+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 7.0 in stage 81.0 (TID 217) in 26 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:54.304+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 9.0 in stage 81.0 (TID 219) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4877 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.307+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 8.0 in stage 81.0 (TID 218) in 24 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:54.316+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_293_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.319+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 9.0 in stage 81.0 (TID 219) in 12 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:54.319+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-05-07T23:25:54.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: ResultStage 81 (foreachPartition at PageRank.scala:199) finished in 0.197 s
[2025-05-07T23:25:54.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:54.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
[2025-05-07T23:25:54.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Job 36 finished: foreachPartition at PageRank.scala:199, took 2.868637 s
[2025-05-07T23:25:54.325+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO PageRank: PageRank finished iteration 0.
[2025-05-07T23:25:54.325+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MapPartitionsRDD: Removing RDD 275 from persistence list
[2025-05-07T23:25:54.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MapPartitionsRDD: Removing RDD 277 from persistence list
[2025-05-07T23:25:54.331+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManager: Removing RDD 275
[2025-05-07T23:25:54.331+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManager: Removing RDD 277
[2025-05-07T23:25:54.342+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:54.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Registering RDD 295 (mapPartitions at GraphImpl.scala:208) as input to shuffle 35
[2025-05-07T23:25:54.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Registering RDD 303 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 34
[2025-05-07T23:25:54.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Got job 37 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:54.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Final stage: ResultStage 92 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:54.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82, ShuffleMapStage 89, ShuffleMapStage 86, ShuffleMapStage 87, ShuffleMapStage 91)
[2025-05-07T23:25:54.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
[2025-05-07T23:25:54.347+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[295] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:54.350+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 164.0 KiB, free 417.3 MiB)
[2025-05-07T23:25:54.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.2 MiB)
[2025-05-07T23:25:54.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 3530b0b864fd:41807 (size: 58.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:54.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:54.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 90 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[295] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:54.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Adding task set 90.0 with 10 tasks resource profile 0
[2025-05-07T23:25:54.354+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 220) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.360+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.20.0.5:40779 (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.368+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 221) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.368+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 220) in 14 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:54.378+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 222) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.378+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 221) in 11 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:54.391+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 223) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.391+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 222) in 14 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:54.404+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 4.0 in stage 90.0 (TID 224) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.405+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 223) in 14 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:54.413+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 5.0 in stage 90.0 (TID 225) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.414+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 4.0 in stage 90.0 (TID 224) in 9 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:54.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 6.0 in stage 90.0 (TID 226) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 5.0 in stage 90.0 (TID 225) in 13 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:54.438+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 7.0 in stage 90.0 (TID 227) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.438+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 6.0 in stage 90.0 (TID 226) in 13 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:54.450+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 8.0 in stage 90.0 (TID 228) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.450+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 7.0 in stage 90.0 (TID 227) in 13 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:54.461+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 9.0 in stage 90.0 (TID 229) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4866 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.462+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 8.0 in stage 90.0 (TID 228) in 13 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:54.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 9.0 in stage 90.0 (TID 229) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:54.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-05-07T23:25:54.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: ShuffleMapStage 90 (mapPartitions at GraphImpl.scala:208) finished in 0.126 s
[2025-05-07T23:25:54.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:54.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:54.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: waiting: Set(ShuffleMapStage 91, ResultStage 92)
[2025-05-07T23:25:54.473+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:54.474+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[303] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:54.475+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 12.8 KiB, free 417.2 MiB)
[2025-05-07T23:25:54.490+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 417.2 MiB)
[2025-05-07T23:25:54.490+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 3530b0b864fd:41807 (size: 5.9 KiB, free: 433.3 MiB)
[2025-05-07T23:25:54.491+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:54.491+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 91 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[303] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:54.491+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Adding task set 91.0 with 10 tasks resource profile 0
[2025-05-07T23:25:54.492+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 3530b0b864fd:41807 in memory (size: 56.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.493+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.20.0.5:40779 in memory (size: 56.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.493+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 230) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.499+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.20.0.5:40779 in memory (size: 58.0 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.500+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 3530b0b864fd:41807 in memory (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.504+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.20.0.5:40779 (size: 5.9 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.506+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 3530b0b864fd:41807 in memory (size: 57.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.509+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.20.0.5:40779 in memory (size: 57.7 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.511+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.20.0.5:47382
[2025-05-07T23:25:54.514+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 3530b0b864fd:41807 in memory (size: 5.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.516+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.20.0.5:40779 in memory (size: 5.7 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.519+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.521+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 3530b0b864fd:41807 in memory (size: 5.0 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.522+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.20.0.5:40779 in memory (size: 5.0 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.537+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 231) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.538+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 230) in 45 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:54.538+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 3530b0b864fd:41807 in memory (size: 5.3 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.541+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.20.0.5:40779 in memory (size: 5.3 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.547+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.552+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 2.0 in stage 91.0 (TID 232) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.553+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 231) in 16 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:54.559+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.563+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 3.0 in stage 91.0 (TID 233) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.564+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 2.0 in stage 91.0 (TID 232) in 11 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:54.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.576+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 4.0 in stage 91.0 (TID 234) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.576+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 3.0 in stage 91.0 (TID 233) in 13 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:54.583+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 5.0 in stage 91.0 (TID 235) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 4.0 in stage 91.0 (TID 234) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:54.593+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.598+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 6.0 in stage 91.0 (TID 236) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.598+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 5.0 in stage 91.0 (TID 235) in 12 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:54.604+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.608+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 7.0 in stage 91.0 (TID 237) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.608+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 6.0 in stage 91.0 (TID 236) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:54.615+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.619+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 8.0 in stage 91.0 (TID 238) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.619+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 7.0 in stage 91.0 (TID 237) in 12 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:54.625+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.629+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 9.0 in stage 91.0 (TID 239) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4787 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.629+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 8.0 in stage 91.0 (TID 238) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:54.636+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_299_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:54.640+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 9.0 in stage 91.0 (TID 239) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:54.640+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-05-07T23:25:54.640+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: ShuffleMapStage 91 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.166 s
[2025-05-07T23:25:54.640+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:54.641+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:54.641+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: waiting: Set(ResultStage 92)
[2025-05-07T23:25:54.641+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:54.641+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting ResultStage 92 (EdgeRDDImpl[306] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:54.644+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 163.8 KiB, free 417.7 MiB)
[2025-05-07T23:25:54.645+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 57.8 KiB, free 417.7 MiB)
[2025-05-07T23:25:54.645+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 3530b0b864fd:41807 (size: 57.8 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:54.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 92 (EdgeRDDImpl[306] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:54.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Adding task set 92.0 with 10 tasks resource profile 0
[2025-05-07T23:25:54.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 240) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.653+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.20.0.5:40779 (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.20.0.5:47382
[2025-05-07T23:25:54.661+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.663+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 241) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.664+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 240) in 17 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:54.671+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.673+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 242) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.674+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 241) in 10 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:54.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.685+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 243) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.685+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 242) in 12 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:54.698+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.732+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 4.0 in stage 92.0 (TID 244) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.732+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 243) in 47 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:54.742+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.744+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 5.0 in stage 92.0 (TID 245) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.745+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 4.0 in stage 92.0 (TID 244) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:54.757+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.760+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 6.0 in stage 92.0 (TID 246) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.769+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 5.0 in stage 92.0 (TID 245) in 25 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:54.771+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.773+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 7.0 in stage 92.0 (TID 247) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.774+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 6.0 in stage 92.0 (TID 246) in 14 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:54.785+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.787+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 8.0 in stage 92.0 (TID 248) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.788+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 7.0 in stage 92.0 (TID 247) in 14 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:54.802+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.805+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 9.0 in stage 92.0 (TID 249) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4918 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 8.0 in stage 92.0 (TID 248) in 19 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:54.817+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added rdd_305_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.820+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 9.0 in stage 92.0 (TID 249) in 15 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:54.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool
[2025-05-07T23:25:54.823+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: ResultStage 92 (foreachPartition at PageRank.scala:199) finished in 0.179 s
[2025-05-07T23:25:54.824+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:54.824+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
[2025-05-07T23:25:54.824+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Job 37 finished: foreachPartition at PageRank.scala:199, took 0.482040 s
[2025-05-07T23:25:54.825+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO PageRank: PageRank finished iteration 1.
[2025-05-07T23:25:54.825+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO ZippedPartitionsRDD2: Removing RDD 287 from persistence list
[2025-05-07T23:25:54.830+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO ZippedPartitionsRDD2: Removing RDD 293 from persistence list
[2025-05-07T23:25:54.846+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManager: Removing RDD 287
[2025-05-07T23:25:54.846+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManager: Removing RDD 293
[2025-05-07T23:25:54.869+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:54.871+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Registering RDD 307 (mapPartitions at GraphImpl.scala:208) as input to shuffle 37
[2025-05-07T23:25:54.871+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Registering RDD 315 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 36
[2025-05-07T23:25:54.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Got job 38 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:54.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Final stage: ResultStage 105 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:54.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102, ShuffleMapStage 100, ShuffleMapStage 104, ShuffleMapStage 93, ShuffleMapStage 97, ShuffleMapStage 98)
[2025-05-07T23:25:54.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
[2025-05-07T23:25:54.879+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[307] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:54.885+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 164.3 KiB, free 417.5 MiB)
[2025-05-07T23:25:54.889+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 417.5 MiB)
[2025-05-07T23:25:54.890+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 3530b0b864fd:41807 (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T23:25:54.890+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:54.891+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 103 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[307] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:54.891+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Adding task set 103.0 with 10 tasks resource profile 0
[2025-05-07T23:25:54.891+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 250) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.905+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.20.0.5:40779 (size: 58.4 KiB, free: 433.5 MiB)
[2025-05-07T23:25:54.914+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 251) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.915+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 250) in 24 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:54.924+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 2.0 in stage 103.0 (TID 252) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.925+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 251) in 10 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:54.933+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 3.0 in stage 103.0 (TID 253) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.933+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 2.0 in stage 103.0 (TID 252) in 9 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:54.945+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 4.0 in stage 103.0 (TID 254) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.945+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 3.0 in stage 103.0 (TID 253) in 12 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:54.953+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 5.0 in stage 103.0 (TID 255) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.953+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 4.0 in stage 103.0 (TID 254) in 8 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:54.960+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 6.0 in stage 103.0 (TID 256) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.960+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 5.0 in stage 103.0 (TID 255) in 8 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:54.971+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 7.0 in stage 103.0 (TID 257) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.971+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 6.0 in stage 103.0 (TID 256) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:54.980+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 8.0 in stage 103.0 (TID 258) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.980+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 7.0 in stage 103.0 (TID 257) in 10 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:54.988+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Starting task 9.0 in stage 103.0 (TID 259) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4907 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:54.988+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 8.0 in stage 103.0 (TID 258) in 8 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:54.995+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSetManager: Finished task 9.0 in stage 103.0 (TID 259) in 8 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:54.997+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:54 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-05-07T23:25:55.001+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: ShuffleMapStage 103 (mapPartitions at GraphImpl.scala:208) finished in 0.116 s
[2025-05-07T23:25:55.002+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:55.002+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:55.002+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 104, ResultStage 105)
[2025-05-07T23:25:55.002+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:55.004+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[315] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:55.033+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 13.5 KiB, free 417.4 MiB)
[2025-05-07T23:25:55.040+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.4 MiB)
[2025-05-07T23:25:55.041+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 3530b0b864fd:41807 (size: 6.1 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.044+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:55.048+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 104 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[315] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:55.048+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Adding task set 104.0 with 10 tasks resource profile 0
[2025-05-07T23:25:55.049+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 260) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.089+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.20.0.5:40779 (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.102+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.20.0.5:47382
[2025-05-07T23:25:55.119+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.127+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 261) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.128+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 260) in 78 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:55.133+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.136+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 262) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.136+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 261) in 9 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:55.141+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.144+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 263) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.145+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 262) in 8 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:55.149+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.153+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 4.0 in stage 104.0 (TID 264) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.153+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 263) in 9 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:55.158+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.161+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 5.0 in stage 104.0 (TID 265) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.162+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 4.0 in stage 104.0 (TID 264) in 10 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:55.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.176+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 6.0 in stage 104.0 (TID 266) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.177+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 5.0 in stage 104.0 (TID 265) in 15 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:55.183+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 7.0 in stage 104.0 (TID 267) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 6.0 in stage 104.0 (TID 266) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:55.195+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.199+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 8.0 in stage 104.0 (TID 268) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.200+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 7.0 in stage 104.0 (TID 267) in 12 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:55.206+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 9.0 in stage 104.0 (TID 269) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4860 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 8.0 in stage 104.0 (TID 268) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:55.217+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_311_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 9.0 in stage 104.0 (TID 269) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:55.222+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool
[2025-05-07T23:25:55.224+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: ShuffleMapStage 104 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.214 s
[2025-05-07T23:25:55.224+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:55.224+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:55.224+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: waiting: Set(ResultStage 105)
[2025-05-07T23:25:55.224+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:55.225+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting ResultStage 105 (EdgeRDDImpl[318] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:55.236+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 164.1 KiB, free 417.3 MiB)
[2025-05-07T23:25:55.238+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 57.8 KiB, free 417.2 MiB)
[2025-05-07T23:25:55.238+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 3530b0b864fd:41807 (size: 57.8 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.241+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:55.243+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 105 (EdgeRDDImpl[318] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:55.243+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Adding task set 105.0 with 10 tasks resource profile 0
[2025-05-07T23:25:55.243+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 270) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.251+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.20.0.5:40779 (size: 57.8 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.257+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.20.0.5:47382
[2025-05-07T23:25:55.261+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 271) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.264+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 270) in 20 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:55.280+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.283+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 272) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.284+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 271) in 20 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:55.302+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 273) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.305+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 272) in 22 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:55.315+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.317+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 4.0 in stage 105.0 (TID 274) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.317+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 273) in 13 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:55.326+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.329+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 5.0 in stage 105.0 (TID 275) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.329+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 4.0 in stage 105.0 (TID 274) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:55.338+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.340+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 6.0 in stage 105.0 (TID 276) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.340+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 5.0 in stage 105.0 (TID 275) in 12 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:55.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.355+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 7.0 in stage 105.0 (TID 277) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.355+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 6.0 in stage 105.0 (TID 276) in 15 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:55.364+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.367+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 8.0 in stage 105.0 (TID 278) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.367+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 7.0 in stage 105.0 (TID 277) in 12 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:55.375+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.377+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 9.0 in stage 105.0 (TID 279) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4959 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.377+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 8.0 in stage 105.0 (TID 278) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:55.386+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_317_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.388+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 9.0 in stage 105.0 (TID 279) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:55.389+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-05-07T23:25:55.389+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: ResultStage 105 (foreachPartition at PageRank.scala:199) finished in 0.161 s
[2025-05-07T23:25:55.389+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:55.389+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
[2025-05-07T23:25:55.389+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Job 38 finished: foreachPartition at PageRank.scala:199, took 0.520601 s
[2025-05-07T23:25:55.389+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO PageRank: PageRank finished iteration 2.
[2025-05-07T23:25:55.390+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO ZippedPartitionsRDD2: Removing RDD 299 from persistence list
[2025-05-07T23:25:55.391+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO ZippedPartitionsRDD2: Removing RDD 305 from persistence list
[2025-05-07T23:25:55.399+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManager: Removing RDD 299
[2025-05-07T23:25:55.399+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManager: Removing RDD 305
[2025-05-07T23:25:55.415+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:55.417+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Registering RDD 319 (mapPartitions at GraphImpl.scala:208) as input to shuffle 39
[2025-05-07T23:25:55.417+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Registering RDD 327 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 38
[2025-05-07T23:25:55.417+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Got job 39 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:55.418+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Final stage: ResultStage 120 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:55.418+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 117, ShuffleMapStage 115, ShuffleMapStage 119, ShuffleMapStage 111, ShuffleMapStage 106, ShuffleMapStage 113, ShuffleMapStage 110)
[2025-05-07T23:25:55.418+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
[2025-05-07T23:25:55.421+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[319] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:55.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 164.6 KiB, free 417.1 MiB)
[2025-05-07T23:25:55.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.0 MiB)
[2025-05-07T23:25:55.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 3530b0b864fd:41807 (size: 58.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.427+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:55.430+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 118 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[319] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:55.430+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Adding task set 118.0 with 10 tasks resource profile 0
[2025-05-07T23:25:55.431+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 280) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.436+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.20.0.5:40779 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.444+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 281) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.445+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 280) in 13 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:55.460+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 2.0 in stage 118.0 (TID 282) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.461+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 281) in 16 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:55.471+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 3.0 in stage 118.0 (TID 283) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.471+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 2.0 in stage 118.0 (TID 282) in 11 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:55.479+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 4.0 in stage 118.0 (TID 284) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.480+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 3.0 in stage 118.0 (TID 283) in 9 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:55.487+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 5.0 in stage 118.0 (TID 285) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.487+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 4.0 in stage 118.0 (TID 284) in 8 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:55.495+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 6.0 in stage 118.0 (TID 286) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.495+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 5.0 in stage 118.0 (TID 285) in 8 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:55.503+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 7.0 in stage 118.0 (TID 287) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.503+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 6.0 in stage 118.0 (TID 286) in 9 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:55.511+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 8.0 in stage 118.0 (TID 288) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.511+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 7.0 in stage 118.0 (TID 287) in 9 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:55.518+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 9.0 in stage 118.0 (TID 289) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4948 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.519+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 8.0 in stage 118.0 (TID 288) in 7 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:55.526+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 9.0 in stage 118.0 (TID 289) in 8 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:55.526+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-05-07T23:25:55.526+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: ShuffleMapStage 118 (mapPartitions at GraphImpl.scala:208) finished in 0.105 s
[2025-05-07T23:25:55.526+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:55.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:55.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 119, ResultStage 120)
[2025-05-07T23:25:55.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:55.527+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[327] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:55.529+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 14.2 KiB, free 417.0 MiB)
[2025-05-07T23:25:55.530+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 417.0 MiB)
[2025-05-07T23:25:55.530+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 3530b0b864fd:41807 (size: 6.1 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.530+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:55.530+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 119 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[327] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:55.530+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Adding task set 119.0 with 10 tasks resource profile 0
[2025-05-07T23:25:55.531+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 290) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.536+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.20.0.5:40779 (size: 6.1 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.539+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.20.0.5:47382
[2025-05-07T23:25:55.546+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.549+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 291) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.550+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 290) in 19 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:55.561+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.565+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 2.0 in stage 119.0 (TID 292) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.565+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 291) in 16 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:55.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.575+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 3.0 in stage 119.0 (TID 293) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.575+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 2.0 in stage 119.0 (TID 292) in 10 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:55.581+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.585+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 4.0 in stage 119.0 (TID 294) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.585+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 3.0 in stage 119.0 (TID 293) in 11 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:55.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.594+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 5.0 in stage 119.0 (TID 295) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.595+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 4.0 in stage 119.0 (TID 294) in 10 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:55.600+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.604+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 6.0 in stage 119.0 (TID 296) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 5.0 in stage 119.0 (TID 295) in 10 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:55.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.615+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 7.0 in stage 119.0 (TID 297) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.616+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 6.0 in stage 119.0 (TID 296) in 12 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:55.622+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.626+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 8.0 in stage 119.0 (TID 298) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.626+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 7.0 in stage 119.0 (TID 297) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:55.632+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.636+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 9.0 in stage 119.0 (TID 299) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4933 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.636+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 8.0 in stage 119.0 (TID 298) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:55.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_323_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 9.0 in stage 119.0 (TID 299) in 9 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:55.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-05-07T23:25:55.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: ShuffleMapStage 119 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.119 s
[2025-05-07T23:25:55.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:55.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:55.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: waiting: Set(ResultStage 120)
[2025-05-07T23:25:55.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:55.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting ResultStage 120 (EdgeRDDImpl[330] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:55.651+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 164.4 KiB, free 416.8 MiB)
[2025-05-07T23:25:55.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 57.8 KiB, free 416.8 MiB)
[2025-05-07T23:25:55.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 3530b0b864fd:41807 (size: 57.8 KiB, free: 433.2 MiB)
[2025-05-07T23:25:55.670+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 3530b0b864fd:41807 in memory (size: 58.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.670+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:55.670+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 120 (EdgeRDDImpl[330] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:55.670+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Adding task set 120.0 with 10 tasks resource profile 0
[2025-05-07T23:25:55.671+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 300) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.683+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.20.0.5:40779 (size: 57.8 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.683+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.20.0.5:40779 in memory (size: 58.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.687+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 3530b0b864fd:41807 in memory (size: 57.8 KiB, free: 433.3 MiB)
[2025-05-07T23:25:55.707+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.20.0.5:40779 in memory (size: 57.8 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.711+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 3530b0b864fd:41807 in memory (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.714+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.20.0.5:40779 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.718+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 3530b0b864fd:41807 in memory (size: 6.1 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.719+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.20.0.5:40779 in memory (size: 6.1 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.720+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.20.0.5:47382
[2025-05-07T23:25:55.724+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 3530b0b864fd:41807 in memory (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.727+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.20.0.5:40779 in memory (size: 58.4 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.727+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.730+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 301) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.731+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 300) in 59 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:55.732+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.20.0.5:40779 in memory (size: 5.9 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.740+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 3530b0b864fd:41807 in memory (size: 5.9 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.744+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.751+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.20.0.5:40779 in memory (size: 57.8 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.753+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 3530b0b864fd:41807 in memory (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-07T23:25:55.758+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 302) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.758+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 301) in 29 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:55.788+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.790+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 303) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.790+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 302) in 33 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:55.799+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.801+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 4.0 in stage 120.0 (TID 304) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.801+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 303) in 12 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:55.809+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.811+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 5.0 in stage 120.0 (TID 305) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.811+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 4.0 in stage 120.0 (TID 304) in 10 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:55.819+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 6.0 in stage 120.0 (TID 306) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 5.0 in stage 120.0 (TID 305) in 11 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:55.830+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.832+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 7.0 in stage 120.0 (TID 307) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.832+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 6.0 in stage 120.0 (TID 306) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:55.841+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.843+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 8.0 in stage 120.0 (TID 308) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.844+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 7.0 in stage 120.0 (TID 307) in 13 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:55.853+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.855+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 9.0 in stage 120.0 (TID 309) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5000 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:55.855+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 8.0 in stage 120.0 (TID 308) in 12 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:55.864+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added rdd_329_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.6 MiB)
[2025-05-07T23:25:55.866+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Finished task 9.0 in stage 120.0 (TID 309) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:55.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-05-07T23:25:55.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: ResultStage 120 (foreachPartition at PageRank.scala:199) finished in 0.220 s
[2025-05-07T23:25:55.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:55.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
[2025-05-07T23:25:55.869+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Job 39 finished: foreachPartition at PageRank.scala:199, took 0.454039 s
[2025-05-07T23:25:55.870+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO PageRank: PageRank finished iteration 3.
[2025-05-07T23:25:55.870+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO ZippedPartitionsRDD2: Removing RDD 311 from persistence list
[2025-05-07T23:25:55.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManager: Removing RDD 311
[2025-05-07T23:25:55.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO ZippedPartitionsRDD2: Removing RDD 317 from persistence list
[2025-05-07T23:25:55.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManager: Removing RDD 317
[2025-05-07T23:25:55.925+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:55.966+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Registering RDD 331 (mapPartitions at GraphImpl.scala:208) as input to shuffle 41
[2025-05-07T23:25:55.966+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Registering RDD 339 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 40
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Got job 40 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Final stage: ResultStage 137 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132, ShuffleMapStage 121, ShuffleMapStage 136, ShuffleMapStage 125, ShuffleMapStage 126, ShuffleMapStage 130, ShuffleMapStage 134, ShuffleMapStage 128)
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[331] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 164.9 KiB, free 417.7 MiB)
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 417.7 MiB)
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 3530b0b864fd:41807 (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 135 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[331] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSchedulerImpl: Adding task set 135.0 with 10 tasks resource profile 0
[2025-05-07T23:25:55.987+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:55 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 310) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.125+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.20.0.5:40779 (size: 58.4 KiB, free: 433.6 MiB)
[2025-05-07T23:25:56.135+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 311) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.135+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 310) in 154 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:56.144+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 312) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.144+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 311) in 11 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:56.152+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 313) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.152+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 312) in 9 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:56.231+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 4.0 in stage 135.0 (TID 314) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.234+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 313) in 82 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:56.242+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 5.0 in stage 135.0 (TID 315) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.242+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 4.0 in stage 135.0 (TID 314) in 13 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:56.248+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 6.0 in stage 135.0 (TID 316) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.248+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 5.0 in stage 135.0 (TID 315) in 7 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:56.256+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 7.0 in stage 135.0 (TID 317) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.257+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 6.0 in stage 135.0 (TID 316) in 8 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:56.265+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 8.0 in stage 135.0 (TID 318) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.265+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 7.0 in stage 135.0 (TID 317) in 9 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:56.272+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 9.0 in stage 135.0 (TID 319) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4989 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.272+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 8.0 in stage 135.0 (TID 318) in 8 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:56.279+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 9.0 in stage 135.0 (TID 319) in 7 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:56.281+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool
[2025-05-07T23:25:56.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at GraphImpl.scala:208) finished in 0.328 s
[2025-05-07T23:25:56.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:56.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:56.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 136, ResultStage 137)
[2025-05-07T23:25:56.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:56.290+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[339] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:56.303+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 14.9 KiB, free 417.7 MiB)
[2025-05-07T23:25:56.325+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 417.6 MiB)
[2025-05-07T23:25:56.326+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 3530b0b864fd:41807 (size: 6.3 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:56.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 136 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[339] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:56.328+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Adding task set 136.0 with 10 tasks resource profile 0
[2025-05-07T23:25:56.328+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 320) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.350+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.20.0.5:40779 (size: 6.3 KiB, free: 433.6 MiB)
[2025-05-07T23:25:56.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.20.0.5:47382
[2025-05-07T23:25:56.359+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:56.362+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 321) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.363+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 320) in 34 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:56.368+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:56.371+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 2.0 in stage 136.0 (TID 322) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.371+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 321) in 9 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:56.376+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:56.379+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 3.0 in stage 136.0 (TID 323) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.380+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 2.0 in stage 136.0 (TID 322) in 9 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:56.386+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:56.389+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 4.0 in stage 136.0 (TID 324) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.390+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 3.0 in stage 136.0 (TID 323) in 11 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:56.397+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.400+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 5.0 in stage 136.0 (TID 325) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.401+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 4.0 in stage 136.0 (TID 324) in 11 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:56.411+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.415+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 6.0 in stage 136.0 (TID 326) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.416+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 5.0 in stage 136.0 (TID 325) in 15 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:56.421+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 7.0 in stage 136.0 (TID 327) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 6.0 in stage 136.0 (TID 326) in 10 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:56.432+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.454+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 8.0 in stage 136.0 (TID 328) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.455+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 7.0 in stage 136.0 (TID 327) in 29 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:56.462+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.466+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 9.0 in stage 136.0 (TID 329) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5006 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.466+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 8.0 in stage 136.0 (TID 328) in 12 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:56.483+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_335_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 9.0 in stage 136.0 (TID 329) in 22 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:56.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool
[2025-05-07T23:25:56.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: ShuffleMapStage 136 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.197 s
[2025-05-07T23:25:56.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:56.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:56.489+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: waiting: Set(ResultStage 137)
[2025-05-07T23:25:56.489+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:56.489+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting ResultStage 137 (EdgeRDDImpl[342] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:56.494+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 164.7 KiB, free 417.5 MiB)
[2025-05-07T23:25:56.496+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.4 MiB)
[2025-05-07T23:25:56.496+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 3530b0b864fd:41807 (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.496+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:56.496+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 137 (EdgeRDDImpl[342] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:56.497+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Adding task set 137.0 with 10 tasks resource profile 0
[2025-05-07T23:25:56.497+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 330) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.501+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.20.0.5:40779 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.507+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.20.0.5:47382
[2025-05-07T23:25:56.511+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.513+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 331) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.513+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 330) in 16 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:56.523+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.525+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 332) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.525+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 331) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:56.534+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.536+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 333) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.537+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 332) in 12 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:56.545+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.547+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 4.0 in stage 137.0 (TID 334) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.547+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 333) in 11 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:56.555+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 5.0 in stage 137.0 (TID 335) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 4.0 in stage 137.0 (TID 334) in 11 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:56.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 6.0 in stage 137.0 (TID 336) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 5.0 in stage 137.0 (TID 335) in 13 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:56.578+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 7.0 in stage 137.0 (TID 337) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 6.0 in stage 137.0 (TID 336) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:56.588+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.590+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 8.0 in stage 137.0 (TID 338) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.590+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 7.0 in stage 137.0 (TID 337) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:56.598+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 9.0 in stage 137.0 (TID 339) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5041 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.601+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 8.0 in stage 137.0 (TID 338) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:56.608+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_341_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 9.0 in stage 137.0 (TID 339) in 10 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:56.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool
[2025-05-07T23:25:56.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: ResultStage 137 (foreachPartition at PageRank.scala:199) finished in 0.121 s
[2025-05-07T23:25:56.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:56.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
[2025-05-07T23:25:56.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Job 40 finished: foreachPartition at PageRank.scala:199, took 0.687583 s
[2025-05-07T23:25:56.612+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO PageRank: PageRank finished iteration 4.
[2025-05-07T23:25:56.612+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO ZippedPartitionsRDD2: Removing RDD 323 from persistence list
[2025-05-07T23:25:56.614+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManager: Removing RDD 323
[2025-05-07T23:25:56.614+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO ZippedPartitionsRDD2: Removing RDD 329 from persistence list
[2025-05-07T23:25:56.615+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManager: Removing RDD 329
[2025-05-07T23:25:56.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:56.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Registering RDD 343 (mapPartitions at GraphImpl.scala:208) as input to shuffle 43
[2025-05-07T23:25:56.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Registering RDD 351 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 42
[2025-05-07T23:25:56.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Got job 41 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:56.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Final stage: ResultStage 156 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:56.636+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143, ShuffleMapStage 153, ShuffleMapStage 147, ShuffleMapStage 151, ShuffleMapStage 155, ShuffleMapStage 138, ShuffleMapStage 145, ShuffleMapStage 142, ShuffleMapStage 149)
[2025-05-07T23:25:56.636+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
[2025-05-07T23:25:56.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[343] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:56.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 165.2 KiB, free 417.3 MiB)
[2025-05-07T23:25:56.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.2 MiB)
[2025-05-07T23:25:56.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 3530b0b864fd:41807 (size: 58.3 KiB, free: 433.3 MiB)
[2025-05-07T23:25:56.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:56.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 154 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[343] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:56.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Adding task set 154.0 with 10 tasks resource profile 0
[2025-05-07T23:25:56.651+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 340) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.665+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.20.0.5:40779 (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.674+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 341) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.675+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 340) in 24 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:56.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 2.0 in stage 154.0 (TID 342) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 341) in 8 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:56.690+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 3.0 in stage 154.0 (TID 343) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.690+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 2.0 in stage 154.0 (TID 342) in 9 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:56.697+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 4.0 in stage 154.0 (TID 344) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.697+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 3.0 in stage 154.0 (TID 343) in 8 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:56.704+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 5.0 in stage 154.0 (TID 345) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.705+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 4.0 in stage 154.0 (TID 344) in 7 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:56.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 6.0 in stage 154.0 (TID 346) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 5.0 in stage 154.0 (TID 345) in 8 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:56.719+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 7.0 in stage 154.0 (TID 347) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.720+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 6.0 in stage 154.0 (TID 346) in 8 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:56.728+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 8.0 in stage 154.0 (TID 348) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.729+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 7.0 in stage 154.0 (TID 347) in 9 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:56.736+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 9.0 in stage 154.0 (TID 349) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5030 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.736+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 8.0 in stage 154.0 (TID 348) in 8 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:56.746+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 9.0 in stage 154.0 (TID 349) in 10 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:56.746+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-05-07T23:25:56.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: ShuffleMapStage 154 (mapPartitions at GraphImpl.scala:208) finished in 0.104 s
[2025-05-07T23:25:56.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:56.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:56.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 155, ResultStage 156)
[2025-05-07T23:25:56.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:56.747+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[351] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:56.749+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 15.6 KiB, free 417.2 MiB)
[2025-05-07T23:25:56.750+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 417.2 MiB)
[2025-05-07T23:25:56.751+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 3530b0b864fd:41807 (size: 6.4 KiB, free: 433.3 MiB)
[2025-05-07T23:25:56.751+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:56.752+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 155 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[351] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:56.752+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Adding task set 155.0 with 10 tasks resource profile 0
[2025-05-07T23:25:56.752+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 350) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.759+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.20.0.5:40779 (size: 6.4 KiB, free: 433.5 MiB)
[2025-05-07T23:25:56.762+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.20.0.5:47382
[2025-05-07T23:25:56.770+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 351) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 350) in 23 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:56.781+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.785+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 352) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.785+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 351) in 11 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:56.791+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.795+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 353) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.795+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 352) in 10 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:56.802+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 4.0 in stage 155.0 (TID 354) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.806+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 353) in 11 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:56.813+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.817+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 5.0 in stage 155.0 (TID 355) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.818+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 4.0 in stage 155.0 (TID 354) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:56.823+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.860+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 6.0 in stage 155.0 (TID 356) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 5.0 in stage 155.0 (TID 355) in 43 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:56.866+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.871+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 7.0 in stage 155.0 (TID 357) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.871+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 6.0 in stage 155.0 (TID 356) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:56.877+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.881+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 8.0 in stage 155.0 (TID 358) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.881+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 7.0 in stage 155.0 (TID 357) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:56.890+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 9.0 in stage 155.0 (TID 359) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5079 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:56.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 8.0 in stage 155.0 (TID 358) in 13 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:56.900+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added rdd_347_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:56.904+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Finished task 9.0 in stage 155.0 (TID 359) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:56.904+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool
[2025-05-07T23:25:56.905+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: ShuffleMapStage 155 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.157 s
[2025-05-07T23:25:56.905+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:56.905+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:56.905+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: waiting: Set(ResultStage 156)
[2025-05-07T23:25:56.905+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:56.905+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting ResultStage 156 (EdgeRDDImpl[354] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:56.915+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 165.0 KiB, free 417.0 MiB)
[2025-05-07T23:25:56.927+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 58.1 KiB, free 417.0 MiB)
[2025-05-07T23:25:56.928+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 3530b0b864fd:41807 (size: 58.1 KiB, free: 433.3 MiB)
[2025-05-07T23:25:56.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:56.940+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 156 (EdgeRDDImpl[354] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:56.940+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSchedulerImpl: Adding task set 156.0 with 10 tasks resource profile 0
[2025-05-07T23:25:56.950+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:56 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 360) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.031+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.20.0.5:40779 (size: 58.1 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.040+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.20.0.5:47382
[2025-05-07T23:25:57.055+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.057+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 361) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.060+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 360) in 114 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:57.067+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.070+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 362) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.070+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 361) in 13 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:57.079+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.082+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 363) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.082+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 362) in 13 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:57.091+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.097+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 4.0 in stage 156.0 (TID 364) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.098+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 363) in 16 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:57.105+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.109+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 5.0 in stage 156.0 (TID 365) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.109+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 4.0 in stage 156.0 (TID 364) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:57.117+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 6.0 in stage 156.0 (TID 366) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.121+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 5.0 in stage 156.0 (TID 365) in 11 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:57.129+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.131+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 7.0 in stage 156.0 (TID 367) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.131+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 6.0 in stage 156.0 (TID 366) in 11 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:57.141+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.143+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 8.0 in stage 156.0 (TID 368) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.143+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 7.0 in stage 156.0 (TID 367) in 13 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:57.151+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.154+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 9.0 in stage 156.0 (TID 369) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5082 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.155+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 8.0 in stage 156.0 (TID 368) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:57.163+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_353_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.166+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 9.0 in stage 156.0 (TID 369) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:57.166+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool
[2025-05-07T23:25:57.166+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: ResultStage 156 (foreachPartition at PageRank.scala:199) finished in 0.260 s
[2025-05-07T23:25:57.167+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:57.167+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
[2025-05-07T23:25:57.167+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Job 41 finished: foreachPartition at PageRank.scala:199, took 0.534361 s
[2025-05-07T23:25:57.167+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO PageRank: PageRank finished iteration 5.
[2025-05-07T23:25:57.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO ZippedPartitionsRDD2: Removing RDD 335 from persistence list
[2025-05-07T23:25:57.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManager: Removing RDD 335
[2025-05-07T23:25:57.172+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO ZippedPartitionsRDD2: Removing RDD 341 from persistence list
[2025-05-07T23:25:57.174+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManager: Removing RDD 341
[2025-05-07T23:25:57.206+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:57.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Registering RDD 355 (mapPartitions at GraphImpl.scala:208) as input to shuffle 45
[2025-05-07T23:25:57.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Registering RDD 363 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 44
[2025-05-07T23:25:57.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Got job 42 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:57.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Final stage: ResultStage 177 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:57.210+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 161, ShuffleMapStage 168, ShuffleMapStage 157, ShuffleMapStage 172, ShuffleMapStage 166, ShuffleMapStage 176, ShuffleMapStage 170, ShuffleMapStage 162, ShuffleMapStage 174, ShuffleMapStage 164)
[2025-05-07T23:25:57.211+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 176)
[2025-05-07T23:25:57.224+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[355] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:57.236+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 165.5 KiB, free 416.8 MiB)
[2025-05-07T23:25:57.269+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 58.6 KiB, free 416.8 MiB)
[2025-05-07T23:25:57.271+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 3530b0b864fd:41807 (size: 58.6 KiB, free: 433.2 MiB)
[2025-05-07T23:25:57.271+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:57.272+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 175 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[355] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:57.272+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Adding task set 175.0 with 10 tasks resource profile 0
[2025-05-07T23:25:57.273+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 3530b0b864fd:41807 in memory (size: 6.1 KiB, free: 433.2 MiB)
[2025-05-07T23:25:57.273+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 370) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.313+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.20.0.5:40779 in memory (size: 6.1 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.318+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 3530b0b864fd:41807 in memory (size: 58.0 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.319+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.20.0.5:40779 in memory (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.319+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.20.0.5:40779 (size: 58.6 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.322+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.20.0.5:40779 in memory (size: 6.4 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.322+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 3530b0b864fd:41807 in memory (size: 6.4 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.324+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 3530b0b864fd:41807 in memory (size: 58.4 KiB, free: 433.3 MiB)
[2025-05-07T23:25:57.325+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.20.0.5:40779 in memory (size: 58.4 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 3530b0b864fd:41807 in memory (size: 58.1 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.329+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.20.0.5:40779 in memory (size: 58.1 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.331+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 3530b0b864fd:41807 in memory (size: 6.3 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.332+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.20.0.5:40779 in memory (size: 6.3 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.332+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 371) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.332+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 370) in 59 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:57.335+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 3530b0b864fd:41807 in memory (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.336+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.20.0.5:40779 in memory (size: 58.3 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.338+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.20.0.5:40779 in memory (size: 57.8 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.339+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 3530b0b864fd:41807 in memory (size: 57.8 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 2.0 in stage 175.0 (TID 372) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 371) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:57.355+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 3.0 in stage 175.0 (TID 373) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.356+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 2.0 in stage 175.0 (TID 372) in 12 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:57.366+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 4.0 in stage 175.0 (TID 374) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.366+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 3.0 in stage 175.0 (TID 373) in 11 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:57.376+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 5.0 in stage 175.0 (TID 375) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.376+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 4.0 in stage 175.0 (TID 374) in 11 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:57.384+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 6.0 in stage 175.0 (TID 376) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.384+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 5.0 in stage 175.0 (TID 375) in 8 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:57.391+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 7.0 in stage 175.0 (TID 377) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.392+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 6.0 in stage 175.0 (TID 376) in 8 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:57.402+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 8.0 in stage 175.0 (TID 378) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.402+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 7.0 in stage 175.0 (TID 377) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:57.409+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 9.0 in stage 175.0 (TID 379) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5071 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.409+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 8.0 in stage 175.0 (TID 378) in 8 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:57.416+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 9.0 in stage 175.0 (TID 379) in 7 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:57.417+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool
[2025-05-07T23:25:57.420+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: ShuffleMapStage 175 (mapPartitions at GraphImpl.scala:208) finished in 0.192 s
[2025-05-07T23:25:57.420+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:57.420+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:57.420+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 176, ResultStage 177)
[2025-05-07T23:25:57.420+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:57.421+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[363] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:57.427+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 16.4 KiB, free 417.9 MiB)
[2025-05-07T23:25:57.430+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 417.9 MiB)
[2025-05-07T23:25:57.431+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 3530b0b864fd:41807 (size: 6.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.432+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:57.433+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 176 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[363] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:57.433+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Adding task set 176.0 with 10 tasks resource profile 0
[2025-05-07T23:25:57.434+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 380) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.442+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.20.0.5:40779 (size: 6.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.445+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.20.0.5:47382
[2025-05-07T23:25:57.453+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 381) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 380) in 25 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:57.466+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.470+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 2.0 in stage 176.0 (TID 382) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.471+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 381) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:57.477+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.480+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 3.0 in stage 176.0 (TID 383) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.481+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 2.0 in stage 176.0 (TID 382) in 10 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:57.499+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.505+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 4.0 in stage 176.0 (TID 384) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.506+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 3.0 in stage 176.0 (TID 383) in 25 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:57.531+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.536+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 5.0 in stage 176.0 (TID 385) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.542+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 4.0 in stage 176.0 (TID 384) in 32 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:57.545+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.549+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 6.0 in stage 176.0 (TID 386) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.549+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 5.0 in stage 176.0 (TID 385) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:57.555+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.559+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 7.0 in stage 176.0 (TID 387) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.560+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 6.0 in stage 176.0 (TID 386) in 12 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:57.566+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 8.0 in stage 176.0 (TID 388) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 7.0 in stage 176.0 (TID 387) in 12 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:57.577+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.581+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 9.0 in stage 176.0 (TID 389) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5152 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.582+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 8.0 in stage 176.0 (TID 388) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:57.587+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_359_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:57.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 9.0 in stage 176.0 (TID 389) in 10 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:57.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool
[2025-05-07T23:25:57.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: ShuffleMapStage 176 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.169 s
[2025-05-07T23:25:57.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:57.591+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:57.592+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: waiting: Set(ResultStage 177)
[2025-05-07T23:25:57.592+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:57.592+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting ResultStage 177 (EdgeRDDImpl[366] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:57.603+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 165.3 KiB, free 417.7 MiB)
[2025-05-07T23:25:57.609+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.7 MiB)
[2025-05-07T23:25:57.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 3530b0b864fd:41807 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:57.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 177 (EdgeRDDImpl[366] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:57.611+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Adding task set 177.0 with 10 tasks resource profile 0
[2025-05-07T23:25:57.612+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 390) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.618+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.20.0.5:40779 (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.627+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.20.0.5:47382
[2025-05-07T23:25:57.632+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 391) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.635+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 390) in 24 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:57.643+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.645+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 392) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 391) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:57.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.660+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 393) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.660+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 392) in 15 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:57.668+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.671+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 4.0 in stage 177.0 (TID 394) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.671+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 393) in 12 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:57.680+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 5.0 in stage 177.0 (TID 395) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.682+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 4.0 in stage 177.0 (TID 394) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:57.693+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.696+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 6.0 in stage 177.0 (TID 396) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.696+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 5.0 in stage 177.0 (TID 395) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:57.705+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.707+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 7.0 in stage 177.0 (TID 397) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.708+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 6.0 in stage 177.0 (TID 396) in 12 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:57.716+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.717+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 8.0 in stage 177.0 (TID 398) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.718+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 7.0 in stage 177.0 (TID 397) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:57.726+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.728+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 9.0 in stage 177.0 (TID 399) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5123 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.728+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 8.0 in stage 177.0 (TID 398) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:57.739+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added rdd_365_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.741+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 9.0 in stage 177.0 (TID 399) in 13 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:57.741+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool
[2025-05-07T23:25:57.742+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: ResultStage 177 (foreachPartition at PageRank.scala:199) finished in 0.147 s
[2025-05-07T23:25:57.742+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:57.742+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
[2025-05-07T23:25:57.742+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Job 42 finished: foreachPartition at PageRank.scala:199, took 0.536436 s
[2025-05-07T23:25:57.743+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO PageRank: PageRank finished iteration 6.
[2025-05-07T23:25:57.743+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO ZippedPartitionsRDD2: Removing RDD 347 from persistence list
[2025-05-07T23:25:57.745+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManager: Removing RDD 347
[2025-05-07T23:25:57.745+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO ZippedPartitionsRDD2: Removing RDD 353 from persistence list
[2025-05-07T23:25:57.746+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManager: Removing RDD 353
[2025-05-07T23:25:57.771+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:57.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Registering RDD 367 (mapPartitions at GraphImpl.scala:208) as input to shuffle 47
[2025-05-07T23:25:57.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Registering RDD 375 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 46
[2025-05-07T23:25:57.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Got job 43 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:57.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Final stage: ResultStage 200 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:57.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 197, ShuffleMapStage 183, ShuffleMapStage 187, ShuffleMapStage 191, ShuffleMapStage 195, ShuffleMapStage 189, ShuffleMapStage 199, ShuffleMapStage 178, ShuffleMapStage 193, ShuffleMapStage 185, ShuffleMapStage 182)
[2025-05-07T23:25:57.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 199)
[2025-05-07T23:25:57.788+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[367] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:57.797+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 165.8 KiB, free 417.5 MiB)
[2025-05-07T23:25:57.811+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.4 MiB)
[2025-05-07T23:25:57.817+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 3530b0b864fd:41807 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:57.817+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:57.820+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 198 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[367] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:57.820+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Adding task set 198.0 with 10 tasks resource profile 0
[2025-05-07T23:25:57.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 400) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.859+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.20.0.5:40779 (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:57.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 1.0 in stage 198.0 (TID 401) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 400) in 46 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:57.875+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 2.0 in stage 198.0 (TID 402) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.875+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 1.0 in stage 198.0 (TID 401) in 8 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:57.884+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 3.0 in stage 198.0 (TID 403) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.884+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 2.0 in stage 198.0 (TID 402) in 10 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:57.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 4.0 in stage 198.0 (TID 404) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.894+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 3.0 in stage 198.0 (TID 403) in 10 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:57.901+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 5.0 in stage 198.0 (TID 405) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 4.0 in stage 198.0 (TID 404) in 8 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:57.909+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 6.0 in stage 198.0 (TID 406) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.912+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 5.0 in stage 198.0 (TID 405) in 11 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:57.935+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 7.0 in stage 198.0 (TID 407) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.935+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 6.0 in stage 198.0 (TID 406) in 27 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:57.946+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 8.0 in stage 198.0 (TID 408) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.946+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 7.0 in stage 198.0 (TID 407) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:57.956+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Starting task 9.0 in stage 198.0 (TID 409) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5112 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:57.956+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 8.0 in stage 198.0 (TID 408) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:57.973+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSetManager: Finished task 9.0 in stage 198.0 (TID 409) in 17 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:57.974+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool
[2025-05-07T23:25:57.979+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: ShuffleMapStage 198 (mapPartitions at GraphImpl.scala:208) finished in 0.185 s
[2025-05-07T23:25:57.979+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:57.979+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:57.980+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: waiting: Set(ShuffleMapStage 199, ResultStage 200)
[2025-05-07T23:25:57.980+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:57.980+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[375] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:57.989+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:57 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 17.1 KiB, free 417.4 MiB)
[2025-05-07T23:25:58.000+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.4 MiB)
[2025-05-07T23:25:58.002+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 3530b0b864fd:41807 (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:58.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 199 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[375] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:58.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Adding task set 199.0 with 10 tasks resource profile 0
[2025-05-07T23:25:58.007+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 410) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.027+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.20.0.5:40779 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.031+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to 172.20.0.5:47382
[2025-05-07T23:25:58.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.049+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 411) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.049+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 410) in 42 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:58.055+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.085+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 2.0 in stage 199.0 (TID 412) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.085+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 411) in 37 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:58.090+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.094+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 3.0 in stage 199.0 (TID 413) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.094+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 2.0 in stage 199.0 (TID 412) in 10 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:58.099+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.103+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 4.0 in stage 199.0 (TID 414) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.103+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 3.0 in stage 199.0 (TID 413) in 9 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:58.108+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.112+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 5.0 in stage 199.0 (TID 415) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.112+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 4.0 in stage 199.0 (TID 414) in 10 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:58.117+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 6.0 in stage 199.0 (TID 416) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 5.0 in stage 199.0 (TID 415) in 9 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:58.126+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.130+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 7.0 in stage 199.0 (TID 417) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.130+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 6.0 in stage 199.0 (TID 416) in 10 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:58.141+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.144+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 8.0 in stage 199.0 (TID 418) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.145+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 7.0 in stage 199.0 (TID 417) in 15 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:58.149+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.153+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 9.0 in stage 199.0 (TID 419) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5225 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.154+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 8.0 in stage 199.0 (TID 418) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:58.159+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_371_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.162+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 9.0 in stage 199.0 (TID 419) in 9 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:58.162+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool
[2025-05-07T23:25:58.162+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: ShuffleMapStage 199 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.182 s
[2025-05-07T23:25:58.162+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:58.162+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:58.162+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: waiting: Set(ResultStage 200)
[2025-05-07T23:25:58.163+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:58.163+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting ResultStage 200 (EdgeRDDImpl[378] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:58.168+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 165.5 KiB, free 417.3 MiB)
[2025-05-07T23:25:58.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 58.3 KiB, free 417.2 MiB)
[2025-05-07T23:25:58.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 3530b0b864fd:41807 (size: 58.3 KiB, free: 433.3 MiB)
[2025-05-07T23:25:58.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:58.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 200 (EdgeRDDImpl[378] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:58.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Adding task set 200.0 with 10 tasks resource profile 0
[2025-05-07T23:25:58.172+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 420) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.177+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.20.0.5:40779 (size: 58.3 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.185+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.20.0.5:47382
[2025-05-07T23:25:58.189+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.191+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 421) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.192+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 420) in 19 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:58.203+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.206+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 422) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.206+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 421) in 15 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:58.217+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 423) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.231+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 422) in 23 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:58.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.242+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 4.0 in stage 200.0 (TID 424) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.242+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 423) in 23 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:58.254+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.256+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 5.0 in stage 200.0 (TID 425) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.257+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 4.0 in stage 200.0 (TID 424) in 15 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:58.270+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.273+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 6.0 in stage 200.0 (TID 426) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.273+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 5.0 in stage 200.0 (TID 425) in 17 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:58.284+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.286+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 7.0 in stage 200.0 (TID 427) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.287+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 6.0 in stage 200.0 (TID 426) in 14 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:58.296+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.298+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 8.0 in stage 200.0 (TID 428) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.298+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 7.0 in stage 200.0 (TID 427) in 12 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:58.306+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.308+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 9.0 in stage 200.0 (TID 429) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5164 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.308+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 8.0 in stage 200.0 (TID 428) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:58.316+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_377_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.318+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 9.0 in stage 200.0 (TID 429) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:58.319+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool
[2025-05-07T23:25:58.320+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: ResultStage 200 (foreachPartition at PageRank.scala:199) finished in 0.156 s
[2025-05-07T23:25:58.321+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:58.321+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
[2025-05-07T23:25:58.321+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Job 43 finished: foreachPartition at PageRank.scala:199, took 0.549660 s
[2025-05-07T23:25:58.321+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO PageRank: PageRank finished iteration 7.
[2025-05-07T23:25:58.321+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO ZippedPartitionsRDD2: Removing RDD 359 from persistence list
[2025-05-07T23:25:58.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManager: Removing RDD 359
[2025-05-07T23:25:58.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO ZippedPartitionsRDD2: Removing RDD 365 from persistence list
[2025-05-07T23:25:58.324+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManager: Removing RDD 365
[2025-05-07T23:25:58.340+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:58.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Registering RDD 379 (mapPartitions at GraphImpl.scala:208) as input to shuffle 49
[2025-05-07T23:25:58.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Registering RDD 387 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 48
[2025-05-07T23:25:58.343+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Got job 44 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:58.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Final stage: ResultStage 225 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:58.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 212, ShuffleMapStage 222, ShuffleMapStage 201, ShuffleMapStage 216, ShuffleMapStage 208, ShuffleMapStage 205, ShuffleMapStage 220, ShuffleMapStage 206, ShuffleMapStage 224, ShuffleMapStage 210, ShuffleMapStage 214, ShuffleMapStage 218)
[2025-05-07T23:25:58.344+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 224)
[2025-05-07T23:25:58.345+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[379] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:58.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 166.0 KiB, free 417.0 MiB)
[2025-05-07T23:25:58.351+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 58.5 KiB, free 417.0 MiB)
[2025-05-07T23:25:58.351+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 3530b0b864fd:41807 (size: 58.5 KiB, free: 433.3 MiB)
[2025-05-07T23:25:58.352+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:58.352+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 223 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[379] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:58.352+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Adding task set 223.0 with 10 tasks resource profile 0
[2025-05-07T23:25:58.353+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 430) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.20.0.5:40779 (size: 58.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.383+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 431) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.384+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 430) in 31 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:58.390+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 2.0 in stage 223.0 (TID 432) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.391+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 431) in 8 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:58.398+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 3.0 in stage 223.0 (TID 433) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.398+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 2.0 in stage 223.0 (TID 432) in 8 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:58.407+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 4.0 in stage 223.0 (TID 434) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.408+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 3.0 in stage 223.0 (TID 433) in 10 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:58.415+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 5.0 in stage 223.0 (TID 435) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.415+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 4.0 in stage 223.0 (TID 434) in 9 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:58.422+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 6.0 in stage 223.0 (TID 436) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.422+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 5.0 in stage 223.0 (TID 435) in 8 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:58.432+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 7.0 in stage 223.0 (TID 437) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.432+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 6.0 in stage 223.0 (TID 436) in 10 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:58.442+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 8.0 in stage 223.0 (TID 438) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.443+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 7.0 in stage 223.0 (TID 437) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:58.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 9.0 in stage 223.0 (TID 439) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5153 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.453+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 8.0 in stage 223.0 (TID 438) in 10 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:58.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 9.0 in stage 223.0 (TID 439) in 17 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:58.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool
[2025-05-07T23:25:58.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: ShuffleMapStage 223 (mapPartitions at GraphImpl.scala:208) finished in 0.124 s
[2025-05-07T23:25:58.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:58.469+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:58.470+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: waiting: Set(ShuffleMapStage 224, ResultStage 225)
[2025-05-07T23:25:58.470+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:58.470+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[387] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:58.474+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 17.8 KiB, free 417.0 MiB)
[2025-05-07T23:25:58.530+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.0 MiB)
[2025-05-07T23:25:58.551+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 3530b0b864fd:41807 (size: 6.7 KiB, free: 433.3 MiB)
[2025-05-07T23:25:58.551+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 3530b0b864fd:41807 in memory (size: 58.5 KiB, free: 433.3 MiB)
[2025-05-07T23:25:58.551+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:58.552+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 224 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[387] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:58.552+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Adding task set 224.0 with 10 tasks resource profile 0
[2025-05-07T23:25:58.552+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 440) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.552+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.20.0.5:40779 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.555+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 3530b0b864fd:41807 in memory (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.556+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.20.0.5:40779 in memory (size: 58.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.569+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.20.0.5:40779 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 3530b0b864fd:41807 in memory (size: 58.6 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.571+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.20.0.5:40779 in memory (size: 58.6 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.574+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 49 to 172.20.0.5:47382
[2025-05-07T23:25:58.574+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 3530b0b864fd:41807 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.575+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.20.0.5:40779 in memory (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.579+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 3530b0b864fd:41807 in memory (size: 6.5 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.20.0.5:40779 in memory (size: 6.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.583+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 3530b0b864fd:41807 in memory (size: 58.3 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.583+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.20.0.5:40779 in memory (size: 58.3 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.583+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.589+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 1.0 in stage 224.0 (TID 441) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.589+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 440) in 50 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:58.596+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.599+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 2.0 in stage 224.0 (TID 442) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.599+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 1.0 in stage 224.0 (TID 441) in 11 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:58.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 3.0 in stage 224.0 (TID 443) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.610+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 2.0 in stage 224.0 (TID 442) in 11 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:58.616+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.620+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 4.0 in stage 224.0 (TID 444) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.621+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 3.0 in stage 224.0 (TID 443) in 10 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:58.627+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.632+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 5.0 in stage 224.0 (TID 445) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.633+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 4.0 in stage 224.0 (TID 444) in 12 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:58.639+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.642+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 6.0 in stage 224.0 (TID 446) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.643+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 5.0 in stage 224.0 (TID 445) in 11 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:58.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.652+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 7.0 in stage 224.0 (TID 447) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.652+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 6.0 in stage 224.0 (TID 446) in 10 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:58.665+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 8.0 in stage 224.0 (TID 448) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 7.0 in stage 224.0 (TID 447) in 17 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:58.676+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.680+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 9.0 in stage 224.0 (TID 449) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5298 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.680+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 8.0 in stage 224.0 (TID 448) in 12 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:58.687+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_383_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:25:58.691+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 9.0 in stage 224.0 (TID 449) in 12 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:58.691+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool
[2025-05-07T23:25:58.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: ShuffleMapStage 224 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.220 s
[2025-05-07T23:25:58.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:58.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:58.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: waiting: Set(ResultStage 225)
[2025-05-07T23:25:58.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:58.693+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting ResultStage 225 (EdgeRDDImpl[390] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:25:58.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 165.8 KiB, free 417.7 MiB)
[2025-05-07T23:25:58.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 58.0 KiB, free 417.7 MiB)
[2025-05-07T23:25:58.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 3530b0b864fd:41807 (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:58.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 225 (EdgeRDDImpl[390] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:58.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Adding task set 225.0 with 10 tasks resource profile 0
[2025-05-07T23:25:58.702+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 450) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.706+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.20.0.5:40779 (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.713+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to 172.20.0.5:47382
[2025-05-07T23:25:58.716+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.718+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 451) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.718+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 450) in 17 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:58.726+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.728+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 2.0 in stage 225.0 (TID 452) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.729+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 451) in 10 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:58.741+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.743+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 3.0 in stage 225.0 (TID 453) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.743+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 2.0 in stage 225.0 (TID 452) in 15 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:58.756+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.758+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 4.0 in stage 225.0 (TID 454) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.759+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 3.0 in stage 225.0 (TID 453) in 15 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:58.770+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.773+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 5.0 in stage 225.0 (TID 455) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.773+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 4.0 in stage 225.0 (TID 454) in 15 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:58.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.786+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 6.0 in stage 225.0 (TID 456) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.786+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 5.0 in stage 225.0 (TID 455) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:58.798+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.800+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 7.0 in stage 225.0 (TID 457) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.801+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 6.0 in stage 225.0 (TID 456) in 16 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:58.809+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.811+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 8.0 in stage 225.0 (TID 458) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.812+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 7.0 in stage 225.0 (TID 457) in 11 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:58.821+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.823+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 9.0 in stage 225.0 (TID 459) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5205 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.824+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 8.0 in stage 225.0 (TID 458) in 12 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:58.832+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added rdd_389_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.834+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 9.0 in stage 225.0 (TID 459) in 11 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:58.835+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool
[2025-05-07T23:25:58.836+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: ResultStage 225 (foreachPartition at PageRank.scala:199) finished in 0.140 s
[2025-05-07T23:25:58.836+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:25:58.836+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
[2025-05-07T23:25:58.838+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Job 44 finished: foreachPartition at PageRank.scala:199, took 0.496797 s
[2025-05-07T23:25:58.838+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO PageRank: PageRank finished iteration 8.
[2025-05-07T23:25:58.838+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO ZippedPartitionsRDD2: Removing RDD 371 from persistence list
[2025-05-07T23:25:58.841+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManager: Removing RDD 371
[2025-05-07T23:25:58.842+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO ZippedPartitionsRDD2: Removing RDD 377 from persistence list
[2025-05-07T23:25:58.843+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManager: Removing RDD 377
[2025-05-07T23:25:58.872+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Starting job: foreachPartition at PageRank.scala:199
[2025-05-07T23:25:58.875+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Registering RDD 391 (mapPartitions at GraphImpl.scala:208) as input to shuffle 51
[2025-05-07T23:25:58.876+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Registering RDD 399 (mapPartitions at VertexRDDImpl.scala:247) as input to shuffle 50
[2025-05-07T23:25:58.876+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Got job 45 (foreachPartition at PageRank.scala:199) with 10 output partitions
[2025-05-07T23:25:58.876+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Final stage: ResultStage 252 (foreachPartition at PageRank.scala:199)
[2025-05-07T23:25:58.876+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 233, ShuffleMapStage 230, ShuffleMapStage 237, ShuffleMapStage 249, ShuffleMapStage 241, ShuffleMapStage 235, ShuffleMapStage 245, ShuffleMapStage 239, ShuffleMapStage 231, ShuffleMapStage 243, ShuffleMapStage 247, ShuffleMapStage 226)
[2025-05-07T23:25:58.876+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 251)
[2025-05-07T23:25:58.881+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[391] at mapPartitions at GraphImpl.scala:208), which has no missing parents
[2025-05-07T23:25:58.886+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 166.3 KiB, free 417.5 MiB)
[2025-05-07T23:25:58.890+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 58.4 KiB, free 417.4 MiB)
[2025-05-07T23:25:58.891+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 3530b0b864fd:41807 (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T23:25:58.891+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:58.892+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 250 (GraphImpl.aggregateMessages - preAgg MapPartitionsRDD[391] at mapPartitions at GraphImpl.scala:208) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:58.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSchedulerImpl: Adding task set 250.0 with 10 tasks resource profile 0
[2025-05-07T23:25:58.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 460) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.901+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.20.0.5:40779 (size: 58.4 KiB, free: 433.5 MiB)
[2025-05-07T23:25:58.910+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 1.0 in stage 250.0 (TID 461) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.910+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 460) in 17 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:25:58.919+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 2.0 in stage 250.0 (TID 462) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.919+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 1.0 in stage 250.0 (TID 461) in 10 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:25:58.927+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 3.0 in stage 250.0 (TID 463) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.927+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 2.0 in stage 250.0 (TID 462) in 9 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:25:58.935+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 4.0 in stage 250.0 (TID 464) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.936+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 3.0 in stage 250.0 (TID 463) in 8 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:25:58.945+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 5.0 in stage 250.0 (TID 465) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.945+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 4.0 in stage 250.0 (TID 464) in 10 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:25:58.953+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 6.0 in stage 250.0 (TID 466) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.953+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 5.0 in stage 250.0 (TID 465) in 8 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:25:58.965+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Starting task 7.0 in stage 250.0 (TID 467) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:58.965+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:58 INFO TaskSetManager: Finished task 6.0 in stage 250.0 (TID 466) in 13 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:25:59.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSetManager: Starting task 8.0 in stage 250.0 (TID 468) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:59.045+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSetManager: Finished task 7.0 in stage 250.0 (TID 467) in 80 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:25:59.049+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSetManager: Starting task 9.0 in stage 250.0 (TID 469) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5194 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:59.050+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSetManager: Finished task 8.0 in stage 250.0 (TID 468) in 7 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:25:59.058+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSetManager: Finished task 9.0 in stage 250.0 (TID 469) in 9 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:25:59.060+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool
[2025-05-07T23:25:59.068+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO DAGScheduler: ShuffleMapStage 250 (mapPartitions at GraphImpl.scala:208) finished in 0.177 s
[2025-05-07T23:25:59.074+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:25:59.101+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO DAGScheduler: running: Set()
[2025-05-07T23:25:59.103+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 251, ResultStage 252)
[2025-05-07T23:25:59.103+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO DAGScheduler: failed: Set()
[2025-05-07T23:25:59.116+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO DAGScheduler: Submitting ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[399] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
[2025-05-07T23:25:59.158+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 18.5 KiB, free 417.4 MiB)
[2025-05-07T23:25:59.177+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 417.4 MiB)
[2025-05-07T23:25:59.178+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 3530b0b864fd:41807 (size: 6.8 KiB, free: 433.4 MiB)
[2025-05-07T23:25:59.190+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:25:59.200+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 251 (ReplicatedVertexView.updateVertices - shippedVerts true false (broadcast) MapPartitionsRDD[399] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:25:59.204+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSchedulerImpl: Adding task set 251.0 with 10 tasks resource profile 0
[2025-05-07T23:25:59.246+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 470) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:25:59.678+0000] {spark_submit.py:571} INFO - 25/05/07 23:25:59 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.20.0.5:40779 (size: 6.8 KiB, free: 433.5 MiB)
[2025-05-07T23:26:00.030+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 51 to 172.20.0.5:47382
[2025-05-07T23:26:00.129+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO BlockManagerInfo: Added rdd_395_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:00.153+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Starting task 1.0 in stage 251.0 (TID 471) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:00.155+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 470) in 922 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:26:00.160+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO BlockManagerInfo: Added rdd_395_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:00.164+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Starting task 2.0 in stage 251.0 (TID 472) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:00.164+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Finished task 1.0 in stage 251.0 (TID 471) in 12 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:26:00.171+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO BlockManagerInfo: Added rdd_395_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:00.243+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Starting task 3.0 in stage 251.0 (TID 473) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:00.330+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Finished task 2.0 in stage 251.0 (TID 472) in 62 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:26:00.514+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO BlockManagerInfo: Added rdd_395_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:00.632+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Starting task 4.0 in stage 251.0 (TID 474) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:00.634+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:00 INFO TaskSetManager: Finished task 3.0 in stage 251.0 (TID 473) in 458 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:26:01.749+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO BlockManagerInfo: Added rdd_395_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:01.972+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO TaskSetManager: Starting task 5.0 in stage 251.0 (TID 475) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:02.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO TaskSetManager: Finished task 4.0 in stage 251.0 (TID 474) in 1344 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:26:02.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO BlockManagerInfo: Added rdd_395_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:02.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO TaskSetManager: Starting task 6.0 in stage 251.0 (TID 476) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:02.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO TaskSetManager: Finished task 5.0 in stage 251.0 (TID 475) in 36 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:26:02.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO BlockManagerInfo: Added rdd_395_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:02.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO TaskSetManager: Starting task 7.0 in stage 251.0 (TID 477) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:02.006+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:01 INFO TaskSetManager: Finished task 6.0 in stage 251.0 (TID 476) in 9 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:26:02.011+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO BlockManagerInfo: Added rdd_395_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:02.014+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSetManager: Starting task 8.0 in stage 251.0 (TID 478) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:02.015+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSetManager: Finished task 7.0 in stage 251.0 (TID 477) in 21 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:26:02.020+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO BlockManagerInfo: Added rdd_395_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:02.027+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSetManager: Starting task 9.0 in stage 251.0 (TID 479) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5371 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:02.027+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSetManager: Finished task 8.0 in stage 251.0 (TID 478) in 13 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:26:02.039+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO BlockManagerInfo: Added rdd_395_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.5 MiB)
[2025-05-07T23:26:02.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSetManager: Finished task 9.0 in stage 251.0 (TID 479) in 16 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:26:02.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO DAGScheduler: ShuffleMapStage 251 (mapPartitions at VertexRDDImpl.scala:247) finished in 2.910 s
[2025-05-07T23:26:02.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:26:02.042+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO DAGScheduler: running: Set()
[2025-05-07T23:26:02.043+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO DAGScheduler: waiting: Set(ResultStage 252)
[2025-05-07T23:26:02.043+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO DAGScheduler: failed: Set()
[2025-05-07T23:26:02.043+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO DAGScheduler: Submitting ResultStage 252 (EdgeRDDImpl[402] at RDD at EdgeRDD.scala:41), which has no missing parents
[2025-05-07T23:26:02.044+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool
[2025-05-07T23:26:02.075+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 166.1 KiB, free 417.3 MiB)
[2025-05-07T23:26:02.141+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 58.2 KiB, free 417.2 MiB)
[2025-05-07T23:26:02.146+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 3530b0b864fd:41807 (size: 58.2 KiB, free: 433.3 MiB)
[2025-05-07T23:26:02.156+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:26:02.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 252 (EdgeRDDImpl[402] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:26:02.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSchedulerImpl: Adding task set 252.0 with 10 tasks resource profile 0
[2025-05-07T23:26:02.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:02 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 480) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:03.169+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:03 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.20.0.5:40779 (size: 58.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:03.446+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 50 to 172.20.0.5:47382
[2025-05-07T23:26:04.149+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:04 INFO BlockManagerInfo: Added rdd_401_0 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:04.185+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:04 INFO TaskSetManager: Starting task 1.0 in stage 252.0 (TID 481) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:04.191+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:04 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 480) in 2004 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:26:05.159+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:05 INFO BlockManagerInfo: Added rdd_401_1 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:05.235+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:05 INFO TaskSetManager: Starting task 2.0 in stage 252.0 (TID 482) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:05.235+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:05 INFO TaskSetManager: Finished task 1.0 in stage 252.0 (TID 481) in 1049 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:26:05.679+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:05 INFO BlockManagerInfo: Added rdd_401_2 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:05.800+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:05 INFO TaskSetManager: Starting task 3.0 in stage 252.0 (TID 483) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:05.804+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:05 INFO TaskSetManager: Finished task 2.0 in stage 252.0 (TID 482) in 607 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:26:06.930+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:06 INFO BlockManagerInfo: Added rdd_401_3 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:08.084+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:07 INFO TaskSetManager: Starting task 4.0 in stage 252.0 (TID 484) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:08.156+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:07 INFO TaskSetManager: Finished task 3.0 in stage 252.0 (TID 483) in 1682 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:26:09.003+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:08 INFO BlockManagerInfo: Added rdd_401_4 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:09.404+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:09 INFO TaskSetManager: Starting task 5.0 in stage 252.0 (TID 485) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:09.535+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:09 INFO TaskSetManager: Finished task 4.0 in stage 252.0 (TID 484) in 1985 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:26:23.984+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:23 INFO BlockManagerInfo: Added rdd_401_5 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:25.329+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:25 INFO TaskSetManager: Starting task 6.0 in stage 252.0 (TID 486) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:25.698+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:25 INFO TaskSetManager: Finished task 5.0 in stage 252.0 (TID 485) in 16021 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:26:33.684+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO BlockManagerInfo: Added rdd_401_6 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:33.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO TaskSetManager: Starting task 7.0 in stage 252.0 (TID 487) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:33.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO TaskSetManager: Finished task 6.0 in stage 252.0 (TID 486) in 8557 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:26:33.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO BlockManagerInfo: Added rdd_401_7 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:33.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO TaskSetManager: Starting task 8.0 in stage 252.0 (TID 488) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:33.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO TaskSetManager: Finished task 7.0 in stage 252.0 (TID 487) in 15 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:26:33.715+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO BlockManagerInfo: Added rdd_401_8 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:33.720+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO TaskSetManager: Starting task 9.0 in stage 252.0 (TID 489) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5246 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:33.720+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:33 INFO TaskSetManager: Finished task 8.0 in stage 252.0 (TID 488) in 16 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:26:36.118+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:36 INFO BlockManagerInfo: Added rdd_401_9 in memory on 172.20.0.5:40779 (size: 2.2 KiB, free: 433.4 MiB)
[2025-05-07T23:26:36.559+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:36 INFO TaskSetManager: Finished task 9.0 in stage 252.0 (TID 489) in 2820 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:26:38.142+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:36 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool
[2025-05-07T23:26:38.454+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:36 INFO DAGScheduler: ResultStage 252 (foreachPartition at PageRank.scala:199) finished in 34.512 s
[2025-05-07T23:26:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:36 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:26:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished
[2025-05-07T23:26:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:37 INFO DAGScheduler: Job 45 finished: foreachPartition at PageRank.scala:199, took 38.062714 s
[2025-05-07T23:26:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:37 INFO PageRank: PageRank finished iteration 9.
[2025-05-07T23:26:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:37 INFO ZippedPartitionsRDD2: Removing RDD 383 from persistence list
[2025-05-07T23:26:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:37 INFO BlockManager: Removing RDD 383
[2025-05-07T23:26:38.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:37 INFO ZippedPartitionsRDD2: Removing RDD 389 from persistence list
[2025-05-07T23:26:38.638+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:37 INFO BlockManager: Removing RDD 389
[2025-05-07T23:26:40.550+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO SparkContext: Starting job: sum at PageRank.scala:503
[2025-05-07T23:26:40.558+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO DAGScheduler: Got job 46 (sum at PageRank.scala:503) with 10 output partitions
[2025-05-07T23:26:40.558+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO DAGScheduler: Final stage: ResultStage 278 (sum at PageRank.scala:503)
[2025-05-07T23:26:40.558+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 263, ShuffleMapStage 255, ShuffleMapStage 273, ShuffleMapStage 267, ShuffleMapStage 277, ShuffleMapStage 256, ShuffleMapStage 271, ShuffleMapStage 259, ShuffleMapStage 275, ShuffleMapStage 261, ShuffleMapStage 265, ShuffleMapStage 254)
[2025-05-07T23:26:40.558+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:26:40.567+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO DAGScheduler: Submitting ResultStage 278 (MapPartitionsRDD[403] at values at PageRank.scala:503), which has no missing parents
[2025-05-07T23:26:40.572+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 18.9 KiB, free 417.2 MiB)
[2025-05-07T23:26:40.580+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 417.2 MiB)
[2025-05-07T23:26:40.603+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 3530b0b864fd:41807 (size: 7.1 KiB, free: 433.3 MiB)
[2025-05-07T23:26:40.604+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:26:40.604+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 278 (MapPartitionsRDD[403] at values at PageRank.scala:503) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:26:40.605+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO TaskSchedulerImpl: Adding task set 278.0 with 10 tasks resource profile 0
[2025-05-07T23:26:40.606+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 490) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:40.991+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:40 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.20.0.5:40779 (size: 7.1 KiB, free: 433.5 MiB)
[2025-05-07T23:26:43.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:43 INFO TaskSetManager: Starting task 1.0 in stage 278.0 (TID 491) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:43.819+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:43 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 490) in 3137 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:26:45.566+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:45 INFO TaskSetManager: Starting task 2.0 in stage 278.0 (TID 492) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:45.722+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:45 INFO TaskSetManager: Finished task 1.0 in stage 278.0 (TID 491) in 1990 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:26:48.002+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:47 INFO TaskSetManager: Starting task 3.0 in stage 278.0 (TID 493) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:48.238+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:48 INFO TaskSetManager: Finished task 2.0 in stage 278.0 (TID 492) in 2521 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:26:48.838+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:48 INFO TaskSetManager: Starting task 4.0 in stage 278.0 (TID 494) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:48.922+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:48 INFO TaskSetManager: Finished task 3.0 in stage 278.0 (TID 493) in 983 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:26:50.941+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:50 INFO TaskSetManager: Starting task 5.0 in stage 278.0 (TID 495) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:51.188+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:50 INFO TaskSetManager: Finished task 4.0 in stage 278.0 (TID 494) in 2204 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:26:52.466+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:52 INFO TaskSetManager: Starting task 6.0 in stage 278.0 (TID 496) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:53.286+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:53 INFO TaskSetManager: Finished task 5.0 in stage 278.0 (TID 495) in 2298 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:26:53.929+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:53 INFO TaskSetManager: Starting task 7.0 in stage 278.0 (TID 497) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:54.046+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:54 INFO TaskSetManager: Finished task 6.0 in stage 278.0 (TID 496) in 1576 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:26:55.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:55 INFO TaskSetManager: Starting task 8.0 in stage 278.0 (TID 498) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:56.103+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:55 INFO TaskSetManager: Finished task 7.0 in stage 278.0 (TID 497) in 1684 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:26:57.119+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:57 INFO TaskSetManager: Starting task 9.0 in stage 278.0 (TID 499) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:26:57.318+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:57 INFO TaskSetManager: Finished task 8.0 in stage 278.0 (TID 498) in 1633 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:26:59.297+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:59 INFO TaskSetManager: Finished task 9.0 in stage 278.0 (TID 499) in 2237 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:26:59.424+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:59 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool
[2025-05-07T23:26:59.424+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:59 INFO DAGScheduler: ResultStage 278 (sum at PageRank.scala:503) finished in 18.729 s
[2025-05-07T23:26:59.424+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:59 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:26:59.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 278: Stage finished
[2025-05-07T23:26:59.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:26:59 INFO DAGScheduler: Job 46 finished: sum at PageRank.scala:503, took 18.861249 s
[2025-05-07T23:27:01.018+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:00 INFO SparkContext: Starting job: fold at VertexRDDImpl.scala:90
[2025-05-07T23:27:01.463+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:01 INFO DAGScheduler: Got job 47 (fold at VertexRDDImpl.scala:90) with 10 output partitions
[2025-05-07T23:27:01.754+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:01 INFO DAGScheduler: Final stage: ResultStage 304 (fold at VertexRDDImpl.scala:90)
[2025-05-07T23:27:01.946+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 287, ShuffleMapStage 281, ShuffleMapStage 299, ShuffleMapStage 291, ShuffleMapStage 303, ShuffleMapStage 285, ShuffleMapStage 289, ShuffleMapStage 293, ShuffleMapStage 282, ShuffleMapStage 297, ShuffleMapStage 301, ShuffleMapStage 280, ShuffleMapStage 295)
[2025-05-07T23:27:02.176+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:01 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:27:02.276+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:01 INFO DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[404] at map at VertexRDDImpl.scala:90), which has no missing parents
[2025-05-07T23:27:02.277+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:01 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 18.7 KiB, free 417.2 MiB)
[2025-05-07T23:27:02.560+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:02 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 417.1 MiB)
[2025-05-07T23:27:03.022+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:02 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 3530b0b864fd:41807 (size: 6.9 KiB, free: 433.3 MiB)
[2025-05-07T23:27:03.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:03 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:27:03.406+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:03 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 304 (MapPartitionsRDD[404] at map at VertexRDDImpl.scala:90) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:27:03.549+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:03 INFO TaskSchedulerImpl: Adding task set 304.0 with 10 tasks resource profile 0
[2025-05-07T23:27:03.731+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:03 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 500) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:10.403+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:10 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.20.0.5:40779 (size: 6.9 KiB, free: 433.4 MiB)
[2025-05-07T23:27:14.409+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:14 INFO TaskSetManager: Starting task 1.0 in stage 304.0 (TID 501) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:14.753+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:14 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 500) in 10846 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:27:16.456+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:16 INFO TaskSetManager: Starting task 2.0 in stage 304.0 (TID 502) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:17.789+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:17 INFO TaskSetManager: Finished task 1.0 in stage 304.0 (TID 501) in 3454 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:27:19.638+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:19 INFO TaskSetManager: Starting task 3.0 in stage 304.0 (TID 503) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:19.769+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:19 INFO TaskSetManager: Finished task 2.0 in stage 304.0 (TID 502) in 3343 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:27:21.818+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:21 INFO TaskSetManager: Starting task 4.0 in stage 304.0 (TID 504) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:24.972+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:24 INFO TaskSetManager: Finished task 3.0 in stage 304.0 (TID 503) in 5478 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:27:26.208+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:26 INFO TaskSetManager: Starting task 5.0 in stage 304.0 (TID 505) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:26.329+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:26 INFO TaskSetManager: Finished task 4.0 in stage 304.0 (TID 504) in 4483 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:27:27.295+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:27 INFO TaskSetManager: Starting task 6.0 in stage 304.0 (TID 506) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:27.381+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:27 INFO TaskSetManager: Finished task 5.0 in stage 304.0 (TID 505) in 1200 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:27:29.816+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:29 INFO TaskSetManager: Starting task 7.0 in stage 304.0 (TID 507) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:29.903+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:29 INFO TaskSetManager: Finished task 6.0 in stage 304.0 (TID 506) in 2544 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:27:34.542+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:34 INFO TaskSetManager: Starting task 8.0 in stage 304.0 (TID 508) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:34.856+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:34 INFO TaskSetManager: Finished task 7.0 in stage 304.0 (TID 507) in 4771 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:27:36.259+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:36 INFO TaskSetManager: Starting task 9.0 in stage 304.0 (TID 509) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5350 bytes) taskResourceAssignments Map()
[2025-05-07T23:27:36.310+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:36 INFO TaskSetManager: Finished task 8.0 in stage 304.0 (TID 508) in 1890 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:27:37.405+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:37 INFO TaskSetManager: Finished task 9.0 in stage 304.0 (TID 509) in 1124 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:27:37.659+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:37 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool
[2025-05-07T23:27:37.684+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:37 INFO DAGScheduler: ResultStage 304 (fold at VertexRDDImpl.scala:90) finished in 35.628 s
[2025-05-07T23:27:37.690+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:37 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:27:37.690+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished
[2025-05-07T23:27:37.691+0000] {spark_submit.py:571} INFO - 25/05/07 23:27:37 INFO DAGScheduler: Job 47 finished: fold at VertexRDDImpl.scala:90, took 36.536811 s
[2025-05-07T23:28:05.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 3530b0b864fd:41807 in memory (size: 58.0 KiB, free: 433.4 MiB)
[2025-05-07T23:28:05.378+0000] {spark_submit.py:571} INFO - 2025-05-07 23:28:05,365 [INFO] Экспортируем граф в GraphML
[2025-05-07T23:28:05.491+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.20.0.5:40779 in memory (size: 58.0 KiB, free: 433.5 MiB)
[2025-05-07T23:28:05.597+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.20.0.5:40779 in memory (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T23:28:05.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 3530b0b864fd:41807 in memory (size: 6.7 KiB, free: 433.4 MiB)
[2025-05-07T23:28:05.668+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 3530b0b864fd:41807 in memory (size: 6.9 KiB, free: 433.4 MiB)
[2025-05-07T23:28:05.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.20.0.5:40779 in memory (size: 6.9 KiB, free: 433.5 MiB)
[2025-05-07T23:28:05.672+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 3530b0b864fd:41807 in memory (size: 58.4 KiB, free: 433.4 MiB)
[2025-05-07T23:28:05.673+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.20.0.5:40779 in memory (size: 58.4 KiB, free: 433.6 MiB)
[2025-05-07T23:28:05.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 3530b0b864fd:41807 in memory (size: 58.5 KiB, free: 433.5 MiB)
[2025-05-07T23:28:05.693+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.20.0.5:40779 in memory (size: 58.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:05.700+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 3530b0b864fd:41807 in memory (size: 6.8 KiB, free: 433.5 MiB)
[2025-05-07T23:28:05.701+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.20.0.5:40779 in memory (size: 6.8 KiB, free: 433.6 MiB)
[2025-05-07T23:28:05.711+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.20.0.5:40779 in memory (size: 7.1 KiB, free: 433.6 MiB)
[2025-05-07T23:28:05.712+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 3530b0b864fd:41807 in memory (size: 7.1 KiB, free: 433.5 MiB)
[2025-05-07T23:28:05.722+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.20.0.5:40779 in memory (size: 58.2 KiB, free: 433.7 MiB)
[2025-05-07T23:28:05.723+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:05 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 3530b0b864fd:41807 in memory (size: 58.2 KiB, free: 433.6 MiB)
[2025-05-07T23:28:08.612+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 6.610749 ms
[2025-05-07T23:28:08.618+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DefaultCachedBatchSerializer: Predicate isnotnull(id#952) generates partition filter: ((id.count#2040 - id.nullCount#2039) > 0)
[2025-05-07T23:28:08.640+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 25.857194 ms
[2025-05-07T23:28:08.643+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:28:08.644+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 446 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 53
[2025-05-07T23:28:08.644+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 48 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T23:28:08.645+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 308 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.645+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 306, ShuffleMapStage 307)
[2025-05-07T23:28:08.645+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.646+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 308 (MapPartitionsRDD[446] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.652+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 23.3 KiB, free 418.1 MiB)
[2025-05-07T23:28:08.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 418.1 MiB)
[2025-05-07T23:28:08.657+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 10.79182 ms
[2025-05-07T23:28:08.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 3530b0b864fd:41807 (size: 9.9 KiB, free: 433.6 MiB)
[2025-05-07T23:28:08.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 308 (MapPartitionsRDD[446] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:28:08.658+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 308.0 with 10 tasks resource profile 0
[2025-05-07T23:28:08.659+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got job 49 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T23:28:08.659+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ResultStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.659+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 305)
[2025-05-07T23:28:08.659+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 0.0 in stage 308.0 (TID 510) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.660+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.664+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ResultStage 309 (MapPartitionsRDD[443] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.664+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 43.9 KiB, free 418.0 MiB)
[2025-05-07T23:28:08.666+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 418.0 MiB)
[2025-05-07T23:28:08.667+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 3530b0b864fd:41807 (size: 19.4 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.667+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.668+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 309 (MapPartitionsRDD[443] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:28:08.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 309.0 with 10 tasks resource profile 0
[2025-05-07T23:28:08.670+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 6.325311 ms
[2025-05-07T23:28:08.674+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 449 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 54
[2025-05-07T23:28:08.674+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 50 (toPandas at /opt/airflow/spark/build_graph.py:207) with 10 output partitions
[2025-05-07T23:28:08.675+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.675+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 317, ShuffleMapStage 306, ShuffleMapStage 321, ShuffleMapStage 310, ShuffleMapStage 307, ShuffleMapStage 325, ShuffleMapStage 329, ShuffleMapStage 323, ShuffleMapStage 315, ShuffleMapStage 327, ShuffleMapStage 319, ShuffleMapStage 331, ShuffleMapStage 313)
[2025-05-07T23:28:08.676+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.677+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 332 (MapPartitionsRDD[449] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.681+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 7.205066 ms
[2025-05-07T23:28:08.687+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 31.6 KiB, free 418.0 MiB)
[2025-05-07T23:28:08.689+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 418.0 MiB)
[2025-05-07T23:28:08.690+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 3530b0b864fd:41807 (size: 11.8 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.691+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.692+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 332 (MapPartitionsRDD[449] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
[2025-05-07T23:28:08.694+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 332.0 with 10 tasks resource profile 0
[2025-05-07T23:28:08.694+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 6.489226 ms
[2025-05-07T23:28:08.704+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 7.177892 ms
[2025-05-07T23:28:08.706+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.20.0.5:40779 (size: 9.9 KiB, free: 433.7 MiB)
[2025-05-07T23:28:08.716+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 7.692357 ms
[2025-05-07T23:28:08.737+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 16.143658 ms
[2025-05-07T23:28:08.745+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 4.104277 ms
[2025-05-07T23:28:08.748+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:28:08.758+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 457 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 55
[2025-05-07T23:28:08.759+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 51 (toPandas at /opt/airflow/spark/build_graph.py:207) with 6 output partitions
[2025-05-07T23:28:08.761+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.761+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.761+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.762+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 8.79031 ms
[2025-05-07T23:28:08.762+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 333 (MapPartitionsRDD[457] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:28:08.767+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 36.4 KiB, free 418.0 MiB)
[2025-05-07T23:28:08.771+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 417.9 MiB)
[2025-05-07T23:28:08.772+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 3530b0b864fd:41807 (size: 11.2 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.773+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.774+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 333 (MapPartitionsRDD[457] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
[2025-05-07T23:28:08.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 333.0 with 6 tasks resource profile 0
[2025-05-07T23:28:08.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 459 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 56
[2025-05-07T23:28:08.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 52 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:08.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 334 (MapPartitionsRDD[459] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.779+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 12.7 KiB, free 417.9 MiB)
[2025-05-07T23:28:08.780+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 417.9 MiB)
[2025-05-07T23:28:08.782+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 3530b0b864fd:41807 (size: 6.7 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.782+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.782+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 13.187774 ms
[2025-05-07T23:28:08.782+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 334 (MapPartitionsRDD[459] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:08.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 334.0 with 1 tasks resource profile 0
[2025-05-07T23:28:08.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 461 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 57
[2025-05-07T23:28:08.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 53 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:08.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.783+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.785+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 335 (MapPartitionsRDD[461] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.787+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:28:08.789+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 27.3 KiB, free 417.9 MiB)
[2025-05-07T23:28:08.790+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 417.9 MiB)
[2025-05-07T23:28:08.790+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 3530b0b864fd:41807 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.792+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.793+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 335 (MapPartitionsRDD[461] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:08.793+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 335.0 with 1 tasks resource profile 0
[2025-05-07T23:28:08.793+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 463 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 58
[2025-05-07T23:28:08.793+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 54 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:08.793+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.794+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.794+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.795+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 336 (MapPartitionsRDD[463] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.798+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 28.5 KiB, free 417.9 MiB)
[2025-05-07T23:28:08.800+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 417.8 MiB)
[2025-05-07T23:28:08.802+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 3530b0b864fd:41807 (size: 13.5 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.802+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.803+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 336 (MapPartitionsRDD[463] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:08.803+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 336.0 with 1 tasks resource profile 0
[2025-05-07T23:28:08.807+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 13.850687 ms
[2025-05-07T23:28:08.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:28:08.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 465 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 59
[2025-05-07T23:28:08.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 55 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:08.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.808+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.812+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 337 (MapPartitionsRDD[465] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.816+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 28.5 KiB, free 417.8 MiB)
[2025-05-07T23:28:08.819+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 417.8 MiB)
[2025-05-07T23:28:08.820+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 3530b0b864fd:41807 (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.822+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.822+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 337 (MapPartitionsRDD[465] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:08.823+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 337.0 with 1 tasks resource profile 0
[2025-05-07T23:28:08.828+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 15.512791 ms
[2025-05-07T23:28:08.834+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:28:08.835+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 467 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 60
[2025-05-07T23:28:08.835+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 56 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:08.835+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.835+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.835+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.838+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 338 (MapPartitionsRDD[467] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.840+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 27.4 KiB, free 417.8 MiB)
[2025-05-07T23:28:08.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 417.8 MiB)
[2025-05-07T23:28:08.864+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 3530b0b864fd:41807 (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T23:28:08.866+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 1.0 in stage 308.0 (TID 511) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.867+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 0.0 in stage 308.0 (TID 510) in 207 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:28:08.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 338 (MapPartitionsRDD[467] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:08.868+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 338.0 with 1 tasks resource profile 0
[2025-05-07T23:28:08.873+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 35.485695 ms
[2025-05-07T23:28:08.878+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:28:08.881+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 469 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 61
[2025-05-07T23:28:08.882+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 57 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:08.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.883+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.885+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 339 (MapPartitionsRDD[469] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.886+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 2.0 in stage 308.0 (TID 512) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.886+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 1.0 in stage 308.0 (TID 511) in 20 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:28:08.888+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 28.5 KiB, free 417.7 MiB)
[2025-05-07T23:28:08.890+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 417.7 MiB)
[2025-05-07T23:28:08.891+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 3530b0b864fd:41807 (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T23:28:08.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 339 (MapPartitionsRDD[469] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:08.893+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 339.0 with 1 tasks resource profile 0
[2025-05-07T23:28:08.902+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 3.0 in stage 308.0 (TID 513) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.903+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 2.0 in stage 308.0 (TID 512) in 17 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:28:08.904+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO CodeGenerator: Code generated in 15.501441 ms
[2025-05-07T23:28:08.907+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Registering RDD 471 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 62
[2025-05-07T23:28:08.907+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Got map stage job 58 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:08.908+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Final stage: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:08.908+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:08.908+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:08.908+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting ShuffleMapStage 340 (MapPartitionsRDD[471] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:08.910+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 31.7 KiB, free 417.7 MiB)
[2025-05-07T23:28:08.911+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 417.7 MiB)
[2025-05-07T23:28:08.912+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 3530b0b864fd:41807 (size: 14.9 KiB, free: 433.4 MiB)
[2025-05-07T23:28:08.912+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:08.912+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 340 (MapPartitionsRDD[471] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:08.912+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSchedulerImpl: Adding task set 340.0 with 1 tasks resource profile 0
[2025-05-07T23:28:08.916+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 4.0 in stage 308.0 (TID 514) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.916+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 3.0 in stage 308.0 (TID 513) in 14 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:28:08.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 5.0 in stage 308.0 (TID 515) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.934+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 4.0 in stage 308.0 (TID 514) in 19 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:28:08.946+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 6.0 in stage 308.0 (TID 516) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.946+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 5.0 in stage 308.0 (TID 515) in 13 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:28:08.958+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 7.0 in stage 308.0 (TID 517) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.959+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 6.0 in stage 308.0 (TID 516) in 12 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:28:08.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 8.0 in stage 308.0 (TID 518) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.967+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 7.0 in stage 308.0 (TID 517) in 9 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:28:08.974+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Starting task 9.0 in stage 308.0 (TID 519) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4536 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:08.975+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:08 INFO TaskSetManager: Finished task 8.0 in stage 308.0 (TID 518) in 8 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:28:09.004+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 520) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.004+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 9.0 in stage 308.0 (TID 519) in 30 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:28:09.004+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSchedulerImpl: Removed TaskSet 308.0, whose tasks have all completed, from pool
[2025-05-07T23:28:09.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: ShuffleMapStage 308 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.358 s
[2025-05-07T23:28:09.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:28:09.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ShuffleMapStage 332, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 340, ShuffleMapStage 333, ResultStage 309, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T23:28:09.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:28:09.005+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: failed: Set()
[2025-05-07T23:28:09.009+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.20.0.5:40779 (size: 19.4 KiB, free: 433.7 MiB)
[2025-05-07T23:28:09.028+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:28:09.028+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 1.0 in stage 309.0 (TID 521) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.029+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 520) in 24 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:28:09.029+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:28:09.036+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 2.0 in stage 309.0 (TID 522) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.036+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 1.0 in stage 309.0 (TID 521) in 8 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:28:09.043+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 3.0 in stage 309.0 (TID 523) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.044+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 2.0 in stage 309.0 (TID 522) in 8 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:28:09.051+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 4.0 in stage 309.0 (TID 524) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.052+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 3.0 in stage 309.0 (TID 523) in 9 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:28:09.060+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 5.0 in stage 309.0 (TID 525) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.061+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 4.0 in stage 309.0 (TID 524) in 10 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:28:09.071+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 6.0 in stage 309.0 (TID 526) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.072+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 5.0 in stage 309.0 (TID 525) in 9 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:28:09.075+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:28:09.076+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Got job 59 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:09.076+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Final stage: ResultStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:09.077+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 341)
[2025-05-07T23:28:09.077+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:09.078+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Submitting ResultStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:09.081+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 7.2 KiB, free 417.7 MiB)
[2025-05-07T23:28:09.082+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 417.7 MiB)
[2025-05-07T23:28:09.084+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 7.0 in stage 309.0 (TID 527) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.084+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 6.0 in stage 309.0 (TID 526) in 14 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:28:09.085+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T23:28:09.086+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:09.086+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 342 (MapPartitionsRDD[477] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:09.087+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSchedulerImpl: Adding task set 342.0 with 1 tasks resource profile 0
[2025-05-07T23:28:09.094+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 8.0 in stage 309.0 (TID 528) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.095+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 7.0 in stage 309.0 (TID 527) in 12 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:28:09.101+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 9.0 in stage 309.0 (TID 529) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.101+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 8.0 in stage 309.0 (TID 528) in 7 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:28:09.107+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 0.0 in stage 332.0 (TID 530) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.107+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 9.0 in stage 309.0 (TID 529) in 6 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:28:09.107+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool
[2025-05-07T23:28:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: ResultStage 309 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.445 s
[2025-05-07T23:28:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:28:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 309: Stage finished
[2025-05-07T23:28:09.108+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Job 49 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 0.465609 s
[2025-05-07T23:28:09.115+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.20.0.5:40779 (size: 11.8 KiB, free: 433.7 MiB)
[2025-05-07T23:28:09.118+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO CodeGenerator: Code generated in 6.552663 ms
[2025-05-07T23:28:09.121+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 2.1 MiB, free 415.6 MiB)
[2025-05-07T23:28:09.138+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 415.6 MiB)
[2025-05-07T23:28:09.139+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 3530b0b864fd:41807 (size: 27.5 KiB, free: 433.4 MiB)
[2025-05-07T23:28:09.139+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO SparkContext: Created broadcast 103 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:28:09.140+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_0 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.7 MiB)
[2025-05-07T23:28:09.180+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 1.0 in stage 332.0 (TID 531) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.184+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 0.0 in stage 332.0 (TID 530) in 77 ms on 172.20.0.5 (executor 2) (1/10)
[2025-05-07T23:28:09.190+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_1 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.202+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 2.0 in stage 332.0 (TID 532) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.203+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 1.0 in stage 332.0 (TID 531) in 23 ms on 172.20.0.5 (executor 2) (2/10)
[2025-05-07T23:28:09.215+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_2 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.222+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 3.0 in stage 332.0 (TID 533) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.223+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 2.0 in stage 332.0 (TID 532) in 20 ms on 172.20.0.5 (executor 2) (3/10)
[2025-05-07T23:28:09.231+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_3 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.237+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO CodeGenerator: Code generated in 6.12409 ms
[2025-05-07T23:28:09.239+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 4.0 in stage 332.0 (TID 534) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 3.0 in stage 332.0 (TID 533) in 18 ms on 172.20.0.5 (executor 2) (4/10)
[2025-05-07T23:28:09.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Registering RDD 487 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 63
[2025-05-07T23:28:09.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Got map stage job 60 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:09.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Final stage: ShuffleMapStage 343 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:09.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:28:09.240+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:09.241+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Submitting ShuffleMapStage 343 (MapPartitionsRDD[487] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:09.245+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 16.6 KiB, free 415.6 MiB)
[2025-05-07T23:28:09.246+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 415.5 MiB)
[2025-05-07T23:28:09.246+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 3530b0b864fd:41807 (size: 8.3 KiB, free: 433.4 MiB)
[2025-05-07T23:28:09.246+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:09.246+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 343 (MapPartitionsRDD[487] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:09.247+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSchedulerImpl: Adding task set 343.0 with 1 tasks resource profile 0
[2025-05-07T23:28:09.249+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_4 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.254+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 5.0 in stage 332.0 (TID 535) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.255+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 4.0 in stage 332.0 (TID 534) in 16 ms on 172.20.0.5 (executor 2) (5/10)
[2025-05-07T23:28:09.260+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_5 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.268+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 6.0 in stage 332.0 (TID 536) (172.20.0.5, executor 2, partition 6, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.268+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 5.0 in stage 332.0 (TID 535) in 14 ms on 172.20.0.5 (executor 2) (6/10)
[2025-05-07T23:28:09.274+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_6 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.281+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 7.0 in stage 332.0 (TID 537) (172.20.0.5, executor 2, partition 7, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.282+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 6.0 in stage 332.0 (TID 536) in 13 ms on 172.20.0.5 (executor 2) (7/10)
[2025-05-07T23:28:09.288+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_7 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.310+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 8.0 in stage 332.0 (TID 538) (172.20.0.5, executor 2, partition 8, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.311+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 7.0 in stage 332.0 (TID 537) in 31 ms on 172.20.0.5 (executor 2) (8/10)
[2025-05-07T23:28:09.315+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_8 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.321+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 9.0 in stage 332.0 (TID 539) (172.20.0.5, executor 2, partition 9, PROCESS_LOCAL, 5339 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.322+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 8.0 in stage 332.0 (TID 538) in 11 ms on 172.20.0.5 (executor 2) (9/10)
[2025-05-07T23:28:09.327+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added rdd_405_9 in memory on 172.20.0.5:40779 (size: 5.5 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.338+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Starting task 0.0 in stage 333.0 (TID 540) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:28:09.338+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSetManager: Finished task 9.0 in stage 332.0 (TID 539) in 17 ms on 172.20.0.5 (executor 2) (10/10)
[2025-05-07T23:28:09.339+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSchedulerImpl: Removed TaskSet 332.0, whose tasks have all completed, from pool
[2025-05-07T23:28:09.347+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: ShuffleMapStage 332 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 0.659 s
[2025-05-07T23:28:09.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:28:09.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 333, ShuffleMapStage 337, ShuffleMapStage 334)
[2025-05-07T23:28:09.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:28:09.349+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: failed: Set()
[2025-05-07T23:28:09.370+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.20.0.5:40779 (size: 11.2 KiB, free: 433.6 MiB)
[2025-05-07T23:28:09.395+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO ShufflePartitionsUtil: For shuffle(54), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:28:09.455+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:28:09.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Got job 61 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:28:09.459+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Final stage: ResultStage 367 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:28:09.460+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 366)
[2025-05-07T23:28:09.460+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:28:09.460+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Submitting ResultStage 367 (MapPartitionsRDD[492] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:28:09.462+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 7.2 KiB, free 415.5 MiB)
[2025-05-07T23:28:09.476+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.5 MiB)
[2025-05-07T23:28:09.479+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T23:28:09.480+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:28:09.482+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 367 (MapPartitionsRDD[492] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:28:09.483+0000] {spark_submit.py:571} INFO - 25/05/07 23:28:09 INFO TaskSchedulerImpl: Adding task set 367.0 with 1 tasks resource profile 0
[2025-05-07T23:30:04.205+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:04 INFO TaskSetManager: Starting task 1.0 in stage 333.0 (TID 541) (172.20.0.5, executor 2, partition 1, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:03.655+0000] {job.py:213} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.20.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 184, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.20.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-05-07T23:30:04.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:04 INFO TaskSetManager: Finished task 0.0 in stage 333.0 (TID 540) in 114879 ms on 172.20.0.5 (executor 2) (1/6)
[2025-05-07T23:30:05.119+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Starting task 2.0 in stage 333.0 (TID 542) (172.20.0.5, executor 2, partition 2, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:05.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Finished task 1.0 in stage 333.0 (TID 541) in 920 ms on 172.20.0.5 (executor 2) (2/6)
[2025-05-07T23:30:05.243+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Starting task 3.0 in stage 333.0 (TID 543) (172.20.0.5, executor 2, partition 3, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:05.243+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Finished task 2.0 in stage 333.0 (TID 542) in 126 ms on 172.20.0.5 (executor 2) (3/6)
[2025-05-07T23:30:05.310+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Starting task 4.0 in stage 333.0 (TID 544) (172.20.0.5, executor 2, partition 4, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:05.311+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Finished task 3.0 in stage 333.0 (TID 543) in 68 ms on 172.20.0.5 (executor 2) (4/6)
[2025-05-07T23:30:05.405+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Starting task 5.0 in stage 333.0 (TID 545) (172.20.0.5, executor 2, partition 5, PROCESS_LOCAL, 4401 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:05.405+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:05 INFO TaskSetManager: Finished task 4.0 in stage 333.0 (TID 544) in 95 ms on 172.20.0.5 (executor 2) (5/6)
[2025-05-07T23:30:07.157+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSetManager: Starting task 0.0 in stage 334.0 (TID 546) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:07.214+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSetManager: Finished task 5.0 in stage 333.0 (TID 545) in 1769 ms on 172.20.0.5 (executor 2) (6/6)
[2025-05-07T23:30:07.214+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSchedulerImpl: Removed TaskSet 333.0, whose tasks have all completed, from pool
[2025-05-07T23:30:07.214+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: ShuffleMapStage 333 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 118.409 s
[2025-05-07T23:30:07.214+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:07.214+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ShuffleMapStage 334, ResultStage 367)
[2025-05-07T23:30:07.215+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:07.215+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:07.304+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:30:07.309+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO ShufflePartitionsUtil: For shuffle(55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:30:07.341+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.20.0.5:40779 (size: 6.7 KiB, free: 433.6 MiB)
[2025-05-07T23:30:07.391+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:30:07.392+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Got job 62 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:30:07.392+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Final stage: ResultStage 369 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:30:07.392+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 368)
[2025-05-07T23:30:07.392+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:30:07.393+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Submitting ResultStage 369 (MapPartitionsRDD[497] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:30:07.394+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 7.2 KiB, free 415.5 MiB)
[2025-05-07T23:30:07.457+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.6 MiB)
[2025-05-07T23:30:07.462+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T23:30:07.462+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:30:07.464+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 3530b0b864fd:41807 in memory (size: 9.9 KiB, free: 433.4 MiB)
[2025-05-07T23:30:07.465+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 369 (MapPartitionsRDD[497] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:30:07.466+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSchedulerImpl: Adding task set 369.0 with 1 tasks resource profile 0
[2025-05-07T23:30:07.479+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.20.0.5:40779 in memory (size: 9.9 KiB, free: 433.6 MiB)
[2025-05-07T23:30:07.488+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 3530b0b864fd:41807 in memory (size: 11.8 KiB, free: 433.4 MiB)
[2025-05-07T23:30:07.489+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.20.0.5:40779 in memory (size: 11.8 KiB, free: 433.6 MiB)
[2025-05-07T23:30:07.553+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 3530b0b864fd:41807 in memory (size: 11.2 KiB, free: 433.4 MiB)
[2025-05-07T23:30:07.629+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.20.0.5:40779 in memory (size: 11.2 KiB, free: 433.6 MiB)
[2025-05-07T23:30:07.644+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSetManager: Starting task 0.0 in stage 335.0 (TID 547) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:07.649+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSetManager: Finished task 0.0 in stage 334.0 (TID 546) in 501 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:07.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSchedulerImpl: Removed TaskSet 334.0, whose tasks have all completed, from pool
[2025-05-07T23:30:07.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: ShuffleMapStage 334 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 118.873 s
[2025-05-07T23:30:07.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:07.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ShuffleMapStage 335, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ResultStage 367)
[2025-05-07T23:30:07.650+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:07.651+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:07.665+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 3530b0b864fd:41807 in memory (size: 19.4 KiB, free: 433.4 MiB)
[2025-05-07T23:30:07.668+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.20.0.5:40779 in memory (size: 19.4 KiB, free: 433.6 MiB)
[2025-05-07T23:30:07.669+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.20.0.5:40779 (size: 13.0 KiB, free: 433.6 MiB)
[2025-05-07T23:30:07.688+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO ShufflePartitionsUtil: For shuffle(56), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:30:07.768+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:30:07.768+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Got job 63 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:30:07.769+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Final stage: ResultStage 371 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:30:07.769+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 370)
[2025-05-07T23:30:07.769+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:30:07.769+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Submitting ResultStage 371 (MapPartitionsRDD[505] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:30:07.771+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 7.2 KiB, free 415.7 MiB)
[2025-05-07T23:30:07.775+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 415.7 MiB)
[2025-05-07T23:30:07.776+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 3530b0b864fd:41807 (size: 3.8 KiB, free: 433.4 MiB)
[2025-05-07T23:30:07.777+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:30:07.777+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 371 (MapPartitionsRDD[505] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:30:07.777+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:07 INFO TaskSchedulerImpl: Adding task set 371.0 with 1 tasks resource profile 0
[2025-05-07T23:30:08.011+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 336.0 (TID 548) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.012+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 335.0 (TID 547) in 370 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.013+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 335.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.013+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ShuffleMapStage 335 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.229 s
[2025-05-07T23:30:08.013+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:08.013+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 371, ResultStage 342, ShuffleMapStage 339, ShuffleMapStage 336, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ResultStage 367)
[2025-05-07T23:30:08.013+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:08.013+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:08.019+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.20.0.5:40779 (size: 13.5 KiB, free: 433.6 MiB)
[2025-05-07T23:30:08.113+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 337.0 (TID 549) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.115+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 336.0 (TID 548) in 104 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.115+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 336.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.116+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ShuffleMapStage 336 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.319 s
[2025-05-07T23:30:08.116+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:08.116+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 371, ResultStage 342, ShuffleMapStage 339, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ShuffleMapStage 337, ResultStage 367)
[2025-05-07T23:30:08.116+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:08.116+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:08.120+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.20.0.5:40779 (size: 13.4 KiB, free: 433.6 MiB)
[2025-05-07T23:30:08.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 338.0 (TID 550) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 337.0 (TID 549) in 74 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 337.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.187+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ShuffleMapStage 337 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.375 s
[2025-05-07T23:30:08.188+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:08.188+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: running: Set(ShuffleMapStage 338, ResultStage 371, ResultStage 342, ShuffleMapStage 339, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ResultStage 367)
[2025-05-07T23:30:08.188+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:08.188+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:08.201+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.20.0.5:40779 (size: 13.0 KiB, free: 433.6 MiB)
[2025-05-07T23:30:08.262+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 339.0 (TID 551) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.262+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 338.0 (TID 550) in 76 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.262+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 338.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ShuffleMapStage 338 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.425 s
[2025-05-07T23:30:08.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:08.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: running: Set(ResultStage 371, ResultStage 342, ShuffleMapStage 339, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ResultStage 367)
[2025-05-07T23:30:08.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:08.263+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:08.270+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.20.0.5:40779 (size: 13.4 KiB, free: 433.6 MiB)
[2025-05-07T23:30:08.321+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 340.0 (TID 552) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.322+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 339.0 (TID 551) in 60 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.322+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 339.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ShuffleMapStage 339 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.437 s
[2025-05-07T23:30:08.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:08.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: running: Set(ResultStage 371, ResultStage 342, ResultStage 369, ShuffleMapStage 343, ShuffleMapStage 340, ResultStage 367)
[2025-05-07T23:30:08.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:08.323+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:08.334+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.20.0.5:40779 (size: 14.9 KiB, free: 433.6 MiB)
[2025-05-07T23:30:08.423+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 342.0 (TID 553) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 340.0 (TID 552) in 102 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 340.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ShuffleMapStage 340 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.516 s
[2025-05-07T23:30:08.425+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:08.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: running: Set(ResultStage 371, ResultStage 342, ResultStage 369, ShuffleMapStage 343, ResultStage 367)
[2025-05-07T23:30:08.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:08.426+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:08.437+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.20.0.5:40779 (size: 3.8 KiB, free: 433.6 MiB)
[2025-05-07T23:30:08.452+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 53 to 172.20.0.5:47382
[2025-05-07T23:30:08.463+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO ShufflePartitionsUtil: For shuffle(57, 58, 59, 60, 61, 62), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:30:08.542+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 343.0 (TID 554) (172.20.0.5, executor 2, partition 0, PROCESS_LOCAL, 4292 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.556+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 342.0 (TID 553) in 134 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.556+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 342.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ResultStage 342 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.477 s
[2025-05-07T23:30:08.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:30:08.557+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 342: Stage finished
[2025-05-07T23:30:08.564+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Job 59 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 119.487523 s
[2025-05-07T23:30:08.573+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.20.0.5:40779 (size: 8.3 KiB, free: 433.5 MiB)
[2025-05-07T23:30:08.617+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 38.935461 ms
[2025-05-07T23:30:08.618+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:30:08.637+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 17.335836 ms
[2025-05-07T23:30:08.647+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.20.0.5:40779 (size: 27.5 KiB, free: 433.5 MiB)
[2025-05-07T23:30:08.655+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 7.469781 ms
[2025-05-07T23:30:08.683+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 1088.0 KiB, free 414.6 MiB)
[2025-05-07T23:30:08.699+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:30:08.714+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 414.6 MiB)
[2025-05-07T23:30:08.717+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 367.0 (TID 555) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.721+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 3530b0b864fd:41807 (size: 32.6 KiB, free: 433.4 MiB)
[2025-05-07T23:30:08.727+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 343.0 (TID 554) in 175 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.728+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 343.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.729+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO SparkContext: Created broadcast 108 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:30:08.729+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 22.56202 ms
[2025-05-07T23:30:08.730+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ShuffleMapStage 343 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.482 s
[2025-05-07T23:30:08.730+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: looking for newly runnable stages
[2025-05-07T23:30:08.730+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: running: Set(ResultStage 371, ResultStage 369, ResultStage 367)
[2025-05-07T23:30:08.730+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: waiting: Set()
[2025-05-07T23:30:08.730+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: failed: Set()
[2025-05-07T23:30:08.743+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:30:08.749+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.20.0.5:40779 (size: 3.8 KiB, free: 433.5 MiB)
[2025-05-07T23:30:08.764+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 16.794967 ms
[2025-05-07T23:30:08.765+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 54 to 172.20.0.5:47382
[2025-05-07T23:30:08.790+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:30:08.814+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Starting task 0.0 in stage 369.0 (TID 556) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4473 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:08.815+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSetManager: Finished task 0.0 in stage 367.0 (TID 555) in 98 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:08.822+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Removed TaskSet 367.0, whose tasks have all completed, from pool
[2025-05-07T23:30:08.822+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: ResultStage 367 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 119.357 s
[2025-05-07T23:30:08.827+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:30:08.828+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 367: Stage finished
[2025-05-07T23:30:08.829+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 27.625089 ms
[2025-05-07T23:30:08.831+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Job 61 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 119.366550 s
[2025-05-07T23:30:08.832+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 1088.0 KiB, free 413.5 MiB)
[2025-05-07T23:30:08.853+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:30:08.854+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.20.0.5:40779 (size: 3.8 KiB, free: 433.5 MiB)
[2025-05-07T23:30:08.859+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 413.5 MiB)
[2025-05-07T23:30:08.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 3530b0b864fd:41807 (size: 23.7 KiB, free: 433.4 MiB)
[2025-05-07T23:30:08.861+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO SparkContext: Created broadcast 109 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:30:08.863+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 55 to 172.20.0.5:47382
[2025-05-07T23:30:08.897+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 35.326421 ms
[2025-05-07T23:30:08.901+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO CodeGenerator: Code generated in 13.817201 ms
[2025-05-07T23:30:08.915+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Registering RDD 540 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 64
[2025-05-07T23:30:08.922+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Got map stage job 64 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:30:08.923+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Final stage: ShuffleMapStage 372 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:30:08.924+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:30:08.925+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:30:08.929+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO DAGScheduler: Submitting ShuffleMapStage 372 (MapPartitionsRDD[540] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:30:08.954+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 17.6 KiB, free 413.5 MiB)
[2025-05-07T23:30:08.974+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-07T23:30:09.109+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 413.5 MiB)
[2025-05-07T23:30:09.109+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 3530b0b864fd:41807 (size: 8.3 KiB, free: 433.4 MiB)
[2025-05-07T23:30:09.111+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1474
[2025-05-07T23:30:09.113+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO TaskSetManager: Starting task 0.0 in stage 371.0 (TID 557) (172.20.0.5, executor 2, partition 0, NODE_LOCAL, 4476 bytes) taskResourceAssignments Map()
[2025-05-07T23:30:09.116+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 372 (MapPartitionsRDD[540] at toPandas at /opt/airflow/spark/build_graph.py:207) (first 15 tasks are for partitions Vector(0))
[2025-05-07T23:30:09.119+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO TaskSchedulerImpl: Adding task set 372.0 with 1 tasks resource profile 0
[2025-05-07T23:30:09.122+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO TaskSetManager: Finished task 0.0 in stage 369.0 (TID 556) in 309 ms on 172.20.0.5 (executor 2) (1/1)
[2025-05-07T23:30:09.124+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO TaskSchedulerImpl: Removed TaskSet 369.0, whose tasks have all completed, from pool
[2025-05-07T23:30:09.127+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 3530b0b864fd:41807 in memory (size: 13.0 KiB, free: 433.4 MiB)
[2025-05-07T23:30:09.129+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO DAGScheduler: ResultStage 369 (toPandas at /opt/airflow/spark/build_graph.py:207) finished in 1.728 s
[2025-05-07T23:30:09.132+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-07T23:30:09.132+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 369: Stage finished
[2025-05-07T23:30:09.132+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO DAGScheduler: Job 62 finished: toPandas at /opt/airflow/spark/build_graph.py:207, took 1.730561 s
[2025-05-07T23:30:09.160+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.20.0.5:40779 (size: 3.8 KiB, free: 433.5 MiB)
[2025-05-07T23:30:09.163+0000] {spark_submit.py:571} INFO - 25/05/07 23:30:09 INFO CodeGenerator: Code generated in 188.459976 ms
[2025-05-07T23:31:24.454+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO CodeGenerator: Code generated in 75528.067313 ms
[2025-05-07T23:31:24.462+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.20.0.5:40779 in memory (size: 13.0 KiB, free: 433.5 MiB)
[2025-05-07T23:31:24.465+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 56 to 172.20.0.5:47382
[2025-05-07T23:31:24.472+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 5.0 MiB, free 408.5 MiB)
[2025-05-07T23:31:24.502+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 3530b0b864fd:41807 in memory (size: 13.4 KiB, free: 433.4 MiB)
[2025-05-07T23:31:24.534+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO DAGScheduler: Registering RDD 548 (toPandas at /opt/airflow/spark/build_graph.py:207) as input to shuffle 65
[2025-05-07T23:31:32.842+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO DAGScheduler: Got map stage job 65 (toPandas at /opt/airflow/spark/build_graph.py:207) with 1 output partitions
[2025-05-07T23:31:33.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO DAGScheduler: Final stage: ShuffleMapStage 373 (toPandas at /opt/airflow/spark/build_graph.py:207)
[2025-05-07T23:31:33.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO DAGScheduler: Parents of final stage: List()
[2025-05-07T23:31:33.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO DAGScheduler: Missing parents: List()
[2025-05-07T23:31:33.220+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO DAGScheduler: Submitting ShuffleMapStage 373 (MapPartitionsRDD[548] at toPandas at /opt/airflow/spark/build_graph.py:207), which has no missing parents
[2025-05-07T23:31:33.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.20.0.5:40779 in memory (size: 13.4 KiB, free: 433.5 MiB)
[2025-05-07T23:31:33.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 502.1 KiB, free 408.1 MiB)
[2025-05-07T23:31:33.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 77.9 KiB, free 408.0 MiB)
[2025-05-07T23:31:33.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO SparkContext: Starting job: toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:31:33.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO ShufflePartitionsUtil: For shuffle(63), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-07T23:31:33.221+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:24 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.20.0.5:40779 in memory (size: 8.3 KiB, free: 433.5 MiB)
[2025-05-07T23:31:33.259+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:33 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 3530b0b864fd:41807 (size: 502.1 KiB, free: 432.9 MiB)
[2025-05-07T23:32:08.780+0000] {spark_submit.py:571} INFO - 25/05/07 23:31:41 INFO SparkContext: Created broadcast 111 from toPandas at /opt/airflow/spark/build_graph.py:207
[2025-05-07T23:34:27.329+0000] {job.py:213} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.20.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 184, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.20.0.3), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-05-07T23:34:34.648+0000] {local_task_job_runner.py:202} ERROR - Heartbeat time limit exceeded!
[2025-05-07T23:34:34.700+0000] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 13052. PIDs of all processes in the group: [13053, 13100, 13052]
[2025-05-07T23:34:34.701+0000] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 13052
[2025-05-07T23:34:34.701+0000] {taskinstance.py:1517} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-05-07T23:34:34.702+0000] {spark_submit.py:697} INFO - Sending kill signal to spark-submit
[2025-05-07T23:34:35.074+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=13100, status='terminated', started='23:14:46') (13100) terminated with exit code None
[2025-05-07T23:34:35.179+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 174, in execute
    self._hook.submit(self.application)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 490, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 539, in _process_spark_submit_log
    for line in itr:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1519, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2025-05-07T23:34:35.220+0000] {taskinstance.py:1345} INFO - Marking task as UP_FOR_RETRY. dag_id=graph_analysis, task_id=build_graph, execution_date=20250507T231436, start_date=20250507T231445, end_date=20250507T233435
[2025-05-07T23:34:35.302+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 293 for task build_graph (Task received SIGTERM signal; 13052)
[2025-05-07T23:34:35.326+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=13053, status='terminated', started='23:14:44') (13053) terminated with exit code None
[2025-05-07T23:34:35.327+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=13052, status='terminated', exitcode=1, started='23:14:44') (13052) terminated with exit code 1
